{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c22289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium\n",
    "# !pip install webdriver-manager\n",
    "# View your Google Chrome browser version: chrome://settings/help\n",
    "# Download ChromeDriver that corresponds to your Google Chrome browser version: https://sites.google.com/chromium.org/driver/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f511dc19",
   "metadata": {},
   "source": [
    "Useful links:\n",
    "https://stackoverflow.com/questions/69875125/find-element-by-commands-are-deprecated-in-selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551a1ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba1211f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROME_DRIVER_PATH = \"C:/Users/ernes/Downloads/chromedriver_win32/chromedriver.exe\"\n",
    "DATA_WRITE_PATH = \"C:/Users/ernes/Git/dsa3101-2220-12-ds/Backend/Data/jobs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc58f5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = Service(CHROME_DRIVER_PATH)\n",
    "op = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=ser, options=op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060faff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '\"data analyst\"'\n",
    "save_file_name = \"data_analyst\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c82a01",
   "metadata": {},
   "source": [
    "# JobStreet Scraping for URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148aca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "website = \"https://www.jobstreet.com.sg/\"\n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding search bar\n",
    "search = driver.find_element(By.ID, \"searchKeywordsField\")\n",
    "\n",
    "# Remove all words in search bar\n",
    "search.send_keys(Keys.CONTROL + \"a\")\n",
    "search.send_keys(Keys.DELETE)\n",
    "\n",
    "# Send query\n",
    "search.send_keys(query)\n",
    "search.send_keys(Keys.RETURN)\n",
    "\n",
    "# Waiting for 10 seconds after sending keys to search bar\n",
    "try:\n",
    "    # Finding element by XPATH and class attribute since div class names are dynamic\n",
    "    jobs = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//*[@data-automation='jobListing']\"))\n",
    "    )\n",
    "    \n",
    "except:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bceee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page_url = []\n",
    "visited = []\n",
    "queue = [driver.current_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25058752",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "all_jobs_links = []\n",
    "while len(queue) > 0: # REVISE\n",
    "    \n",
    "    # Visiting all pages\n",
    "    \n",
    "    # Dequeue next URL\n",
    "    next_url = queue[-1]\n",
    "    queue = queue[:-1]\n",
    "    visited.append(next_url)\n",
    "    print(f\"Visiting {next_url}\")\n",
    "    driver.get(next_url)\n",
    "    \n",
    "    # Waiting for 10 seconds after sending keys to search bar\n",
    "    try:\n",
    "        # Finding element by XPATH and class attribute since div class names are dynamic\n",
    "        jobs = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//*[@data-automation='jobListing']\"))\n",
    "        )\n",
    "        \n",
    "        # Getting the job postings on the page\n",
    "        jobs_list = jobs.find_elements(By.XPATH, \"./*\")[:-2] # The last two results are invalid\n",
    "\n",
    "        # Getting the links for each job posting\n",
    "        jobs_links_found = [job.find_element(By.TAG_NAME, \"h1\").find_element(By.XPATH, \"a[@href]\").get_attribute(\"href\") for job in jobs_list]\n",
    "        all_jobs_links.extend(jobs_links_found)\n",
    "        \n",
    "    except:\n",
    "        print(f\"FAILED: {next_url}\")\n",
    "        driver.quit()\n",
    "    \n",
    "    # Finding new URLs\n",
    "    next_page_url = [page.get_attribute(\"href\") for page in driver.find_element(By.XPATH, \"//*[@data-automation='pagination']\").find_elements(By.XPATH, \"a[@href]\")]\n",
    "    for url in next_page_url:\n",
    "        if url not in visited:\n",
    "            queue.append(url)\n",
    "            \n",
    "print(f\"Job completed in {round(time.time() - start_time)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff3df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(all_jobs_links)} job sites found\")\n",
    "print(all_jobs_links[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5715479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_WRITE_PATH + f'jobstreet_job_url_query-{save_file_name}.txt', 'w') as f:\n",
    "    for url in all_jobs_links:\n",
    "        f.write(url)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fe14c6",
   "metadata": {},
   "source": [
    "## Scraping Job Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e669b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_WRITE_PATH + f'jobstreet_job_url_query-{save_file_name}.txt') as file:\n",
    "    all_jobs_links = [line.rstrip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c91cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANR = re.compile('<.*?>') \n",
    "def cleanhtml(raw_html):\n",
    "    clean_text = re.sub(CLEANR, ' ', raw_html)\n",
    "    clean_text = re.sub(\"&nbsp;\", \" \", clean_text)\n",
    "    clean_text = re.sub('\\s+', \" \", clean_text)\n",
    "    if clean_text[0] == \" \":\n",
    "        clean_text = clean_text[1:]\n",
    "    if clean_text[-1] == \" \":\n",
    "        clean_text = clean_text[:-1]\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ffbad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = []\n",
    "job_employers = []\n",
    "job_descriptions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c1dfb11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 540/540 [11:03<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.trange(len(all_jobs_links)):\n",
    "    driver.get(all_jobs_links[i])\n",
    "    \n",
    "    # Getting job title & employer details\n",
    "    title_element = driver.find_element(By.XPATH, \"//*[@data-automation='detailsTitle']\")\n",
    "    while len(title_element.find_elements(By.XPATH, \"./*\")) == 1:\n",
    "        title_element = title_element.find_element(By.XPATH, \"./*\")\n",
    "        \n",
    "    job_title, job_employer = [cleanhtml(title_element.find_elements(By.XPATH, \"./*\")[i].get_attribute('outerHTML')) for i in range(len(title_element.find_elements(By.XPATH, \"./*\")))]\n",
    "    \n",
    "    # Getting job description\n",
    "    description_element = driver.find_element(By.XPATH, \"//*[@data-automation='jobDescription']\")\n",
    "    html = description_element.get_attribute(\"outerHTML\")\n",
    "    job_description = cleanhtml(html)\n",
    "    \n",
    "    # Recording results\n",
    "    job_titles.append(job_title)\n",
    "    job_employers.append(job_employer)\n",
    "    job_descriptions.append(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a22f665",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd1d9315",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df = pd.DataFrame([job_titles, job_employers, job_descriptions, all_jobs_links]).\\\n",
    "                transpose().\\\n",
    "                rename(columns = {0 : \"Title\",\n",
    "                                  1 : \"Company\",\n",
    "                                  2 : \"Description\",\n",
    "                                  3 : \"URL\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6b20397",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.to_csv(DATA_WRITE_PATH + f\"jobstreet_query-{save_file_name}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
