{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1193756c",
   "metadata": {},
   "source": [
    "Output dataset must have the following format:\n",
    "\n",
    "[[‘Who is Shaka Khan?’, {‘entities’: [[7, 17, ‘PERSON’]]}],\n",
    " [‘I like London and Berlin.’,\n",
    "  {‘entities’: [[7, 13, ‘LOC’], [18, 24, ‘LOC’]]}]]\n",
    "  \n",
    "  \n",
    "#### Credits: \n",
    "\n",
    "https://www.youtube.com/watch?v=YLQvVpCXpbU&ab_channel=PradipNichite\n",
    "\n",
    "https://spacy.io/usage/training#quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bef35d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "doc_bin = DocBin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e15f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:/Users/ernes/Git/dsa3101-2220-12-ds/Backend/Data/skills/lightcast_skills_queries-data_analysis_machine learning_ML_statistic.csv'\n",
    "skills = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fb54290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_start_index(skill, description):\n",
    "    return [n for n in range(len(description)) if description.lower().find(skill.lower(), n) == n]\n",
    "\n",
    "def find_end_index(skill, description):\n",
    "    start_indices = find_start_index(skill, description)\n",
    "    skill_length = len(skill)\n",
    "    end_indices = [ind + skill_length for ind in start_indices]\n",
    "    return end_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e17938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the first and last indexes of each skill in their skill description\n",
    "skills['start_ind'] = skills.apply(lambda x: find_start_index(x.Skill, x.Skill_Description), axis=1)\n",
    "skills['end_ind'] = skills.apply(lambda x: find_end_index(x.Skill, x.Skill_Description), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fda02ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_formatted_for_spacy = []\n",
    "for ind, row in skills.iterrows():\n",
    "    query, skill, description, start_ind_list, end_ind_list = row\n",
    "    start_ind_list = start_ind_list\n",
    "    end_ind_list = end_ind_list\n",
    "    entities = []\n",
    "    for i in range(len(start_ind_list)):\n",
    "        start_ind = int(start_ind_list[i])\n",
    "        end_ind = int(end_ind_list[i])\n",
    "        entities.append([start_ind, end_ind, 'TECHNICAL_SKILL'])\n",
    "    skills_formatted_for_spacy.append([description, {'entities': entities}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b03a799e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 487/487 [00:00<00:00, 1305.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity: Datagram\n",
      "Skipping entity: Datagram\n",
      "Skipping entity: datagram\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for training_example in tqdm(skills_formatted_for_spacy): \n",
    "    text = training_example[0]\n",
    "    labels = training_example[1]\n",
    "    doc = nlp.make_doc(text)\n",
    "    ents = []\n",
    "    for k, entities in labels.items():\n",
    "        for entity in entities:\n",
    "            start, end, label = entity\n",
    "            #print(start, end, label)\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print(f\"Skipping entity: {str(doc)[start:end]}\")\n",
    "            else:\n",
    "                #print(f\"Added entity: {str(doc)[start:end]}\")\n",
    "                ents.append(span)\n",
    "    filtered_ents = filter_spans(ents)\n",
    "    doc.ents = filtered_ents \n",
    "    doc_bin.add(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee1491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this line ONLY if you want to save it to your disk\n",
    "# doc_bin.to_disk(\"train.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42982c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e26b113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
