{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1193756c",
   "metadata": {},
   "source": [
    "Output dataset must have the following format:\n",
    "\n",
    "[[‘Who is Shaka Khan?’, {‘entities’: [[7, 17, ‘PERSON’]]}],\n",
    " [‘I like London and Berlin.’,\n",
    "  {‘entities’: [[7, 13, ‘LOC’], [18, 24, ‘LOC’]]}]]\n",
    "  \n",
    "  \n",
    "#### Credits: \n",
    "\n",
    "https://dfelo93.medium.com/how-to-train-a-spacy-model-for-ner-cc8f964372ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bef35d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "from spacy.util import filter_spans\n",
    "import re\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "doc_bin = DocBin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4634dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEPT_LABELS = [\"Data_Structure\", \"Application\", \"Language\", \"Library\", \"Operating_System\", \"Algorithm\"]\n",
    "DATASETS = [\"train\", \"test\", \"dev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a570b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in DATASETS:\n",
    "    all_labels = []\n",
    "    with open(f\"./../../Data/NER_annotated_data/StackOverflow/{dataset}.txt\", \"r\", encoding = \"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line == \"\\n\":\n",
    "                continue\n",
    "            word, man_label, comp_label = line.split(\"\\t\")\n",
    "            man_label = man_label.strip()\n",
    "            comp_label = comp_label.strip()\n",
    "            if man_label != 'O':\n",
    "                man_label = man_label.split(\"-\")[1]\n",
    "            if comp_label != 'O':\n",
    "                comp_label = comp_label.split(\"-\")[1]\n",
    "\n",
    "            if man_label != \"O\" and man_label not in all_labels:\n",
    "                all_labels.append(man_label)\n",
    "            if comp_label != \"O\" and comp_label not in all_labels:\n",
    "                all_labels.append(comp_label)\n",
    "\n",
    "    with open(f\"./../../Data/NER_annotated_data/StackOverflow/{dataset}.txt\", \"r\", encoding = \"utf-8\") as f:\n",
    "        file = f.read()\n",
    "\n",
    "    for label in all_labels:\n",
    "        if label in KEPT_LABELS:\n",
    "            file = re.sub(f'B-{label}', 'B-Skill', file)\n",
    "            file = re.sub(f'I-{label}', 'I-Skill', file)\n",
    "        else:\n",
    "            file = re.sub(f'B-{label}', 'O', file)\n",
    "            file = re.sub(f'I-{label}', 'O', file)\n",
    "\n",
    "    with open(f\"./../../Data/NER_annotated_data/StackOverflow/{dataset}2.txt\", \"w\", encoding = \"utf-8\") as f:\n",
    "        f.write(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e891fca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m[i] Auto-detected token-per-line NER format\u001b[0m\n",
      "\u001b[38;5;4m[i] Grouping every 10 sentences into a document.\u001b[0m\n",
      "\u001b[38;5;2m[+] Generated output file (1 documents):\n",
      "..\\..\\Data\\NER_annotated_data\\StackOverflow\\train2.json\u001b[0m\n",
      "\u001b[38;5;4m[i] Auto-detected token-per-line NER format\u001b[0m\n",
      "\u001b[38;5;4m[i] Grouping every 10 sentences into a document.\u001b[0m\n",
      "\u001b[38;5;2m[+] Generated output file (1 documents):\n",
      "..\\..\\Data\\NER_annotated_data\\StackOverflow\\test2.json\u001b[0m\n",
      "\u001b[38;5;4m[i] Auto-detected token-per-line NER format\u001b[0m\n",
      "\u001b[38;5;4m[i] Grouping every 10 sentences into a document.\u001b[0m\n",
      "\u001b[38;5;2m[+] Generated output file (1 documents):\n",
      "..\\..\\Data\\NER_annotated_data\\StackOverflow\\dev2.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy convert \"./../../Data/NER_annotated_data/StackOverflow/train2.txt\" \"./../../Data/NER_annotated_data/StackOverflow/\" -t json -n 10 -c iob\n",
    "!python -m spacy convert \"./../../Data/NER_annotated_data/StackOverflow/test2.txt\" \"./../../Data/NER_annotated_data/StackOverflow/\" -t json -n 10 -c iob\n",
    "!python -m spacy convert \"./../../Data/NER_annotated_data/StackOverflow/dev2.txt\" \"./../../Data/NER_annotated_data/StackOverflow/\" -t json -n 10 -c iob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e58f9812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[+] Generated output file (927 documents):\n",
      "..\\..\\Data\\NER_annotated_data\\StackOverflow\\train2.spacy\u001b[0m\n",
      "\u001b[38;5;2m[+] Generated output file (311 documents):\n",
      "..\\..\\Data\\NER_annotated_data\\StackOverflow\\test2.spacy\u001b[0m\n",
      "\u001b[38;5;2m[+] Generated output file (294 documents):\n",
      "..\\..\\Data\\NER_annotated_data\\StackOverflow\\dev2.spacy\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy convert \"./../../Data/NER_annotated_data/StackOverflow/train2.json\" \"./../../Data/NER_annotated_data/StackOverflow/\" -t spacy\n",
    "!python -m spacy convert \"./../../Data/NER_annotated_data/StackOverflow/test2.json\" \"./../../Data/NER_annotated_data/StackOverflow/\" -t spacy\n",
    "!python -m spacy convert \"./../../Data/NER_annotated_data/StackOverflow/dev2.json\" \"./../../Data/NER_annotated_data/StackOverflow/\" -t spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42982c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy convert \"./../../Data/NER_annotated_data/StackOverflow/train.txt\" \"./../../Data/NER_annotated_data/StackOverflow/\" -t json -n 10 -c iob\n",
    "!python -m spacy convert \"./../../Data/NER_annotated_data/StackOverflow/test.txt\" \"./../../Data/NER_annotated_data/StackOverflow/\" -t json -n 10 -c iob\n",
    "!python -m spacy convert \"./../../Data/NER_annotated_data/StackOverflow/dev.txt\" \"./../../Data/NER_annotated_data/StackOverflow/\" -t json -n 10 -c iob\n",
    "!python -m spacy convert \"./../../Data/NER_annotated_data/GitHub/gh_test.txt\" \"./../../Data/NER_annotated_data/GitHub/\" -t json -n 10 -c iob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e26b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy convert \"./../../Data/NER_annotated_data/StackOverflow/train.json\" \"./../../Data/NER_annotated_data/StackOverflow/\" -t spacy\n",
    "!python -m spacy convert \"./../../Data/NER_annotated_data/StackOverflow/test.json\" \"./../../Data/NER_annotated_data/StackOverflow/\" -t spacy\n",
    "!python -m spacy convert \"./../../Data/NER_annotated_data/StackOverflow/dev.json\" \"./../../Data/NER_annotated_data/StackOverflow/\" -t spacy\n",
    "!python -m spacy convert \"./../../Data/NER_annotated_data/GitHub/gh_test.json\" \"./../../Data/NER_annotated_data/GitHub/\" -t spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0402559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
