{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b2e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this line to rewrite config file. DO NOT RUN\n",
    "#!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1efcfb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this line to retrain spacy model. Will take hours\n",
    "# !python -m spacy train config.cfg --output ./ --paths.train ./train.spacy --paths.dev ./train.spacy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a232fe2",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f3be271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25fc7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_ner = spacy.load(\"model-best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d9985",
   "metadata": {},
   "source": [
    "#### The following document was in the training data, with 'exploratory data analysis' as the entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a065aa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>In statistics, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    exploratory data analysis\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECHNICAL_SKILL</span>\n",
       "</mark>\n",
       " is an approach to analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Exploratory data analysis\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECHNICAL_SKILL</span>\n",
       "</mark>\n",
       " was promoted by John Tukey to encourage statisticians to explore the data, and possibly formulate hypotheses that could lead to new data collection and experiments. EDA is different from initial data analysis (IDA), which focuses more narrowly on checking assumptions required for model fitting and hypothesis testing, and handling missing values and making transformations of variables as needed. EDA encompasses IDA.</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp_ner(\n",
    "'''\n",
    "In statistics, exploratory data analysis is an approach to analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task. Exploratory data analysis was promoted by John Tukey to encourage statisticians to explore the data, and possibly formulate hypotheses that could lead to new data collection and experiments. EDA is different from initial data analysis (IDA), which focuses more narrowly on checking assumptions required for model fitting and hypothesis testing, and handling missing values and making transformations of variables as needed. EDA encompasses IDA.\n",
    "'''\n",
    ")\n",
    "spacy.displacy.render(doc, style = 'ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d5c0a",
   "metadata": {},
   "source": [
    "#### The below few documents are not in the training data. Model performs extremely poorly. May need better labelling of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c8c383c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ernes\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\displacy\\__init__.py:211: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>A datagram is a basic transfer unit associated with a packet-switched network. Datagrams are typically structured in header and payload sections. Datagrams provide a connectionless communication service across a packet-switched network. The delivery, arrival time, and order of arrival of datagrams need not be guaranteed by the network.</br>    </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp_ner(\n",
    "    \"\"\"\n",
    "A datagram is a basic transfer unit associated with a packet-switched network. Datagrams are typically structured in header and payload sections. Datagrams provide a connectionless communication service across a packet-switched network. The delivery, arrival time, and order of arrival of datagrams need not be guaranteed by the network.\n",
    "    \"\"\")\n",
    "spacy.displacy.render(doc, style='ent', jupyter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee39c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Data killmyself\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECHNICAL_SKILL</span>\n",
       "</mark>\n",
       " is a fictional skill lmao I am a stupid model.</br>    </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp_ner(\n",
    "    \"\"\"\n",
    "Data killmyself is a fictional skill lmao I am a stupid model.\n",
    "    \"\"\")\n",
    "spacy.displacy.render(doc, style='ent', jupyter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ebaccd",
   "metadata": {},
   "source": [
    "#### Taken from https://www.linkedin.com/jobs/collections/recommended/?currentJobId=3505458887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f87a61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>What a College Intern - Data Science does at HP:</br>Attached to the &quot;Smart Manufacturing Application and Research Center&quot;.</br>Work with an enterprising team of data scientists and build solutions to track, analyze and visualize the manufacturing and outbound quality of our supplies.</br>Generate deep insights through the analysis of data and understanding of operational processes and turn them into actionable recommendations.</br>Develop methodologies for optimizing our business processes through data visualization, real-time monitoring, predictive analytics etc.</br>Are you a high-performer? We are looking for an individual with:</br>Studying Bachelor’s degree in Computer Science, Business Analytics, Information Systems, Industrial Engineering, Statistics with good experience in programming.</br>Excellent analytical thinking, programming (using R/Python is desirable), and problem-solving skills.</br>Knowledge of data analytics, data warehousing, database management (preferably using SQL) and data visualization using RShiny/Plotly.</br>Fundamental knowledge of statistics and probability.</br>Good visualization skills to create real-time dashboards and/or reports to inform trends and insights.</br>Able to commit for 6 Months.</br>    </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp_ner(\n",
    "    \"\"\"\n",
    "What a College Intern - Data Science does at HP:\n",
    "Attached to the \"Smart Manufacturing Application and Research Center\".\n",
    "Work with an enterprising team of data scientists and build solutions to track, analyze and visualize the manufacturing and outbound quality of our supplies.\n",
    "Generate deep insights through the analysis of data and understanding of operational processes and turn them into actionable recommendations.\n",
    "Develop methodologies for optimizing our business processes through data visualization, real-time monitoring, predictive analytics etc.\n",
    "Are you a high-performer? We are looking for an individual with:\n",
    "Studying Bachelor’s degree in Computer Science, Business Analytics, Information Systems, Industrial Engineering, Statistics with good experience in programming.\n",
    "Excellent analytical thinking, programming (using R/Python is desirable), and problem-solving skills.\n",
    "Knowledge of data analytics, data warehousing, database management (preferably using SQL) and data visualization using RShiny/Plotly.\n",
    "Fundamental knowledge of statistics and probability.\n",
    "Good visualization skills to create real-time dashboards and/or reports to inform trends and insights.\n",
    "Able to commit for 6 Months.\n",
    "    \"\"\")\n",
    "spacy.displacy.render(doc, style='ent', jupyter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd76b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
