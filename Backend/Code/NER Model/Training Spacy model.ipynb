{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b2e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this line to rewrite config file. DO NOT RUN\n",
    "#!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3be271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f11110",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACY_WORD_VECTORS_PATH = \"./Models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7130b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(SPACY_WORD_VECTORS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90bc5bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.add_pipe(\"ner\")\n",
    "# nlp.to_disk(\"./Models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1efcfb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m[i] Saving to output directory: .\u001b[0m\n",
      "\u001b[38;5;4m[i] Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m[+] Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4m[i] Pipeline: ['ner']\u001b[0m\n",
      "\u001b[38;5;4m[i] Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  --------  ------  ------  ------  ------\n",
      "  0       0    115.93    0.00    0.00    0.00    0.00\n",
      "  0     200   5683.82    7.61   19.30    4.74    0.08\n",
      "  0     400   3953.75   19.73   40.62   13.03    0.20\n",
      "  0     600   3571.21   26.33   41.09   19.37    0.26\n",
      "  0     800   3094.94   32.03   41.39   26.12    0.32\n",
      "  1    1000   3293.09   34.98   50.10   26.87    0.35\n",
      "  1    1200   3097.46   37.61   47.77   31.01    0.38\n",
      "  1    1400   3515.81   41.66   49.15   36.15    0.42\n",
      "  1    1600   4655.86   43.18   55.06   35.51    0.43\n",
      "  2    1800   5587.55   44.65   49.58   40.62    0.45\n",
      "  3    2000   6402.50   47.02   57.68   39.68    0.47\n",
      "  3    2200   6860.41   48.22   58.54   41.00    0.48\n",
      "  4    2400   8412.15   48.89   55.82   43.48    0.49\n",
      "  5    2600   9222.53   49.69   58.29   43.30    0.50\n",
      "  7    2800   8633.62   49.90   55.99   45.01    0.50\n",
      "  8    3000   7718.86   48.04   54.84   42.73    0.48\n",
      "  9    3200   7437.77   49.59   54.15   45.73    0.50\n",
      " 11    3400   6697.10   49.57   55.07   45.06    0.50\n",
      " 12    3600   5884.67   48.99   52.99   45.54    0.49\n",
      " 13    3800   5581.13   49.11   52.23   46.35    0.49\n",
      " 14    4000   5274.59   48.22   54.62   43.16    0.48\n",
      " 16    4200   4848.53   49.54   54.46   45.44    0.50\n",
      " 17    4400   4533.61   49.25   55.77   44.10    0.49\n",
      "\u001b[38;5;2m[+] Saved pipeline to output directory\u001b[0m\n",
      "model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-22 14:24:52,265] [INFO] Set up nlp object from config\n",
      "[2023-03-22 14:24:52,287] [INFO] Pipeline: ['ner']\n",
      "[2023-03-22 14:24:52,294] [INFO] Created vocabulary\n",
      "[2023-03-22 14:24:52,932] [INFO] Added vectors: ./Models/\n",
      "[2023-03-22 14:24:52,938] [INFO] Finished initializing nlp object\n",
      "[2023-03-22 14:24:57,299] [INFO] Initialized pipeline components: ['ner']\n"
     ]
    }
   ],
   "source": [
    "# Run this line to retrain spacy model. Will take hours\n",
    "!python -m spacy train ./Models/config.cfg --output . --paths.train ../../Data/NER_annotated_data/StackOverflow/train.spacy --paths.dev ../../Data/NER_annotated_data/StackOverflow/dev.spacy --paths.vectors ./Models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a98c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy train ./Models/config.cfg --output . --paths.train ../../Data/NER_annotated_data/Job_Mod_Descriptions/mod_annotations.spacy --paths.dev ../../Data/NER_annotated_data/ChatGPT/annotations.spacy --paths.vectors ./Models/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a232fe2",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fc7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_ner = spacy.load(\"model-best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d9985",
   "metadata": {},
   "source": [
    "#### The following document was in the training data, with 'exploratory data analysis' as the entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a065aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp_ner(\n",
    "'''\n",
    "In statistics, exploratory data analysis is an approach to analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task. Exploratory data analysis was promoted by John Tukey to encourage statisticians to explore the data, and possibly formulate hypotheses that could lead to new data collection and experiments. EDA is different from initial data analysis (IDA), which focuses more narrowly on checking assumptions required for model fitting and hypothesis testing, and handling missing values and making transformations of variables as needed. EDA encompasses IDA.\n",
    "'''\n",
    ")\n",
    "spacy.displacy.render(doc, style = 'ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d5c0a",
   "metadata": {},
   "source": [
    "#### The below few documents are not in the training data. Model performs extremely poorly. May need better labelling of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp_ner(\n",
    "    \"\"\"\n",
    "A datagram is a basic transfer unit associated with a packet-switched network. Datagrams are typically structured in header and payload sections. Datagrams provide a connectionless communication service across a packet-switched network. The delivery, arrival time, and order of arrival of datagrams need not be guaranteed by the network.\n",
    "    \"\"\")\n",
    "spacy.displacy.render(doc, style='ent', jupyter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee39c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp_ner(\n",
    "    \"\"\"\n",
    "Data killmyself is a fictional skill lmao I am a stupid model.\n",
    "    \"\"\")\n",
    "spacy.displacy.render(doc, style='ent', jupyter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ebaccd",
   "metadata": {},
   "source": [
    "#### Taken from https://www.linkedin.com/jobs/collections/recommended/?currentJobId=3505458887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f87a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp_ner(\n",
    "    \"\"\"\n",
    "What a College Intern - Data Science does at HP:\n",
    "Attached to the \"Smart Manufacturing Application and Research Center\".\n",
    "Work with an enterprising team of data scientists and build solutions to track, analyze and visualize the manufacturing and outbound quality of our supplies.\n",
    "Generate deep insights through the analysis of data and understanding of operational processes and turn them into actionable recommendations.\n",
    "Develop methodologies for optimizing our business processes through data visualization, real-time monitoring, predictive analytics etc.\n",
    "Are you a high-performer? We are looking for an individual with:\n",
    "Studying Bachelorâ€™s degree in Computer Science, Business Analytics, Information Systems, Industrial Engineering, Statistics with good experience in programming.\n",
    "Excellent analytical thinking, programming (using R/Python is desirable), and problem-solving skills.\n",
    "Knowledge of data analytics, data warehousing, database management (preferably using SQL) and data visualization using RShiny and Plotly.\n",
    "Fundamental knowledge of statistics and probability.\n",
    "Good visualization skills to create real-time dashboards and/or reports to inform trends and insights.\n",
    "Able to commit for 6 Months.\n",
    "    \"\"\")\n",
    "spacy.displacy.render(doc, style='ent', jupyter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd76b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp_ner(\n",
    "    \"\"\"\n",
    "This module focuses on the classical theory and methods of multivariate statistical analysis. Topics include distribution theory multivariate normal distribution, Hotelling's T2 and Wishart distributions, inference on the mean and covariance, principal components and canonical correlation, factor analysis, discrimination and classification. This module is targeted at students who are interested in Statistics, are able to meet the pre-requisites and are matriculated in or after 2002.\n",
    "    \"\"\")\n",
    "spacy.displacy.render(doc, style='ent', jupyter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c8f5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
