{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b2e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this line to rewrite config file. DO NOT RUN\n",
    "#!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f3be271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d504a7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACY_WORD_VECTORS_PATH = \"./Models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7e78fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(SPACY_WORD_VECTORS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28eedbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(\"ner\")\n",
    "nlp.to_disk(\"./Models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1efcfb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m[i] Saving to output directory: .\u001b[0m\n",
      "\u001b[38;5;4m[i] Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m[+] Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4m[i] Pipeline: ['ner']\u001b[0m\n",
      "\u001b[38;5;4m[i] Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  --------  ------  ------  ------  ------\n",
      "  0       0    115.93    0.00    0.00    0.00    0.00\n",
      "  0     200   5683.82    7.61   19.30    4.74    0.08\n",
      "  0     400   3953.75   19.73   40.62   13.03    0.20\n",
      "  0     600   3571.21   26.33   41.09   19.37    0.26\n",
      "  0     800   3094.94   32.03   41.39   26.12    0.32\n",
      "  1    1000   3293.09   34.98   50.10   26.87    0.35\n",
      "  1    1200   3097.46   37.61   47.77   31.01    0.38\n",
      "  1    1400   3515.81   41.66   49.15   36.15    0.42\n",
      "  1    1600   4655.86   43.18   55.06   35.51    0.43\n",
      "  2    1800   5587.55   44.65   49.58   40.62    0.45\n",
      "  3    2000   6402.50   47.02   57.68   39.68    0.47\n",
      "  3    2200   6860.41   48.22   58.54   41.00    0.48\n",
      "  4    2400   8412.15   48.89   55.82   43.48    0.49\n",
      "  5    2600   9222.53   49.69   58.29   43.30    0.50\n",
      "  7    2800   8633.62   49.90   55.99   45.01    0.50\n",
      "  8    3000   7718.86   48.04   54.84   42.73    0.48\n",
      "  9    3200   7437.77   49.59   54.15   45.73    0.50\n",
      " 11    3400   6697.10   49.57   55.07   45.06    0.50\n",
      " 12    3600   5884.67   48.99   52.99   45.54    0.49\n",
      " 13    3800   5581.13   49.11   52.23   46.35    0.49\n",
      " 14    4000   5274.59   48.22   54.62   43.16    0.48\n",
      " 16    4200   4848.53   49.54   54.46   45.44    0.50\n",
      " 17    4400   4533.61   49.25   55.77   44.10    0.49\n",
      "\u001b[38;5;2m[+] Saved pipeline to output directory\u001b[0m\n",
      "model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-22 14:24:52,265] [INFO] Set up nlp object from config\n",
      "[2023-03-22 14:24:52,287] [INFO] Pipeline: ['ner']\n",
      "[2023-03-22 14:24:52,294] [INFO] Created vocabulary\n",
      "[2023-03-22 14:24:52,932] [INFO] Added vectors: ./Models/\n",
      "[2023-03-22 14:24:52,938] [INFO] Finished initializing nlp object\n",
      "[2023-03-22 14:24:57,299] [INFO] Initialized pipeline components: ['ner']\n"
     ]
    }
   ],
   "source": [
    "# Run this line to retrain spacy model. Will take hours\n",
    "!python -m spacy train ./Models/config.cfg --output . --paths.train ../../Data/NER_annotated_data/StackOverflow/train.spacy --paths.dev ../../Data/NER_annotated_data/StackOverflow/dev.spacy --paths.vectors ./Models/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a232fe2",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25fc7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_ner = spacy.load(\"model-best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d9985",
   "metadata": {},
   "source": [
    "#### The following document was in the training data, with 'exploratory data analysis' as the entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a065aa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>In statistics, exploratory data analysis is an approach to analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task. Exploratory data analysis was promoted by \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    John\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">User_Name</span>\n",
       "</mark>\n",
       " Tukey to encourage statisticians to explore the data, and possibly formulate hypotheses that could lead to new data collection and experiments. EDA is different from initial data analysis (IDA), which focuses more narrowly on checking assumptions required for model fitting and hypothesis testing, and handling missing values and making transformations of variables as needed. EDA encompasses IDA.</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp_ner(\n",
    "'''\n",
    "In statistics, exploratory data analysis is an approach to analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task. Exploratory data analysis was promoted by John Tukey to encourage statisticians to explore the data, and possibly formulate hypotheses that could lead to new data collection and experiments. EDA is different from initial data analysis (IDA), which focuses more narrowly on checking assumptions required for model fitting and hypothesis testing, and handling missing values and making transformations of variables as needed. EDA encompasses IDA.\n",
    "'''\n",
    ")\n",
    "spacy.displacy.render(doc, style = 'ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d5c0a",
   "metadata": {},
   "source": [
    "#### The below few documents are not in the training data. Model performs extremely poorly. May need better labelling of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c8c383c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>A datagram is a basic transfer unit associated with a packet-switched network. Datagrams are typically structured in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    header\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">User_Interface_Element</span>\n",
       "</mark>\n",
       " and payload sections. Datagrams provide a connectionless communication service across a packet-switched network. The delivery, arrival time, and order of arrival of datagrams need not be guaranteed by the network.</br>    </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp_ner(\n",
    "    \"\"\"\n",
    "A datagram is a basic transfer unit associated with a packet-switched network. Datagrams are typically structured in header and payload sections. Datagrams provide a connectionless communication service across a packet-switched network. The delivery, arrival time, and order of arrival of datagrams need not be guaranteed by the network.\n",
    "    \"\"\")\n",
    "spacy.displacy.render(doc, style='ent', jupyter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dee39c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ernest.liu\\Anaconda3\\lib\\site-packages\\spacy\\displacy\\__init__.py:211: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>Data killmyself is a fictional skill lmao I am a stupid model.</br>    </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp_ner(\n",
    "    \"\"\"\n",
    "Data killmyself is a fictional skill lmao I am a stupid model.\n",
    "    \"\"\")\n",
    "spacy.displacy.render(doc, style='ent', jupyter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ebaccd",
   "metadata": {},
   "source": [
    "#### Taken from https://www.linkedin.com/jobs/collections/recommended/?currentJobId=3505458887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f87a61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>What a College \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Intern - Data Science\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Application</span>\n",
       "</mark>\n",
       " does at HP:</br>Attached to the &quot;Smart Manufacturing Application and Research Center&quot;.</br>Work with an enterprising team of data scientists and build solutions to track, analyze and visualize the manufacturing and outbound quality of our supplies.</br>Generate deep insights through the analysis of data and understanding of operational processes and turn them into actionable recommendations.</br>Develop methodologies for optimizing our business processes through data visualization, real-time monitoring, predictive analytics etc.</br>Are you a high-performer? We are looking for an individual with:</br>Studying Bachelor’s degree in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Computer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Device</span>\n",
       "</mark>\n",
       " Science, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Business\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Variable</span>\n",
       "</mark>\n",
       " Analytics, Information Systems, Industrial Engineering, Statistics with good experience in programming.</br>Excellent analytical thinking, programming (using \n",
       "<mark class=\"entity\" style=\"background: #ff8197; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    R/\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Language</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ff8197; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Language</span>\n",
       "</mark>\n",
       " is desirable), and problem-solving skills.</br>Knowledge of data analytics, data warehousing, database management (preferably using \n",
       "<mark class=\"entity\" style=\"background: #ff8197; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SQL\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Language</span>\n",
       "</mark>\n",
       ") and data visualization using \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    RShiny/Plotly.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">File_Name</span>\n",
       "</mark>\n",
       "</br>Fundamental knowledge of statistics and probability.</br>Good visualization skills to create real-time dashboards and/or reports to inform trends and insights.</br>Able to commit for 6 Months.</br>    </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp_ner(\n",
    "    \"\"\"\n",
    "What a College Intern - Data Science does at HP:\n",
    "Attached to the \"Smart Manufacturing Application and Research Center\".\n",
    "Work with an enterprising team of data scientists and build solutions to track, analyze and visualize the manufacturing and outbound quality of our supplies.\n",
    "Generate deep insights through the analysis of data and understanding of operational processes and turn them into actionable recommendations.\n",
    "Develop methodologies for optimizing our business processes through data visualization, real-time monitoring, predictive analytics etc.\n",
    "Are you a high-performer? We are looking for an individual with:\n",
    "Studying Bachelor’s degree in Computer Science, Business Analytics, Information Systems, Industrial Engineering, Statistics with good experience in programming.\n",
    "Excellent analytical thinking, programming (using R/Python is desirable), and problem-solving skills.\n",
    "Knowledge of data analytics, data warehousing, database management (preferably using SQL) and data visualization using RShiny/Plotly.\n",
    "Fundamental knowledge of statistics and probability.\n",
    "Good visualization skills to create real-time dashboards and/or reports to inform trends and insights.\n",
    "Able to commit for 6 Months.\n",
    "    \"\"\")\n",
    "spacy.displacy.render(doc, style='ent', jupyter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd76b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
