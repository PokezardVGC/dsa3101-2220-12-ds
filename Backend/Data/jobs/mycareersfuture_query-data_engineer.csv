,Title,Company,Description,URL
0,Data Engineer with AWS,MICHAEL PAGE INTERNATIONAL PTE LTD,"Creative and Innovative Workplace
Opportunity to learn and grow
About Our Client
Our esteemed client is one of the well-known, well-established brands in the insurance domain. They bagged two more awards last year cementing their position as a leaders in Singapore ! With customers at the heart of what they do, they are shifting from being an insurance company to being a technology-empowered, financial services partner for their customers!
Job Description
Development of new data management layers and build data processes
Solutioning and tech designing for Data Systems
Tech lead to drive data engineering activities
Provide support for enhancements and any BAU issues on the new data management layers and existing data lakes
Support and migration of existing on-premises databases to AWS cloud.
Understanding the existing applications, data architecture, and suggest improvements
Lead business requirements and plan deliveries
Handle data extractions and data analysis for the requirements
The Successful Applicant
Atleast 10 years of experience with Information Technology using RDBMS and Non-RDBMS and Cloud databases
Atleast 8 years of strong hands-on experience on any of the databases like SQL/PLSQL, Oracle, MS-SQL server, Postgres, and Snowflake
Atleast 3 years of strong experience in AWS Cloud
Good understanding of Data integration, Data Flows, Data Quality, Data Architecture and Data Engineering
Technical expertise in data models, data mining and segmentation techniques
Experience in Tech Design and Solution Designing for data systems
Experience with full SDLC lifecycle and Lean or Agile development methodologies
AWS tools and components knowledge is good to have
CI/CD and GIT exposure
Experience on UNIX shell scripts
What's on Offer
Creative and Innovative Workplace
Opportunity to learn and grow
Good work culture",https://www.mycareersfuture.gov.sg/job/insurance/data-engineer-aws-michael-page-international-8262c1c92ad3c74427c162814ed764e7?source=MCF&event=Search
1,Data Engineer,BASIL TECHNOLOGIES PTE. LTD.,"What will you do?
· Develop data processing pipelines for ingestion, modelling, analysis, mining and reporting with Enterprise Big Data Lake
· Responsible for the code writing of the core module of the system
· Develop POC and build data pipeline architecture using of the overall technical framework of the software
· Work closely with teams ensure timely delivery of assignments
What do you need to succeed?
· Possess good communications skills to understand our customers' core business objectives and build end-to-end data centric solutions to address them
· Good critical thinking and problem-solving abilities
Must-have:
· Experience building large scale enterprise data pipelines using commercial and/or open source Big Data platforms from vendors such as Hortonworks/Cloudera, MapR, for Hadoop based platforms or NoSQL platforms such as Cassandra, HBase, DataStax, Couchbase, Elastic Search, Neo4j etc
· Hands on experience in Spark, Scala, Impala, Hive SQL, Apache Nifi necessary to build and maintain complex queries, streaming and real-time data pipelines
· Data modelling and architecting skills including strong foundation in data warehousing concepts, data normalisation, and dimensional data modelling such as OLAP",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-basil-technologies-dc31ae8dc930f163c94774d284718f9f?source=MCF&event=Search
2,Data Engineer,OKBL PTE. LTD.,"About OKX
OKX is a leading crypto trading app, and a Web3 ecosystem. Trusted by more than 20 million global customers in over 180 international markets, OKX is known for being the fastest and most reliable crypto trading app of choice for investors and professional traders globally.
Since 2017, OKX has served a global community of people who share a common interest in participating in a new financial system that is designed to be a level playing field for everyone. We strive to educate people on the potential of crypto markets and how to invest Beyond the OKX trading app, our Web3 wallet, known as MetaX, is our latest offering for people looking to explore the world of NFTs and the metaverse while trading GameFi and DeFi tokens.
About the team:
OKX data team is responsible for the whole data scope of OKG, from techincal selection, architecture design, data ingestion, data storage, ETL, data visualization to business intelligence and data science. We are data engineers, data analysts and data scientists. The team has end-to-end ownership of most of the data at OKx throughout the whole data lifecycle including data ingestion, data ETL, data warehouse and data services. As a data engineer of the team, you will work with the team to leverage data technologies to empower evidence-based decision-making and improve the quality of the company's products and services.
Responsibilities:
Design and build resilient and efficient data pipelines for both batch and real-time streaming data
Architect and design data infrastructure on cloud using industry standard tools
Execute projects with an Agile mindset
Build software frameworks to solve data problems at scale
Collaborate with product managers, software engineers, data analysts and data scientists to build scalable and data-driven platforms and tools
Ensure data integrity and scalability through enforcement of data standards. Improve data validation and monitoring processes to proactively prevent issues and quickly identify issues. Drive resolution on the issues.
Define, understand, and test external/internal opportunities to improve our products and services.
Requirements:
Bachelor’s Degree in Computer Science or have equivalent professional experience
Solid Experience with data processing tools such as Spark, Flink
Solid Experience implementing batch and streaming data pipelines
Solid experiences in Python/Go/Scala/Java.
In-depth knowledge of both SQL and NoSQL databases, including performance tuning and troubleshooting
Familiar with DevOps tools such as Git, Docker, k8s
Experience with the cloud (e.g. AWS, Ali Cloud, GCP, Azure)
Be proficient in SQL, familiar with advanced SQL features such as window functions, aggregate functions and creating scalar functions/user-defined functions.
Proven successful and trackable experience in full end-to-end data solutions involving data ingestion, data persistence, data extraction and data analysis.
Self-driven, innovative, collaborative, with good communication and presentation skills
Fluent in English, both written and spoken.
Preferred Qualifications:
Experience in FinTech, eCommerce, SaaS, AdTech, or Digital Wallet business industries.
Experience in working with teams across offices and timezones is a plus.
Experience in big data tools such as Amplitude/Tableau/QlikView, Ali Cloud DataWorks, MaxCompute, Hadoop, Hive, Spark and HBase is a big plus.",https://www.mycareersfuture.gov.sg/job/banking-finance/data-engineer-okbl-7b796d4ad6a29675e594917739e3e50d?source=MCF&event=SuggestedJob
3,Senior Data Engineer,GOVERNMENT TECHNOLOGY AGENCY,"The Government Technology Agency (GovTech) aims to transform the delivery of Government digital services by taking an ""outside-in"" view, putting citizens and businesses at the heart of everything we do. We also develop the Smart Nation infrastructure and applications, and facilitate collaboration with citizens and businesses to co-develop technologies.

Join us as we support Singapore’s vision of building a Smart Nation - a nation of possibilities empowered through info-communications technology and related engineering.
As a Senior Data Engineer in the Data Engineering team of GovTech’s Data Science and Artificial Intelligence Division, you will be building Whole-of-Government data infrastructure to power the insights needed for evidence-based decision-making and enhancing agencies’ service-delivery. You will be architecting, designing and building next-generation data infrastructure to galvanise digitalisation in the public sector. You will be given opportunities to lead other engineers to drive impact at scale.

We are looking for enthusiastic and passionate engineers to join us in this journey to make a difference.


What you will be working on:
Design and build resilient and efficient data pipelines for both batch and real-time streaming data
Architect and design data infrastructure on cloud using industry standard Infrastructure-as-Code tools
Execute projects with an Agile mindset
Build software frameworks to solve data problems at scale
Collaborate with product managers, software engineers, data analysts and data scientists to build scalable and data-driven platforms and tools
Be put in the driving seat as an engineering leader

What we are looking for:
Bachelor’s Degree in Computer Science or have equivalent professional experience
Have more than 4 years of experience in a technical role
Experience with data processing tools such as Spark, Beam, Flink
Experience with the cloud (e.g. AWS, GCP, Azure)
Experience implementing batch and streaming data pipelines
Experience writing efficient SQL
In-depth knowledge of both SQL and NoSQL databases, including performance tuning and troubleshooting
Familiar with DevOps tools such as Git, Docker, Terraform
Experience in the public sector is a bonus
Previous technical leadership experience is a bonus

We are an equal opportunity employer and value diversity at our company as we believe that diversity is meaningful to innovation. Our employee benefits are based on a total rewards approach, offering a holistic and market-competitive suite of perks. This includes generous leave benefits to meet your work-life needs. We trust that you will get the job done wherever you are, and whatever works best for you – so work from home or take a break to exercise if you need to*. We also believe it’s important for you to keep honing your craft in the constantly-evolving tech landscape, so we provide and support a plethora of in-house and external learning and development opportunities all year round.


*Subject to the nature of your job role that might require you to be onsite during fixed hours",https://www.mycareersfuture.gov.sg/job/information-technology/senior-data-engineer-government-technology-agency-559820f5a0995dd9eb73a6d7d5c50eae?source=MCF&event=Search
4,Data Engineer,KEYTEO CONSULTING PTE. LTD.,"⇒ Qualifications & Experience
● Minimum education of Bachelors’ degree in Information Technology.
● An academic background in Computing or an Engineering-based field.
● At least 5 years' experience of working as a data engineer via organization legacy systems.
● Solid working knowledge of implementing ETL pipelines using Informatica BDM (DEI) on data warehouses and big data platforms, such as RDBMS, Informatica etc.
● Familiar with application integration with RDBMS such as Oracle, MS-SQL or MySQL. (Working knowledge of Oracle and MS-SQL will be a plus).
● Hands-on experience of using Linux (or Unix-like OS) as the development environment and familiar with shell scripts and command line tools in Linux/Unix environment.
● Experienced with the Systems Development Life Cycle implementation methodology (SDLC) and/or agile methodologies like Scrum and Kanban.
● Understand and apply the good industry practice of code versioning, testing, CICD workflow and code documentation.
● Good team player, with strong analytical skills and enjoy complex problem solving with innovative ideas.
● Strong communication/people skills required to interact with data analysts, business end-users and vendors to design and develop solutions.
● Good at working with details and is meticulous.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-keyteo-consulting-941df120a111ef54ad18e8ba1bd28b88?source=MCF&event=Search
5,Data Engineer,ENCORA TECHNOLOGIES PTE. LTD.,"Build and support data lake, data warehouse and data API based solutions in Singapore by using suitable technology
Document data solutions, standards, requirement specifications, and business processes
Design, develop and implement secured, reliable, cost effective and high performance ETL solutions using Python, Pyspark and Talend
Perform unit testing, design & support integration testing strategies and automate data quality monitoring
Develop good understanding of existing data sets and data model
Develop good understanding of existing solutions and be able to support and enhance them
Establish and follow best practices in code version control & deployment and help to reduce the deployment time
Monitor scheduled jobs and reduce BAU monitoring efforts by automation
Take ownership and manage timely completion of deliverables
Maintain good documentation of the solutions and effectively communicate stakeholders about the value added
Minimum 5 years of professional experience in big data, data warehousing, operational data stores, and large-scale architecture and implementations

Ability to understand and write SQL
Ability to work with SQL/NOSQL database management systems and data warehouses
Hands on experience in AWS/Azure/Google cloud services
Using distributed computing frameworks like Apache spark using python or scala
Developing data processing python programs based on Pandas and related libraries
Knowledge in orchestration tools like Apache Airflow or similar tools
Good experience in ETL tools like Talend, Informatica or DataStage
Must have stream processing frameworks like Apache Kafka or AWS Kinesis or similar frameworks
Using Change data capture systems like IBM Infosphere CDC or Attunity or AWS DMS or similar tools
Shell scripting to automate tasks",https://www.mycareersfuture.gov.sg/job/insurance/data-engineer-encora-technologies-fc3876e54f63538893ca9ae827cda386?source=MCF&event=Search
6,Senior Data Engineer,INTEGRATED HEALTH INFORMATION SYSTEMS PTE. LTD.,"We are expanding our strong data science team and are looking for talented AI practitioner with applied experience in the fields of Machine Learning and Deep learning to join us. This role is best suited for candidate that is interested in developing new AI application that has a direct and immense, real-world healthcare impact.
You need to have a deep passion for analyzing and resolving healthcare problems. You display an intellectual curiosity about the business needs as well as the capability to engage with stakeholders to understand business issues.
Critical Work Functions and Key Tasks:
Analyze data
Scope out problem definition and hypothesis for analysis for image related use case
Responsible for image analysis, synthesis and other aspects of algorithm development, including visual recognition, object detection, segmentation and medical image processing, etc.
Responsible for the exploration of cutting-edge technology in image related algorithms and ensure the technologies get successfully applied.
Design experiments to test data assumptions
Evaluate experiment outcomes to draw actionable conclusions
Deploy data models across different channels and customer platforms
Collaborative work
Partner with stakeholders to translate business problems into data science projects
Develop strategies to identify, acquire and use appropriate data sets to develop practical solutions and support decision making
Maintain an advanced knowledge of trends affecting the industry
Present insights
Synthesize findings into actionable insights
Apply data analysis, datamining and data processing to present data clearly
Provide rationale, business cases and ROI models to support investment
Requirements / Qualifications
PhD or Masters in a quantitative field such as Mathematics, Statistics, Information Technology, Physics, Engineering, Finance or equivalent
Solid research and engineering background and experience in computer vision, machine learning, and image processing/analysis algorithms.
Good experience with Python or R is prerequisite
Good experience with Deep learning framework e.g. Tensorflow, keras, Pytorch is prerequisite
Hands on experience in the development of image classification, object detection, segmentation or related is preferred.
Good experience with SQL and/or NoSQL is preferred
Preferably 5 - 7 years of relevant working experience.
Proven communication skill to explain insights from technical work to non-technical audience through presentation or other means",https://www.mycareersfuture.gov.sg/job/information-technology/senior-data-engineer-integrated-health-information-systems-166dd1e941c7a9c288cfe297a333e0b1?source=MCF&event=Search
7,Data Engineer (Senior Manager),INTEGRATED HEALTH INFORMATION SYSTEMS PTE. LTD.,"We are expanding our strong data science team and are looking for talented AI practitioner with applied experience in the fields of Machine Learning and Deep learning to join us. This role is best suited for candidate that is interested in developing new AI application that has a direct and immense, real-world healthcare impact.
You need to have a deep passion for analyzing and resolving healthcare problems. You display an intellectual curiosity about the business needs as well as the capability to engage with stakeholders to understand business issues.
Critical Work Functions and Key Tasks:
Analyze data
Scope out problem definition and hypothesis for analysis for image related use case
Responsible for image analysis, synthesis and other aspects of algorithm development, including visual recognition, object detection, segmentation and medical image processing, etc.
Responsible for the exploration of cutting-edge technology in image related algorithms and ensure the technologies get successfully applied.
Design experiments to test data assumptions
Evaluate experiment outcomes to draw actionable conclusions
Deploy data models across different channels and customer platforms
Collaborative work
Partner with stakeholders to translate business problems into data science projects
Develop strategies to identify, acquire and use appropriate data sets to develop practical solutions and support decision making
Maintain an advanced knowledge of trends affecting the industry
Present insights
Synthesize findings into actionable insights
Apply data analysis, datamining and data processing to present data clearly
Provide rationale, business cases and ROI models to support investment
Requirements / Qualifications
PhD or Masters in a quantitative field such as Mathematics, Statistics, Information Technology, Physics, Engineering, Finance or equivalent
Solid research and engineering background and experience in computer vision, machine learning, and image processing/analysis algorithms.
Good experience with Python or R is prerequisite
Good experience with Deep learning framework e.g. Tensorflow, keras, Pytorch is prerequisite
Hands on experience in the development of image classification, object detection, segmentation or related is preferred.
Good experience with SQL and/or NoSQL is preferred
Preferably 5 - 7 years of relevant working experience.
Proven communication skill to explain insights from technical work to non-technical audience through presentation or other means",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-integrated-health-information-systems-cebf080b53b8566558e03157f727d085?source=MCF&event=Search
8,Data Engineer,CDG ZIG PTE. LTD.,"Responsibilities:
Expanding data collection as well as optimizing data pipelines for cross-functional teams
Work closely with data analysts and business end-users to implement and support data platforms
Tuning, troubleshooting and scaling identified big data technologies.
Analyse, tackle and resolve day-to-day operational incidents related to data provision
Build suitable tools to provide data through acquiring, monitoring and analyzing root cause of data issues
Identify, design, and implement process improvements and tools to automate data processing with data integrity
Work with data scientist and business analytics to assist in data ingestion and data-related technical issues
Design, build and maintain the batch or real time data pipeline in production using big data technology
Design, build and manage data warehouse such as designing data model
Create data views from big data platform to feed into analysis engines or visualization engines
Requirements:
Bachelor degree in Computer Science, Computer Engineering, Software Engineering or equivalent
At least 2 years of relevant working experience in ETL/data integration and data modelling
Experience with Data Engineering and Data Quality
Cloud experience, ideally with Azure and AWS
Understanding of Big data technologies like HDFS, Hive, Spark
Experience of relational or NoSQL database (e.g. Oracle) and using database technologies (PL/SQL, SQL)
Experience in data warehousing / distributed system
Experience in data ingestion, cleaning and processing tools
Experience in data acquiring, data processing using Scala/Python/Java
Highly organized, self-motivated, pro-active, and desire to learn new technology
Excellent communication and collaborative skills",https://www.mycareersfuture.gov.sg/job/engineering/data-engineer-cdg-zig-6da6bb4870385257e273f9c92695e4ba?source=MCF&event=Search
9,Data Engineer,PERSOLKELLY SINGAPORE PTE. LTD.,"At least 5 - 6 years’ experience in developing, implementing and maintaining IT systems

Position Summary / Project Description
ETL (Informatica BDM/DEI) with Data Model experience. He/she will co-lead ETL developers.
Role and Responsibilities
Involve in various stages of the systems development life cycle; adopting waterfall, agile or hybrid development methodology.
Performs analysis, design and development of ETL processes to support project requirements
Design and develop complex Informatica ETL mappings, sessions, workflows and maintain existing ETL/data warehouse processes.
Prepare technical design specifications based on the projects and change request assigned.
Conduct system integration testing and create test cases to ensure data quality prior to implementation.
Resolve issues raised during user acceptance testing.
Evaluate potential technical solutions and make recommendations to resolve business problems.
Work with business partners during system implementation and manage post implementation support.
Provide on-going support (24x7) to various applications running in the data warehouse if required.
Technical Skills:
ETL: Informatica Data Engineering Integration/Big Data Management, Informatica Powercenter, SAP BODS
Business Intelligence: Oracle Business Intelligence (OBIEE), Tableau
Databases: Oracle, Microsoft SQL Server, Teradata

Degree in Computer Science, Information Technology, Computer Engineering or equivalent.
Technical skills in order of priority: Informatica BDM/DEI, Informatica PowerCenter, Strong SQL, Oracle, SQL Server and Teradata Experience.
Minimum Seven (7) to eight (8) years’ experience in ETL Development and Data Integration.
Strong analytical and problem solving skills.
Strong understanding of ETL Development best practices, strong understanding of Data Lake and Warehouse Concepts, Performance Tuning in SQL and Informatica
Proven ability to work independently in a dynamic environment with multiple assigned projects and tasks.
Outstanding ability to communicate, both verbally and in writing.
Ability to develop complex mappings and workflows in accordance with requirements
Exposure to hospital information / clinical systems is an added advantage.
Experience in using business intelligence tools (e.g. OBIEE, Tableau, etc.) is an added advantage.
Experience in Vendor Management is an added advantage.

Please note: Only shortlisted candidates will be contacted

EA Registration No. R1871815 (Saravanan)

EA License No. 01C4394

**By sending us your personal data and curriculum vitae (CV), you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its local and overseas subsidiaries and affiliates collecting, using and disclosing your personal data to prospective employers/companies based in any country for purposes of evaluating suitability for employment, conducting reference checks, administering employment related services, complying with Government’s COVID-19 health advisories and such other purposes stated in our privacy policy. Our full privacy policy is available at www.persolkelly.com.sg. If you wish to withdraw your consent, please drop us an email to let us know. Please feel free to contact us if you have any queries.**",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-persolkelly-singapore-a7a86e1333dff4e9ae67cd88306f5ac9?source=MCF&event=Search
10,Senior Data Engineer,DYNAMIC HUMAN CAPITAL PTE. LTD.,"Role and responsibilities
· Responsible for designing and developing Azure Data Factory ETL/ELT or ingestion processes and collaborating with cross-functional teams. You will also need to participate in architectural discussions to provide technical guidance and ensure customer success
· Oversee complex data analytics projects from start to finish. You will be in charge of delivering solutions on the Azure cloud, using various Azure cloud tools and languages.
· Work closely with teams located in different locations globally to ensure the successful delivery of projects. Collaborate with other stakeholders such as developers, data scientists, and project managers to ensure the project's success.
· Participating in deep architectural discussions to build confidence in your solutions.
· Provide technical guidance to other teams and stakeholders to ensure that the project is delivered within scope, on time, and within budget.
· Establishing customer success when building new solutions and migrating existing data applications on the Azure platform.
· Understands customer needs and deliver solutions that meet those needs.

Skills and experience
· Bachelor's Degree in Computer Science/Engineering, Information Science/Engineering, or a related IT discipline.
· At least 5 years of experience as a Senior Data Engineer and deep expertise in data engineering as applied to Azure.
· Experience with multiple or all Azure components, including API Management, Event Hubs, Data Factory, Functions, Resource Manager Templates, Storage Accounts, Notifications Hub, Key Vault, DevOps, Data Lake Stores, Data Lake Analytics, Synapse Analytics, Databricks, HD Insight, SSAS, SQL Database, or similar cloud infrastructure.
· In-depth knowledge of standard concepts, practices, and procedures related to database modeling (logical and physical) and management. You also have an understanding of concepts of data lakes, data warehousing, and data marts, as well as legacy migrations to cloud services.
· Hands-on experience in scripting languages such as Python, R, etc.
· Advanced Business Intelligence experience, including an understanding of BI areas and reporting using SQL, SSAS, Tabular Models, and Power BI.
· Able to identify issues and coordinate resolutions, which is essential in ensuring that your solutions meet customer needs.
· Knowledgeable with the technology stack available in the industry for data management, data ingestion, capture, processing, and curation.
· Experience in metadata management, including data governance, data quality, master data management, lineage, data cataloguing, etc.


HOW TO APPLY:

We would like to invite interested applicants to email detailed resume in MS Word format to: joane@dhc.com.sg

By submitting any application or résumé to us, you will be deemed to have agreed and consented to us disclosing your personal information to prospective employers for their consideration.

Under the revised Employment Agencies Licence Condition 5(b), employment agencies (EAs) are required to collect the personal data (e.g. NRIC, FIN) of applicants referred to employers for permanent or contract job positions of at least 6 months with a fixed monthly salary of $3,300 and above. PDPA requirements on collection, use and disclosure of personal data are not applicable to EAs that are collecting such information, as it is a regulatory requirement.

https://www.mom.gov.sg/faq/submit-quarterly-referral-and-placement/are-employment-agencies-allowed-to-collect-personal-data

We regret to inform you that only shortlisted candidates will be notified. All applications will be treated with the strictest confidence.

Joane Carrido
Registration number: R1770751
EA Licence No: 12C6253",https://www.mycareersfuture.gov.sg/job/information-technology/senior-data-engineer-dynamic-human-capital-9961bfa212285bdab0bff40acb055981?source=MCF&event=Search
11,Senior Data Engineer (Digital),SPACE PTE. LTD.,"Why Work for Us
We Power the Nation.
Make the most of your talents and develop products that can create impact on a national scale. We are an in-house software team, assembled to move with speed and deliver with quality.

We Build Reliable Solutions. For Customers, Company and Country.
You will be part of the Digital Technology Team and together, you will innovate, create, and deploy digital products that will empower more than 3,800 employees within SP Group and improve the quality of life for the 1.6 million commercial, industrial and residential customers that SP Group serves. We build solutions that enable sustainable high quality lifestyles and help consumers save energy and cost, as well as supporting national goals for a sustainable livable city. Now, imagine the impact you can create.

What You’ll Do:
Create and maintain multiple robust and high-performance data processing pipeline within Cloud, Private Data Centre and Hybrid data ecosystem
Assemble large, complex data sets from a wide variety of data sources
Collaborate with Data Scientist, Machine Learning Engineer, Business Analyst and Business users to derive actionable insights and reliable foresights into customer acquisition, operational efficiency and other key business performance metrics
Develop, deploy and maintain multiple microservices, rest API and reporting services
Design and implement internal processes to automate manual workflow, optimize data delivery and re-designing infrastructure for greater scalability, etc
Establish expertise in designing, analyzing and troubleshooting large-scale distributed systems
What You’ll Need:
Experience building and operating large scale data lake and data warehouse
Experience with Hadoop ecosystem and big data tools, including Spark and Kafka
Experience with stream-processing systems including Spark-Streaming
Advance working experience with relational SQL and NoSQL databases, including Hive, Hbase and Postgres
Deep understanding in SQL and able to optimize data queries
Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc
A successful history of manipulating, processing and extracting value from large disconnected datasets
Experience applying modern development principles (Scrum, TDD, continuous integration, and code reviews)
Bonus:
Experience with ETL tools such as Talend Big Data, Apache Nifi, etc
Experience working with Hortonworks Data Platform or Cloudera Data Platform
Experience with Metadata Management tools
Exposure to Data Governance processes and tools
Proven ability in supporting and working with cross-functional teams in a dynamic environment
Thank you for your interest in SP Group. You will be contacted if you are shortlisted for an interview.



#LI-DNI",https://www.mycareersfuture.gov.sg/job/engineering/senior-data-engineer-space-7a32ab4fc9d2262dd563839373ab0bcb?source=MCF&event=Search
12,Manager - Data Engineering,ARYAN SOLUTIONS PTE. LTD.,"Key Roles & Responsibilities:
Purpose
● Place client value and human experience at the center of everything we do
● Develop and deliver value to clients by building large scale enterprise data pipelines to capture, transform and store date to support reporting, automated systems and AI/ML
Team
● Build a world-class team with experts in Data engineering
● Create a culture of excellence and lead with confidence, charisma, context, and humility, working effectively at all levels
Delivery
● Lead design & delivery of Data pipelines to drive material impact and drive disruptive transformation across our clients in public and private sectors
● Support development of go-to-market plans for Data engineering, understand strategic opportunities, develop trusted partnerships, and deliver social progress
● Thought leadership for data engineering and scaling deployments
Partnership
● Educate, enable, and coach teams on Data Machine Learning Engineers within the organisation, clients and in the broader community
● Adopt a cloud-first strategy to enhance agility and elasticity by partnering with vendors to support specific public sector needs
● Harness cutting-edge research through a triple helix partnership between research, industry, and government to drive state-of-the-art with bi-directional rotations

Requirements & Qualifications:
● Bachelor’s Degree/Masters Degree in Computer Science/Data Analytics or similar technology field
● Minimum 7 years of designing, building and operationalizing large scale enterprise data solutions and applications (both with batch and streaming data)
● Experience using one or more of AWS / Azure / GCP data and analytics services in combination with custom solutions - Spark, Azure Data Lake, Databricks, Snowflake, HDInsights, SQL DW, DocumentDB, Glue, Athena, Elastic Pool etc.
● Experience with Stream platforms and real-time aggregation platforms like Kafka, Kinesis, Spark, Flink, KSQL etc.
● Experience with multiple data storage solutions for analytics, operational and archival purposes like MongoDB, Cassandra, HBase, Redis, PostgreSQL, MySQL, DB2, Neo4j, S3 etc.
● Experience with data transformation tools/platforms like: dbt, Alteryx, Datameer, dataform, Informatica, Talend etc. and their data quality management features
● Mastered at least one core language: Python, Scala, Java
● Good exposure to concepts like Serverless computing, CI/CD, Containerization, Infrastructure as Code, code version control and automated testing
● Experience building historical and real-time operational ‘feature layers’ to support AI/ML teams
● Excellent understanding of the state of Data Engineering evolution in the industry through active tracks of improving knowledge and skills (e.g. courses, podcasts, books, experimentation, open source volunteering, tech meetups etc.)
● Track record of delivering scalable Data pipeline services running in production.
● Strong ability to communicate with a broad range of clients, colleagues, and partners across a variety of contexts and formats.
● Strong ability to explain design decisions and provide alternatives supported by analysis like pro/con, past experiences etc.
● Strong ability to develop and maintain relationships amongst clients, colleagues, and partners
● Demonstrated capability to lead, inspire, coach and mentor team members and colleagues.
● Ability to work within an unstructured environment with ability to multitask well",https://www.mycareersfuture.gov.sg/job/information-technology/manager-data-engineering-aryan-solutions-2b45b9e2c5e020dc80e611222fa6ae3e?source=MCF&event=Search
13,Data Engineer,SOFTENGER (SINGAPORE) PTE. LTD.,"Data Engineer:
· 3 or more years of experience with Python, SQL, and data visualization/exploration tools
· Familiarity with the AWS ecosystem specifically RedShift and RDS
· Communication skills, especially explaining technical concepts to non-technical business leaders
· Comfort working in a dynamic, research-oriented team with concurrent projects",https://www.mycareersfuture.gov.sg/job/banking-finance/data-engineer-softenger-b65aaca47c27f72b3d70bb42a994769b?source=MCF&event=SuggestedJob
14,Data Engineer,INFODRIVE SOLUTIONS PTE. LTD.,"· 5-10 years of application development experience in Spark, Spark SQL, Scala with Java/python/.Net is a must.
· Strong understanding and hands on experience of Big Data technologies like CDH, Hadoop/HDFS, S3, Colibra, Claudera Workbench, etc
· Technical proficiency on data mining techniques and performance optimization
· Adequate knowledge of database systems (RDBMS, MariaDB, SQL, NOSQL)
· Handling of reporting packages (Tableau, QlikView) is nice to have
· AWS experience is nice to have
· Degree in Computer Science or Engineering is a must
· Good problem diagnosis and creative problem-solving skills
· Passion to learn and master diverse new technologies in the open-source community
· Accuracy and attention to detail
· Team-working, Verbal and Written communication skills",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-infodrive-solutions-0601d93e9fc6f84936fb407e5ad61f6a?source=MCF&event=Search
15,Data Engineer,DYNAMIC TECHNOLOGY LAB PRIVATE LIMITED,"Data Engineers coordinate with researchers to ensure efficient processing of large-scale data.

Responsibilities
Develop and manage data inventories
Design a strong data framework
Monitor and maintain data production on a daily basis
Qualifications
Strong problem-solving skills in python and a good understanding of data structure/ algorithms
Comfortable with Linux
Highly detail-oriented
Ability to prioritize work and multi-task
Ability to take responsibility and work well as a team member
The following are bonuses
Knowledge of ETL
C++ development experience
Web development experience
Experience with large data (>100G)",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-dynamic-technology-lab-d579cd9e7d9b0c4811d02ab3d5da504b?source=MCF&event=Search
16,Data Engineer,KEYRUS SINGAPORE PTE. LTD.,"Responsibilities:
(a) Engage in both exploratory data analysis to identify trends and predictive data analysis to solve problems;
(b) Perform data preparation and data cleaning part of advanced analytics projects;
(c) Create visualizations to communicate findings and results; and
(d) Deploy developed models and integrate with existing healthcare IT system.

Requirements:
(a) Masters/Bachelors in Computer Science/Engineering, Business Analytics, Information System, or other related disciplines;
(b) Proficient in visualization/analytics tools such as Tableau, D3.js, Java script, R, Python and ETL tools such as PL/SQL, Informatica;
(c) Excellent communication, relationship skills and a strong team player
(d) Good to have:
(i) Deep understanding of statistical modelling, machine learning, or data
mining, text mining concepts and a track record of solving problems with
these methods
(ii) Experience in big data techniques (such as Hadoop, MapReduce, Hive, Pig, Spark) and deep learning.",https://www.mycareersfuture.gov.sg/job/consulting/data-engineer-keyrus-singapore-b87e88e050c1940ab2cb3ff1e51b0615?source=MCF&event=Search
17,Data Engineer,MDR LIMITED,"Job description

● Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
● Mine and analyze data from company databases to drive optimization and improvement of product / project development, marketing techniques and business strategies.
● Assess the effectiveness and accuracy of new data sources and data gathering techniques.
● Develop custom data models and algorithms to apply to data sets.
● Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
● Work with Product to define product / project requirements.
● Strong problem solving skills with an emphasis on product / project development.
● Provide 2nd layer develops support.
● Manage & develop company A/B testing framework and test model quality.
● Coordinate with different functional teams to implement models and monitor outcomes.
● Develop processes and tools to monitor and analyze model performance and data accuracy.
● Other ad hoc technical related assignments by senior manager.


Requirements

● Degree in Data Science, Computer Science, Big Data, Machine Learning
● Fresh graduates are welcome to apply
● Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
● Coding knowledge with several languages: C, C++, Java, JavaScript, etc.
● Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
● Experience querying databases and using statistical computer languages: R, Python, SQL, etc.
● Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.
● Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
● Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
● Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
● Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.",https://www.mycareersfuture.gov.sg/job/others/data-engineer-handphoneshop-077aaa47ced8dd9d98cf3c826d69aa72?source=MCF&event=Search
18,Data Engineer,IDC TECHNOLOGIES (SINGAPORE) PTE. LTD.,"Responsibilities
· Implementing Data Architecture/ Data modelling for data platform and Analytics.
· Responsible for the technical design and development of Analytics and big data systems including ETL, data transformations.
· Define and govern banking logical model and data platform best practices and standards to include software development practices, design styles and software deployment.
· Facilitate the discovery of entities, attributes, relationships, and business rules from the functional experts and the user community.
· Metadata management.
· Working with cross-functional teams to discover and develop actionable, high-impact data analytics requirements and opportunity statements in a variety of core business areas.
· Assessing tool implementations and architectures in the Analytics & Big data space, reviewing for gaps against business needs and industry best practices.
· Contributing to business process design and re-engineering impacted areas

Requirements
· At least 6 to 8 years of working experience, preferably in banking environments
· Familiarity with key technologies and concepts, e.g. Hadoop, Hive, Spark, Scala, Java and Impala are necessary
· Familiarity with Cloudera echo systems.
· Candidate with experience in Analytics and big data architecture.
· Familiarity with key technologies and concepts, SQL & Big Data.
· Knowledge of products in Banking and Financial Services.
· Ability to write clear documentation of procedures, and ability to write specifications for data models to be developed.
· Detail-oriented and able to follow clear methodologies for troubleshooting and development.
· Expert knowledge of data Architecture in financial service data models.
· Expert knowledge of Erwin data modeler tool. Certifications would be a plus.
· Expert in Data Analysis and Data Profiling.
· Efficient in prioritising work and multi-tasking

Mandatory Skills : Java, Scala, Impala, Hive",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-idc-technologies-710fe4308b25149046cd62249a162bee?source=MCF&event=Search
19,Data Engineer Senior Manager,ACCENTURE PTE LTD,"About Accenture
Accenture is a global professional services company with leading capabilities in digital, cloud and security. Combining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services and Accenture Song — all powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. Our 721,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. We embrace the power of change to create value and shared success for our clients, people, shareholders, partners and communities.

Data Engineer Lead – Senior Manager
Key Responsibilities
Developing, testing and implementing business systems of the highest complexity
Ensures cross team integration and proper hand-offs of code/tasks to meet schedules
Designs reusable software components and incorporates reusable assets into the application design
Research and evaluate Data Engineering tools and frameworks
Participate on POCs and assist in client presentations
Assist engineering leadership in hiring and interviewing top talent
Mentor junior staff conduct design/code/test reviews
Assist in developing centre of excellence, best practices, documentation, re-usable assets
Proficient in distributed architecture, understanding of required infrastructure setup
Mentor junior team members
Qualifications
15+ years of experience with significant experience in the Data Engineering space
Experience in designing and building robust and highly scalable data platform and data pipelines
Experience with leading a team of experienced Data Engineers
Prior experience working in the consulting space will be highly advantageous
Strong programming proficiency using 1 or 2 of the following languages: Scala, Python, Java
Extensive experience with data modelling and designing/supporting both streaming and batch ETL pipelines
Clear understanding of distributed computing, especially in databases
Hands-on in SQL and NOSQL with a deep understanding of query optimization
Experience with open-source technologies (Spark, Kafka, Presto, Hive, Cassandra etc.)
Experience working on any of the Cloud platforms (GCP, AWS, Azure)
Good to have: Certification for Data Engineers or Solution Architect in 1 or more Cloud Technologies (AWS, GCP, Azure)
Strong communications skills and presentation skills to C levels
Ability to manage numerous requests concurrently and be able to prioritize and deliver
You will also have opportunities to hone your functional skills and expertise in an area of specialization. We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-senior-manager-accenture-830445ca3645ac7d5c91d478973fb37e?source=MCF&event=Search
20,Data Engineer ( Linux / Python / Spark / Talend / CAT 1 / Tampines ),TRUST RECRUIT PTE. LTD.,"Job Description:
Be part of a team to build and maintain data systems or pipelines.
Perform setup, installation, configuration, troubleshooting and/or upgrade for COTS products.
Develop or implement ways to improve data warehouses, data lakes or equivalent platforms.
Involve in the creation of documentations e.g. design documents, troubleshooting guides etc.
Job Requirements:
Knowledge and/or experience in data management or data engineering
Experience with Linux commands and shell script
Knowledge and/or experience in relational (including SQL) or NoSQL database (e.g. document, graph)Data / Search / Automation platforms such as Hadoop, Elasticsearch, Ansible respectively
Data integration tools such as Talend, DataStage, Denodo
Programming languages such as Python, Spark
Microsoft Azure Cloud services such as Azure Data Factory, Azure Synapse Analytics
o Analytics platforms such as Databricks, Dataiku, Data Robot
Good problem-solving skills
Able to work independently and as a team
HOW TO APPLY:
Interested applicants, please click on “Apply Now” and provide the below details in your resume.
We regret only shortlisted candidates will be notified.
Important Note: Trust Recruit Pte Ltd is committed to safeguarding your personal data in accordance with the Personal Data Protection Act (PDPA).
Please read our privacy statement on our corporate website www.trustrecruit.com.sg.

Trust Recruit Pte Ltd
EA License No: 19C9950
EA Personnel: Jordan Fung Si Jong
EA Personnel Reg No: R23112945",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-trust-recruit-8604b1f2c74cfa3d8b7cd43cb503ad8d?source=MCF&event=Search
21,Data Engineer,MORGAN MCKINLEY PTE. LTD.,"An exciting role as a Data Engineer is available now in a technology company within the essential services. The Data Engineer plays an important role in supporting the implementation of data structure and architecture through master data management approach and data quality programme to facilitate access to data and information.

Job Responsibilities:
Work with stakeholders to understand needs for data structure, availability, scalability and accessibility
Support translation of data business needs into technical system requirements
Identify opportunities for improvements and optimisation • Translate concepts into user flows, wireframes, mockups and prototypes that lead to intuitive user experiences
Design and deliver wireframes, user stories, user journeys, and mockups optimized for a wide range of devices and interfaces
Develop tools to improve data flows between internal/external systems and the data lake/warehouse
Build robust and reproducible data ingest pipelines to collect, clean, harmonise, merge and consolidate data sources
Design and build API gateways to expose data to systems via secure means
Integrate and collate data sources with data systems, with compliance to data security and organisational governance standards
Implement critical data infrastructure on cloud including AWS EC2, S3, EMR, Redshift, Workspaces
Contribute to defining data retention policies
Job Requirements:
Degree, Information Technology, Computer Engineering or equivalent
The ability to work towards strict and conflicting deadlines, be able to plan and prioritise in an environment with multiple stakeholders
A good understanding of Singapore Healthcare System Good interpersonal skills, a detail-oriented & flexible person who can work across different areas within the team
Familiarity or experience with health informatics would be preferred
An understanding of healthcare data governance, data acquisition and data management would be an advantage
Experience in interacting with analytics stakeholders (economists, statisticians, clinicians, policy makers) on a business or domain level would be preferred
Please click ""Apply Now"" should you be interested to proceed with the job application.
Morgan McKinley Pte Ltd
EA Licence No: 11C5502
Registration No: R22109486
EAP Name: YU CIET XIA",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-morgan-mckinley-bdde91720e54fd029ab98ce1be7d5670?source=MCF&event=Search
22,Data Engineer,MORGAN MCKINLEY PTE. LTD.,"We are looking for Data Engineer on a 12-month Contract role with high possibility of extension. There is a high chance of extension as its for long term Project.

Job Summary:
Lead a small team of 2-5 full-stack software engineers, data engineers, and data scientists
Work closely with customers and the product team to gather software requirements
Lead the maintenance of data warehouses on analytics platforms such as Snowflake or Databricks
Lead the architecture, design, and deployment of analytics apps to cloud platforms such as Azure or AWS
Perform build vs buy analysis for each customer-facing service
Drive the choice of software stack for each application
Employ Agile, CI/CD, and TDD methodologies to enable rapid software development with high quality
Follow best practices for data governance to ensure high-quality, secure customer data
Work with the IT and InfoSec teams to ensure highly available, performant, and secure applications
Participate in new product introduction (NPI) and process improvement activities with the product team
Job Qualifications:
Candidate must have good understanding of full-stack software applications, data engineering, data science, and Agile methodologies
Experience with common frontend and backend web frameworks such as React, Angular, Express, Flutter, Flask, and Django preferred
Experience with data warehouse solutions such as Snowflake and Databricks preferred
Experience with cloud infrastructure such as AWS, Azure, or GCP preferred
B.S. (or equivalent) in science, engineering, or mathematics required
10+ years of software engineering, data engineering, or data science experience required
2+ years leading a team of software / data engineers required
Excellent verbal and written communication skills.
Only shortlisted candidates will be responded to, therefore if you do not receive a response within 14 days please accept this as notification that you have not been shortlisted.

Thanks,
Morgan McKinley
EA License No: 11C5502
EAP Registration No: R22108361",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-morgan-mckinley-dd08a4aae7a4c415e05030d26d8d0573?source=MCF&event=Search
23,Data Engineer,SOURCEO PTE. LTD.,"Data Engineer (AWS/AZURE)

In this role, the Data Engineer will be exposed to many aspects of data collection and data pipeline to serve stakeholders requirements. Stakeholders can range from Business Analysts, Product Analysts, Data Analyst to Data Scientists who need datasets for modelling, visualization and decision making.
The Data Engineer should have a proven track record of delivering data pipeline solutions and architecture. He/She should also understand business requirement and able to build reliable data infrastructure using big data technologies. Ideally, you are someone who enjoys optimizing data pipeline, automating and building from scratch.

Responsibilities:
Expanding data collection as well as optimizing data pipelines for cross-functional teams
Work closely with data analysts and business end-users to implement and support data platforms
Tuning, troubleshooting and scaling identified big data technologies.
Analyse, tackle and resolve day-to-day operational incidents related to data provision
Build suitable tools to provide data through acquiring, monitoring and analyzing root cause of data issues
Identify, design, and implement process improvements and tools to automate data processing with data integrity
Work with data scientist and business analytics to assist in data ingestion and data-related technical issues
Design, build and maintain the batch or real time data pipeline in production using big data technology
Design, build and manage data warehouse such as designing data model
Create data views from big data platform to feed into analysis engines or visualization engines
Requirement:
Bachelor degree in Computer Science, Computer Engineering, Software Engineering or equivalent
At least 2 years of relevant working experience in ETL/data integration and data modelling
Experience with Data Engineering and Data Quality
Cloud experience, ideally with Azure and AWS
Understanding of Big data technologies like HDFS, Hive, Spark
Experience of relational or NoSQL database (e.g. Oracle) and using database technologies (PL/SQL, SQL)
Experience in data warehousing / distributed system
Experience in data ingestion, cleaning and processing tools
Experience in data acquiring, data processing using Scala/Python/Java",https://www.mycareersfuture.gov.sg/job/engineering/data-engineer-sourceo-706a17bff51b02a7b9b53c609822e80a?source=MCF&event=Search
24,Data Engineer,VUI SYSTEMS PTE. LTD.,"Roles and Responsibilities:

• Ability to extract required data from data warehouse, source systems, flat files for analytics use cases
• Create data ingestion pipelines and deploy the same in production for real-time analytics
• Analysing raw data, including pre-processing of data, addressing data quality issues
• Developing and maintaining datasets
• Conduct complex data analysis and report on results
• Prepare data for prescriptive and predictive modelling
• Combine raw information from different sources
• Create data model on which the analytics would be built.

Skills Required:

• We are looking for a Singapore citizen with 4+ years of hands on experience in a Data Engineer role
• Experience using the following software/tools: • Experience with Oracle databases and Informatica
• Experienced in python
• Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
• Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
• Experience supporting and working with cross-functional teams in a dynamic environment.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-vui-systems-3438ace80fbde4d706491461034546e2?source=MCF&event=Search
25,Senior Data Engineer,QUANTEXA PTE. LTD.,"Founded in 2016 with only a handful of individuals, Quantexa was built with a purpose that through a greater understanding of context, better decisions can be made. 6 years, 10 locations and 500+ employees later we still believe that today. We connect the dots within our customers data using dynamic entity resolution and advanced network analytics to create context, empowering businesses to see the bigger picture and drive real value from their data.

Due to the continuous success and high demand from our customers, we are looking for senior level Data Engineers with a proven track record to join the Quantexa family. We also have positions open for mid-level candidates looking for an opportunity to learn new skills and progress their careers in a dynamic and exciting start-up environment. 🚀

What does a Data Engineer role at Quantexa look like?
In order to be a successful Data Engineer at Quantexa, you’ll need to be comfortable dealing with both internal and external stakeholders. You will be managing, transforming and cleansing high volume data, helping our Tier 1 clients solve business problems in the area of fraud, compliance and financial crime.

Being Agile is an integral part to the success we have at Quantexa and having regular team sprints and Scrum meetings with your Projects team is essential. You’ll be working closely with Data Scientists, Business Analysts, Technical Leads, Project Managers and Solutions Architects, with everyone following the same goal of meeting our clients expectations and delivering a first-class service. 🥇

We want our employees to use the latest and leading open source big-data technology possible. You will be using tools such as Spark, Hadoop, Scala, Data Fusion, Entity Resolution and Elasticsearch, with our platform being hosted on both private and public virtual clouds, such as Google cloud, Microsoft Azure and Amazon. Our primary language is written in Scala, but don’t worry If that’s not currently your strongest language, we make sure that every Quantexan goes through our training academy so they’re comfortable and confident with using our platform.

Typical responsibilities include:
Write defensive, fault tolerant and efficient code for data processing.
Automate data processing to enable on-going alerts on high-risk activity.
Participate in customer workshops and refinement sessions, presenting project results to clients both face to face and virtually.
Work very closely with data scientists to ensure efficient and effective delivery of solutions.
Use leading open source big-data tools, such as Spark, Hadoop, Scala and Elasticsearch. You should be comfortable with working with high profile clients, including on their sites.
Work with our expert software development team to produce reusable applications.
Use emerging and open-source technologies such as Spark, Hadoop, and Scala.
Collaborate on scalability issues involving access to massive amounts of data and information.
Take on ad-hoc tasks as required for the running of a small, yet rapidly expanding business.

What do I need to have?
Proven big data experience, either from an implementation or a data science prospective.
Several years of hands-on experience working as part of an engineering development team, ideally in SCRUM.
Arrive with experience at working with a variety of modern development tooling (e.g. Git, Gradle, Jenkins, Nexus) as well as technologies supporting automation and DevOps (e.g. Ansible, Chef, Puppet, Docker and a little bit of good old Bash scripting).
Excellent technical skills including hands-on knowledge of at least one big data technology such as Spark, Hadoop, or Elasticsearch.
Experience with MVC frameworks such as AngularJS
Experience of building data processing pipelines for use in production “hands off” batch systems, including either (or preferably both) traditional ETL pipelines and/or analytics pipelines.
Strong coding experience in the likes of Scala, Java, or Python.
Enthusiasm to learn and develop emerging technologies and techniques.
Exhibit strong technical communication skills with demonstrable experience of working in rapidly changing client environments.
Demonstrate strong analytical and problem-solving skills and the ability to debug and solve technical challenges with sometimes unfamiliar technologies.
Strong academic qualifications and come from a software engineering background or other scientific degree incorporating IT modules (e.g. Maths/Physics).",https://www.mycareersfuture.gov.sg/job/consulting/senior-data-engineer-quantexa-8c0bed7ac547929ed9780fe1dd2eb632?source=MCF&event=Search
26,Data Engineer,RAPSYS TECHNOLOGIES PTE. LTD.,"Role:Data Engineer

Job Description:
Support data management operations activities in research and investment data applications of Data Strategy
Job Requirements:
Experience in data analysis.
Experience in managing data reconciliation/quality checks (gather requirements, implementation, monitoring and troubleshooting).
Proficient in Oracle PL/SQL.
Experience in working with enterprise databases using database technologies (MS SQL, Snowflake, Redshift and PostgreSQL) and data integration products (e.g. Informatica).
Experience in performing UAT.
Able to manage SLA and queries from end users.
Familiar with providing documentation support, e.g. in technical/functional specifications.
Possess finance domain knowledge.
Problem solving and logical thinking.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-rapsys-technologies-d957b6fd44b3d8a2bfc429e09884f3c0?source=MCF&event=Search
27,Data Engineer,RAPSYS TECHNOLOGIES PTE. LTD.,"Role: Data Engineer


Job Description:
Support PEG projects
Support new Allegro data migration from GEMS to Master Data Management (MDM) for PEG.
Job Requirements:
Must have
Bachelor Degree in Computer Science, Computer Engineering or equivalent.
At least 5 years' experience of working as a data engineer via organization legacy systems.
Solid working knowledge of implementing ETL pipelines using Informatica BDM (DEI) on data warehouses and big data platforms, such as RDBMS, Informatica etc.
Familiar with application integration with RDBMS such as Oracle, MS-SQL or MySQL. Working knowledge of Oracle and MS-SQL will be a plus.
Hands-on experience of using Linux (or Unix-like OS) as the development environment and familiar with shell scripts and command line tools in Linux/Unix environment.
Possess experience in Systems Development Life Cycle implementation methodology (SDLC) and/or Agile methodologies like Scrum and Kanban.
Able to understand and apply the good industry practice of code versioning, testing, CICD workflow and code documentation.
Good team player, with strong analytical skills and enjoy complex problem solving with innovative ideas.
Strong communication/people skills are required to interact with data analysts, business end-users and vendors to design and develop solutions.
Good at working with details and meticulous for operations.
Nice to have
Big Data Platforms - Informatica, Snowflake, Kafka
Programming and Scripting - Python, .NET, Java
SQL Databases - Oracle, MS-SQL",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-rapsys-technologies-62cd750a265f212d220b8f3123932b13?source=MCF&event=Search
28,Data Engineer,PROPERTYLIMBROTHERSMEDIA PTE. LTD.,"This role is under: the Tech Team

PropertyLimBrothers is looking for a data engineer with strong data engineering skills and is responsible for building and managing platforms that will enable the business to thrive in the technology space.
You are required to have a deep appreciation of the complexity of the data engineering process, such as the challenges of data ingestion involving large or near-real-time datasets, the maintenance of high data quality, and the importance of automation for increasing ETL pipeline robustness and reducing the need for human intervention.

What will I be doing?

- Maintain and improve systems architecture for data engineering services and their ecosystem, spanning distributed cloud databases and databanks (AWS, Redshift, Google).
- Develop highly automated self-service data platforms with automated data pipelines for business users and data team to leverage on building visualisations. Ensure data-quality is of highest standards and accuracy.
- Champion the introduction of next-generation technologies in the data-ingestion workflow. Explore and evaluate possibilities of expanding the scope of data that can be ingested to future-proof and achieve our roadmap.
- Support the research and development of statistical machine learning and deep learning algorithms to meet complex product requirements. The scope includes defining hypotheses, executing necessary tests and experiments; evaluating, tuning and optimising algorithms and methods; and having an eye towards cloud implementation ease, scalability, and robustness in a live customer-facing production environment.

JOB REQUIREMENT

What is required of me?

- Minimum 3 years experience as a Data Engineer with hands-on experience in building data pipelines and web scrapping.
- Proficient in Python, SQL and JavaScript.
- Front-end Reporting & Dashboard and Data Exploration tools – Tableau.
- Strong analytical and technical skills in building data pipelines and API.
- Degree in Computer Science, Computer Engineering or equivalent.
- Experience in setting up AWS databases.
- Self-starter who is able to work independently in a fast-paced environment.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-propertylimbrothersmedia-1f7dccb275969428edcf7349db9d265a?source=MCF&event=Search
29,Data Engineer,CDG ZIG PTE. LTD.,"Responsibilities:
Expanding data collection as well as optimizing data pipelines for cross-functional teams
Work closely with data analysts and business end-users to implement and support data platforms
Tuning, troubleshooting and scaling identified big data technologies.
Analyse, tackle and resolve day-to-day operational incidents related to data provision
Build suitable tools to provide data through acquiring, monitoring and analyzing root cause of data issues
Identify, design, and implement process improvements and tools to automate data processing with data integrity
Work with data scientist and business analytics to assist in data ingestion and data-related technical issues
Design, build and maintain the batch or real time data pipeline in production using big data technology
Design, build and manage data warehouse such as designing data model
Create data views from big data platform to feed into analysis engines or visualization engines
Requirements:
Bachelor degree in Computer Science, Computer Engineering, Software Engineering or equivalent
At least 2 years of relevant working experience in ETL/data integration and data modelling
Experience with Data Engineering and Data Quality
Cloud experience, ideally with Azure and AWS
Understanding of Big data technologies like HDFS, Hive, Spark
Experience of relational or NoSQL database (e.g. Oracle) and using database technologies (PL/SQL, SQL)
Experience in data warehousing / distributed system
Experience in data ingestion, cleaning and processing tools
Experience in data acquiring, data processing using Scala/Python/Java
Highly organized, self-motivated, pro-active, and desire to learn new technology
Excellent communication and collaborative skills",https://www.mycareersfuture.gov.sg/job/engineering/data-engineer-cdg-zig-519c58fa52a902f66f17c84a73edefc1?source=MCF&event=Search
30,Data Engineer,HEALINT PTE. LTD.,"Overview of the role
The role provides a tremendous opportunity for a candidate to work in a fast-growing startup with a million users (and growing) by deriving value from the massive volume of data we capture.
This is your chance to deploy Algorithms & Pipelines at SCALE. Over the coming years, those will be progressively supporting some, if not all, of the following: user classification from multimodal data, simple NLP supporting data capture & classification, providing AI Diagnosis, Prediction of treatment opportunities, inference of Health events from time series, Context inference from Geo-data & weather, etc. (i.e., prior knowledge of medical etc. is not expected).
As the Data Engineer+Scientist, you are responsible for designing and implementing data-driven services and solutions (Ie: Pipelines & Algorithms). You must be comfortable deploying your solutions (algorithms) to the cloud, ready to scale, and have a proven track record of designing pipelines for batch as well as streaming needs.
Roles & Responsibilities
Develop data pipelines that ingest data from a variety data sources to enable better data-informed decision-making within the business
Design and implement data science solutions / algorithms that provide smart features to our users
Contribute to an ongoing effort to improve data reliability, efficiency and quality
Skills/Experience should include some of those (by order of importance):
Experience in Python, REST APIs, and SQL
Familiarity with data warehousing concepts and data-modeling
Experience in using AWS cloud infrastructure and solutions such as Kinesis, Glue, S3, Redshift, ECS
Experience with ELT processing and workflow orchestration using Airflow and dbt
Experience with development systems such as Bitbucket & Docker
We want someone who is:
Able to deliver your work in a planned and timely manner
Able to work across cross-functional teams to gather requirements and come up with solutions
Qualities:
Rigor: 5/10 *
Self-Learning: 7/10
Initiative/Enthusiasm: 6/10
Team-Work: 6/10 **
*You will have the opportunity to learn good practices and methods to nurture Rigor. Rigor is critical to scale models & data collection.
** Team-Work is also critical for scalability, but keep in mind that here this is teamwork across functional teams, not within a silo. It will be about passing the ball to the person working on the UX showing the output from your algorithm, receiving the ball from the product manager, and even about understanding how the algorithm is impacted by the feelings of the user doing input.
Other info
Work Location: Singapore
COVID-19 Vaccination Requirement: Fully Vaccinated
If you are passionate and motivated to join our efforts in improving patient’s quality of life, please send your CV and brief description of your successful growth campaigns (if available) to careers@healint.com",https://www.mycareersfuture.gov.sg/job/engineering/data-engineer-healint-8163861e3f82baf823e381d3b38b3944?source=MCF&event=Search
31,Data Engineer,BLUESG PTE. LTD.,"We are looking for talented Data Engineers, who will join our Data Science Team and help us build the state-of-the-art data analytics capabilities powering the future of our platform.

Roles and Responsibilities
Collaborate with DevOps and Business Intelligence teams to establish a common data processing and analytics platform and best practices.
Work closely with data scientists and software engineers to support the analysis of data, and the development and validation of models.
Design and implement data storage solutions to ensure data quality, availability, and scalability.
Monitor the performance of the data infrastructure and implement optimizations to improve efficiency and reduce costs.
Participate in technical discussions across the team through code reviews, RFC, or architecture review sessions.
Requirements
At least 2 years of experience working as a data engineer or similar.
Good understanding of Agile and DevOps practices: version control, CI/CD, Infrastructure-as-Code, containerization, observability/monitoring.
Experience building data infrastructure to address the needs of business and data teams. Strong knowledge of data architecture, data modeling, and data warehousing.
Deep familiarity with data processing systems such as Airflow, Dagster, Flyte, Spark, DBT, or similar and data cataloging tools such as Atlas, Amundsen, DataHub, or similar.
Deep familiarity with SQL (PostgreSQL preferred) and NoSQL databases (Redis, Elasticsearch preferred).
We use AWS, so familiarity with its data analytics services and databases, e.g., Redshift, Athena, Glue, EMR, etc. Also, familiarity with data platforms such as Sagemaker, Dataiku, Databricks, Datarobot, or similar.
Experience with data visualization and reporting tools like Metabase, Tableau, PowerBI, or Looker.
Preferred Qualifications
Hands-on experience supporting high-traffic consumer apps.
Experience with real-time data processing using Kafka, Flink, or similar tools.
Data science, MLOps, or related education or work experience.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-bluesg-4b54a716fea036d94dc69fea6b1e8a1a?source=MCF&event=Search
32,Engineer Data Management,EAGLESTAR MARINE (S) PTE. LTD.,"KEY ACCOUNTABILITIES
Manage, plan and maintain the facilitation of support for data analysis across Eaglestar’s growing global fleet
Project-manage and deliver on data-related implementations ensuring that deliverables are met within agreed scope and timelines
Manage, develop, and provide Eaglestar’s internal/external stakeholders with various analysis, reports on monthly, quarterly and yearly basis.
Perform ETL on large and complex datasets for AI applications - work closely on performance optimization of large-scale ML/DL model training.
Manage, plan and design relevant Planned Maintenance System reports as requested by Fleet Operations and QAHSSE.
Manage and plan the implementation of Planned Maintenance System data on Eaglestar’s new vessels in collaboration with Group ICT, system vendors and newbuilding site office.
Manage and control system enhancement initiatives as per user feedbacks to enable the full optimization of analysis within ERP system by ship and shore personnel.
Enhance networking and relationship with external peers working in the similar capacity and functions, with the objective of contributing new ideas and improvements to enhance the operational and technical excellence of Eaglestar’s fleet of vessels.
Ensure that the data management team delivers the requirements for all stakeholders as per plan as app
Any additional work as appropriate and delegated by the head for the organizational requirements and growth.
KNOWLEDGE & EXPERIENCE REQUIRED
Professional Qualifications
Degree in Marine Studies/Marine Engineering/ Naval Architect/Mechanical Engineering, Finance, Economics, Computer Science, Data Science, Engineering or equivalent field.
Specialist Knowledge / Skills
General knowledge of global shipping industry and fleet technical management.
Expert working knowledge on SQL and Python/Scala/R/Jason to perform data processing, building data models, conducting data analysis.
Exceptional visualisation skills using Powerbi, Tableau, Qlikview, Qliksense or other relevant visualisation tools.
Well versed in Python programming especially handling large volumes of data both in traditional and distributed environments - pandas, numpy, scikitlearn, pySpark
Well versed with structured (SQL) and unstructured (noSQL) database in traditional and Big data environments (Hive, Spark)
Well versed with concepts like containerization (Dockers, Kubernetes, Openshift), workflow management (AirFlow), streaming data (Kafka or Spark Streaming), CICD pipeline (Jenkins).
Experienced in shell scripting and writing schedulers, Some experience with Cloud deployment (AWS / Azure / GCP) would be a big advantageous.
Strong knowledge of data security best practices
Experience
5 years’ experience in maritime based industries specializing in data analysis and reporting processes.
At least 2-3 years of Software Project Management experience successfully managing both internal stakeholders and external vendors.",https://www.mycareersfuture.gov.sg/job/information-technology/engineer-data-management-eaglestar-marine-80571b5f8d64aed5e4cf90a229e08759?source=MCF&event=Search
33,Data Engineer,AMARIS CONSULTING PTE. LTD.,"ABOUT THE JOB
Choosing the right technologies for our use cases, deploy and operate.
Setting up Data stores structured, semi structured and non-structured.
Secure data at rest via encryption
Implement tool to access securely multiple data sources
Implement solutions to run real-time analytics
Use container technologies
ABOUT YOU
Technical and Behavioral Competencies required
Experience in one of the following: Elastic Search, Cassandra, Hadoop, Mongo DB
Experience in Spark and Presto/Trino
Experience with microservice based architectures
Experience on Kubernetes
Experience of Unix/Linux environments is plus
Experience of Agile/Scrum development methodologies is a plus
Cloud knowledge a big plus (AWS/GCP) – (Kubernetes/Docker)
Be nice, respectful, able to work in a team
Willingness to learn
EQUAL OPPORTUNITY
Amaris Consulting is proud to be an equal opportunity workplace. We are committed to promoting diversity within the workforce and creating an inclusive working environment. For this purpose, we welcome applications from all qualified candidates regardless of gender, sexual orientation, race, ethnicity, beliefs, age, marital status, disability or other characteristics.",https://www.mycareersfuture.gov.sg/job/consulting/data-engineer-amaris-consulting-628e2abebceffcc98ad425898a9e6bc0?source=MCF&event=Search
34,Senior Data Engineer,NMG FINANCIAL SERVICES CONSULTING PTE LTD,"SUMMARY STATEMENT
We’re looking for a curious, intelligent, and proactive cloud focused Senior Data Engineer
to help us tackle complex data analytics projects end-to-end in Microsoft Azure. You will work with various teams based in multiple locations globally to deliver solutions on the Azure Cloud using core Azure cloud tools and languages. In addition, you will participate in improving recent implementations. You’re committed to delivering high quality interactions and you’re excited about making a big impact on a small team.

You love building the best data storage, processing, and visualization solutions; apart from being functional and insightful you really want it all to look beautiful, from initial design to naming conventions, code & visualization.
We won’t have to tell you much about data architectures, data processing and integration technologies and methodologies or business intelligence ecosystems; your expert knowledge is up to date or you can research and learn. You have deep understanding of all things data including ingestion, transformation, and consumption.
You enjoy working in a diverse business with multiple cultures and stakeholders.
You thrive in a fast-pace project environment where excellent collaboration and communication skills are key to success.
When it comes to the crunch, you love the pressure of an occasional healthy deadline.
You proactively identify opportunities for work optimisation including opportunities for automation.
You’re fluent in English.
This position is not an infrastructure position.

KEY RESPONSIBILITIES
Data Architecture
Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the Azure platform.
Reverse engineer existing database data models, manage and maintain existing and new logical and physical data models.
Data Engineering (Development)
Collaborate with functional group leaders and engineering team(s) to gather and analyse business and technical data requirement needs and understand how data is collected, analysed & utilised to design and implement the management, monitoring, security, and privacy of data using the full stack of Azure data services.
SQL server development and coding complex functions, stored procedures, triggers, indexes, queries or ad-hoc analyses, and views (using T-SQL).
Design and develop Azure Data Factory ETL, ELT or ingestion processes that will transform a variety of on-prem and cloud (structured and unstructured) data sources into SQL databases or data warehouses or integration solutions, including REST APIs, Event Drive or Queue based integrations.
Design and build Microsoft Azure functions to optimize data extractions and ensure data validation, cleansing and merging forms a critical part of data processing solutions.
Ensure that data services securely and seamlessly integrate with other data platform technologies or application services such as Azure Cognitive Services, Azure Search, or even bots.
Enhance existing or build new SQL Server Analysis Services solutions, tabular models or OLAP cubes used in the business intelligence ecosystem and develop Multi-Dimensional Expression (MDX) queries to extract data from OLAP cubes for reporting and analytical purposes.
Enhance existing or build new enterprise or departmental business intelligence solutions, inclusive of Power BI.
Adhere to or recommend best practice cloud services, database or data engineering, and identity standards and perform team and 3rd party code reviews in accordance with such standards.
Build prototypes or pilots using new technologies.
Present solutions and recommendations to stakeholders.
Testing
Perform unit, integration, or system testing (automated or otherwise) on all developed code and / or system components through stringent routines and procedures to ensure accuracy and solution integrity and that solutions run smoothly with optimum operational efficiency, ensuring all solutions will meet SLAs & performance criteria.
Provide feedback on solutions’ usability, features, and design based on results of testing.
High focus on performing your own data reconciliations during testing phases to ensure that your development work has been completed successfully prior to deployments for user acceptance testing.
Production Support and Maintenance
Provide exceptional support by applying critical thinking skills to troubleshoot, determine the cause of failure, and quickly restore failed components or processes when they occur; Diagnose and remediate resource contention issues and failures in application logs.
Participate in an on-call rotation with the team when necessary, specifically related to customer-facing digital cloud solutions.
Report and escalate issues to 3rd party vendors if necessary.
Conduct monthly reviews of incidents and service requests, analyse, and recommend improvement in quality and work with the internal team on identifying pain points in existing Azure deployments and configuration and ways to alleviate them.
Working experience in hardening cloud production environments for error handling, fault tolerance, self-healing, monitoring and incident alerting and recovery beneficial.
Monitor connections and locks and performance of SQL instances to track historical peak load on servers and proactively working on performance tuning and writing queries for front-end applications.
Manage, monitor, and ensure the security and privacy of data to satisfy business needs.
Other Critical Deliverables:
Legacy Migrations: Migrating on-prem SQL instances and legacy SAS datasets to Azure SQL in development, test, or production environments.
Training and Mentorship: Provide technical training and mentoring to other teams and team members and organize and execute training sessions for the user base of in-house developments for new workflows, procedure recommendations, the availability of data in operational data stores as well as the data warehouse and how to consume the data effectively in business intelligence and analytics tools withing the organization.
Documentation: Originate and maintain documentation for new and existing solutions throughout the solutioning life cycle, covering all applicable functional areas, such as bugs, change requests, operational policies and procedures, solution designs, integration and API specifications, technical specifications, test plans and test results, production control (and / or job scheduling), security administration, TSQL code and logical as well as physical data models where applicable.
Our values: Living the NMG values of Collaboration, Curiosity, Go for It, and Make it Count in all that you do.
YOUR EXPERIENCE & CAPABILITIES
The successful candidate for this role will be able to demonstrate:
Strong organisational abilities and high attention to detail.
The ability to thrive within a small team whilst also working independently.
Agility in approach, reacting positively to change and shifting priorities.
Effective communication skills and the ability to collaborate cross-group or cross-geo.
Working well under pressure with excellent time management skills.
A passion for technical excellence and a flair for user experience and design.
Excellent analytical, process design and problem-solving skills.
Resourcefulness and troubleshooting aptitude.
Ability to communicate technical needs and solutions with non-technical staff and comfortable performing component demonstration for key business stakeholders and project managers.
Technical Capabilities must encompass the following:
Experience in multiple or all Azure components, including: API Management, Event Hubs, Data Factory, Functions, Resource Manager Templates, Storage Accounts, Notifications Hub, Key Vault, DevOps, Data Lake Stores, Data Lake Analytics, Synapse Analytics, Databricks, HD Insight, SSAS, SQL Database or similar cloud infrastructure (5+ years’ experience and deep expertise in data engineering as applied to Azure preferred), including Visual Studio as applied to SSAS development.
In-depth knowledge of standard concepts, practices and procedures related to database modelling (logical and physical) and management, concepts of data lakes, data warehousing and data marts as well as legacy migrations to cloud services.
Infrastructure automation for continuous integration and continuous deployment of technical solutions leveraging Azure Services and Features.
Hands-on experience in scripting languages such as Python, R, etc.
Modern version control Git, SVN, TFS, etc.
Experience that will make you stand out:
Advanced Business Intelligence experience, understanding of BI areas and reporting using SQL, SSAS, Tabular Models and Power BI, including proactive identification of issues and coordination of resolutions.
Applicable Azure certifications including for example Implementing an Azure Data Solution, Designing an Azure Data Solution, Designing and Implementing Microsoft DevOps Solutions.
Familiarity with the Technology stack available in the industry for data management, data ingestion, capture, processing, and curation as well as metadata management: data governance, data quality, master data management, lineage, data cataloguing, etc.
Being able to conceptualize the full project life cycle.
QA testing.
If you are interested in this role and meet the criteria, kindly apply directly at https://nmgconsulting.peoplehr.net/Pages/JobBoard/Opening.aspx?v=ad882e44-6723-48eb-8975-266f874eb075",https://www.mycareersfuture.gov.sg/job/information-technology/senior-data-engineer-nmg-financial-services-consulting-fd0c2a7245d87f4f0aecf62da80f959f?source=MCF&event=Search
35,Data Engineer,INCOME INSURANCE LIMITED,"Responsibilities:
Collaborate with data scientists, coders, programmers and other stakeholders
Creating and managing the AI development process and general infrastructure of a product
Doing statistical analysis and interpreting findings
Automating critical tasks and procedures for a data science team
Creating data transformation infrastructure
Developing AI models communicating the utility of the AI models they generate to a diverse range of employees inside the organisation, including product managers and management executives
Converting machine learning models into APIs with which other apps may interact
Qualifications:
Master / Bachelor’s degree in computer science, computer engineering, or relevant field.
A minimum of 5 - 7 years’ experience in a similar role.
Strong knowledge of Datawarehouse / database / Cloud systems and data mining.
Excellent organizational and analytical abilities.
Outstanding problem solver.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-income-insurance-e61e3801c7fa383d302f9f0b09d5ad6c?source=MCF&event=Search
36,Data Engineer,CENTRAL PROVIDENT FUND BOARD,"As trustee of the nation’s retirement savings, the Central Provident Fund (CPF) Board helps 4 million CPF members save for their retirement, healthcare and housing needs. Every CPF Ambassador plays a vital role in helping Singaporeans save for a secure retirement. So long as you have the passion and commitment to serve the public, you will find your niche in our big family.

Corporate Development
We have a strong corporate development team to engage our staff and support our business operations. There is a wide range of job opportunities from Finance, Audit, Strategic Planning, Risk Management to Human Resource and Organisation Development. If you are meticulous, enjoy planning and implementing internal policies to help meet organisation objectives, this is the job for you.

Job Responsibilities
- Develop, test and maintain the data infrastructure, the data ingestion pipeline, data store and data processing on-premises and cloud.
- Design, build, deploy and manage end-to-end data pipelines for batch and stream processing that can adequately handle the needs of a rapidly growing data-driven organisation.
- Responsible for the building of scalable and reliable ETL processes for the ingestion and integration of large, structured and unstructured data from variety of data sources on-premises and on the cloud platforms.
- Implement and execute data security and data quality measurements to ensure compliance to data security and data governance policies
- Implement analytic tools, analytic applications and user self-service portal for data scientists and business users.

Requirements
- At least 5 years of relevant working experience as a data engineer on data lake.
- Experience with cloud computing environment and familiar with government commercial cloud.
- Experience working with big data ecosystems, Hadoop & Spark architecture and building data-intensive applications and pipelines.
- Experience in installing, configuring and supporting Linux and Microsoft Windows Servers",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-central-provident-fund-board-a576da0da192d751e21c27ce480eadd2?source=MCF&event=Search
37,Data Engineer (ETL),INTEGRATED HEALTH INFORMATION SYSTEMS PTE. LTD.,"Role and Responsibilities
Manage multiple projects and is responsible for the execution from initiation to completion
Determine project goals to ensure the project supports business objectives and strategies.
Develop project plans which include requirements, scope, deliverables, budget and schedules.
Projects tasks and resource requirements and to achieve optimal resource utilisation.
Manage the vendor selection process (calling, evaluation and awarding of tenders).
Evaluate potential solutions and make recommendations to resolve business problems.
Liaise closely with business users and build good rapport.
Liaise closely with vendors in project implementation, application testing, supporting application patches and upgrades in accordance with project methodologies and policies.
Manage the risks that affect the delivery of the project outcome.
Track project deliverables and ensure projects are completed within budget, schedules and quality standards.
Implement process improvements to reduce development time.
Present reports and project updates to stakeholders on a regular basis.
Provide on-going application support and be involved in various stages of the SDLC.
Conduct user requirement analysis for the development / implementation of new systems and for enhancements to existing systems, including involvement in the system integration testing phase.
Perform project implementation and application testing according to project and quality assurance procedures and methodologies.
Conduct end user training for system implementations or enhancements.
Manage a team by monitoring the work progress to meet project requirements for medium to large projects.
Provide 24/7 primary application maintenance standby support.
Provide guidance and coaching to junior team members.
Requirements / Qualifications
· At least 7 years experience in IT Project Management
· At least 3 years experience in vendor management
· Has implemented at least 2 medium to large scale projects
· Solid understanding in Business Processes
· Solid understanding and hands on experience in all phases of project lifecycle
· Experience in budgeting (costing, cost evaluation analysis etc.)
· Experience in various procurement methodology e.g. RFQ, RFP etc.
· Experience in writing approval papers
· Having good communication skills (written and spoken)
· Be a team player
· Being a creative problem-solver, make choices and take responsibility for their own actions
· Ability to interact with all levels of stakeholders
· Ability to perform root cause analysis
· Degree in Computer Science, Computer Engineering or equivalent",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-integrated-health-information-systems-e0fddd0bed9f351358248b48f95b8f62?source=MCF&event=Search
38,"Data Engineer, Associate",MORGAN STANLEY MANAGEMENT SERVICE (SINGAPORE) PTE. LTD.,"Business Background
Position is for a role in TEDRA department.

TEDRA (Trade Enrichment Data Reporting & Allocations) is part of the Institutional Securities Technology (IST) Division.  It is responsible for maintaining, distributing, and reporting on trading, revenue, risk, and reference data (client, product, and pricing). As the authoritative source of key data sets, we are at the forefront of database technology and are heavily involved in data engineering, data science, data visualization, and machine learning efforts across the Firm.

Position Introduction
This is a data engineer role in the team responsible for developing on the firm's Trade Capture data stores that holds the transactional bigdata for real time and archive processing and getting it into the archives and data lake.

The global team consists of highly technical team members who are adaptable and hands on in software development and life cycle management and proficient in devOps. We deliver multiple projects for multiple business areas in parallel. The business owners and subject matter experts will be globally distributed, making communication and pro-active to be important. The candidate will be expected to work closely with our users and support partners.

The development will be performed using an agile methodology which is based on scrum (time boxing, daily scrum meetings, retrospectives, etc) and XP (continuous integration, refactoring, unit testing, etc) best practices. Candidates must therefore be able to work collaboratively, demonstrate good ownership and be able to work well in teams.

Primary responsibilities include:
1. Translate business requirement into queries against a set of relational tables and produce reporting based on the requirements.
2. Design and build scalable and performant databases
3. Database and ETL development, including stored procedures, queries, performance tuning, archiving, etc.; using python, SQL and ETL tools
4. Build efficient automation scripts (using Python etc.)
The current global team members are all very skilled in domain modeling, database design, big data, Java and messaging so this is an excellent opportunity to play a key role in the growing team.

Technical Skills Requirement
* Strong relational database skills especially with DB2/Sybase or/and Greenplum.
* Knowledge of Hadoop/Spark/Snowflake is desirable.
* Create high quality and optimized stored procedures and queries
* Experience with Power Designer or some similar modeling tool.
* Python and Unix / K-Shell
* Strong knowledge base of relational database performance and tuning such as: proper use of indices, database statistics/reorgs, de-normalization concepts.
* Experience with data mining is a big plus
* Familiar with lifecycle of a trade and flows of data in an investment banking operation.
* Experienced in Agile development process",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-associate-morgan-stanley-management-service-d7788732efc54bc6a06c23f7e55677b7?source=MCF&event=Search
39,Data Engineer,SIMULATION SOFTWARE & TECHNOLOGY (S2T) PTE. LTD.,"We are on the lookout for a highly competent, self-motivated Data Engineer to join our team. The ideal candidate will have experience in scaping data from social media platforms and the ability to reverse engineer undocumented APIs.

The Role:
Develop and maintain efficient scripts to scrape data from social media platforms.
Clean and organize data sets for analysis.
Work with the data science team to implement data models and algorithms.
Continuously monitor the performance of the scraping process and make improvements as necessary.
Reverse engineer undocumented APIs and navigate complex web structures to extract data.
Requirement:
A degree in Computer Science from a recognized foreign or local university; a relevant master’s degree will be an added qualification.
2 to 4 years of relevant working experience with data scraping and Web scraping techniques
Strong technical and analytical skill sets.
Familiarity with Python and its libraries for data scraping such as beautiful soup, selenium and scrapy.
Experience with data cleaning and preprocessing
Good presentation skills, both oral and written.
Passionate about innovating, learning new skills and technology.
Interested parties, please send your resume with current & expected salary & date available to agnes.ho@s2t.ai. We regret only shortlisted applicants will be notified.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-simulation-software-technology-bddba62375155de31b9692f8fb4fb6d0?source=MCF&event=Search
40,Data Engineer,RMA CONSULTANTS PTE LTD,"Job Title: Data Engineer
Job Type: Contract - 12 Months(Extendable)
Work Location: Nanyang Drive, Singapore
Working hours : Mon – Thu 8.30am to 5.45pm, Fri 8.30am to 5.15pm

Job Scope: As a member of the Analytics and AI team, the incumbent will collaborate with cross-functional teams to analyze, design, and implement analytics/data science solutions and innovations that will enhance business operations and performance.

Job Responsibilities
Engage business stakeholders to identify, design, and implement Data Analytics (DA)/Data Science (DS) projects, including problem scoping, use case formulation, data sourcing, development, and maintenance of analytical models. Examples of DA/DS projects in organisation includes Learning analytics for the Learn ecosystems, Analytics for Administration, including students’ administration.
Support the development of data strategy and in-house analytics capabilities.
Provide guidance to business units on the application of DA/DS (including solution) to help drive business initiatives e.g., improving the students’ journey and University operations.
Conduct data-driven analysis to drive process improvements or draw out actionable insights, including designing and building data visualization to support management decision making, and aid learning outcomes, as well as enhancing the experience of students’ end-to-end journey in Organisation.
Apply analytical techniques such as data mining, statistical analysis, machine learning etc., and build predictive models to address business challenges, support Learning ecosystems, and enhance administration.
Work closely with relevant teams to productionize analytical models, including tracking and improving its performance.
Familiar with setting up end-to-end processing platform to automate data processing, dashboarding and machine learning will be an added advantage.
Participate in the design and implementation of DA/DS projects of various scales.
Participate in the identification, evaluation, and recommendation of DA/DS solutions.
Participate in the identification of potential use cases for analytics/data science.
Evaluate applications and tools for data analytics, mining and machine learning.
Job Requirements
Minimally 3-5 years of in-depth experience in implementing end-to-end analytics/data science solutions.
Degree in Mathematics, Statistics, Operations Research, Computer Science, Engineering or other related discipline. Poly graduates with relevant experiences are welcome to apply.
Specialization in Data Analytics or Data Science will be an added advantage
Experience in data Extraction / Transformation / Load using SQL, Excel or any other applications.
Experience in using data analytical and visualization tools such as Qlik Sense, Power BI, Python.
Experience in using data mining tool such as Orange or any other applications.
Ability to work collaboratively across teams and quickly breakdown problems and find innovative solutions.
Experience with analytical modelling, predictive analytics, AI and machine learning would be an added advantage.
Experience with using Microsoft Azure AI Platform to deploy automated data processing and machine learning would be an added advantage.
Ability to communicate data-driven findings and ideas to technical and non-technical stakeholders.
Knowledge in deploying solutions in a cloud environment, and in implementing DA/DS solutions will be an added advantage.
Good communication, written and presentation skills.
Good analytical, problem solving and critical thinking skills and meticulous attitude.
Ability to work independently or in a team with minimal supervision.
If your experinece & skills align with this job, please send your updated resume(Word format) to manisha@rmagroup.com.sg to take it forward.

EA License No 93C4403
EA Regn No R1872602",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-rma-consultants-8558cf468f77cfd3afa786a100d8b152?source=MCF&event=Search
41,"Data Engineer, Group Data Office",OVERSEA-CHINESE BANKING CORPORATION LIMITED,"Job Description & Requirements
Based in the Group Data Office – Data Engineering team, you will be responsible for developing and enhancing data pipelines and architecture
Create and maintain the optimal data pipeline to enable ingestion from a wide variety of structured and unstructured data sources via Talend
Working with business users to define and understand business requirements to develop and implement solutions
Support development and deployment of applications utilising the data pipelines to provide actionable insights
Involve in UAT execution with a focus on strategic testing processes and procedures to ensure that business standards and specifications are met
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery and cleansing/transformation
Support various business functions by collaborating with multiple stakeholders – business, IT, and vendors independently
Qualifications
Minimum 4 to 6 years of working experience in Data Engineering, Big Data solutions, and analytics functions
Solid background in traditional structured database environments such as Teradata / Oracle, SQL & PL/SQL
Knowledge on Hadoop ecosystem components such as HIVE, Impala, HDFS, Spark, Scala, HBase
Fluent in structured and unstructured data, its management, and modern data transformation methodologies
Hands-on experience working on real-time data and streaming applications using Kafka or other similar tools
Experience in automation process – building procedures, ETL and automated job scheduling using data integration tool such as Talend
Knowledge on data warehouse and FSLDM concepts
Understanding of banking with exposure to consumer business functions is preferred
Energetic personality with an innovative, self-starting spirit. Someone that likes to ask “why?”",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-group-data-office-oversea-chinese-banking-corporation-d04a854e9beeeb8273b18ebf9979570a?source=MCF&event=Search
42,Senior / Data Engineer,LIBERTY INSURANCE PTE LTD,"We are looking for a Senior / Data Engineer that under limited direction, prototypes/develops data solutions of high complexity to meet the needs of the organization and business customers. This person needs to have a good communication skill to be able to manage project across East markets.
You will use various methods to transform raw data into useful data systems. For example, you’ll create data for pricing modeling and conduct data quality checks. Overall, you’ll strive for efficiency by aligning data systems with E&W modeling teams’ goals.
To succeed in this data engineering position, you should have strong analytical skills and the ability to combine data from different sources. Data Engineer skills also include communication, familiarity with
several programming languages and knowledge of learning machine methods.

Responsibilities:
With a comprehensive understanding of Agile techniques, set expectations for deliverables of high complexity.
Maintains proof-of-concepts and prototype data solutions, and handles any assessment of their viability and scalability, with own team or in partnership with IT.
Ensures data solutions include deliverables required to achieve high quality data.
Displays a working understanding of complex multi-tier, IT | Data teams’ systems, and applies principles of metadata, lineage, business definitions, compliance, and data security to project work.
Experience:
5+ years previous experience as a data engineer or in a similar role.
Technical expertise with data models and data pipeline automation.
Experience with big data tools: Spark, Kafka is a plus.
Experience with as developer with SAS and SQL databases, including Postgres, Oracle and SQL Server.
Hands-on experience with AWS cloud services: S3, Glue, Crawlers, EC2, EMR, RDS, Redshift.
Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc.
Degree in Computer Science, IT, or similar field; a master’s is a plus.
Data engineering certification (AWS) is a plus.",https://www.mycareersfuture.gov.sg/job/engineering/senior-data-engineer-liberty-insurance-996cc1ad77be9295a235a60c80ebe07e?source=MCF&event=Search
43,DATA ENGINEER,SERVICE CONNECTIONS HR CONSULTANCY PTE. LTD.,"CONTRACT JOBS!
(1 year Renewable!)
DATA ENGINEER
(CENTRE FOR IT SERVICES)
SINGAPOREANS/ PRs ONLY
(Salary – $5,000 to $5,200)
LOCATION
Jurong | Pioneer

JOB DESCRIPTION

As a member of the Analytics and AI team, the incumbent will collaborate with cross-functional teams to analyze, design, and implement analytics/data science solutions and innovations that will enhance the tertiary's business operations and performance.

Key Responsibilities
Engage business stakeholders to identify, design, and implement Data Analytics (DA)/Data Science (DS) projects, including problem scoping, use case formulation, data sourcing, development, and maintenance of analytical models. Examples of DA/DS projects in the tertiary includes Learning analytics for the Analytics for Administration, including students’ administration.
Support the development of tertiary’s data strategy and in-house analytics capabilities.
Provide guidance to business units on the application of DA/DS (including solution) to help drive business initiatives e.g., improving the students’ journey and tertiary operations.
Conduct data-driven analysis to drive process improvements or draw out actionable insights, including designing and building data visualization to support management decision making, and aid learning outcomes, as well as enhancing the experience of students’ end-to-end journey in the tertiary.
Apply analytical techniques such as data mining, statistical analysis, machine learning etc., and build predictive models to address business challenges and enhance administration.
Work closely with relevant teams to productionize analytical models, including tracking and improving its performance.
Familiar with setting up end-to-end processing platform to automate data processing, dashboarding and machine learning will be an added advantage.
Key Decisions
Participate in the design and implementation of DA/DS projects of various scales.
Participate in the identification, evaluation, and recommendation of DA/DS solutions for the tertiary.
Participate in the identification of potential use cases for analytics/data science.
Evaluate applications and tools for data analytics, mining and machine learning.
WORKING HOURS
Mondays to Thursdays: 8.30am to 5.45pm
Fridays: 8.30am to 5.15pm (with 45 mins – 1 hour lunch breaks)
Service not required on Saturdays, Sundays and gazetted public holidays.
JOB REQUIREMENTS
Minimally 3-5 years of in-depth experience in implementing end-to-end analytics/data science solutions. Renumeration and appointment grades will be based on experience.
Experience in data Extraction / Transformation / Load using SQL, Excel or any other applications.
Experience in using data analytical and visualization tools such as Qlik Sense, Power BI, Python.
Experience in using data mining tool such as Orange or any other applications.
Ability to work collaboratively across teams and quickly breakdown problems and find innovative solutions.
Experience with analytical modelling, predictive analytics, AI and machine learning would be an added advantage.
Experience with using Microsoft Azure AI Platform to deploy automated data processing and machine learning would be an added advantage.
Degree in Mathematics, Statistics, Operations Research, Computer Science, Engineering or other related discipline. Poly graduates with relevant experiences are welcome to apply.
Specialization in Data Analytics or Data Science will be an added advantage.
Ability to communicate data-driven findings and ideas to technical and non-technical stakeholders.
Knowledge in deploying solutions in a cloud environment, and in implementing DA/DS solutions will be an added advantage.
Good communication, written and presentation skills.
Good analytical, problem solving and critical thinking skills and meticulous attitude.
Ability to work independently or in a team with minimal supervision.
Interested applicants, please email detailed to
SERVICE CONNECTIONS HR CONSULTANCY PTE LTD
Email resume to - servcon@singnet.com.sg / recruit@serviceconnections.com.sg
Call for more details please call at 6333 0052
Mondays to Fridays
9.00am - 5.00pm
111 North Bridge Road #07-30 Peninsula Plaza Singapore 179098

www.serviceconnections.com.sg
License no: 09C4937 / R11022931",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-service-connections-hr-consultancy-c5c4dbca59a1d6cb3e36ced8c4034388?source=MCF&event=Search
44,Data Engineer,INFOSYS COMPAZ PTE. LTD.,"Key Responsibilities :
1. Applications Service Requests
DAGs health checkup & monitoring
Debug & fix DAGs issues
Documentation - Operate Guide
Periodic DAGs resource utilization review
Understand DAGs design & requirement, prior to implementing & takeover from TP/s
Audit support
2. Applications Incidents
User incident support
3. Admin & Reporting
Daily standup meeting with application and platform support team, as well with Customer project team
Monthly reporting, which includes SNOW tickets & AWS utilization costing, to product and business owners.
Timesheet submission
Disaster Recovery (DR) support
4. Business Operation Support
Participate in business requirements gathering
Guide & support business teams on Airflow, minor enhancements and/or data retrieval (3rd parties and/or within Temasek)
Manage 3rd party data provider(s) where appropriate; and onboarding to Airflow.
Detailed Skills:
5 – 7 years of experience working with Airflow, Python, AWS.
Ability to effectively triage and troubleshoot Data Engineering issues.
Well-versed in agile ways of working and familiar with common tools including JIRA and Confluence.
Familiarity with cloud-based technologies and architectures (AWS, Azure or GCP). AWS know-how is preferred.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-infosys-compaz-0b3800d86d0ab243db95768c3908e8ff?source=MCF&event=Search
45,Data Engineer,TATA CONSULTANCY SERVICES ASIA PACIFIC PTE. LTD.,"Job Description

Are you a multitasker and good at managing stakeholders? Would you like to manage the day-to-day activities of the APAC Business Solutions team, leading experienced change staff through Team by Team or Value Stream Optimization projects, support APAC BoW and other initiatives covering Asia Pacific? We're looking for someone who can:
– lead Cloud Transaformation or Migration initiatives pertaining Wealth Management under Finance Domain
– ensure a consistent way in leveraging the Process Excellence Way
– identify transformational levers across the 5 lenses
– coach key stakeholders on their role as lean managers within the lean management system
– coach project teams on tools and methods deployment, and help line managers with the consistent implementation of the PEW
– collaborate with Investment Bank engagement leads and solution design specialists in identifying automation solutions

Job Requirements

1)Work on GCP Migration Task to align with bank initiatives
2) Technical expertise regarding requirements specification, analysis, reviews, track & respond to stakeholder feedback and support end to end change management
2) Front-to-back business process design
3) Use-case definition, documentation and target design of new solutions (mainly from a business point of view)
4) Close interaction with Data team
5) Establish impact assessment and gap analysis related to Google Cloud and Wealth management process and
6) an excellent communicator and highly organized
7) customer orientated and focused on service quality
8) fluent in English both oral and written

Must Have Skills

1) Google Cloud Platform and components like App Engine, Compute Engine, GKE, Data pipelines, Terraform, and Containerization tools, Git/GitHub
2) Oracle 12c/19c, Unix, Python
3) Java, Agile ways of working Experience

Good To Have Skills

1) Knowledg of Wealth Management Domain
2) Dev Ops Skills
3) Datawarehousing concepts",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-tata-consultancy-services-asia-pacific-5fb974bc4cdf16ef5ee5b7aa96e2149f?source=MCF&event=Search
46,Data Engineer,CLPS TECHNOLOGY (SINGAPORE) PTE. LTD.,"• Must have development experience in Big Data, Hadoop, Python, PySpark technologies.

• Proficient in Oracle & PL/SQL with at least experience with the ability to fine tune performance of queries.

• Ability to write complex analytical queries / Stored Procedures / Packages.

• Good exposure to Unix/ Linux OS basic commands and hands on in Shell scripting.

• Experience in L3 Production Support and Analysing & troubleshooting the production issues by engaging other relevant support teams.

• Multi-tasking abilities and should be able to work under stringent deadlines.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-clps-technology-e0b32f9391d7b75e809a63a5555fabf5?source=MCF&event=Search
47,Data Engineer,BIOFOURMIS SINGAPORE PTE. LTD.,"Responsibilities:
Creation and maintenance of optimal Data lake pipeline architectures.
Stay abreast of industry trends and enable successful data solutions by leveraging best practices.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Partnering effectively with inhouse Products, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources and AWS ‘big data’ technologies.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Keep our data separated and secure within national boundaries through multiple AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader
Experience / Training:
7+ years of experience in software engineering and Big Data Analytics.
Prior experience on AWS cloud services EC2, Glue, Athena, S3, EKS, RDS, Redshift, Data pipeline, EMR, DynamoDB, cloud watch.
Experience in creating and maintain Data lake on AWS cloud.
Experience in Big Data analytics tools like Hadoop, Spark, Kafka etc...
Strong experience in collecting data from different source systems and create ETL pipelines to handle complex data sets & uncertain schema changes in data.
Strong experience in Python programming and analytics libraries like Pandas, NumPy etc...
Strong experience on Analytics skills and complex SQL based queries implementation.
Data engineer also need to very passionate about efficient/accurate code development, optimizing performance of organization Data lake.
Good experience in UNIX based shell scripting.
Support to Data scientist team for data availability, extract & provide required data sets.
Coordinating with various teams and clients to provide data based on specific requirements.
Education:
Bachelor/Master/Engineering in IT/Computer science/software engineering or relevant experience.",https://www.mycareersfuture.gov.sg/job/engineering/data-engineer-biofourmis-singapore-2a5f14be78342dfc929402cfc2a65cf3?source=MCF&event=Search
48,Data Engineer,UNITED OVERSEAS BANK LIMITED,"Take end-to-end development ownership for one or more modules and deliver to production
Understand functional requirements / user stories and come up with effective solutions by breaking down into meaningful tasks
Participate as a member of agile team and deliver high quality software
Manage multiple projects at the same time
Guide and support other members of the team, including temporary staff to perform effectively in their role
Communicate with other stakeholders like other project teams, infrastructure & security teams as required and manage dependencies
Understand and follow UOB software delivery process & deliverables, ensure process compliance
Create a network with other departments and teams, to know about strategic issues and new developments
Understand long terms strategic plans for the department and support towards the same
Possess personal courage to do what is right and work as a team member to meet customer expectations
Continuously prioritize technical debt for the team and ensure they are taken care in project releases
Participate in sprint meetings (planning, review) and estimate stories, breakdown to tasks
Prepare for sprint demos and demonstrate to Product Owner, receive feedback and implement
Exhibit good attention to detail and enthusiasm to take ownership
Requirements:

Degree in Computer Science or related discipline
0 to 2 years of working experience.
Strong knowledge and experience building Apache Kafka applications
Strong working experience with Java, Spring Boot and API (Microservices)
Experience building data pipelines with Apache NiFi in production scale
Experience building data streaming applications using Apache Spark and Kafka Streams
Experience working with a variety of data sources and sinks (API, MQ, Files, Databases, Hot lakes, Big data systems etc.)
Experience with both SQL and NoSQL databases (like MariaDB, Oracle, MongoDB) and Object-Relational Mapping (ORM) frameworks (e.g. Hibernate)
Experience with CI/CD practices and tools (Bitbucket, Jenkins, Artifactory, Veracode etc.) to build pipelines
Familiarity with Agile development methodologies
Experience with software design and development in a test-driven environment
Experience tuning Kafka and NiFi components for varying traffic and performance requirements
Ability to learn new programming languages and technologies
Excellent communication skills to interact within and outside the team",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-united-overseas-bank-d2c92e6bf7c16f8ff7e68a45832e6ee2?source=MCF&event=Search
49,Senior Data Engineer,ADNOVUM SINGAPORE PTE. LTD.,"What you’re going to do
Design, construct, install, test, and maintain data management systems
Build high-performance algorithms, predictive models, and prototypes
Ensure that all systems meet the business/company requirements as well as industry practices
Integrate up-and-coming data management and software engineering technologies into existing data structures
Develop set processes for data mining, data modeling, and data production
Create custom software components and analytics applications
Research new uses for existing data
Employ an array of technological languages and tools to connect systems together
Install/update disaster recovery procedures
Recommend different ways to constantly improve data reliability and quality

What we’re looking for
Bachelor’s degree in computer science or similar
Min. 5 years’ proven experience as a Data Engineer or similar
Proficient in Data Modelling, Data Architecture , ETL, Data warehousing, Data Lake.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Proficient in one or more scripting language (e.g Python, R)
Experience in Apache Hadoop based analytics coving data processing, access, storage, governance, security, and operations.
Experience in Cloud based Big Data technologies.
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Prior data streaming experience with Spark/Python,...
Knowledge in deploying microservices
Creative thinking backed by strong analytical and problem-solving skills

Sharp minds, good vibes

We are the sharp-minded IT experts who tackle the trickiest software and security challenges. With more than 630 employees in our locations in Zurich (HQ), Bern, Lausanne, Budapest, Lisbon, Singapore, and Ho Chi Minh City, we make the digital business of our clients work.
As a great team, we empower each other to share, grow and succeed. The unique Adnovum spirit across locations stands for helping each other at any time, having an open door and contributing to an appreciating and trustful atmosphere. We always enjoy having a laugh, a coffee or a drink together!
Apart from our unique «one Adnovum» spirit, we offer a solution-oriented engineering culture with flat hierarchies, which gives you the opportunity to contribute with your opinions and ideas. We embrace flexible working, like the possibility to work part-time and a hybrid work model. Your continuous education and development are key to us. Therefore, we actively encourage and support individual training opportunities.
For data privacy reasons, we only accept applications submitted via our online portal. Applications received by e-mail cannot be processed. Thank you for your understanding.

Adnovum accepts only direct applications. Any applications submitted by recruitment agencies without contractual agreement will be treated as direct applications.",https://www.mycareersfuture.gov.sg/job/information-technology/senior-data-engineer-adnovum-singapore-9e0893e61542fd4e2478a6e4f781aada?source=MCF&event=Search
50,Senior Data Engineer,AMPLIFY HEALTH ASIA PTE. LIMITED,"Instructions for interested applicants
Please apply for this position via the following link https://aia.wd3.myworkdayjobs.com/en-US/amplifyhealthexternal/job/Senior-Data-Engineer_JR-35657
What you will do?
The role entails building a reusable sustainable framework to ensure collection, processing and availability of high-quality health care data to enable us to achieve the core purpose. The Data Engineer will work collaboratively with the Program Managers, Data Scientists, Systems Architects to define data sources and to build a custom data framework that facilitates Machine Learning, AI and productionising AI models based on the principles of ETL/ELT. Together these teams will enable data driven actionable insights.
The role is based in Singapore.
Core responsibilities include:
Develop and implement a reusable architecture of data pipelines to make data available for various purposes including Machine Learning (ML), Analytics and Reporting
Work collaboratively as part of team engaging with system architects, data scientists and business in a healthcare context
Work comfortably with structured and unstructured data in a variety of different programming languages such as SQL, R, python, Java etc
Understanding of distributing programming and advising data scientists on how to optimally structure program code for maximum efficiency
Build data solutions that leverage controls to ensure privacy, security, compliance and data quality
Understand meta-data management systems
Orchestration architecture in the designing of ML/AI pipelines
Deep understanding of cutting-edge cloud technology and frameworks to enable Data Science
System integration skills between Business Intelligence and source transactional
Improving overall production landscape as required
Write unit tests and participate in code reviews
Define strategies with Data Scientists to monitor models postproduction
What skills do you need?
Behavioural skills
A passion for programming and working with data
Self-starter
Experience of leading a team to deliver solutions
Willingness to learn and grow exponentially
A restless curiosity in learning new technology
Ability to work cohesively in a team environment and balance multiple priorities
A team player who can work alone when required and without supervision
High level of attention to detail, resilience, enthusiasm, energy and drive
Positive, can-do attitude
Ethical and able to maintain confidentiality and manage boundaries
Technical understanding
Essential:
Advanced database knowledge in SQL
Advanced MS Azure tools such as
Azure Data Factory
Synapse Analytics
Azure Data Lake Gen2
Azure Databricks
Modern Azure datawarehouse skills
Experience working on large and complex datasets
Advantageous:
Programming languages such as
R
Python
Scala
Java
Unix/Linux admin experience including shell script development
Exposure to AI or model development
Knowledge of:
Azure stream analytics
PowerBI
Azure ML Services
ML Flow
Understanding and application of Big Data and distributed computing principles (Hadoop and MapReduce)
ML model optimization skills in a production environment
Production environment machine learning and AI
DevOps/DataOps and CI/CD experience
Kubernetes and container setup and configuration
Feature store design and development
Master data management
Qualifications
The following requirements are preferred:
Honours or Master’s degree in BSc Computer Science
Honours or Master’s degree in Engineering or Software Engineering with solid experience in data mining and machine learning
Other qualifications will also be considered if accompanied by the relevant experience
10 to 15 years of experience is preferred",https://www.mycareersfuture.gov.sg/job/others/senior-data-engineer-amplify-health-asia-478c742579c96951b990bf8631ca87d9?source=MCF&event=Search
51,Data Engineer,ENCORA TECHNOLOGIES PTE. LTD.,"Build and support data lake, data warehouse and data API based solutions in Singapore by using suitable technology
Document data solutions, standards, requirement specifications, and business processes
Design, develop and implement secured, reliable, cost effective and high performance ETL solutions using Python, Pyspark and Talend
Perform unit testing, design & support integration testing strategies and automate data quality monitoring
Develop good understanding of existing data sets and data model
Develop good understanding of existing solutions and be able to support and enhance them
Establish and follow best practices in code version control & deployment and help to reduce the deployment time
Monitor scheduled jobs and reduce BAU monitoring efforts by automation
Take ownership and manage timely completion of deliverables
Maintain good documentation of the solutions and effectively communicate stakeholders about the value added
Minimum 5 years of professional experience in big data, data warehousing, operational data stores, and large-scale architecture and implementations

Ability to understand and write SQL
Ability to work with SQL/NOSQL database management systems and data warehouses
Hands on experience in AWS/Azure/Google cloud services
Using distributed computing frameworks like Apache spark using python or scala
Developing data processing python programs based on Pandas and related libraries
Knowledge in orchestration tools like Apache Airflow or similar tools
Good experience in ETL tools like Talend, Informatica or DataStage
Knowledge in stream processing frameworks like Apache Kafka or AWS Kinesis or similar frameworks
Using Change data capture systems like IBM Infosphere CDC or Attunity or AWS DMS or similar tools
Shell scripting to automate tasks",https://www.mycareersfuture.gov.sg/job/insurance/data-engineer-encora-technologies-59a898519fcd275b3afacae696f97dc3?source=MCF&event=Search
52,Data Engineer,HELIUS TECHNOLOGIES PTE. LTD.,"Title: Data Engineer

1. Identify areas for improvement.
2. Prepare proper documentation on proposed new design.
3. Develop optimisation code based on the new design.
4. standardize the normal course of work to streamline current processes and improve accuracy.
5. Ensure completeness and reduce turnaround time when delivering Finance MIS results to Business Finance users",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-helius-technologies-fb2018cf2b9db46973e5a700a488c2e4?source=MCF&event=Search
53,Data Engineer,SOFTENGER (SINGAPORE) PTE. LTD.,"Data Engineer:
· 3 or more years of experience with Python, SQL, and data visualization/exploration tools
· Familiarity with the AWS ecosystem specifically RedShift and RDS
· Communication skills, especially explaining technical concepts to non-technical business leaders
· Comfort working in a dynamic, research-oriented team with concurrent projects",https://www.mycareersfuture.gov.sg/job/banking-finance/data-engineer-softenger-b65aaca47c27f72b3d70bb42a994769b?source=MCF&event=Search
54,Senior Data Engineer,SOFTENGER (SINGAPORE) PTE. LTD.,"Senior Data Engineer

POSITION OVERVIEW :

Collaborate with data management and governance team and IT to analyse and translate requirements to design end-to-end data pipelines that supports data management processes and data quality assessment and monitoring.

Responsible for building, deploying and managing these data pipelines and workflows. It involves data ingestion, data transformation and integration to Enterprise data governance (EDG) platform.
Ensure best practices and standard development protocols are applied. Perform periodic review to ensure the performance of data pipelines remain efficient and sustainable.
Provide support for SIT, UAT and Production implementation.
Prepare technical documentations.",https://www.mycareersfuture.gov.sg/job/banking-finance/senior-data-engineer-softenger-db9bc61118933e02d3e3ab50ea2ffaba?source=MCF&event=Search
55,Data Engineer,TRINITY CONSULTING SERVICES PTE. LTD.,"· Bachelor’s degree/Diploma in Computer Science, Computer Studies, Information Technology, or related disciplines
· 5+ years of experience in software development
· Minimum 2 years of experience with Snowflake
· Minimum 3 years of designing, building and operationalizing data solutions and applications (with batch or streaming data)
· Excellent understanding on SQL data storage structures and storage/query optimizations
· Mastered SQL querying to build any data presentations using joins, reference tables, groupings, statistics etc.
· Proficient in at least one core language: Python, Scala, Java
· Exposure to concepts like Serverless computing, CI/CD, Containerization, Infrastructure as Code, code version control and automated testing
· Exposure to one of more of cloud services like AWS, Azure or GCP
· Excellent communication and presentation skills",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-trinity-consulting-services-e76f33ae5779295f960f0a5c84cafcc6?source=MCF&event=Search
56,Data Engineer,MAXEON SOLAR PTE. LTD.,"Maxeon is seeking a Data Engineer to design and build databases, Big Data Platforms, Datawarehouse, ELT, ETL pipelines for the Industry 4.0 data program. The position will be based in Singapore. The Data Engineer will report to the Senior for industry 4.0 data program. This person will closely work with Project Lead, Data Analytics Lead, implementation partner and other key project stakeholders. The candidate for this role will need to have a meticulous eye for data and appreciates the process of manipulating, storing and understanding data. This person will closely work with a team of experienced data experts, analyst and business resources to build databases, data warehouses and ETL/ELT pipelines as part of Industry 4.0 data program.

· Work with Industry 4.0 data program team which includes project implementation vendor resources, data experts from manufacturing engineering team, data analysts & business stakeholders.
· Support end to end set up of data platform which is scalable and future proof for Maxeon based on the functional/non-functional & technical requirements.
· Integrate data platform with Maxeon Applications and 3rd party system as required from both On-Premise and Multi Cloud.
· Expand and optimize our data and data pipeline architecture, as well as optimize data flow systems in a secured and scalable manner.
· Assemble large, complex data sets that meet functional / non-functional business requirements, transforming data into formats that are easy to consume and analyze.
· Translate complex business requirements into scalable technical solutions meeting data warehousing design standards.
· Solid understanding of analytics needs and proactiveness to build generic solutions to improve overall efficiency.
· Data Profiling & Cleansing of data by applying data quality checks before ingesting the data.
· Ingest, transform, process and store data efficiently into a database, data lake or Datawarehouse platform hosted on premise or cloud based environment.
· Design & Build database, Enterprise Datawarehouse design and data modelling. To be able to organize data at both macro and micro level and provide logical data models for the consumers.
· Build data foundation to provide an enterprise view of data across the organization which can be seamlessly accessed by Business users through Self-Service reporting.
· Build a centralized data repository (Sand Box environment) with a robust data foundation to enable data discovery, data mining for advanced analytics usecases.
· Work with stakeholders including the Product owner, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
· Work with data and analytics experts to strive for greater functionality in our data systems.
· Able to communicate effectively, both written and verbal, with technical and non-technical multi-functional teams.

Knowledge and Technical Skills:
· Bachelors degree in Science or Information Technology
· Certified in Data & Analytics Cloud based solution
· Proven track record in designing and implementing large-scale data solutions, performing architectural assessments, optimizing data models, establish and enforce engineering guidelines and standards on Cloud based environments
· 4+ years of experience in technical architecture, design & build of Data & Analytics projects in a multinational organization on On-Premise & Cloud based solutions.
· In-depth experience in working with a data warehouse and knowledgeable on data warehouse modelling techniques
· Highly knowledgeable in ETL/ELT processes, both design and implementation using various leading tools like for example Informatica, Ab-Initio, Talend etc
· Experienced in implementing data pipelines for stream and batch ingestion/processing using Open-Source tools (Kafka, Apache Spark) as well as Cloud Native solutions.
· Good experience in building data pipelines that ingests various types of data sources (structured, semi-structured and unstructured) into a database or data lake and populating a structured warehouse or data mart
· Experienced in building data lake (distributed storage, Object store), databases & Datawarehouse in cloud (AWS, Azure, GCP), moving data applications to the cloud, and developing cloud native data applications.
· Experienced in implementing SQL, NoSQL databases & MPP databases
· Experience in Data archiving & Life Cycle Management.
· Data Warehouse design, BI reporting and Dashboard development.
· Prior experience in leading a team of technical developers will be a plus
· Advanced SQL and Python skills are mandatory
· Prior data modeling (dimensional, relational) and data engineering experience is mandatory
· Prior experience in leading a team of technical developers will be mandatory
· Strong understanding of development processes and agile methodologies is necessary

Complexity:
· Works on problems and projects of diverse complexity.
· Engages in analyses requiring evaluation of identifiable factors.
· Exercises independent judgment within generally defined boundaries.
· Networks with senior individuals, internally and externally, within own area of expertise.

Safety Compliance
Your safety is our number one priority at Maxeon. All our employees must complete regular workplace safety training and comply with our mandatory safety standards.

Equal Employment Opportunity
It is Maxeon’s policy to provide equal employment opportunity to all applicants and employees. Maxeon will not tolerate unlawful discrimination against any applicant or employee because of race, color, national origin or ancestry, gender (including pregnancy, childbirth, or related medical conditions), gender identity, ages, religion, disability, family care status, veteran status, marital status, sexual orientation, or any other basis protected by national, local, state or federal laws or regulations.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-maxeon-solar-301d5060a4e293563e19eb71310d42f0?source=MCF&event=Search
57,Data Engineer,ALUMNI SERVICES PTE. LTD.,"Alumni Services is a global digital transformation management consultancy with offices in Singapore, Hong Kong, Australia, UAE and the UK providing high-end expertise to industry leading clients to drive real business improvement through disruptive technologies. We offer advice, provide technology, transformation, and people change expertise to deliver real impact. Our global team are hand-picked experts located all over the globe, with executive-level experience in tech-focused MNCs, consultancies, and start-ups.

Alumni Services are looking for a Singapore based Data Engineer to join our growing team of analytics experts.
The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.

Responsibilities will include:
Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
What We Offer
A vibrant and entrepreneurial culture where we fuel and realise your ambition
The chance to work with and learn from a group of global experts in their field
Career progression, training, and professional development
Access to global clients and well-known brands across a broad range of industries including Telecoms, Financial Services, Government, Hospitality, and Logistics
Competitive salary and benefits
Experience
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Experience supporting and working with cross-functional teams in a dynamic environment.
Qualifications
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. They should also have experience using the following software/tools:
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Characteristics
Self-directed and comfortable supporting the data needs of multiple teams, systems and products.
Excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
Excellent communicator with Leadership skills and ability to influence the executive team and their direct reports cross-functionally.
Demonstrates a hunger for technology and continuous learning mindset.
Self-Starter with pro-active approach and solution focused working style.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-alumni-services-1fb020b3cd6daaf260494a0245235fa2?source=MCF&event=Search
58,Data Engineer,RECRUIT EXPRESS PTE LTD,"Responsibilities:
Design and build resilient and efficient data pipelines for both batch and real-time streaming data
Architect and design data infrastructure on cloud using industry standard tools
Execute projects with an Agile mindset
Build software frameworks to solve data problems at scale
Collaborate with product managers, software engineers, data analysts and data scientists to build scalable and data-driven platforms and tools
Ensure data integrity and scalability through enforcement of data standards. Improve data validation and monitoring processes to proactively prevent issues and quickly identify issues. Drive resolution on the issues.
Define, understand, and test external/internal opportunities to improve our products and services.
Requirements:
Bachelor’s Degree in Computer Science or have equivalent professional experience
Solid Experience with data processing tools such as Spark, Flink
Solid Experience implementing batch and streaming data pipelines
Solid experiences in Python/Go/Scala/Java.
In-depth knowledge of both SQL and NoSQL databases, including performance tuning and troubleshooting
Familiar with DevOps tools such as Git, Docker, k8s
Experience with the cloud (e.g. AWS, Ali Cloud, GCP, Azure)
Be proficient in SQL, familiar with advanced SQL features such as window functions, aggregate functions and creating scalar functions/user-defined functions.
Proven successful and trackable experience in full end-to-end data solutions involving data ingestion, data persistence, data extraction and data analysis.
Self-driven, innovative, collaborative, with good communication and presentation skills
Preferred Qualifications:
Experience in FinTech, eCommerce, SaaS, AdTech, or Digital Wallet business industries.
Experience in working with teams across offices and timezones is a plus.
Experience in big data tools such as Amplitude/Tableau/QlikView, Ali Cloud DataWorks, MaxCompute, Hadoop, Hive, Spark and HBase is a big plus.
EA Licence No: 99C4599
CEI Reg No: R1104662
EA Personnel: Celine Tan Si Ling",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-recruit-express-10ffa2ac5fb9ca0741701d946a5e7076?source=MCF&event=Search
59,Data Engineer,INFINEUM SINGAPORE LLP,"Position Summary
The Digital & Analytics Centre of Excellence (D&A CoE) is an independent team that helps fast track and spearhead our digital & analytics capabilities across the organisation. The D&A CoE is designed around key pillars, with Delivery and Execution being the one responsible for Infineum’s effective use of data to provide high value solutions to the business.

The Data Engineer is responsible for collaborating across the business and working with heterogenous data sources to build, manage and optimise data pipelines on Infineum’s Data and Analytics Platform to maximise the business value from our data. The Data Engineer will also ensure compliance with data governance and data security requirements.

The Data Engineer will play a pivotal role in operationalizing prioritised data and analytics initiatives within Infineum’s digital portfolio. This role will require both creative and collaborative working with Data Architects, Data Scientists, Analytics Developers, IT experts as well as directly with key business stakeholders. This role will involve evangelizing effective data management practices and promoting better understanding of data and analytics.

The Data Engineer position is an emerging role in Infineum’s Digital and Analytics CoE and as such the successful candidate will have the opportunity to drive the development of data engineering tools, processes, and procedures by collaborating with D&A CoE and broader IT teams.

This Data Engineer role is accountable to the Delivery and Execution Leader within the Digital and Analytics Centre of Excellence.

Key Outputs: What we can expect from you
Collaborate closely with business users, domain experts, architects, analytics developers, and data scientists to rapidly design, build and embed data pipelines
Design and maintain data models to support business analytics
Drive automation using modern data and analytical tools to develop repeatable data integration and data preparation flows from multiple source systems into our data lake and enterprise data warehouse systems
Maintain data pipelines ensuring on-going adoption of automation and incorporation of best practice
Work side by side with Data Scientists to understand business problems and support the integration of diverse data sets to support data science and advanced analytics activities
Collaborate with business, D&A CoE, and broader IT colleagues to evangelise data management. Act as a ‘data guru’ and work across business silos to promote better understanding of data and analytics.
What will you gain from this role?
Opportunity to influence the build of a new data and analytics platform
Work closely with the Architecture Working Group to define data engineering and data architecture strategies
Skills in defining and developing data engineering processes and best practices for use internally and with our technical partners
Exposure to a wide variety of technologies and data engineering challenges as we continue to further develop our digital capability
Work in a global environment interacting with all regions and functions at Infineum
A successful candidate is likely to have:
Bachelor’s Degree in Computer Science, Engineering, Business or equivalent discipline
5 or more years of experience in a Data Management discipline including experience in data warehousing concepts and data modelling.
Strong experience working with heterogeneous datasets in building and optimizing data pipelines, pipeline architectures and integrated datasets using Talend and Azure Data Lake
Experience of working with Snowflake to build data warehouses / data marts, and experience of working with data from SAP, manufacturing, or research systems is strong plus but not required/compulsory
Basic understanding of popular open-source and commercial data science tools and platforms such as Python and Azure ML is an advantage
Experience working in a virtual team setting and self-driven with desire to take the lead and drive tasks to completion in a remote environment
Detail-oriented and strict attention to details and the ability to quickly spot and fix problems
Able to stay abreast of Data Engineering industry trends",https://www.mycareersfuture.gov.sg/job/others/data-engineer-infineum-singapore-6978fa0af8ef9282b2370e29ca7b78d1?source=MCF&event=Search
60,Data Engineer,U3 INFOTECH PTE. LTD.,"Job Description:
Support PEG projects
Support new Allegro data migration from GEMS to Master Data Management (MDM) for PEG.
Job Requirements:
Must have
Bachelor Degree in Computer Science, Computer Engineering or equivalent.
At least 5 years' experience of working as a data engineer via organization legacy systems.
Solid working knowledge of implementing ETL pipelines using Informatica BDM (DEI) on data warehouses and big data platforms, such as RDBMS, Informatica etc.
Familiar with application integration with RDBMS such as Oracle, MS-SQL or MySQL. Working knowledge of Oracle and MS-SQL will be a plus.
Hands-on experience of using Linux (or Unix-like OS) as the development environment and familiar with shell scripts and command line tools in Linux/Unix environment.
Possess experience in Systems Development Life Cycle implementation methodology (SDLC) and/or Agile methodologies like Scrum and Kanban.
Able to understand and apply the good industry practice of code versioning, testing, CICD workflow and code documentation.
Good team player, with strong analytical skills and enjoy complex problem solving with innovative ideas.
Strong communication/people skills are required to interact with data analysts, business end-users and vendors to design and develop solutions.
Good at working with details and meticulous for operations.
Nice to have
Big Data Platforms - Informatica, Snowflake, Kafka
Programming and Scripting - Python, .NET, Java
SQL Databases - Oracle, MS-SQL",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-u3-infotech-6d1638d1459ba98ac685604698a07ce4?source=MCF&event=Search
61,Data Engineer,CAREERSTAR INTERNATIONAL PTE. LTD.,"Looking for a stable IT position in the banking industry? Our client, an award winning organisation, is looking for a Data Engineer.

Job responsibilities:

• Perform administration and support of Enterprise grade critical production database.
• Play a key role in architecting database architecture and relevant infra deployment.
• Plan, design and set standards for database operations.
• Hand-on implementation and troubleshooting in multiple database technologies like Sybase, MongoDB and MariaDB
• Manage schema, access controls, and perform regular optimization checks.
• Implement database level replication, configure database backup, and assist OS platform team in configuring VCS high availability.
• Implement monitoring and alerting using scripts and automation. Deploy the code via CI/CD pipeline.
• Perform Database upgrades, patching, archiving to S3 object storage.
• Perform database tuning, SQL code reviews, assist application in optimizing LRQ and relevant troubleshooting.
• Configure batch jobs using schedulers like TWS.
• Build Grafana/Kibana dashboards, ingest the relevant DB logs in logging platforms, build monitoring metrics using custom SQL query for continuous monitoring.
• Build docker image for database, author custom scripts to deploy DB as a container.
• Perform continuous engagement with application support team and assist in preparing audit reports.
• Prepare management reports, presentations and run workshops, sessions for user community

Requirements:
• Hands-on experience in Enterprise-grade Production Database administration and Support
• Expertise in Relational and No SQL database is required.
• Hands-on experience in databases like Sybase, MongoDB and MariaDB is preferred
• Database schema creation, management, and ensuring data integrity.
• Performance management tuning, Implementing robust backup and recovery
• Run SQL code reviews and walk-through application teams. Have necessary procedural skills
• Experience in capacity planning and general Linux/Unix system/networking skillsets is required.
• Good know-how about storage management, replication setup of database.
• Hands-on experience in automation and scripting.
• Familiar with batch jobs, shell scripts, enabling monitoring and dashboarding for database stacks.
• Experience in DevOps toolsets and Container platform deployments would be a plus
• Self-driven, strong, committed, and reliable team player. Ability to contribute to discussions on design and strategy. Good written and oral communication skills.
• Minimum of 7 years technology experience (preferably in the financial industry).

Sng Yi Lin
E.A. Lic. No: 03C3254 R22106344",https://www.mycareersfuture.gov.sg/job/banking-finance/data-engineer-careerstar-international-a17e831ea0b43b6ca7c78b06e4426216?source=MCF&event=Search
62,Data Engineer,QUANTEXA PTE. LTD.,"Founded in 2016 with only a handful of individuals, Quantexa was built with a purpose that through a greater understanding of context, better decisions can be made. 6 years, 10 locations and 600+ employees later we still believe that today. We connect the dots within our customers data using dynamic entity resolution and advanced network analytics to create context, empowering businesses to see the bigger picture and drive real value from their data.

Due to the continuous success and high demand from our customers, we are looking for Data Engineers with a proven track record and who are looking for an opportunity to learn new skills and progress their careers in a dynamic and exciting start-up environment. 🚀

What does a Data Engineer role at Quantexa look like?
In order to be a successful Data Engineer at Quantexa, you’ll need to be comfortable dealing with both internal and external stakeholders. You will be managing, transforming and cleansing high volume data, helping our Tier 1 clients solve business problems in the area of fraud, compliance and financial crime.

Being Agile is an integral part to the success we have at Quantexa and having regular team sprints and Scrum meetings with your Projects team is essential. You’ll be working closely with Data Scientists, Business Analysts, Technical Leads, Project Managers and Solutions Architects, with everyone following the same goal of meeting our clients expectations and delivering a first-class service. 🥇

We want our employees to use the latest and leading open source big-data technology possible. You will be using tools such as Spark, Hadoop, Scala, Data Fusion, Entity Resolution and Elasticsearch, with our platform being hosted on both private and public virtual clouds, such as Google cloud, Microsoft Azure and Amazon. Our primary language is written in Scala, but don’t worry If that’s not currently your strongest language, we make sure that every Quantexan goes through our training academy so they’re comfortable and confident with using our platform.

Typical responsibilities include:
· Write defensive, fault tolerant and efficient code for data processing.
· Automate data processing to enable on-going alerts on high-risk activity.
· Participate in customer workshops and refinement sessions, presenting project results to clients both face to face and virtually.
· Work very closely with data scientists to ensure efficient and effective delivery of solutions.
· Use leading open source big-data tools, such as Spark, Hadoop, Scala and Elasticsearch. You should be comfortable with working with high profile clients, including on their sites.
· Work with our expert software development team to produce reusable applications.
· Use emerging and open-source technologies such as Spark, Hadoop, and Scala.
· Collaborate on scalability issues involving access to massive amounts of data and information.
· Take on ad-hoc tasks as required for the running of a small, yet rapidly expanding business.
What do I need to have?
· Proven big data experience, either from an implementation or a data science prospective.
· Several years of hands-on experience working as part of an engineering development team, ideally in SCRUM.
· Arrive with experience at working with a variety of modern development tooling (e.g. Git, Gradle, Jenkins, Nexus) as well as technologies supporting automation and DevOps (e.g. Ansible, Chef, Puppet, Docker and a little bit of good old Bash scripting).
· Excellent technical skills including hands-on knowledge of at least one big data technology such as Spark, Hadoop, or Elasticsearch.
· Experience with MVC frameworks such as AngularJS
· Experience of building data processing pipelines for use in production “hands off” batch systems, including either (or preferably both) traditional ETL pipelines and/or analytics pipelines.
· Strong coding experience in the likes of Scala, Java, or Python.
· Enthusiasm to learn and develop emerging technologies and techniques.
· Exhibit strong technical communication skills with demonstrable experience of working in rapidly changing client environments.
· Demonstrate strong analytical and problem-solving skills and the ability to debug and solve technical challenges with sometimes unfamiliar technologies.
· Strong academic qualifications and come from a software engineering background or other scientific degree incorporating IT modules (e.g. Maths/Physics).",https://www.mycareersfuture.gov.sg/job/consulting/data-engineer-quantexa-4d8926c53b11d9a951cc316a61656a17?source=MCF&event=Search
63,Data Engineer,ST ENGINEERING AEROSPACE LTD.,"Job Description
Engage in and improve lifecycle of infrastructure services from inception and design through development, deployment and refinement.
Develop web applications using ASP.Net MVC, C# and ASP.Net Web API, following the development standards and technical design provided
Understanding of best practices in software development process (SDLC) including coding standards, code reviews, design patterns, source control and object-oriented programming.
Tap knowledge from domain experts and write SQL scripts to manage & query databases to extract & generate required data for analysis.
Ability to develop web-based dashboards to show the results for internal & external customers is preferred.
Supports and develops software engineers by providing advice, coaching, and educational opportunities.
Develop software solutions by studying information needs conferring with users studying systems flow, data usage and work processes
Document and demonstrate solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code
Design and architect new software product for data analytics
2nd level user support for application interface issues across systems
Analyse issues and work with other team members to identify root cause to prevent future occurrences
Requirements and Skills
5 to 7 years of relevant experience in core software development using Microsoft technologies.
Working knowledge of C#, ASP.Net, MS SQL, JavaScript
ASP.NET Web API and Windows Services, SOAP, JSON
Experience with WPF framework will be an added advantage
Working knowledge in MSDN, TFS and SVN.
Degree in Engineering or Computer Science or IT
Hands on experience in technical design patterns, development and documentation.
Strong in SQL server complex SQL query and Stored procedure development (4+ years)
Experience in Software product development",https://www.mycareersfuture.gov.sg/job/engineering/data-engineer-st-engineering-aerospace-a83450e5264d5a57bc1b1e856d664e4d?source=MCF&event=Search
64,Data Engineer,VUI SYSTEMS PTE. LTD.,"Roles and Responsibilities:
• Ability to extract required data from data warehouse, source systems, flat files for analytics use cases
• Create data ingestion pipelines and deploy the same in production for real-time analytics
• Analysing raw data, including pre-processing of data, addressing data quality issues
• Developing and maintaining datasets
• Conduct complex data analysis and report on results
• Prepare data for prescriptive and predictive modelling
• Combine raw information from different sources
• Create data model on which the analytics would be built.

Skills Required:
We are looking for a candidate with 4+ years of hands on experience in a Data Engineer role.

Experience using the following software/tools:

AWS Data Engineer/ S3 / Lambda/ Python/ Redshift/ Sagemaker/ DevOps

• Experienced in python

• Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.

• Experience supporting and working with cross-functional teams in a dynamic environment.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-vui-systems-ab8b8a59cc2cd61529925dc06c308462?source=MCF&event=Search
65,Data Engineer,ASMPT SINGAPORE PTE. LTD.,"ASM Data Engineer
As ASMPT is rapidly growing, we embark to become a data-driven organization and are expanding our data platform. We seek an individual with strong passion in Data Engineering who will be comfortable to work in both on-premise and Cloud environments to build the data platform to support structured & unstructured datasets. You will be able to use different tools or create customized tools to transform and load data, administrate databases such as SQL and Hadoop, as well as implementing machine learning models for AIoT (Artificial Intelligence of Things).

Your Responsibilities
Manage and support on-premise and Cloud-based data lake and warehouse systems
Design, build, support and optimize new and existing data structure and ETL processes
Build scalable and efficient data pipelines & services to help analytics teams to process the data
Design useful dashboards and visualisation tools to display data insights and prediction/forecasting results
Liaise with third party tool providers to understand and improve data workflow
Work closely with data scientists and data analysts to deliver analytical solutions with robust underlying data platforms
Work with business team and data analysts to understand business requirements and build efficient and scalable data solutions

Minimum Qualification
Bachelor Degree in Computer Science, Software Engineering, Information Technology or any related disciplines
At least 2 years’ experience in data engineering, automation and integration is preferred
Strong programming and scripting skills in Python and other modern programming languages
Strong data management, schema design and SQL development skills
Deep understanding of databases and best engineering practices – which include logging, scaling up computation, continuous integration and continuous development (CI/CD)
Self-motivated and proactive, willing to learn new things
Good communication skills and strong team player

What our preferred candidates have?
Passionate in dealing with data, learning new data technologies, and discovering innovative and interesting solutions
Understand and experienced with Cloud platform, eg. Microsoft Azure, AWS, GCP
Business intelligence and reporting tools, eg. Power BI, Tableau, Qlik, etc
Experienced in development using Big Data platform (Hadoop/Hive/Hbase/Spark, etc.)
REST/Web API development and management
Knowledge in Statistical software is an advantage
Experience In building machine learning models is a plus",https://www.mycareersfuture.gov.sg/job/engineering/data-engineer-asmpt-singapore-df1d0c400a04924bb2aa7a858090b0e5?source=MCF&event=Search
66,Data Engineer,OKBL PTE. LTD.,"About OKX
OKX is a leading crypto trading app, and a Web3 ecosystem. Trusted by more than 20 million global customers in over 180 international markets, OKX is known for being the fastest and most reliable crypto trading app of choice for investors and professional traders globally.
Since 2017, OKX has served a global community of people who share a common interest in participating in a new financial system that is designed to be a level playing field for everyone. We strive to educate people on the potential of crypto markets and how to invest Beyond the OKX trading app, our Web3 wallet, known as MetaX, is our latest offering for people looking to explore the world of NFTs and the metaverse while trading GameFi and DeFi tokens.
About the team:
OKX data team is responsible for the whole data scope of OKG, from techincal selection, architecture design, data ingestion, data storage, ETL, data visualization to business intelligence and data science. We are data engineers, data analysts and data scientists. The team has end-to-end ownership of most of the data at OKx throughout the whole data lifecycle including data ingestion, data ETL, data warehouse and data services. As a data engineer of the team, you will work with the team to leverage data technologies to empower evidence-based decision-making and improve the quality of the company's products and services.
Responsibilities:
Design and build resilient and efficient data pipelines for both batch and real-time streaming data
Architect and design data infrastructure on cloud using industry standard tools
Execute projects with an Agile mindset
Build software frameworks to solve data problems at scale
Collaborate with product managers, software engineers, data analysts and data scientists to build scalable and data-driven platforms and tools
Ensure data integrity and scalability through enforcement of data standards. Improve data validation and monitoring processes to proactively prevent issues and quickly identify issues. Drive resolution on the issues.
Define, understand, and test external/internal opportunities to improve our products and services.
Requirements:
Bachelor’s Degree in Computer Science or have equivalent professional experience
Solid Experience with data processing tools such as Spark, Flink
Solid Experience implementing batch and streaming data pipelines
Solid experiences in Python/Go/Scala/Java.
In-depth knowledge of both SQL and NoSQL databases, including performance tuning and troubleshooting
Familiar with DevOps tools such as Git, Docker, k8s
Experience with the cloud (e.g. AWS, Ali Cloud, GCP, Azure)
Be proficient in SQL, familiar with advanced SQL features such as window functions, aggregate functions and creating scalar functions/user-defined functions.
Proven successful and trackable experience in full end-to-end data solutions involving data ingestion, data persistence, data extraction and data analysis.
Self-driven, innovative, collaborative, with good communication and presentation skills
Fluent in English, both written and spoken.
Preferred Qualifications:
Experience in FinTech, eCommerce, SaaS, AdTech, or Digital Wallet business industries.
Experience in working with teams across offices and timezones is a plus.
Experience in big data tools such as Amplitude/Tableau/QlikView, Ali Cloud DataWorks, MaxCompute, Hadoop, Hive, Spark and HBase is a big plus.",https://www.mycareersfuture.gov.sg/job/banking-finance/data-engineer-okbl-7b796d4ad6a29675e594917739e3e50d?source=MCF&event=Search
67,Senior Data Engineer,THOUGHTWORKS PTE. LTD.,"Are you at your most vibrant when you’ve successfully distilled data into its simplest, most meaningful form?
Thoughtworks is a global software consultancy with an aim to create a positive impact on the world through technology. Our community of technologists thinks disruptively to deliver pragmatic solutions for our clients' most complex challenges. We are curious minds who come together as collaborative and inclusive teams to push boundaries, free to be ourselves and make our mark in tech.
Our developers have been contributing code to major organizations and open source projects for over 25 years. They’ve also been writing books, speaking at conferences and helping push software development forward, changing companies and even industries along the way. We passionately believe that software quality is driven by open communication, review and collaboration. That’s why we’re such vehement supporters of open source and have made significant contributions to open source tools for testing, continuous delivery (GoCD), continuous integration (CruiseControl), machine learning and healthcare.
As consultants, we work with our clients to ensure we’re evolving their technology and empowering adaptive mindsets to meet their business goals. You could influence the digital strategy of a retail giant, build a bold new mobile application for a bank or redesign platforms using event sourcing and intelligent data pipelines. You will learn to use the latest Lean and Agile thinking, create pragmatic solutions to solve mission-critical problems and challenge yourself every day.
Data Engineers develop modern data architecture approaches to meet key business objectives and provide end-to-end data solutions. You might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problems. On other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product. It could also be a software delivery project where you're equally happy coding and tech-leading the team to implement the solution.
You’ll spend time on the following:
You might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problems
You will partner with teammates to create complex data processing pipelines in order to solve our clients’ most ambitious challenges
You will collaborate with Data Scientists in order to design scalable implementations of their models
You will pair to write clean and iterative code based on TDD
Leverage various continuous delivery practices to deploy, support and operate data pipelines
Advise and educate clients on how to use different distributed storage and computing technologies from the plethora of options available
Develop and operate modern data architecture approaches to meet key business objectives and provide end-to-end data solutions
Create data models and speak to the tradeoffs of different modeling approaches
On other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product
Seamlessly incorporate data quality into your day-to-day work as well as into the delivery process
Here’s what we’re looking for:
You are equally happy coding and leading a team to implement a solution
You have a track record of innovation and expertise in Data Engineering
You’re passionate about craftsmanship and have applied your expertise across a range of industries and organizations
You have a deep understanding of data modelling and experience with data engineering tools and platforms such as Kafka, Spark, and Hadoop
You have built large-scale data pipelines and data-centric applications using any of the distributed storage platforms such as HDFS, S3, NoSQL databases (Hbase, Cassandra, etc.) and any of the distributed processing platforms like Hadoop, Spark, Hive, Oozie, and Airflow in a production setting
Hands on experience in MapR, Cloudera, Hortonworks and/or cloud (AWS EMR, Azure HDInsights, Qubole etc.) based Hadoop distributions
You are comfortable taking data-driven approaches and applying data security strategy to solve business problems
You’re genuinely excited about data infrastructure and operations with a familiarity working in cloud environments
Working with data excites you: you have created Big data architecture, you can build and operate data pipelines, and maintain data storage, all within distributed systems
Advocate your data engineering expertise to the broader tech community outside of Thoughtworks, speaking at conferences and acting as a mentor for more junior-level data engineers
Assure effective collaboration between Thoughtworks’ and the client’s teams, encouraging open communication and advocating for shared outcomes",https://www.mycareersfuture.gov.sg/job/consulting/senior-data-engineer-thoughtworks-344128166f66d9eb52b9fc8362ae9c35?source=MCF&event=Search
68,Data Engineer (Qilk),TECHKNOWLEDGEY PTE. LTD.,"The Data Engineer supports the design, implementation and maintenance of data flow channels and data processing systems that support the collection, storage, batch and real-time processing, and analysis of information in a scalable, repeatable and secure manner. He/She focuses on defining optimal solutions to data collection, processing and warehousing. He designs, codes and tests data systems and works on implementing those into the internal infrastructure. He focuses on collecting, parsing, managing, analysing and visualising large sets of data to turn information into insights accessible through multiple platforms.

He is passionate about numbers and works with large data sets. He has a keenness for understanding business processes and resolving challenges in order to provide solutions with the help of clean and interlinked databases and architectures.
Job Requirement
Diploma/Degree in Computer science.
Minimum 1 year experience in data models and reporting packages.
Ability to analyse large datasets, data model and interpret data pattern.
Experience in develop reporting and visualization through any Business Intelligent tools.
Hands-on experience in transforming functional specifications into design specifications.
Hands-on experience in SQL, or any related RDBMS database.
Experience in Dot Net, Python, or any related OOP language.
Good to have ETL/ELT experience, specifically on Microsoft SSIS.
Good problem solving & communication skills.
Working experience with Qlik Sense",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-techknowledgey-ac4dd53bcec3434a9f89ce8e4fd088d2?source=MCF&event=Search
69,Senior Data Engineer,ASIALINQ INVESTMENTS PTE. LTD.,"Responsibilities

We have a fantastic opportunity for an experienced Data Engineer to join our global team. This role will play a major part in the delivery of our Group Data Strategy and Data Transformation Journey by delivering, enhancing, and maintaining our company Data Platform which will drive how our data is managed and used to deliver outcomes in a host of key areas to maximise business value and growth delivering improvements for internal and external stakeholders and clients.

This role will be responsible for expanding and optimizing our data and data pipeline architecture. The ideal candidate is an experienced data pipeline builder and data wrangler who will support our software developers, database architects, data analysts and data scientists on data initiatives to navigate and leverage our significant data assets to build the optimal production models. You will ensure optimal data delivery architecture is consistent throughout ongoing projects and you must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products.

Tasks (what does the role do on a day-to-day basis)
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS big data technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs
Implement data flows to connect operational systems, data for analytics and business intelligence (BI) systems
document source-to-target mappings
re-engineer manual data flows to enable scaling and repeatable use
write ETL (extract, transform, load) scripts and code to ensure the ETL process performs optimally
develop business intelligence reports that can be reused
Key behaviours we expect to see
In addition to demonstrating our Group Values, the role holder will be expected to demonstrate the following:
Communicates Effectively, Adjusting communication style to fit the audience & message.
Providing timely information to help others across the organisation.
Encourages the open expression of diverse ideas and opinions
Action Orientated Readily taking action on challenges without unnecessary planning and identifies new opportunities, taking ownership of them
Interpersonal, Savvy, Relating comfortably with people across all levels, functions, cultures & geographies.
Builds rapport in an open, friendly & accepting way
An analytical mind, excellent problem-solving & diagnostic skills, attention to detail
Required Experience

Education / professional qualifications
Bachelor's degree in computer science or another related field
8+ years of experience in software engineering.
Background in Financial Industry preferred.
Background & Technical experience
Proficiency in Linux fundamentals and Bash scripting skills.
Programming expertise in one or more languages, mainly: Python, Go, Scala, C++, Kotlin
Expertise on Python libraries - Pandas, Numpy, PySpark, Dask.
In-Depth Knowledge of Algorithms and Data Structures
Deep understand of database systems e.g., PgSQL/MySQL and Microsoft SQL server
Experience with at least one cloud platforms e.g., AWS, Azure, GCP
Experience with one or more Datalakes/Datawarehouses - Snowflake / DataBricks / Redshift etc
Experience in Stream processing - Kafka, Kineses etc
Basic Experience with Node.js and JavaScript.
Experienced in the implementation of Data warehousing solutions
Experienced in the implementation of API solutions and tooling",https://www.mycareersfuture.gov.sg/job/engineering/senior-data-engineer-asialinq-investments-64b6c69ac5a6f65941bae6d654e973b5?source=MCF&event=Search
70,Senior Data Engineer,KAYDAN CONSULTING PTE. LTD.,"We are seeking a Senior Data Engineer to develop and prototype high-complexity data solutions that meet the needs of our organization.

Your responsibilities will include
transforming raw data into useful data systems, creating data for pricing modeling, and conducting data quality checks.
You will work to align data systems with the goals of our modeling teams, striving for efficiency.
set expectations for deliverables of high complexity and maintain proof-of-concepts and prototype data solutions.
assess the viability and scalability of these solutions and ensure they meet the required quality standards
To be considered for this position, you would ideally have:
at least 5 years of previous experience as a data engineer or in a similar role.
understanding of Agile techniques and apply principles of metadata, lineage, business definitions, compliance, and data security to project work
technical expertise in data models and data pipeline automation
experience with big data tools such as Spark and Kafka
experience with SAS and SQL databases including Postgres, Oracle, and SQL Server.
Hands-on experience with AWS cloud services, including S3, Glue, Crawlers, EC2, EMR, RDS, and Redshift.
Experience with object-oriented/object function scripting languages such as Python, Java, and Scala
A degree in Computer Science, IT, or a related field is necessary, and a master's degree is preferred
A data engineering certification from AWS is a plus.",https://www.mycareersfuture.gov.sg/job/information-technology/senior-data-engineer-kaydan-consulting-4bcd3861b19b2f3eab4ed046155ec2b8?source=MCF&event=Search
71,Data Engineer,ADECCO PERSONNEL PTE LTD,"Job description

Enables full stack solutions through multi-disciplinary team planning and ecosystem

Integration to accelerate delivery and drive quality across the application lifecycle.

Performs continuous testing for security, API, and regression suite.

Creates automation strategy, automated scripts and supports data and environment configuration.

Participates in code reviews, monitors, and reports defects to support continuous improvement activities for the end-to-end testing process.
Saghana Sithara | Registration Number: R1550224",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-adecco-personnel-d82a556cc413ab06d6c875616886b549?source=MCF&event=Search
72,Data Engineer,FONG'S ENGINEERING AND MANUFACTURING PTE LTD,"Job Description
Recommend and build require infrastructure for optimal extraction, transformation and loading of data from various sources such as ERP. MES and other systems using SQL technologies.
Create, manage and maintain optimal data pipeline architecture. API and integration for ERP, MES and other systems used in the company.
Monitor and manage database and related systems to ensure optimized performance.
Assemble large, complex data sets that meet functional and non-functional business requirements.
Working with stakeholders such as sales, finance, operations, design, and executive teams to support their data infrastructure needs while assisting with data-related technical issues.
Build business intelligence and analytical tools using Power BI to utilize the data pipeline, and provide actionable insight into key business performance metrics.
Participate in external and internal audit to ensure company data and related system is effective and validated.
Create and maintain documentations and compliance for data and systems with reference to industry best practices.
Perform other tasks as assigned by the supervisor.
Requirements
Bachelor’s degree (or equivalent) in Computer Science, Information and Communications Technology, or related discipline
3 or more years with RDBMS and NoSQL databases
3 or more years of experience with Python, SQL, data visualization and exploration tools
Working experience in MedTech / Manufacturing Industry
Experienced in building and maintaining ETL processes.
Experienced with Microsoft-based stack (M365, Power Platform, Azure, Dataverse,Microsoft SQL Server)
Knowledge of best practices in ICT operations and data management
Excellent problem solving and troubleshooting skills.
Process orientated with great documentation practices.
Communication skills, especially for translating technical concepts to non-technical business leaders.
Ability to work on a dynamic, action-focused team that has concurrent projects",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-fongs-engineering-manufacturing-9b51c3a85eee7a3b0f6b039b951864bc?source=MCF&event=Search
73,Data Engineer,GREEN LINK DIGITAL BANK PTE. LTD.,"About Us
Green Link Digital Bank is Singapore's inaugural wholesale digital bank focusing on supply chain finance, mainly serving MSMEs and aiming to help MSMEs grow and improve digitization.

We are looking for a Data Engineer joining our Data Management Office (DMO). The DMO provides comprehensive data services to all business units, and manages data governance policies and procedures. We apply best practices in managing our data assets and making it our competitive advantages to serve our customers better. We are embarking on a greenfield project to build our big data platform with the latest technologies. We invite the best talent to join us on this exciting journey.

Responsibilities
Design, develop and test a custom distributed big data platform using the latest technologies
Design, create and maintain physical data models optimised for performance, security, privacy, and maintenance
Design and develop real-time and batch ETL/ELT processes that ingest and transform a variety of data sources into data warehouse and data lake
Design and build data reconciliation processes to ensure data completeness and accuracy
Diagnose and remediate production issues
Provide training to users and other team members on technical aspects of data flow, procedures, and use of tools to consume the data effectively
Create and maintain documentations of technical solutions such as solution design, system architecture, technical specifications, and user manuals

Requirements
In-depth knowledge of concepts and practices building big data platforms, including data warehouse, data mart, and data lake
Practical experience in big data technologies, such as Hive, Spark, Kafka, Sqoop, Greenplum and any other RDBMS
Proficient with SQL, Stored Procedures, Shell, Python, and Java
Familiar with Elasticsearch or other NoSQL databases
Experiences in CI/CD and containerization are added advantages
Passionate for technical excellence and eager to learn new technologies
Committed to rigorous quality standards",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-green-link-digital-bank-d2b1553b80c4b172fa81d42e4db14317?source=MCF&event=Search
74,Data Engineer,SAKSOFT PTE LIMITED,"KEY REQUIREMENTS
· Minimum 8 years of extensive experience in dealing with Data-Warehousing projects on Teradata, Hadoop and Informatica.
· Working with Hive, Sqoop & spark framewrok. Having good understanding of Partitions, Bucketing concepts in Hive .
· Extensively Worked on Teradata Utilities - BTEQ, FLoad, MLoad, TPump, FExport and TPT
· Solid experience in Teradata MDM, SQL, ETL nformatica, Hadoop, Hive, Unix
· Worked with 10+ different Source Systems which has structured and semi structured data.
· Developed Teradata TPT scripts for continuous loading and implemented real time and near real time data warehouse system for all mobile app services.
· Developed Teradata M-Load and Hadoop-Hive scripts for stage loads.
· Involved and developed data mappings between Staging and Presentation/Reporting layers.
· Data validation of Datamart/Reports
· Wrote many UNIX shell scripts to pre-process and parse the source files
· Must have banking domain experience (digital bank etc)",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-saksoft-ab6c072dfec3a62e98714b4f7fcc5ebf?source=MCF&event=Search
75,Data Engineer,KPLER PTE. LTD.,"Own different data pipelines and ensure data is flowing consistently and efficiently
Work closely with the Product Manager and other business stakeholders to understand
their challenges from both a product and technical perspective
Participate in the evolution of the platform (infrastructure and services) to address any
challenges identified or implement new features
Follow the highest software design standards and Kpler’s best practices",https://www.mycareersfuture.gov.sg/job/engineering/data-engineer-kpler-30e7f76ef9c033120a894bdac7f86753?source=MCF&event=Search
76,Data Engineer,DYNAMIC HUMAN CAPITAL PTE. LTD.,"Role and responsibilities
· Cooperates with DevOps and Business Intelligence teams to establish a common data processing and analytics platform and best practices.
· Work closely with data scientists and software engineers to support the analysis of data, and the development and validation of models.
· Design and implement data storage solutions to ensure data quality, availability, and scalability.
· Check the performance of the data infrastructure and implement optimizations to improve efficiency and reduce costs.
· Involvement in technical discussions across the team through code reviews, RFC, or architecture review sessions.

Skills and experience
· Degree in Computer Science / Engineering, Information Science, or other IT-related disciplines.
· At least 2 years of experience working as a Data Engineer or similar.
· Hands-on experience supporting high-traffic consumer apps.
· Experience with real-time data processing using Kafka, Flink, or similar tools.
· Data science, MLOps, or related education or work experience
· Good understanding of Agile and DevOps practices: version control, CI/CD, Infrastructure-as-Code, containerization, observability/monitoring.
· Experience building data infrastructure to address the needs of business and data teams. Strong knowledge of data architecture, data modeling, and data warehousing.
· Deep familiarity with data processing systems such as Airflow, Dagster, Flyte, Spark, DBT, or similar and data cataloging tools such as Atlas, Amundsen, DataHub, or similar.
· Deep familiarity with SQL (PostgreSQL preferred) and NoSQL databases (Redis, Elasticsearch preferred).
· Familiarity with its data analytics services and databases, e.g., Redshift, Athena, Glue, EMR, etc. Also, familiarity with data platforms such as Sagemaker, Dataiku, Databricks, Datarobot, or similar.
· Experience with data visualization and reporting tools like Metabase, Tableau, PowerBI, or Looker.


HOW TO APPLY:

We would like to invite interested applicants to email detailed resume in MS Word format to: joane@dhc.com.sg

By submitting any application or résumé to us, you will be deemed to have agreed and consented to us disclosing your personal information to prospective employers for their consideration.

Under the revised Employment Agencies Licence Condition 5(b), employment agencies (EAs) are required to collect the personal data (e.g. NRIC, FIN) of applicants referred to employers for permanent or contract job positions of at least 6 months with a fixed monthly salary of $3,300 and above. PDPA requirements on collection, use and disclosure of personal data are not applicable to EAs that are collecting such information, as it is a regulatory requirement.

https://www.mom.gov.sg/faq/submit-quarterly-referral-and-placement/are-employment-agencies-allowed-to-collect-personal-data

We regret to inform you that only shortlisted candidates will be notified. All applications will be treated with the strictest confidence.

Joane Carrido
Registration number: R1770751
EA Licence No: 12C6253",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-dynamic-human-capital-8fb81dd328013c86e2418cc292770134?source=MCF&event=Search
77,DATA ENGINEER,PARADIGM RECRUITMENT PTE. LTD.,"Our clients
Local IT homeland security provider that has more than 20 years of presence in the industry
Highlights
Competitive compensation structure
Great team working environment
Responsibility
Assisting in maintaining system data, setup, installation and configurations
Responsible for troubleshooting, upgrading COTS products, Develop and implementing data warehouses improvements and Etc.
Handling documents creation and guides for troubleshooting
Requirements
Possess diploma or degree in Information technology or any relevant discipline.
3 years of working experience in Data engineering or data management
Knowledge and or experience in Automation platforms, Programming languages E.g (Python, Spark), Analytics platforms Etc.

Interested applicants, please Click on Apply Now or send your CV to kenny.lee(AT)paradigmrecruitment.com.sg

We regret to inform you that only shortlisted applicants will be contacted.

EA Reg No.: R2199565 // EA License No.: 21C0434",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-paradigm-recruitment-e57edbb3569813d0c2bd86345a421366?source=MCF&event=Search
78,Data Engineer,ABBOTT MANUFACTURING SINGAPORE PRIVATE LIMITED,"Job Description
Primary Function/Primary Goals/Objectives:
Identify business needs, collect, data analysis & interpretation and visualization of manufacturing and business data. Report insights and help users to make decisions and find improvement opportunities.
Major Responsibilities:
Engaging cross-functional stakeholders to understand business requirements (voice of customer).
Manage cross-functional projects from ideation, execution to change management.
Extract, transform and load data from data source systems, machines and sensors using tools such as Python, SQL, SEEQ and batch scripting.
Develop data cleaning and data wrangling tools (Python, SQL, Excel) for analysis and analytics modeling.
Extract time series process data from PI process historian using PI Web API.
Implement next generation electronic tier reporting dashboard through data automation and analysis solutions.
Serve as an on-site consultant for existing data systems.
Troubleshoot issues via root cause analysis and implement timely corrective actions
Work with IT and subject matter experts to ensure data accuracy and availability.
Upgrading existing dashboards, apps and tools based on business needs.
Creating Power Platform applications for data entry and improving workflows.
Skills/Experience Requirements:
Strong knowledge and experience in Programming Languages like Java, Python, R, etc.
Strong knowledge in data visualization tools like Python, PowerBI, Tableau, QlikView and SEEQ.
Strong analytical/critical thinking/problem solving skills.
Strong communication skills and stakeholder management skills.
Knowledge in Microsoft Power Platform tools such as Power Apps, Power Automate, Power Query and Power BI.
Strong knowledge and experience in SQL, batch scripting, etc.
2-3 years work experience as a Data Engineer, Data Analyst, Business Analyst or related roles in a mature manufacturing/tech/IT consultancy firm.
Education:
Major in Computer Science, Computer Engineering or related fields from a recognized university.
Major in Engineering with a minor or second major in Computer Science from a recognized university.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-abbott-manufacturing-singapore-cee738b309a3ac56f1e9a3662d954831?source=MCF&event=Search
79,Data Engineer,PEOPLE PROFILERS (SERVICES) PTE. LTD.,"Responsibilities
5+ years experiences of data lake and data warehouse design and development experience.
Deeply understanding of data warehouse modeling and data governance. Solid knowledge of data warehouse development methodology, including dimensional modeling, information factory, and one data, etc.
Proficient in Java / Scala / Python (at least one language) and Hive & Spark SQL programming languages.
Familiar with OLAP technology (such as: kylin, impala, presto, druid, etc.).
Proficient in Big Data batch pipeline development.
Familiar with Big Data components including but not limited to Hadoop, Hive, Spark, Delta lake, Hudi, Presto, Hbase, Kafka, Zookeeper, Airflow, Elasticsearch, Redis, etc.
Experiences with AWS Big Data services are a plus.
Clear mind, with good business requirement understanding, analysis, abstraction, and system design capabilities.
Have a strong team collaboration attitude and develop partnerships with other teams and businesses.
Be optimistic, able to adapt quickly to meet new challenges, and quick to respond to incidents.
We regret that only shortlisted candidates will be notified

Noga Lim Wei Loong
Registration Number: R1329872
EA License Number: 10C3804
People Profilers Pte Ltd, 20 Cecil St, #08-09, PLUS Building, Singapore 049705
http://www.peopleprofilers.com",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-people-profilers-6bf21d8792016044e4249e1e6c418027?source=MCF&event=Search
80,Data Engineer,CASTLERY PRIVATE LIMITED,"Castlery is looking for a Data Engineer to join our Supply Chain Strategy and Business Intelligence team.
As part of our Supply Chain Strategy and Business Intelligence team, your role as a Data Engineer will be to ensure that our team has the right infrastructure to perform analysis that helps in making better-informed business decisions.
You'll be building systems and that collect, manage and convert data into usable information for our team, and the details are as per below.
What you'll be doing
Define, collect, and model data from business processes or third parties to generate insights and drive strategic or continuous improvement initiatives for the whole company.
Work with technology teams to design and implement reliable and scalable data pipelines.
Work with functional stakeholders to build modern data infrastructure (e.g. data warehouse, data lake) and solve any data-related technical issues.
Be the ‘Go-To’ expert and constantly improve data infrastructure in Castlery.
What you'll need
Bachelor’s or Master’s degree in Computer Science, Computing Engineering or other equivalent degrees with outstanding academic achievements.
Proven track records working as Data Engineer, Data Scientist, Data Analyst or equivalent.
Good command of database structures and query languages.
Strong in Python programming and familiar with popular libraries such as Pandas, Scrapy.
Familiar with AWS Data Analytics service and setting up data pipelines, e.g. Airflow, Jenkins.
Knowledge of big data framework and tech stack is a plus, e.g. Spark, Hadoop.
Passion and curiosity for solving challenging problems by leveraging on the right technology.
Ability to work collaboratively in a multi-cultural team environment and lead changes.
Ability to work effectively with people at all levels in an organization.
Ability to deliver sophisticated ideas effectively, both verbally and in writing, in English.
What we promise
Our first promise - the ride of a lifetime
You’ll be joining a company in its most exciting phase; we’ve proven our product market fit, and with the growing online penetration of furniture, we’re now focused on hypergrowth. You’ll have a front-row seat in witnessing the growth of our customer-base and organisation at a global-level.
Our second promise – a place to thrive
We’re building a company that has people as one of the company’s core pillars for success. It’s our mandate to help every employee perform to their highest potential so that they can do the very best work of their lives here, at Castlery.
We’re committed to our employees’ growth, and continuously strive to ensure our employees are set up for success through their journey, starting with an excellent onboarding experience, and carrying over into emphasis on personal and professional development
Castlery strives to maintain a psychologically safe, transparent, and flexible work environment to enable our people can perform at their best level and believes in partnering our employees to raise that level as they grow with us.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-castlery-ad6dcfea763b55e23ee46fc5c57d4128?source=MCF&event=Search
81,Data Engineer (Qilk),TECHKNOWLEDGEY PTE. LTD.,"The Data Engineer supports the design, implementation and maintenance of data flow channels and data processing systems that support the collection, storage, batch and real-time processing, and analysis of information in a scalable, repeatable and secure manner. He/She focuses on defining optimal solutions to data collection, processing and warehousing. He designs, codes and tests data systems and works on implementing those into the internal infrastructure. He focuses on collecting, parsing, managing, analysing and visualising large sets of data to turn information into insights accessible through multiple platforms.

He is passionate about numbers and works with large data sets. He has a keenness for understanding business processes and resolving challenges in order to provide solutions with the help of clean and interlinked databases and architectures.
Job Requirement
Diploma/Degree in Computer science.
Minimum 1 year experience in data models and reporting packages.
Ability to analyse large datasets, data model and interpret data pattern.
Experience in develop reporting and visualization through any Business Intelligent tools.
Hands-on experience in transforming functional specifications into design specifications.
Hands-on experience in SQL, or any related RDBMS database.
Experience in Dot Net, Python, or any related OOP language.
Good to have ETL/ELT experience, specifically on Microsoft SSIS.
Good problem solving & communication skills.
Working experience with Qlik Sense",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-techknowledgey-b23a6b35e9a2a892240367e18a0eacbc?source=MCF&event=Search
82,Data Engineer,FRASERS PROPERTY CORPORATE SERVICES PTE. LTD.,"ABOUT FRASERS PROPERTY
We are a multinational developer-owner-operator of real estate products and services across the property value chain. Listed on the Main Board of the Singapore Exchange Securities Trading Limited (“SGX-ST”) and headquartered in Singapore, Frasers Property's multinational businesses operate across five asset classes, namely, residential, retail, commercial & business parks, industrial & logistics as well as hospitality. The Group has businesses in Southeast Asia, Australia, Europe and China, and its well-established hospitality business owns and/or operates serviced apartments and hotels in over 70 cities and 20 countries across Asia, Australia, Europe, the Middle East and Africa.
The Group is committed to inspiring experiences and creating places for good for its stakeholders. By acting progressively, producing and consuming responsibly, and focusing on its people, Frasers Property aspires to raise sustainability ideals across its value chain and commits to net-zero carbon by 2050.
WHAT YOU WILL BE DOING
Able to understand business requirements and translate to design document from data ingestion to data modelling.
Develop data pipelines and ingest data from various sources to data warehouse for consumption from 3rd party applications.
Develop and manage data schema in data warehouses
Manage data lake API calls from 3rd party application and access controls.
Participate in designing the architecture of the data lake platform for new use cases.
Responsible for verifying changes implemented by vendor and deploy it into the data lake production environment.
Identify, design, and implement continuous improvements on good data governance practices.
Monitor the health of data lake and investigate on issues that occur.
WHAT WE ARE LOOKING FOR
A minimum 2 years’ experience in data engineering (e.g. data modelling, data pipeline, data architecture, ETL).
Experience in utilising Microsoft Azure and any related tooling for data engineering (such as Azure Data Factory, Azure Data Lake Storage, Databricks, Synapse).
Knowledge of data modelling and understanding of different data structures and their benefits and limitations.
Proficiency in writing SQL including stored procedures in languages such as T-SQL and PL/SQL.
Experience in designing, architecting, and building scalable pipelines.
Capability in programming languages (such as Python and Java).
Be a natural problem solver.
Self-motivated and proactive, willing to learn new things.
Good communication skills and strong team player.
Diversity brings us closer to the communities we serve
Guided by our Purpose, we are creating, inspiring, and nurturing an inclusive culture that unlocks the power of diverse teams to drive Frasers Property forward. Our values drive everything we do, which are core to creating safe places where everyone belongs, is mutually respected and feels empowered to be authentic at work. Working collaboratively makes us progressively stronger and better as an organization, which helps our people to thrive each day.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-frasers-property-corporate-services-5ecd91b9e7effed87a3ef4bba3817908?source=MCF&event=Search
83,Senior Data Engineer,JULIAN GREY CORPORATE ADVISORY PTE. LTD.,"Company’s profile
Julian Grey’s client is a local solution provider for high quality IT security products to value add to their MNC clients & channel partners and has been in the market for 25 years. With a team of more than 200 highly experienced professionals, the company is looking for passionate individuals in the IT security industry to join their rapidly expanding team.
Work location: Tampines
Working hours: 8.30am – 6pm (Mon – Thu), 8.30am – 5.30pm (Fri)
Company transport provided to & from Tampines MRT daily.
Benefits
AWS and performance bonus
Annual salary increment
Medical and Dental claim $1900 per annum
Team bonding budget $160 per employee per year
1 day inspirational leave per year
Job Responsibilities
Work in a team to build and maintain data systems or pipelines.
Perform setup, installation, configuration, troubleshooting and/or upgrade for commercial software and hardware.
Develop or implement methods to improve data warehouses, data lakes or equivalent platforms.
Participate in creating documentations e.g., design documents, troubleshooting guides etc.
Requirements
2-3 years experience in data management and installation/troubleshoot of commercial software and hardware
Minimum Diploma in Computer Engineering/Computer Science/Information Technology or related technical fields
Hands-on knowledge with Linux commands and shell script
Hands-on knowledge in relational (i.e., SQL) or NoSQL database (i.e., documents, graphs)
Familiar with any of the below is advantageous:
Data / Search / Automation platforms like Hadoop, Elasticsearch, Ansible
Data integration tools like Talend, DataStage, Denodo
Programming languages like Python, Spark
Microsoft Azure Cloud services like Azure Data Factory, Azure Synapse Analytics
Analytics platforms like Databricks, Dataiku, Data Robot
Follow us for more updates, interview tips!
https://www.instagram.com/juliangreygroup/
https://www.linkedin.com/company/juliangreygroup/
https://www.facebook.com/juliangreygroup/
Our telegram channel for job opportunities - https://t.me/jobopportunitiessg

Celine Chan
Reg No. R21103433
Julian Grey Corporate Advisory Pte. Ltd.
EA License No: 19C9568",https://www.mycareersfuture.gov.sg/job/engineering/senior-data-engineer-julian-grey-corporate-advisory-6522e25f14238bbfddfe69e55e82ceec?source=MCF&event=Search
84,Data Engineer / Associate Data Engineer,SINGAPORE TOURISM BOARD,"What the role is:
Support the Data Science team in:
Helping to project manage, coordinate and implement Data Science & Analytics's (DS&A) data ingestion and data processing pipelines across different platforms
Ensuring that all data systems meet our business requirements and enable scalability of business processes

Main Responsibilities:
Project manage and deliver on data related implementations ensuring that deliverables are met within agreed scope and timelines
Work closely with vendors and internal stakeholders to project manage and coordinate DS&A’s data ingestion and data processing pipelines across platforms which can include mobile apps, SaaS platforms, on-premise databases and partner systems
Help architect DS&A’s data integrations and data processing flows between external / 3rd party data sources, AWS cloud datawarehouses (e.g. Redshift) and internal on-premise database instances for workloads at scale
Help to gather and translate business requirements into relevant database schemas, data integrations and data processing flows to meet business objectives
Develop data integrations (through API, SFTP etc) between AWS S3, Redshift instances and on-premise database instances (e.g. HANA)
Assemble large, complex datasets that meet functional and non-functional business requirements
Analyse and assess the effectiveness and accuracy of new data sources (e.g. datasets received from stakeholders) and annotation/ labelling of new training inputs.
Identify, design and implement internal process improvements: automating manual processes, data validation tools, optimising data delivery, re-designing infrastructure for greater scalability, etc.
Recommend different ways to constantly improve data reliability and quality, including helping review and enhance the existing data collection procedures to include data for building analytics models relevant for industry transformation
Develop monitoring toolkits to ensure that integration is executed successfully and alerts where integrations have failed
Provide guidance to internal teams on best practices for cloud to on-premise data integrations
Develop set processes for data mining, data modelling and data production
Support the integration and deployment of developed algorithms, machine learning and analytical models into current analytics system/production
Help setup, configure, deploy and validate machine learning models and analytics scripts on Amazon Sagemaker
Help in the implementation of CI/CD and deployment of ML models in production

Job requirements:
At least 2-3 years of Software Project Management experience successfully managing both internal stakeholders and external vendors.
Successfully delivered at least 2 medium to large scale software systems in either a Project Management role, Data Architect role or Data Integration role
Ability to understand the different business domains and to make connections between the data and the business needs.
Good and strong communication skills and able to explain the issues, design tradeoffs between performance, maintenance and business requirements.
Able to clearly articulate and justify the design decisions taken
Good attention to details with regards to data workflow, data quality, data integrity and how the data will be stored and accessed.
Strong analytics skills related to working with structured and unstructured datasets.
Experience in performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience in designing database schemas to support OLTP and OLAP systems
Experience with data pipeline tools (e.g. Talend, SSIS, BODS, Airflow, Kafka)
Experience in using Qliksense will be advantageous.
Experience with big data tools: Hadoop, Spark, Hive, Sqoop, etc.
Experience with stream-processing systems: Storm, Spark-Streaming, Kalfka etc.
Experience in software development and developing enterprise applications with integrations to SQL / no-SQL databases
Experience with object-oriented / object function scripting languages: Python, R, Java, etc.
Intellectual curiosity to find new and unusual ways of how to solve data management issues.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Strong working knowledge of SQL
Strong project management, stakeholder management and organisational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
At least 3 years of working experience in a related field with real-world skills and testimonials from formal employers.
Working experience with structured and unstructured datasets is essential
Preferred certifications:
Certified Scrum Master/ Agile Developer
Certified AWS Cloud Architect

Application Status: Shortlisted candidates will be contacted within 2 weeks from the closing date of this job posting. We regret to inform that only shortlisted candidates will be notified.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-associate-data-engineer-singapore-tourism-board-e3ef5b04216b239622b9e879600c32c2?source=MCF&event=Search
85,Senior System Analyst (Data Engineering),UPPER SPRING CONSULTING PTE. LTD.,"We are representing our client (an established leading Hospital Group) looking for a Senior System Analyst to analyse data requirement in new system, perform data mapping from old system to new system, standardization, migration, testing as well as validation and verification.

Responsibilities:
Define roadmap to transform data architecture focusing on scalability, performance and flexibility throughout the entire data life cycle (ingestion, storage and consumption).
Maintain data architecture framework, standards and principles including modelling, metadata, security, master and reference data.
Define reference architecture as a set of patterns that can leveraged by diverse parts of the direction to create and improve data systems.
Lead architectural designs solution context diagram and conceptual data model to optimize security, information leverage and reuse, integration, performance, and availability and ensure solutions developed adhere and aligns to the delivered architecture.
Work with Data Migration Lead and Overseas Partner to influence application teams regarding solutions.
Collaborate with internal IT and business teams to design and implement effective technology solutions, while using innovative business and technology processes to identify and implement improvement initiatives, eliminate redundancies, and maximize the reuse of data.
Work closely with Solutioning, Infrastructure and project teams to understand their needs and ensure the best data architecture is implemented.
Provide training and share best practices across teams regarding data architecture design and solution implementation including review and quality assurance.
Develop and apply industry best practice technology, design and methodology approaches.
Research and recommend new emerging technologies, techniques and tools that will add value to the organisation.
Requirements:
Bachelor's Degree in Computer Science or related discipline.
Minimum 7 years of experience designing and building high performance resilient data architectures.
Strong experience with traditional data technologies (ODS, Data Lake, Data Warehouse).
Strong experience with Structured Query Language, Stored Procedures, Constraints and Indexes on both MS SQL and Oracle databases.
Experience in designing data patterns to support micro-service based application architecture.
Track record of successfully building container-based big data architectures on top of Kubernetes.
Experience in designing systems to efficiently handle real-time and batch use-cases.
Exposure and understanding in the latest open source technologies across the big data ecosystem, such as distributed storage, real-time event processing and large scale distributed OLAP engines.
Exposure to Data as a Service concepts and data virtualization.
Working knowledge of data science processes and best practices, with experience in building scalable architectures through the use of data science workflow orchestrators.
Hands on experience on DevOps / DataOps / MLOps concepts. 12) Experience in 2 or more Healthcare systems like SCM, Cerner, SRIS or Merlin is preferred.
Experience in HL7 standard messages and eLink are an added advantage.
Ability to articulate thoughts and workflows clearly in both writing and speech is essential.
Ability to work under tight schedule and independently is preferred",https://www.mycareersfuture.gov.sg/job/information-technology/senior-system-analyst-upper-spring-consulting-0f91b3e25e56311ea3692cd2f335d228?source=MCF&event=Search
86,Head of Data / Data Engineering / Data Science / Data Platform / Data Analytics,RANDSTAD PTE. LIMITED,"Senior Leadership role over a sizable Data team (>50 headcounts with Directors reporting into this position)
Autonomy to make decisions for data (Strategy roadmap)
About the company
Our Client is a market leader within their industry. They have a well-established presence of more than 50 years. As part of their plan to invest in the internal digital transformation, they have created this new senior headcount to led the Data team.

About the job
Your responsibility involves:
Designing and lead the Data Engineering and Data Analytics vision and roadmap for the organization. This is with the objective of increasing revenue though driving Go-To-Market use cases and driving operational efficiency.
Applying best practices and expertise in data engineering to bring value to the company. This includes Designing and conceptualize solution that address business challenges
Being the main point of contact to the senior management, presenting data analytics findings to senior executives in the development and execution of data strategic initiatives.
Coordinate with different functional teams to implement models and monitor and analyse model performance and data accuracy.
Providing thought leadership to assemble capabilities into Data and AI platforms that can enable and scale a variety of analytical process across the company. This includes managing the internal Data team of more than 50 headcounts within the organization.

Skills and experience required
As a successful applicant, you will have at 12 years of experience in Data. Proven track record in data architecture, data engineering, data science and data analytics is required for this role .
Candidate with proven track record in managing a sizable team of more than 40 headcounts will be highly preferred.

To apply online please use the 'apply' function, alternatively you may contact Hoon Teck TAN at 6510 3633. (EA: 94C3609/ R1219669).",https://www.mycareersfuture.gov.sg/job/information-technology/head-data-data-engineering-data-science-data-platform-data-analytics-randstad-af19fc775147bfce7a01421f773300b7?source=MCF&event=Search
87,"Urgent Hiring!!! Data Ops Engineer (Python , Azure Data Factory , SQL)",TRUST RECRUIT PTE. LTD.,"Highlights:
Homeland Security Domain Provider, CAT 1 Clearance
Permanent job opportunity
Great remuneration and benefits
Great career progression
Responsibilities:
Build and maintain data systems or pipelines.
Perform setup, installation, configuration, troubleshooting and/or upgrade for COTS products.
Develop or implement ways to improve data warehouses, data lakes or equivalent platforms.
Involve in the creation of documentations e.g. design documents, troubleshooting guides etc.
Requirements:
Diploma/Degree in Computer Engineering/Computer
Preferably 1 - 4 years' of working experience in related fields.
Science/Information Technology or related technical discipline
Knowledge and/or experience in data management or data engineering
Experience with Linux commands and shell script
Knowledge and/or experience in relational (including SQL) or NoSQL database (e.g. document, graph)
Knowledge and/or experience in one or more of the following will be an advantage:
Data / Search / Automation platforms such as Hadoop, Elasticsearch, Ansible respectively
Data integration tools such as Talend, DataStage, Denodo
Programming languages such as Python, Spark
Microsoft Azure Cloud services such as Azure Data Factory, Azure Synapse Analytics
Analytics platforms such as Databricks, Dataiku, Data Robot
Good problem-solving skills
Able to work independently and as a team
HOW TO APPLY:
Interested applicants, please send your latest resume to ref19@trustrecruit.com.sg or click on “Apply Now” and provide the below details in your resume.
Last drawn salary:
Expected salary:
Notice period:
Reason for leaving:
We regret only shortlisted candidates will be notified.
Important Note: Trust Recruit Pte Ltd is committed to safeguarding your personal data in accordance with the Personal Data Protection Act (PDPA).
Please read our privacy statement on our corporate website www.trustrecruit.com.sg.
Trust Recruit Pte Ltd
EA License No: 19C9950
EA Personnel: Lim Dick Sern (Dick Sern)
EA Personnel Reg No: R22106832",https://www.mycareersfuture.gov.sg/job/information-technology/urgent-hiring-data-ops-engineer-trust-recruit-0e0120b820c7bc33b9049abf8ed0de0c?source=MCF&event=Search
88,Data Centre Engineer,GENESIS NETWORKS PTE LTD,"Responsibilities:
Maintaining integrity of Data Center
Maintaining optimal power distribution of network and server equipment
Racking of new and used servers and other network equipment, connecting, configuring, and labelling any related equipment associated with installation
Locally administering Windows/Linux servers and various Cisco network equipment
Monitoring and troubleshooting server and network hardware
Providing client services support and coordination on Disaster Recovery, Hosting, and Co-location
Coordinating and managing 3rd parties vendor repair tickets
Coordinating Telco delivery and intra-data centre cross-connects
Participating in data centre expansion and improvement projects
Operational tasks include server and network monitoring, facilities management, maintenance and administration
Server maintenance includes operating system patches, software updates, server security maintenance and server monitoring for failure alerts
Administrative duties include daily system backup, maintenance of anti-virus systems, managing disk space utilization, and user account and security administration utilizing Microsoft Active Directory
Be highly aware of any environment or physical changes in the Data Centre, escalating such changes to appropriate personnel as necessary
Maintains a high level of awareness while working in or on high traffic equipment, this is essential to the efforts of producing no down time on any equipment which is critical to company productivity
Maintain, update and documents all work performed and equipment moves/changes
Prepare and submission incident report, engineering work order, and other documentation as required
Any other duties assigned by the Management on Server/Network project implementation, or maintenance, or troubleshooting
Requirements:
Strong background (with hand-on experience) in VMware, and other virtualized platform
Experience in Disaster Recovery procedure and processes would be advantageous.
Working experience in Data Centre environment will be added advantages
Preferably with CCNA and/or MCSE, if not, at least hand-on experience in installation, configuration, maintaining and troubleshooting of Windows servers, routers, switches, etc
Able to start work immediate or short period
Must be a team player and able to work independently
Willing to perform overtimes, weekends when required (ad-hoc basis)
Able to document and update technical procedures, network/system diagram etc",https://www.mycareersfuture.gov.sg/job/information-technology/data-centre-engineer-genesis-networks-e895fe0d00e63c57c417ae6a44874375?source=MCF&event=Search
89,Data Centre Engineer,GENESIS NETWORKS PTE LTD,"Responsibilities:
Maintaining integrity of Data Center
Maintaining optimal power distribution of network and server equipment
Racking of new and used servers and other network equipment, connecting, configuring, and labelling any related equipment associated with installation
Locally administering Windows/Linux servers and various Cisco network equipment
Monitoring and troubleshooting server and network hardware
Providing client services support and coordination on Disaster Recovery, Hosting, and Co-location
Coordinating and managing 3rd parties vendor repair tickets
Coordinating Telco delivery and intra-data centre cross-connects
Participating in data centre expansion and improvement projects
Operational tasks include server and network monitoring, facilities management, maintenance and administration
Server maintenance includes operating system patches, software updates, server security maintenance and server monitoring for failure alerts
Administrative duties include daily system backup, maintenance of anti-virus systems, managing disk space utilization, and user account and security administration utilizing Microsoft Active Directory
Be highly aware of any environment or physical changes in the Data Centre, escalating such changes to appropriate personnel as necessary
Maintains a high level of awareness while working in or on high traffic equipment, this is essential to the efforts of producing no down time on any equipment which is critical to company productivity
Maintain, update and documents all work performed and equipment moves/changes
Prepare and submission incident report, engineering work order, and other documentation as required
Any other duties assigned by the Management on Server/Network project implementation, or maintenance, or troubleshooting
Requirements:
Strong background (with hand-on experience) in VMware, and other virtualized platform
Experience in Disaster Recovery procedure and processes would be advantageous.
Working experience in Data Centre environment will be added advantages
Preferably with CCNA and/or MCSE, if not, at least hand-on experience in installation, configuration, maintaining and troubleshooting of Windows servers, routers, switches, etc
Able to start work immediate or short period
Must be a team player and able to work independently
Willing to perform overtimes, weekends when required (ad-hoc basis)
Able to document and update technical procedures, network/system diagram etc",https://www.mycareersfuture.gov.sg/job/information-technology/data-centre-engineer-genesis-networks-0c0500621f136e445f3a6209f00e72ca?source=MCF&event=Search
90,Data Centre Engineer,GENESIS NETWORKS PTE LTD,"Responsibilities:
Maintaining integrity of Data Center
Maintaining optimal power distribution of network and server equipment
Racking of new and used servers and other network equipment, connecting, configuring, and labelling any related equipment associated with installation
Locally administering Windows/Linux servers and various Cisco network equipment
Monitoring and troubleshooting server and network hardware
Providing client services support and coordination on Disaster Recovery, Hosting, and Co-location
Coordinating and managing 3rd parties vendor repair tickets
Coordinating Telco delivery and intra-data centre cross-connects
Participating in data centre expansion and improvement projects
Operational tasks include server and network monitoring, facilities management, maintenance and administration
Server maintenance includes operating system patches, software updates, server security maintenance and server monitoring for failure alerts
Administrative duties include daily system backup, maintenance of anti-virus systems, managing disk space utilization, and user account and security administration utilizing Microsoft Active Directory
Be highly aware of any environment or physical changes in the Data Centre, escalating such changes to appropriate personnel as necessary
Maintains a high level of awareness while working in or on high traffic equipment, this is essential to the efforts of producing no down time on any equipment which is critical to company productivity
Maintain, update and documents all work performed and equipment moves/changes
Prepare and submission incident report, engineering work order, and other documentation as required
Any other duties assigned by the Management on Server/Network project implementation, or maintenance, or troubleshooting
Requirements:
Strong background (with hand-on experience) in VMware, and other virtualized platform
Experience in Disaster Recovery procedure and processes would be advantageous.
Working experience in Data Centre environment will be added advantages
Preferably with CCNA and/or MCSE, if not, at least hand-on experience in installation, configuration, maintaining and troubleshooting of Windows servers, routers, switches, etc
Able to start work immediate or short period
Must be a team player and able to work independently
Willing to perform overtimes, weekends when required (ad-hoc basis)
Able to document and update technical procedures, network/system diagram etc",https://www.mycareersfuture.gov.sg/job/information-technology/data-centre-engineer-genesis-networks-8cda42ad1dd3b6b18641f860defecc7a?source=MCF&event=Search
91,"Data Engineer / Technology / Up to $8,000 / month!",INTEGRITY PARTNERS PTE. LTD.,"My client, an established company is looking out for a data Engineer and the incumbent to join needs to have such attributes.

Job roles:
Manage data lake API calls from 3rd party application and access controls.
Participate in designing the architecture of the data lake platform for new use cases.
Responsible for verifying changes implemented by vendor and deploy it into the data lake production environment.
Identify, design, and implement continuous
Able to understand business requirements and translate to design document from data ingestion to data modelling.
Develop data pipelines and ingest data from various sources to data warehouse for consumption from 3rd party applications.
Job requirements:
Experience in utilising Microsoft Azure and any related tooling for data engineering (such as Azure Data Factory, Azure Data Lake Storage, Databricks, Synapse).
Knowledge of data modelling and understanding of different data structures and their benefits and limitations.
Proficiency in writing SQL including stored procedures in languages such as T-SQL and PL/SQL.
A minimum 2 years’ experience in data engineering (e.g. data modelling, data pipeline, data architecture, ETL).
How to Apply:

Interested applicants may apply by sending in your updated résumé (in MS Word format) to my email or apply directly:
Consultant: Tan Jun Jie
EA personnel reg. no.R1878852
EA License No. 17C8502",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-technology-8000-month-integrity-partners-f9ba5f7223e51e4cb56240e3c847bb21?source=MCF&event=Search
92,Senior Technical Data Solution Architect / Engineer (ETL),EXASOFT PTE. LTD.,"For a leading client.
Strong in design and analytical
Extract, Transform, Load (ETL) development experience
Proficient in writing complex SQLs, expertise in performance tuning of SQLs
Knowledge and prior experience in Python, Java
Knowledge and prior experience in using Github
Database architecture design, data modeling and development experience (several cycles of E2E implementation)
Able to work independently.
Must be able to solve complex problems and ability to work on multiple projects/tasks simultaneously to meet project deadlines as required.
Able to read and communicate in English and Chinese (Mandarin) to handle queries, request and feedbacks from English and Chinese speaking counterparts",https://www.mycareersfuture.gov.sg/job/information-technology/senior-technical-data-solution-architect-engineer-exasoft-72fe0ff33c3316832f18043691b076e9?source=MCF&event=Search
93,"Data Engineer / Technology / Up to $8,000 / month!",INTEGRITY PARTNERS PTE. LTD.,"My client, an established company is looking out for a data Engineer and the incumbent to join needs to have such attributes.

Job roles:
Manage data lake API calls from 3rd party application and access controls.
Participate in designing the architecture of the data lake platform for new use cases.
Responsible for verifying changes implemented by vendor and deploy it into the data lake production environment.
Identify, design, and implement continuous
Able to understand business requirements and translate to design document from data ingestion to data modelling.
Develop data pipelines and ingest data from various sources to data warehouse for consumption from 3rd party applications.
Job requirements:
Experience in utilising Microsoft Azure and any related tooling for data engineering (such as Azure Data Factory, Azure Data Lake Storage, Databricks, Synapse).
Knowledge of data modelling and understanding of different data structures and their benefits and limitations.
Proficiency in writing SQL including stored procedures in languages such as T-SQL and PL/SQL.
A minimum 2 years’ experience in data engineering (e.g. data modelling, data pipeline, data architecture, ETL).
How to Apply:

Interested applicants may apply by sending in your updated résumé (in MS Word format) to my email or apply directly:
Consultant: Tan Jun Jie
EA personnel reg. no.R1878852
EA License No. 17C8502",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-technology-8000-month-integrity-partners-ad7bb983082b61679530e39c54df361d?source=MCF&event=Search
94,ASSISTANT PROJECT ENGINEER (DATA CENTRE INDUSTRY),DATA-SPHERE (S) PTE. LTD.,"JOB DESCRIPTION:
1. Assist to coordinate project related activities including scheduling and monitoring project timelines.
2. Oversee and manage sub-contractors and progress at site during project execution stage.
3. Coordinate and resolve technical and site issues with customer/main contractor.
4. Attend site meeting/site inspection with management/consultant/contractors.
5. Ensure proper project documentation and project handover.
6. Ensure and enforce workplace safety procedures compliance with WSH Act & regulations.
1. Prepare safe work procedures, method statements, risk assessment and related documentation.

JOB REQUIREMENTS:
1. Nitec/Diploma in Electrical/Mechanical/Electronics Engineering
2. Minimum 2 to 3 years experience in project management and/or site coordination.
3. Candidate with WSH working experience are welcome
4. Possess Class 2B/Class 3 license
5. Good communication skills, team player and hardworking.

OTHERS:
1. Positive working environment
2. Training will be provided
3. Immediate vacancies available",https://www.mycareersfuture.gov.sg/job/engineering/assistant-project-engineer-data-sphere-e8b11595c9789afa8f5ecceddf74a97e?source=MCF&event=Search
95,BIG DATA ENGINEER (Banking Financial Compliance ANALYTICS),D L RESOURCES PTE LTD,"BIG DATA ENGINEER / DATA SCIENTIST, FCC ANALYTICS

Job Description:

Big Data Engineering
Create, build and maintain the data infrastructure required for Extraction, Transformation and Loading of data from a wide variety of sources.
Ensure high-quality data is delivered to support Compliance / FCC model development.
Support the implementation of Data Analytics / Automation for Compliance teams and Business stakeholders
Liaise with relevant stakeholders (e.g., Data Management Office) to identify and assess suitability of data for Compliance / FCC Data models.
Liaise with Business stakeholders / analysts and ensure assembled data assets used for model development meet business requirements.
Build & maintain data dictionaries / data requirements of implemented data models and coordinate with Data Scientist(s) in developing model narratives.
Monitor the execution & performance of data models and liaise with IT for any technical / system outages
Keep track of datasets / tables in the working schema and support purging of unused tables periodically.
Perform data analysis required to troubleshoot data related issues and support the resolution of raised data issues.

Support model maintenance
Liaise with Business Analyst to receive and understand business feedback on model performance and incorporate feedback into models
Re-train and recalibrate existing FCC analytical models to prevent model drift periodically or as needed

New model development
Work closely with model end-users and other key stakeholders (e.g., Head of FCC Analytics, Business Analyst, Data and Ops Engineer, GC) to identify additional areas which require analytics support or future model build and include those models in development pipeline
Develop model narratives (e.g., purpose, logic, parameters, data requirements, output surfacing / structuring) in collaboration with the business and other relevant stakeholders
Work closely with other Data Scientist(s) and Business Analyst, and undertake the end-to-end FCC model development, including data wrangling, exploratory data analysis, feature selection, model selection, training, testing, etc.
Build a range of models (rule-based, supervised / unsupervised models, etc.) on structured, semi-structured, and/or unstructured data if needed",https://www.mycareersfuture.gov.sg/job/banking-finance/big-data-engineer-d-l-resources-68a461c123124bf84273fb322bc9b344?source=MCF&event=Search
96,Data Engineering,ENVIRODYNAMICS SOLUTIONS PTE. LTD.,"About the job
About us:
Our client is an aspiring nation's Digital Transformation organization, with a mission to empower Smart Nation across public and private sectors and enhance the lives of citizens.
Our services span from strategic advisory through to digital, data and AI delivery. Our focus is on harnessing disruptive innovation to unlock economic and social value enabled by technology. We would be working on a wide range of use cases across different sectors, and our focus would be on generating ROI for our client's data assets.

Key Roles & Responsibilities:
Purpose
Place client value and human experience at the center of everything we do
Develop and deliver value to clients by building large scale enterprise data pipelines to capture, transform and store date to support reporting, automated systems and AI/ML
Team
Be a part of a world-class team of experts in Data engineering
Be a part of a culture of excellence and with confidence, charisma, context, and humility, working effectively at all levels
Delivery
Delivery of data pipelines to drive material impact and drive disruptive transformation across our clients in public and private sectors
Support thought leadership development as a team for data engineering and scaling deployments
Partnership
Work with the organization’s ecosystem of partners to deliver client value
Adopt a cloud-first strategy to enhance agility and elasticity by partnering with vendors to support specific public sector needs
Requirements & Qualifications:
Bachelor’s Degree/Masters Degree in computer science or any other engineering discipline
Minimum 3 years of designing, building and operationalizing data solutions and applications (with batch or streaming data)
Excellent understanding on SQL data storage structures and storage/query optimizations
Mastered SQL querying to build any data presentations using joins, reference tables, groupings, statistics etc.
Proficient in at least one core language: Python, Scala, Java
Exposure to concepts like Serverless computing, CI/CD, Containerization, Infrastructure as Code, code version control and automated testing
Exposure to one of more of cloud services like AWS, Azure or GCP
Awareness of a broad range of tools to assist in the data engineering: Databricks, Snowflake, dbt, Alteryx, Datameer, dataform, Informatica, Talend, Docker, Kubernetes, Kafka, Kinesis, Spark, Flink, MongoDB, Cassandra, HBase, Redis, PostgreSQL, MySQL, DB2, Neo4j, S3, KSQL, Terraform, Ansible & Datadog
Strong ability to communicate with a broad range of clients, colleagues, and partners across a variety of contexts and formats.
Strong ability to develop and maintain relationships amongst clients, colleagues, and partners
Show active tracks of improving knowledge and skills (e.g. courses, podcasts, books, experimentation, open source volunteering, tech meetups etc.)
Ability to work independently with minimal guidance
Ability to work as part of a large team
Ability to work within an unstructured environment with ability to multitask well
EnviroDynamics Solutions Pte Ltd
Terence Ng Yew Beng
Reg. No: R1324803
EA License No.: 12C6285",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineering-envirodynamics-solutions-f0b004759ef3c3bf4d32a149c44a790f?source=MCF&event=Search
97,Data Engineering Manager,ENVIRODYNAMICS SOLUTIONS PTE. LTD.,"Place client value and human experience at first priorities.
Develop and deliver value to clients by building large scale enterprise data pipelines to capture, transform and store date to support reporting, automated systems and AI/MLTeam
Build a world-class team with experts in Data engineering
Create a culture of excellence and lead with confidence, charisma, context, and humility, working effectively at all levels
Lead design & delivery of Data pipelines to drive material impact and drive disruptive transformation across our clients in public and private sectors
Support development of go-to-market plans for Data engineering, understand strategic opportunities, develop trusted partnerships, and deliver social progress
Thought leadership for data engineering and scaling deployments
Educate, enable, and coach teams on Data Machine Learning Engineers and in the broader community
Adopt a cloud-first strategy to enhance agility and elasticity by partnering with vendors to support specific public sector needs
Harness cutting-edge research through a triple helix partnership between research, industry, and government to drive state-of-the-art with bi-directional rotations
Requirements
Bachelor’s Degree/Masters Degree in Computer Science/Data Analytics or similar technology field
Minimum 7 years of designing, building and operationalizing large scale enterprise data solutions and applications (both with batch and streaming data)
Experience using one or more of AWS / Azure / GCP data and analytics services in combination with custom solutions - Spark, Azure Data Lake, Databricks, Snowflake, HDInsights, SQL DW, DocumentDB, Glue, Athena, Elastic Pool etc.
Experience with Stream platforms and real-time aggregation platforms like Kafka, Kinesis, Spark, Flink, KSQL etc.
Experience with multiple data storage solutions for analytics, operational and archival purposes like MongoDB, Cassandra, HBase, Redis, PostgreSQL, MySQL, DB2, Neo4j, S3 etc.
Experience with data transformation tools/platforms like: dbt, Alteryx, Datameer, dataform, Informatica, Talend etc. and their data quality management features
Mastered at least one core language: Python, Scala, Java
Good exposure to concepts like Serverless computing, CI/CD, Containerization, Infrastructure as Code, code version control and automated testing
Experience building historical and real-time operational ‘feature layers’ to support AI/ML teams
Excellent understanding of the state of Data Engineering evolution in the industry through active tracks of improving knowledge and skills (e.g. courses, podcasts, books, experimentation, open source volunteering, tech meetups etc.)
Track record of delivering scalable Data pipeline services running in production.
Strong ability to communicate with a broad range of clients, colleagues, and partners across a variety of contexts and formats.
Strong ability to explain design decisions and provide alternatives supported by analysis like pro/con, past experiences etc.
Strong ability to develop and maintain relationships amongst clients, colleagues, and partners
Demonstrated capability to lead, inspire, coach and mentor team members and colleagues.
Ability to work within an unstructured environment with ability to multitask well
Kindly understand that only shortlisted candidates will be notified.
EnviroDynamics Solutions Pte Ltd
Poon Wai Soon, Bernard
Reg. No: R2197713
EA License No.: 12C6285",https://www.mycareersfuture.gov.sg/job/banking-finance/data-engineering-manager-envirodynamics-solutions-5ebcf998921fcc09d23b110627c6ff29?source=MCF&event=Search
98,Data Centre Engineer,UPPER SPRING CONSULTING PTE. LTD.,"We are representing our client (An Engineering Firm) to look for a Data Centre Engineer to complement their existing team. The Data Centre Engineer mainly provides data centre operations and monitoring service. He/She will be expected to have desktop support background to perform desktop support activities as well.

Responsibilities
Use data centre management tools to produce management information and investigate issues where necessary.
Carry out routine audit and checks
Assist in handling all day-to-day operational data centre monitoring activities.
Configuration for servers, networks and infrastructure-related equipment.
Support planned maintenance events and provide support to system and network administrators.
Perform regular backups and restores on a schedule and track offsite storage. Carry out documented configuration for allocation of storage, installation and maintenance of storage system.
Identify operational problems and contribute to their resolution.
Use standard management and reporting tools to collect and report on storage utilisation, performance and backup statistics.
Perform desktop support roles
Requirements
Minimum Diploma in Information Technology or equivalent.
2 years of experience in data centre operations and DCIM tools and 3 years in desk top support
Experience in VMware, Linux, Windows, network appliances, systems/Active directory, SAN storage and system administration
Good communications and troubleshooting skills.
Job location in the west of Singapore",https://www.mycareersfuture.gov.sg/job/engineering/data-centre-engineer-upper-spring-consulting-73d0a3ef693391be369127f8ea6467b3?source=MCF&event=Search
99,Manager-Data Engineering,TRINITY CONSULTING SERVICES PTE. LTD.,"· Bachelor’s Degree/Master’s Degree in Computer Science/Data Analytics or similar technology field
· Minimum 7 years of designing, building and operationalizing large scale enterprise data solutions and applications
· Experience using one or more of AWS / Azure / GCP data and analytics services in combination with custom solutions - Spark, Azure Data Lake, Data bricks, Snowflake, HDInsights, SQL DW, DocumentDB, Glue, Athena, Elastic Pool etc.
· Experience with Stream platforms and real-time aggregation platforms like Kafka, Kinesis, Spark, Flink, KSQL etc.
· Experience with multiple data storage solutions for analytics, operational and archival purposes like MongoDB, Cassandra, HBase, Redis, PostgreSQL, MySQL, DB2, Neo4j, S3 etc.
· Experience with data transformation tools/platforms like: dbt, Alteryx, Datameer, dataform, Informatica, Talend etc. and their data quality management features
· Mastered at least one core language: Python, Scala, Java
· Good exposure to concepts like Serverless computing, CI/CD, Containerization, Infrastructure as Code, code version control and automated testing
· Excellent understanding of the state of Data Engineering evolution in the industry through active tracks of improving knowledge and skills
· Track record of delivering scalable Data pipeline services running in production.",https://www.mycareersfuture.gov.sg/job/information-technology/manager-data-engineering-trinity-consulting-services-98448cd476bd95877623b8041871685d?source=MCF&event=Search
100,Infrastructure Engineer -Data Centre Operations(Contract),RANDSTAD PTE. LIMITED,"Job Purpose
The enterprise Information Technology field is rapidly changing. The explosion of data tied to the ubiquity of digital technologies and services available to consumers is changing the expectations of senior leaders, employees, customers and patients. People want access to information, everywhere, on any device, anytime. These challenges require IT to significantly uplift its technology assets and skillsets to speed up and drive the changes. To address this challenge, IT has established a three hub model in Singapore, Branchburg and Prague to provide a follow-the-sun operational model leveraging networked teams that can better support the business, the patients and make the crosswork between different departments and regions more and more agile.
We are seeking a talented and energetic Infrastructure Engineer to support our Singapore manufacturing network infrastructure. You will have the opportunity to work with global teams to identify and tackle the biggest opportunities and challenges at the intersection of healthcare, information and technology. This position will report into the Network Availability product group within Network Services.
The Infrastructure Engineer will be the site Network SME working with Network Demand Management on internal and external Network demands, support the deployment of site related projects, manage day to day operations and breakfixes following Network Services strategies and standards. The position requires someone with strong Networking experiences to troubleshoot/remediate wide breadth of issues and support a variety of technologies as part of a lean, agile and fast paced team with the aim to maintain and improve the reliability of the Networks. A strong ability to collaborate with stakeholders across Network Product teams, Managed partners, IT functional groups and Business is also required on a daily basis. We are looking for someone who will partner with the Site IT and Global Support Teams to support the critical manufacturing network environment, with a broad understanding of Data Network and Network Security technology areas as well as wide exposure to complex global network infrastructure setup. The individual will need to demonstrate sound technical knowledge, good communication and good operational mindset.
Extent of Travel
5% - 10%(Locally within Singapore Site – 2 to 3 locations)
Education level:
Education: MSc Degree or BSc Degree or equivalent with relevant experience in Computer Science, Computer Science Engineering, Math, or equivalent experience
Required Experience and Skill:
Strong Routing & Switching and Network Security experiences
Excellent communication and interpersonal skills is a must
Ability to work in high pressure dynamic environment and independently prioritize work.
Maintain the knowledge and integrity of the site Network infrastructure following Network Services standards
Handle operation issues and investigations or operation requests
Work with Network Demand management and local Site IT to support project roll out at site level
Good knowledge in TCP/IP protocol stacks
Strong knowledge in LAN, WAN, Wireless, DDI, Firewall, IPS, DMZ, Structure Cabling etc technologies
Experience with Network Operations and drive Network automation adoptions
Familiar with troubleshooting, automation, monitoring and reporting tool such as or similar to (example ServONE, Ansible, Glueware, NetBrain, Thousand Eyes, Wireshark)
Desired Experience and Skills:
5 years in providing technical operation support and service delivery in Data Networking areas
Certification such as CCIE and CCNP will be added advantages
Familiar with Industrial control systems network design, IOT and manufacturing networks will be added advantages
Familiar with F5, SD-WAN (Velocloud), AWS, Azure, Palo Alto, ASA, FTD and SASE will be ideal
Understanding of service management & best practices (Example ITIL) – Incident, Problem, Change
Understanding of ITSM tools such as ServiceNow
Experience with project management
The selected candidate will have excellent time management skills, be a self-starter, and able to set priorities according to business needs with minimal oversight
A good team player and a strong desire to locate and resolve the root cause of complex problems
“Applicants must be fully vaccinated or have a valid exemption in accordance with MOM’s regulations to allow them to enter the workplace. Applicants may be required to share verifiable COVID-19 vaccination documents or proof of a valid exemption at the point of offer. Randstad Pte. Limited and/or the Client reserve the right to withdraw an offer if the applicant fails to provide verifiable COVID-19 vaccination and/or proof of exemption documents.”
EA License: 94C3609
Reg No: R1107239

Interesr applicants please send CV to vendrick.guirao@randstadsourceright.com.sg",https://www.mycareersfuture.gov.sg/job/healthcare/infrastructure-engineer-data-centre-operations-randstad-2a916583addc6aed8caab44f6de418f1?source=MCF&event=Search
101,Research Engineer (Data Analyst),NATIONAL UNIVERSITY OF SINGAPORE,"Job Description
In this position, you will be working on end-to-end data pipeline implementation from understanding research objectives, data collection using cameras and wearable sensor technology, exploratory data analysis, cleaning and pre-processing of raw data, modelling (using Machine Learning/Deep Learning techniques) and sharing of insights to stakeholders using visualizations. The goal is to find a relationship between qualitative and quantitative data in order to understand passengers’ preferences and improving the passengers’ inflight experience. You will work closely with hardware engineers, design researchers and project manager to successfully collect data from sensors in a cabin stimulator, leverage predictive modelling and provide meaningful insights.
Requirements
- Bachelor's or Master’s degree (preferred) in Data Science, Computer Science, Engineering and Mathematics, Statistics or a related-field
- Applied experience with statistical modelling (hypothesis testing), machine learning (supervised and unsupervised learning techniques) and modern deep learning architectures
(CNNs, LSTMs).
- Experience with at least one programming language (with a preference for those commonly used in machine learning or scientific computing such as Python or C++)
- Proficient in digital signal processing and data analysis
- Familiar with embedded coding and iOS/Android app development
- Experience exploring, analysing, and visualising data.
- Hands-on experience using PyTorch, TensorFlow, Pandas, NumPy, Sklearn or similar machine learning/scientific libraries.
- Proficient in handling complex requirements and turn into computation logic
- Candidate should like reading documentation and research papers.
- Able to communicate and relay Data Science solutions adequately to business stakeholders.
- Candidate should be comfortable working on multiple projects and in a dynamic environment.
- Candidate should be able to work independently as well as be a team player.
Interested applicants are invited to apply directly at our NUS Career Portal.
We regret that only shortlisted candidates will be notified.
Covid-19 Message
At NUS, the health and safety of our staff and students are one of our utmost priorities, and COVID-vaccination supports our commitment to ensure the safety of our community and to make NUS as safe and welcoming as possible. Many of our roles require a significant amount of physical interactions with students/staff/public members. Even for job roles that may be performed remotely, there will be instances where on-campus presence is required.
Taking into consideration the health and well-being of our staff and students and to better protect everyone in the campus, applicants are strongly encouraged to have themselves fully COVID-19 vaccinated to secure successful employment with NUS.",https://www.mycareersfuture.gov.sg/job/sciences/research-engineer-national-university-singapore-19e38e8ea711a4cf5184affc6e41d351?source=MCF&event=Search
102,"Data Operation / Data Ops Engineer ( Python , Azure Data Factory , SQL , Fresh Welcome , Training Provided , AWS + VB!!! ) - URGENT HIRING!!!",TRUST RECRUIT PTE. LTD.,"Benefit:
AWS + VB
Good career progression
Responsibilities:
Build and maintain data systems or pipelines.
Perform setup, installation, configuration, troubleshooting and/or upgrade for COTS products.
Develop or implement ways to improve data warehouses, data lakes or equivalent platforms.
Involve in the creation of documentations e.g. design documents, troubleshooting guides etc
.
Requirements:
Diploma/Degree in Computer Engineering/Computer
Preferably 1 - 4 years' of working experience in related fields.
Science/Information Technology or related technical discipline
Knowledge and/or experience in data management or data engineering
Experience with Linux commands and shell script
Knowledge and/or experience in relational (including SQL) or NoSQL database (e.g. document, graph)
Knowledge and/or experience in one or more of the following will be an advantage:
Data / Search / Automation platforms such as Hadoop, Elasticsearch, Ansible respectively
Data integration tools such as Talend, DataStage, Denodo
Programming languages such as Python, Spark
Microsoft Azure Cloud services such as Azure Data Factory, Azure Synapse Analytics
Analytics platforms such as Databricks, Dataiku, Data Robot
Good problem-solving skills
Able to work independently and as a team
HOW TO APPLY:
Interested applicants, please click on “Apply Now” and provide the below details in your resume.
We regret only shortlisted candidates will be notified.
Important Note: Trust Recruit Pte Ltd is committed to safeguarding your personal data in accordance with the Personal Data Protection Act (PDPA).
Please read our privacy statement on our corporate website www.trustrecruit.com.sg.
Trust Recruit Pte Ltd
EA License No: 19C9950
EA Personnel: Tan Jia Cheng
EA Personnel Reg No: R22110254",https://www.mycareersfuture.gov.sg/job/information-technology/data-operation-data-ops-engineer-urgent-hiring-trust-recruit-a26a408dde3e91bc0ffa073d486a9470?source=MCF&event=Search
103,Data Science Engineer,HAIER SINGAPORE INVESTMENT HOLDING PTE. LTD.,"COMPANY BACKGROUND
Haier is the number one brand of Major Appliances in the world with 9.7 percent of global market share. Headquartered in Qingdao, Haier has over 80,000 employees across 30 countries in the world.
Haier Singapore is one of the holding companies under Haier Group. As the integrated regional centre, Haier Singapore is the main platform to provide procurement, trading, R&D and big data supports to over 80 countries in Asia, Europe, Africa and North America markets.
As the continuous demands from global businesses, we are looking for experienced Data Science Engineer to join our global big data team.
KEY RESPONSIBILITIES
Based in Singapore, you will be part of the global big data team and responsible for the development, maintenance, integration, data governance and data reporting of Haier’s overseas business systems, including:
Work closely with data scientists, analysts and internal and external users to deliver satisfying data products.
Provide ETL solution including significant integrations with tier one bank core systems and between complex business platforms.
Support Enterprise Data Warehouse.
Provide internal training on various planning frameworks developed by Data Science Engineers.
KEY REQUIREMENTS
The ideal candidates we are looking for should be seasoned Data Science Professionals with:
Degree in computer science or its equivalent
With minimum 3 years of experience in Data Science Engineering and object-oriented development within a commercial environment.
Wide experience across databases (Oracle, SQL Server, MySQL), ETL (TALEND, Kettle, Datastage, Informatica, Sqoop) and Business Intelligence tools.
Experienced in large scale data warehouse build and support, Oracle, SQL Server, Oracle ExaData, Teradata architecture and design, logical and physical data modelling, forward engineering to XSD, XSLT for XML messaging.
Knowledge of SAP ERP, Python, Business Object, Bex Analyzer, ABAP, BAPI, BSP, Java, analytics report.
Team player with good people skills, able to work with people at all levels.
Strong communication, presentation and interpersonal skills.",https://www.mycareersfuture.gov.sg/job/information-technology/data-science-engineer-haier-singapore-investment-holding-3e66882c0b5fd3eea74eb2e856611d9d?source=MCF&event=Search
104,Data Centre Engineer,C&W SERVICES (S) PTE. LTD.,"Lead a team of technicians to ensure maximum uptime of the data centre facilities and its equipments.
Delegate task for technicians on the daily work operations.
Plan, prepare and manage the preventive maintenance programmes and servicing work schedules.
Reviewing of site incidents reports, safety documents and other documents/report/ related to the site operations.
Preparing of contract tender/quotations for maintenance works or ad-hoc minor project works.
Propose, revise and implement improvements on existing work, processes and procedures.
Provide support to the Facility Manager on the site operation related matters.
Adhere to company’s environmental safety health policy and procedure, standard operating procedure and risk assessment.
Requirements :
Minimum Nitec in Electrical/Mechanical/Building Services Engineering of its equivalent.
Minimum 4 years relevant working experience, preferably in data centre facilities.
Able to work beyond working hours or weekends, if required.
24/7 Emergency Call support and site attendance, as and when required
Cushman & Wakefield is committed to building a diverse and engaged workforce and supporting an inclusive environment where our employees can do their best work. We believe that embracing new perspectives helps us solve problems, create opportunities and develop new ideas. For more details on DEI, please visit our webpage at https://www.cushmanwakefield.com/en/about-us/diversity-equity-and-inclusion",https://www.mycareersfuture.gov.sg/job/real-estate/data-centre-engineer-cw-services-92188366d46abd39f5b6ff489f6e13aa?source=MCF&event=Search
105,Big Data Engineer,KERRY INTERIM PTE. LTD.,"Description

Kerry Interim is currently hiring a Big Data Developer / Data Modeller who is proficient with Cloudera Distributed Hadoop (CDH), Big Data, Spark, and Informatica. This role will involve strong experience in testing life cycles as well as excellent verbal and written communications skills to add value to the client-facing experiences.

If you have exposure to the core banking / financial services domain and are adept at learning and applying new technologies, we would like to hear from you.

Responsibilities

Your responsibilities will include knowledge of Hadoop administration, SQL and relational database programming. Your role will involve exposure to NoSQL databases (e.g., HBase, Cassandra, Mongo DB, CouchBase) and experience in data integration tools such as Informatica and Data Stage, as well as business intelligence tools such as SAP BO and Cognos.

Skills and experience required:
Min Degree in engineering, computer science, or related technical field with 6 years of relevant working experience and 3 years of experience on Big Data implementation projects
Experience with Cloudera Hadoop Dataware housing tools like Hive, Impala and Spark
Experience in advanced SQL with hands on experience on writing optimized SQLs in Hive/Impala/Spark
Experience with either programming languages like Java or Scala or Python is a must
Proficient in analysing and writing Linux shell scripts
Certification in big data will be an advantage
Experience in Agile development methodology is advantageous
To Apply
Please send us your application via the apply link with your latest resume, salary and notice period for a confidential discussion with Jun Hao at junhao@kerryinterim.com. We regret that only shortlisted candidates will be notified.

Reg: R22110394 Lic: 22C0942",https://www.mycareersfuture.gov.sg/job/information-technology/big-data-engineer-kerry-interim-a43899474599fc3eeb36d559759a264f?source=MCF&event=Search
106,Senior Security Engineer (Data Loss Prevention Operations),MORGAN MCKINLEY PTE. LTD.,"If you are a security Engineer involved in the DLP Operations then this is the role you need to apply to!

Our client is a leading HeathTech agency in Singapore supporting in developing, implementing and maintaining IT systems and security of these systems

Position Summary
The Security Lead is part of the Data Loss Prevention (DLP) Operation team which serve as the central DLP policy and incident response team . You will be reporting to the DLP Operation Lead for DLP incident response management. In addition, you are required to front stakeholders (C-level stakeholders)

Roles And Responsibilities
The Security Lead will be responsible for DLP incidents response management as follow:
· Development and maintenance of DLP Operation Procedure and review for areas of improvement periodically.
· Develop, refine and maintain DLP incident escalation workflow working with relevant forums (e.g. DLP Operations Workgroup)
· Escalate all DLP incidents to the based on the agreed escalation process for respective entities.
· Highlight and work with DLP Policy team for refinements of DLP Policies to improve detection and reduce false positives.
· Deliver statistical reports and management reports to stakeholders.
· Assist the DLP project team in areas of IT Audit, security review or policy compliance assessment related to DLP project/infrastructure.
· Highlight and work closely with the DLP project team if there is any system issue or abnormalities with the DLP infrastructure.
· Recommend configuration changes related to DLP infrastructure to the DLP project team for improvement and efficiency.

Requirements / Qualifications
·Diploma/Degree in Computer Science, Engineering or equivalent
·At least 7+ years of experience in IT and also experience in Incident Management, DLP Operations or SOC
·Good team player as well as strong communications skills with stakeholders at all levels
·Strong analytical skills and ability to work independently
·Knowledge and experience in DLP Operations is an advantage.
As this role has exposure to email content, the incumbent must maintain strict confidentiality in maintaining the chain of information

EA Licence No: 11C5502 | EAP Registration No: R22105417
Smitha Karanth",https://www.mycareersfuture.gov.sg/job/information-technology/senior-security-engineer-morgan-mckinley-24d09ed42c76d1c853640c32436c73f7?source=MCF&event=Search
107,"Data Operation / Data Ops Engineer ( Python , Azure Data Factory , SQL , Fresh Welcome , Training Provided , AWS + VB!!! ) - URGENT HIRING!!!",TRUST RECRUIT PTE. LTD.,"Benefit:
AWS + VB
Good career progression
Responsibilities:
Build and maintain data systems or pipelines.
Perform setup, installation, configuration, troubleshooting and/or upgrade for COTS products.
Develop or implement ways to improve data warehouses, data lakes or equivalent platforms.
Involve in the creation of documentations e.g. design documents, troubleshooting guides etc
.
Requirements:
Diploma/Degree in Computer Engineering/Computer
Preferably 1 - 4 years' of working experience in related fields.
Science/Information Technology or related technical discipline
Knowledge and/or experience in data management or data engineering
Experience with Linux commands and shell script
Knowledge and/or experience in relational (including SQL) or NoSQL database (e.g. document, graph)
Knowledge and/or experience in one or more of the following will be an advantage:
Data / Search / Automation platforms such as Hadoop, Elasticsearch, Ansible respectively
Data integration tools such as Talend, DataStage, Denodo
Programming languages such as Python, Spark
Microsoft Azure Cloud services such as Azure Data Factory, Azure Synapse Analytics
Analytics platforms such as Databricks, Dataiku, Data Robot
Good problem-solving skills
Able to work independently and as a team
HOW TO APPLY:
Interested applicants, please click on “Apply Now” and provide the below details in your resume.
We regret only shortlisted candidates will be notified.
Important Note: Trust Recruit Pte Ltd is committed to safeguarding your personal data in accordance with the Personal Data Protection Act (PDPA).
Please read our privacy statement on our corporate website www.trustrecruit.com.sg.
Trust Recruit Pte Ltd
EA License No: 19C9950
EA Personnel: Tan Jia Cheng
EA Personnel Reg No: R22110254",https://www.mycareersfuture.gov.sg/job/information-technology/data-operation-data-ops-engineer-urgent-hiring-trust-recruit-62ae47544cb3e3a21b423491037a3d93?source=MCF&event=Search
108,"Data Operation / Data Ops Engineer ( Python , Azure Data Factory , SQL , Fresh Welcome , Training Provided , AWS + VB!!! ) - URGENT HIRING!!!",TRUST RECRUIT PTE. LTD.,"Benefit:
AWS + VB
Good career progression
Responsibilities:
Build and maintain data systems or pipelines.
Perform setup, installation, configuration, troubleshooting and/or upgrade for COTS products.
Develop or implement ways to improve data warehouses, data lakes or equivalent platforms.
Involve in the creation of documentations e.g. design documents, troubleshooting guides etc
.
Requirements:
Diploma/Degree in Computer Engineering/Computer
Preferably 1 - 4 years' of working experience in related fields.
Science/Information Technology or related technical discipline
Knowledge and/or experience in data management or data engineering
Experience with Linux commands and shell script
Knowledge and/or experience in relational (including SQL) or NoSQL database (e.g. document, graph)
Knowledge and/or experience in one or more of the following will be an advantage:
Data / Search / Automation platforms such as Hadoop, Elasticsearch, Ansible respectively
Data integration tools such as Talend, DataStage, Denodo
Programming languages such as Python, Spark
Microsoft Azure Cloud services such as Azure Data Factory, Azure Synapse Analytics
Analytics platforms such as Databricks, Dataiku, Data Robot
Good problem-solving skills
Able to work independently and as a team
HOW TO APPLY:
Interested applicants, please click on “Apply Now” and provide the below details in your resume.
We regret only shortlisted candidates will be notified.
Important Note: Trust Recruit Pte Ltd is committed to safeguarding your personal data in accordance with the Personal Data Protection Act (PDPA).
Please read our privacy statement on our corporate website www.trustrecruit.com.sg.
Trust Recruit Pte Ltd
EA License No: 19C9950
EA Personnel: Tan Jia Cheng
EA Personnel Reg No: R22110254",https://www.mycareersfuture.gov.sg/job/information-technology/data-operation-data-ops-engineer-urgent-hiring-trust-recruit-de0321aa879c5d3322b632e83d2e1dec?source=MCF&event=Search
109,Data Engineer (ETL),INTEGRATED HEALTH INFORMATION SYSTEMS PTE. LTD.,"Role and Responsibilities
Manage multiple projects and is responsible for the execution from initiation to completion
Determine project goals to ensure the project supports business objectives and strategies.
Develop project plans which include requirements, scope, deliverables, budget and schedules.
Projects tasks and resource requirements and to achieve optimal resource utilisation.
Manage the vendor selection process (calling, evaluation and awarding of tenders).
Evaluate potential solutions and make recommendations to resolve business problems.
Liaise closely with business users and build good rapport.
Liaise closely with vendors in project implementation, application testing, supporting application patches and upgrades in accordance with project methodologies and policies.
Manage the risks that affect the delivery of the project outcome.
Track project deliverables and ensure projects are completed within budget, schedules and quality standards.
Implement process improvements to reduce development time.
Present reports and project updates to stakeholders on a regular basis.
Provide on-going application support and be involved in various stages of the SDLC.
Conduct user requirement analysis for the development / implementation of new systems and for enhancements to existing systems, including involvement in the system integration testing phase.
Perform project implementation and application testing according to project and quality assurance procedures and methodologies.
Conduct end user training for system implementations or enhancements.
Manage a team by monitoring the work progress to meet project requirements for medium to large projects.
Provide 24/7 primary application maintenance standby support.
Provide guidance and coaching to junior team members.
Requirements / Qualifications
· At least 7 years experience in IT Project Management
· At least 3 years experience in vendor management
· Has implemented at least 2 medium to large scale projects
· Solid understanding in Business Processes
· Solid understanding and hands on experience in all phases of project lifecycle
· Experience in budgeting (costing, cost evaluation analysis etc.)
· Experience in various procurement methodology e.g. RFQ, RFP etc.
· Experience in writing approval papers
· Having good communication skills (written and spoken)
· Be a team player
· Being a creative problem-solver, make choices and take responsibility for their own actions
· Ability to interact with all levels of stakeholders
· Ability to perform root cause analysis
· Degree in Computer Science, Computer Engineering or equivalent",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-integrated-health-information-systems-d8bf157bbd89856873d876c0bc155fff?source=MCF&event=Search
110,DATA SCIENTIST / ENGINEER (Banking Compliance),D L RESOURCES PTE LTD,"Job Description:

BIG data platform maintenance
Create, build and maintain the data infrastructure required for Extraction, Transformation and Loading of data from a wide variety of sources.
Ensure high-quality data is delivered to support Compliance / FCC model development.
Support the implementation of Data Analytics / Automation for Compliance teams and Business stakeholders
Liaise with relevant stakeholders (e.g., Data Management Office) to identify and assess suitability of data for Compliance / Financial Compliance Data models.
Liaise with Business stakeholders / analysts and ensure assembled data assets used for model development meet business requirements.
Build & maintain data dictionaries / data requirements of implemented data models and coordinate with Data Scientist(s) in developing model narratives.
Monitor the execution & performance of data models and liaise with IT for any technical / system outages
Keep track of datasets / tables in the working schema and support purging of unused tables periodically.
Perform data analysis required to troubleshoot data related issues and support the resolution of raised data issues.

Support model maintenance
Liaise with Business Analyst to receive and understand business feedback on model performance and incorporate feedback into models
Re-train and recalibrate existing Finacnial Complienace analytical models to prevent model drift periodically or as needed

New model development
Work closely with model end-users and other key stakeholders (e.g., Head of FCC Analytics, Business Analyst, Data and Ops Engineer, GC) to identify additional areas which require analytics support or future model build and include those models in development pipeline
Develop model narratives (e.g., purpose, logic, parameters, data requirements, output surfacing / structuring) in collaboration with the business and other relevant stakeholders
Work closely with other Data Scientist(s) and Business Analyst, and undertake the end-to-end FCC model development, including data wrangling, exploratory data analysis, feature selection, model selection, training, testing, etc.
Build a range of models (rule-based, supervised / unsupervised models, etc.) on structured, semi-structured, and/or unstructured data if needed",https://www.mycareersfuture.gov.sg/job/banking-finance/data-scientist-engineer-d-l-resources-738c476b96f2d32652b5565bd05d37c8?source=MCF&event=Search
111,Data Engineer - Big Data,SAGL CONSULTING PTE. LTD.,"Requirement
• Experience in developing banking applications using ETL, Hadoop, and Teradata
• Experience in Teradata (SQL, BTEQ scripting) and Hadoop (Hive, Impala, Kudu).
• It is desirable to have working experience in No SQL and virtualized Database Environment.
• Experience in Teradata FSLDM in Finance industry,
• How BI tools integrate with Data Mart and Data Lake (Qlik Sense, Power BI)
• Scripting using Shell script and awk programming
• Good understanding of CI/CD automation, bitbucket, and Github.
• Data Modeling using industry-standard data model (FSLDM)
• Good understanding of Hadoop, In memory, No SQL",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-big-data-sagl-consulting-f4899b3b91a200fc8c6c9e209729c4b6?source=MCF&event=Search
112,Data Engineer - SQL - Contract = 12 months,ZENITH INFOTECH (S) PTE LTD.,"This is a 12 months contract assigned to our client

Work Location: To be confirmed
Salary Range : $3,500-$5,500

Primary Skills
1. Microsoft SQL Server Integration Services SSIS

Job Description
1. Knowledge on MySQL
2. Leverage your understanding of complex data analysis and modeling to ensure project teams and
clients can successfully extract value from their data.
3. Support hypothesis generation and testing, exploratory analysis, data preparation for statistical
modelling/machine learning/deep learning, building machine learning or deep learning models
and model interpretations.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-sql-contract-12-months-zenith-infotech-3058ea82980b9c595c68bb49df5ca8f3?source=MCF&event=Search
113,Data Engineer - SQL - Contract = 12 months,ZENITH INFOTECH (S) PTE LTD.,"This is a 12 months contract assigned to our client

Work Location: To be confirmed
Salary Range : $3,500-$5,500

Primary Skills
1. Microsoft SQL Server Integration Services SSIS

Job Description
1. Knowledge on MySQL
2. Leverage your understanding of complex data analysis and modeling to ensure project teams and
clients can successfully extract value from their data.
3. Support hypothesis generation and testing, exploratory analysis, data preparation for statistical
modelling/machine learning/deep learning, building machine learning or deep learning models
and model interpretations.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-sql-contract-12-months-zenith-infotech-bc5d6c1e69153a70220b5808e5a3dbf1?source=MCF&event=Search
114,Data Engineer - SSIS / SQL - Contract = 12 months,ZENITH INFOTECH (S) PTE LTD.,"This is a 12 months contract assigned to our client

Work Location: To be confirmed
Salary Range : $3,500-$5,500

Primary Skills
1. Microsoft SQL Server Integration Services SSIS

Job Description
1. Knowledge on MySQL
2. Leverage your understanding of complex data analysis and modeling to ensure project teams and
clients can successfully extract value from their data.
3. Support hypothesis generation and testing, exploratory analysis, data preparation for statistical
modelling/machine learning/deep learning, building machine learning or deep learning models
and model interpretations.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-ssis-sql-contract-12-months-zenith-infotech-9e0e1f4f7a816b12bec285b1d522eb44?source=MCF&event=Search
115,TECHNICAL SALES ENGINEER (DATA CENTRE INDUSTRY),DATA-SPHERE (S) PTE. LTD.,"JOB DESCRIPTION:
1. Develop sales leads/opportunities with end customers and integrated service providers.
2. Propose technical solutions to customer’s business requirements
3. Attend to sales enquiries, prepare proposal and follow-up with customers.
4. Conduct sales presentation and demonstration to prospective customers.
5. Build relationship and maintain excellent customer satisfaction.
6. Manage individual KPI/sales target.

JOB REQUIREMENTS:
1. Diploma/Degree in Electrical/Mechanical/Electronics Engineering
2. Minimum 2 to 3 years experience in managing customers in technical sales environment
3. Presentable with excellent communication skills
4. Possess Class 3 license and vehicle

OTHERS:
1. Positive working environment
2. Training will be provided
Immediate vacancies available",https://www.mycareersfuture.gov.sg/job/engineering/technical-sales-engineer-data-sphere-5b698c4653474ad353aab287e44ec9dc?source=MCF&event=Search
116,Big Data Engineer,AURUMJIN CONSULTING PTE. LTD.,"As a Lead you will be responsible for end-to-end development of Data Analytics and AI/ML use cases. The role must be hands on and willingness to work on ML Ops.
The role is for a self-motivated individual with software engineering skills and expertise with Big Data technologies. The candidate will be extensively involved in hands-on activities including POCs, design, documentation, development, and test of new functionality. Candidate must be agile and flexible with changing priorities based on team’s needs.
You will be working with
Massive data: You will source / examine, analyze, engineer data pipelines for gigabytes/terabytes of structured and unstructured data with our platform to create value for customers. You will also be working with Enterprise data.
Pushing the limits: This role will be on the cutting edge of our Data / Machine Learning platform. As we push to solve more of our customer challenges, you will be prototyping new features, tools and ideas. Innovate at a very fast pace to maintain our competitive edge.
Linux hacking: You will be masterfully using the command line, including tools like vi/emacs and understanding beyond basics of grep, bash, awk, sed, etc to aggressively dive into data, systems, and compute platforms to get the results you are seeking.
Production deployment: You will be responsible for integration and deployment of the machine learning pipelines into production where your ideas can come to life.
Coordinate and work with cross functional teams, sometimes located at different geo locations.
Qualification & Experience:
CS fundamentals: You have earned at least a B.S. / MS in Computer Science, or related degree AND you have a strong ethos of continuous learning.
Commercial software engineering: You have 6 to 10 years of professional software development experience with languages and systems such as Python, PySpark, Java and version control (git), with good analytical & debugging skills.
Big data: You have extensive experience with data analytics and working knowledge of big data infrastructure such as Google Cloud, Big Query, Data Flow, Hadoop Eco System, HDFS, Spark. You've routinely built data pipelines with gigabytes/terabytes of data and understand the challenges of manipulating such large datasets.
Data Modeling: Flair for data, schema, data model, PL/SQL, Star & snowflake schema, how to bring efficiency in data modeling for efficient querying data for analysis, understands criticality TDD and develops data validation techniques.
Real Time Systems: Understands evolution of databases for in-memory, NoSQL & indexing technologies along with experience on real-time & stream processing systems like Google pub/sub, GCP technologies, Kafka, Storm, Spark Streaming.
Strong design skills: with a proven track record of success on large/highly complex projects preferably in Enterprise Apps and Integration.
Project management: You demonstrate excellent project and time management skills, exposure to scrum or other agile practices in JIRA.
Excellent verbal and written communication skills: Must be able to effectively communicate & work with fellow team members and other functional team members to coordinate & meet deliverables.
Must Have
Commercial software engineering
Python, version control (git), analytical & debugging skills
Big Data
Google Cloud Platform, Big Query, Data Flow
Data Modeling
Data modeling, PL/SQL, star & snowflake schema design, in-memory
Real Time Systems
Google pub/sub, GCP technologies, Kafka
Good to have
PySpark, Java
Big Data
Hadoop Eco System, HDFS, Spark
Data Modeling
NoSQL & indexing technologies
Real Time Systems
Storm, Spark Streaming",https://www.mycareersfuture.gov.sg/job/information-technology/big-data-engineer-aurumjin-consulting-6bb0022dfc185deb74ee32af90792d90?source=MCF&event=Search
117,Support Engineer (Data Centre),INFOCEPTS PTE. LTD.,"InfoCepts is a global leader of end-to-end data & analytics solutions with nearly 20 years of experience, also named as Gartner’s 2020, 2021 and 2022 customers’ choice for Data & Analytics providers. We continue to grow rapidly year over year, now employing more than 1,200 people in offices across the globe. As we have grown, we have stayed true to our mission—to always help our customers stay modern that help them make smart, data-driven decisions. Since 2004, we have deployed hundreds of high performance analytics applications over web and mobile platforms, built several advanced analytics models, processed petabytes of data using Big Data technologies and delivered several high impact business solutions. Driven by our vision of delivering great customer experiences, we are looking for professionals who are passionate about making the world a better place by leveraging the power of data.

We are hiring aspiring professionals who are keen in the operations and the cogwheels of data centers to join us in our cause to help customers Stay Modern, ahead of the technology curve!

Roles and Responsibilities:
Foster strong understanding of assigned use cases and its respective business/operational context
Handle installation, configuration, testing, operationalization, troubleshooting and maintenance of hardware data infrastructure
Provide technical and engineering support as required including but not limiting to resolving hardware related technical and general data center issues
Collaborate with the Project team to identify opportunities for performance optimization
Serve as a point-of-contact for technical support as and when required
Provide support in server administration (on-prem operating systems and virtual machines) as and when necessary
Skills Required:
At least 1 year of experience in IT Facilities Management, Hardware Management is required
Experience with Linux-based and Windows-based operating systems
Familiarity with hardware components associated with IT, such as network switches, server racks, Ethernet cabling
Understanding of fundamental networking such as WLAN, SAN, VLAN, Subnetting is advantageous
Adept at queries with good communication and stakeholder management skills",https://www.mycareersfuture.gov.sg/job/information-technology/support-engineer-infocepts-69c09d2515e26b289c6d194a039065f8?source=MCF&event=Search
118,Data Centre Operations Engineer,THE GREAT EASTERN LIFE ASSURANCE COMPANY LIMITED,"Job Purpose
This role will be responsible to manage day to day data centre service delivery with oversight on the data centre deliveries, manage project development and implementation and be involved in the Annual Review exercise for the outsourced service provider
The Job
· Manage day to day data centre service delivery with oversight on data centre deliveries
· Manage the service providers SLA in terms of Service Requests
· Monitoring of service level performance in accordance with contractual requirements.
· Analysis of data centre infrastructure components and capacity planning for future projects/growth.
· Billing Management for the outsourced services
· Plan for application of patches, firmware, upgrades and bug fixes necessary to maintain the safe and reliable operations of the systems and platform solutions
· Manage and execute system/application installation, patching, rollouts, releases and upgrades
· Adhere to GEL operation processes and procedures, aligned to the GEL group’s processes and standards, (ITMP, ITSS, TSS and etc)
· Manage and maintain the service provider’s ability to meet SLA at all times
· Strong leadership and influencing skills in engaging the service provider and stakeholders
· Regularly review the service provider’s compliance to policies
· Analyze and execute improvement plans
· Prompt identification and resolution of service delivery issues including implementation of preventive measures
· Work with vendors, partners and service providers to maintain SLA, resolve issues and assess root cause for remediation
· Participate in planning exercises for Data Centre related matters
· Takes accountability in considering business and regulatory compliance risks and takes appropriate steps to mitigate the risks.
· Maintains awareness of industry trends on regulatory compliance, emerging threats and technologies in order to understand the risk and better safeguard the company.
· Highlights any potential concerns /risks and proactively shares best risk management practices.

Our Requirements
· A Bachelor’s degree in Computer Science / IT or Diploma with Professional Certifications.
· Minimum 8 years of experience in Data Centre Management with at least 5 years of relevant experience successfully managing data centre service delivery or platform solutions or IT systems implementation and integration.
· Minimum 6 years of experience in Project Management
· Experience working with multiple infrastructure teams, project teams (business, IT application and infrastructure teams).
· Excellent knowledge of various devices, brands and toolsets related to data centre management and patching.
· Good communication skills both written and verbal
· Strong technical, negotiation, trouble shooting and analytical skills
· Good knowledge in Data Centre Infrastructure management and capacity planning.
· Certified Data Centre Professional, 2018 and ITIL Foundation V3, 2008.
· High level of integrity, takes accountability of work and good attitude over teamwork.
· Takes initiative to improve current state of things and adaptable to embrace new changes.
About Great Eastern
Established in 1908, Great Eastern places customers at the heart of everything we do. Our legacy extends beyond our products and services to our culture, which is defined by our core values and how we work. As champions of Integrity, Initiative and Involvement, our core values act as a compass, guiding and inspiring us to embrace the behaviours associated with each value, upholding our promise to our customers - to continue doing our best for them in a sustainable manner.
We work collaboratively with our stakeholders to look for candidates who exhibit or have the potential to embrace our core values and associated behaviours, as these are the key traits that we expect from our employees as they develop their careers with us.
We embrace inclusivity, giving all employees an equal opportunity to shine and play their role in exploring possibilities to deliver innovative insurance solutions.
Since 2018, Great Eastern has been a signatory to the United Nations (UN) Principles of Sustainable Insurance. Our sustainability approach around environmental, social, and governance (ESG) considerations play a key role in every business decision we make. We are committed to being a sustainability-driven company to achieve a low-carbon economy by managing the environmental footprint of our operations and incorporating ESG considerations in our investment portfolios; improving people’s lives by actively helping customers live healthier, better and longer; and drive responsible business practices through material ESG risk management.

To all recruitment agencies: Great Eastern does not accept unsolicited agency resumes. Please do not forward resumes to our email or our employees. We will not be responsible for any fees related to unsolicited resumes.",https://www.mycareersfuture.gov.sg/job/information-technology/data-centre-operations-engineer-great-eastern-life-assurance-company-6c3b716561105fc5ef3004935cca616f?source=MCF&event=Search
119,DATA SCIENTIST / ENGINEER,D L RESOURCES PTE LTD,"1. BIG data platform maintenance
Create, build and maintain the data infrastructure required for Extraction, Transformation and Loading of data from a wide variety of sources.
Ensure high-quality data is delivered to support Compliance / FCC model development.
Support the implementation of Data Analytics / Automation for Compliance teams and Business stakeholders
Liaise with relevant stakeholders (e.g., Data Management Office) to identify and assess suitability of data for Compliance / FCC Data models.
Liaise with Business stakeholders / analysts and ensure assembled data assets used for model development meet business requirements.
Build & maintain data dictionaries / data requirements of implemented data models and coordinate with Data Scientist(s) in developing model narratives.
Monitor the execution & performance of data models and liaise with IT for any technical / system outages
Keep track of datasets / tables in the working schema and support purging of unused tables periodically.
Perform data analysis required to troubleshoot data related issues and support the resolution of raised data issues.
2. Support model maintenance
Liaise with Business Analyst to receive and understand business feedback on model performance and incorporate feedback into models
Re-train and recalibrate existing FCC analytical models to prevent model drift periodically or as needed
3. New model development
Work closely with model end-users and other key stakeholders (e.g., Head of FCC Analytics, Business Analyst, Data and Ops Engineer, GC) to identify additional areas which require analytics support or future model build and include those models in development pipeline
Develop model narratives (e.g., purpose, logic, parameters, data requirements, output surfacing / structuring) in collaboration with the business and other relevant stakeholders
Work closely with other Data Scientist(s) and Business Analyst, and undertake the end-to-end FCC model development, including data wrangling, exploratory data analysis, feature selection, model selection, training, testing, etc.
Build a range of models (rule-based, supervised / unsupervised models, etc.) on structured, semi-structured, and/or unstructured data if needed
Job Requirements:
Bachelor’s degree/ Diploma holder
Strong analytical skills.
Good communication and interpersonal skills
Able to work independently and in a team",https://www.mycareersfuture.gov.sg/job/information-technology/data-scientist-engineer-d-l-resources-43e4c1977c04b60ef224f31d6f4d5e90?source=MCF&event=Search
120,Data Engineer / Informatica Engineer,OPTIMUM SOLUTIONS (SINGAPORE) PTE LTD,"Requirements:

Bachelor Degree in Computer Science, Computer Engineering, or equivalent.
At least 5 years' experience of working as a data engineer via organization legacy systems.
Solid working knowledge of implementing ETL pipelines using Informatica BDM (DEI) on data warehouses and big data platforms, such as RDBMS, Informatica etc.
Familiar with application integration with RDBMS such as Oracle, MS-SQL or MySQL. Working knowledge of Oracle and MS-SQL will be a plus.
Hands-on experience of using Linux (or Unix-like OS) as the development environment and familiar with shell scripts and command line tools in Linux/Unix environment.
Possess experience in Systems Development Life Cycle implementation methodology (SDLC) and/or Agile methodologies like Scrum and Kanban.
Able to understand and apply the good industry practice of code versioning, testing, CICD workflow and code documentation.
Strong communication/people skills are required to interact with data analysts, business end-users and vendors to design and develop solutions.

Skill sets:

Big Data Platforms: Informatica/Snowflake/Kafka
Programming and Scripting: Python, .Net, Java
SQL Databases: Oracle, MS-SQL",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-informatica-engineer-optimum-solutions-a6398214eda55febf3e1d121d12a4b47?source=MCF&event=Search
121,9866 - Finance & HR Manager ( Data Centre / Engineering & Building Services Industry ),THE SUPREME HR ADVISORY PTE. LTD.,"Finance & HR Manager
Working Hours: 5 Days [9am - 6pm]
Salary: $4500 - $5,500
Location: Neat Potong Pasir
Requirements:
With Diploma/Degree in Finance/Accountancy/Banking or other equivalent
At least 15Year(s) of working experience in the related field is required for this position.
Excellent Finance & Accounts Knowledge and Office management skills
With relevant HR experience
Responsibilities:

This role is work under Operations Department, need to liaise with project team on the progress for claims, AR, payments, invoice etc. + oversee finance team + 1 hr admin under this role + liaise with recruitment agency + liaise with hiring manager + ad hoc duties.

1) Finance & Accounting
Manage the overall accounting and financial reporting
Maintain the accounting system;
Coordinate & facilitate internal & external Audits to effectively communicate and ensure that requirements are adhered to;
Liaise with Auditor for Expatriate Taxation
2) Human Resource
Liaise with recruitment agency
Recruitment & Selection
Payroll
New employee onboarding & orientation
Performance Management
Employee Exit
Employee Data Management (Personnel Data and leaves records)
Employee Benefits Administration (Insurance, medical claims
HR policies & procedures
Karen Lee Kai En Reg No: R22108159
The Supreme Hr Advisory Pte Ltd EA No: 14C7279",https://www.mycareersfuture.gov.sg/job/accounting/9866-finance-hr-manager-supreme-hr-advisory-5f48e46a232e9654bd8757875d9382c6?source=MCF&event=Search
122,9866 - Finance & HR Manager ( Data Centre / Engineering & Building Services Industry ),THE SUPREME HR ADVISORY PTE. LTD.,"Finance & HR Manager
Working Hours: 5 Days [9am - 6pm]
Salary: $4500 - $5,500
Location: Neat Potong Pasir
Requirements:
With Diploma/Degree in Finance/Accountancy/Banking or other equivalent
At least 15Year(s) of working experience in the related field is required for this position.
Excellent Finance & Accounts Knowledge and Office management skills
With relevant HR experience
Responsibilities:
1) Finance & Accounting
Manage the overall accounting and financial reporting
Maintain the accounting system;
Coordinate & facilitate internal & external Audits to effectively communicate and ensure that requirements are adhered to;
Liaise with Auditor for Expatriate Taxation
2) Human Resource
Liaise with recruitment agency
Recruitment & Selection
Payroll
New employee onboarding & orientation
Performance Management
Employee Exit
Employee Data Management (Personnel Data and leaves records)
Employee Benefits Administration (Insurance, medical claims
HR policies & procedures",https://www.mycareersfuture.gov.sg/job/accounting/9866-finance-hr-manager-supreme-hr-advisory-197f16f72e81c148c18047fee76c6bcd?source=MCF&event=Search
123,"Data Engineer, Technology & Operations",DBS BANK LTD.,"Business Function
Group Technology and Operations (T&O) enables and empowers the bank with an efficient, nimble and resilient infrastructure through a strategic focus on productivity, quality & control, technology, people capability and innovation. In Group T&O, we manage the majority of the Bank's operational processes and inspire to delight our business partners through our multiple banking delivery channels.

The role:
We are looking for an experienced Data Engineer to join our growing team of analytics. The candidate will be responsible for expanding and optimizing our data and data pipeline, as well as optimizing data flow. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. Candidate must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.

Job Responsibilities
Create and maintain optimal data pipeline.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing Jobs/code for greater scalability, etc.
Work with stakeholders including the Product owner, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Work with data and analytics experts to strive for greater functionality in our data systems.
Job Requirements
Advanced working SQL knowledge and experience working with RDBMS, Hadoop and NoSQL DB.
Experience building and optimizing ‘big data’ data pipelines, Jobs and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 10 years of experience in a Data Engineer role, who has a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:
Experience with:Big data tools: Hadoop, Spark, Kafka, etc.
Relational SQL and NoSQL databases, including Postgres and Cassandra.
Data pipeline and workflow management tools: Airflow, etc.
AWS cloud services or GCP.
Stream-processing systems: Spark-Streaming, Flink etc.
Apply Now
We offer a competitive salary and benefits package and the professional advantages of a dynamic environment that supports your development and recognises your achievements.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-technology-operations-dbs-bank-4e39819865f57f9cda4e04fb400cacad?source=MCF&event=Search
124,"Data Engineer, Technology & Operations",DBS BANK LTD.,"Business Function
Group Technology and Operations (T&O) enables and empowers the bank with an efficient, nimble and resilient infrastructure through a strategic focus on productivity, quality & control, technology, people capability and innovation. In Group T&O, we manage the majority of the Bank's operational processes and inspire to delight our business partners through our multiple banking delivery channels.

The role:
We are looking for an experienced Data Engineer to join our growing team of analytics. The candidate will be responsible for expanding and optimizing our data and data pipeline, as well as optimizing data flow. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. Candidate must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.

Job Responsibilities
Create and maintain optimal data pipeline.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing Jobs/code for greater scalability, etc.
Work with stakeholders including the Product owner, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Work with data and analytics experts to strive for greater functionality in our data systems.
Job Requirements
Advanced working SQL knowledge and experience working with RDBMS, Hadoop and NoSQL DB.
Experience building and optimizing ‘big data’ data pipelines, Jobs and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 10 years of experience in a Data Engineer role, who has a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:
Experience with:Big data tools: Hadoop, Spark, Kafka, etc.
Relational SQL and NoSQL databases, including Postgres and Cassandra.
Data pipeline and workflow management tools: Airflow, etc.
AWS cloud services or GCP.
Stream-processing systems: Spark-Streaming, Flink etc.
Apply Now
We offer a competitive salary and benefits package and the professional advantages of a dynamic environment that supports your development and recognises your achievements.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-technology-operations-dbs-bank-f9f2116906a1cebe6f2bbb3aaa998bd8?source=MCF&event=Search
125,Data Center operations Engineer,ADECCO PERSONNEL PTE LTD,"Job Responsibilities
Managing the day-to-day Servers, Storage and Network of our inventory across our Global Data Centers
Monitoring of our ticket queues for hardware and network related issues that require resolution
Turning up new servers and network devices
Troubleshooting in a Linux environment
Collaborating with our SRE team, developing the best-in-class processes to deploy hardware and network more efficiently.

Job Requirements
Have 2-5+ years server management, hardware, and network troubleshooting experience
1-2+ years Linux bash command shell experience
1-2+ years of Datacenter Layer 1 experience. You should have some knowledge in cabling and peripheral types.
Experience in PXE config and bootstrapping Linux systems
Growth mentality and an ability to work with partner Engineering teams to develop the most simple and effective solutions
Experience in managing commercial server inventory systems (ServiceNow. Jira ServiceDesk, etc.
Able to lift up to 20kg (45lbs)
Vendor management experience (Remote Hands)
Hardware repair, IT networking, troubleshooting LAN & WAN
CCNA
Hardware replacement experience
ITIL experience

Saghana Sithara | Registration Number: R1550224",https://www.mycareersfuture.gov.sg/job/information-technology/data-center-operations-engineer-adecco-personnel-ccd09b2bd1226f6040f71e6bf7b8cfb9?source=MCF&event=Search
126,"Data Centre Engineer, Associate","JPMORGAN CHASE BANK, N.A.","As a member of our Technology Operations team, your initiative and creative problem-solving will help propel global innovation in technology and business. Working with a team of motivated collaborators, you'll develop and implement strategic technology solutions, ensuring the successful integration of network system and applications servers into existing and new technology infrastructures. You'll play a key role in the care and support of customers, including proactive incident monitoring. In addition to valuable on-the-job experience, you'll receive coaching, mentorship and a host of other development opportunities to advance your career at the firm and beyond.

This role requires a wide variety of strengths and capabilities, including:
• Bachelor’s Degree
• Minimum 2 years in data center operation
• Advanced infrastructure project, operations systems and data analytics knowledge
• Proficiency in one or more of the following: Microsoft Office, VPN, Virtual Machines, Remote Connectivity products, Security
• Understanding of technology offerings and businesses supported
• Ability to identify problems, troubleshoot and deliver strategic solutions to clients
• Genuine interest in continuous feedback, learning and growth opportunities
• Effective collaboration and communication to achieve common goals and maintain a company standard of excellence
• Good knowledge of Windows/MAC OS with the ability to carry out root cause analysis
• Strong analytical and problem resolution skills
• Knowledge of Data Centre Mechanical & Electrical infrastructures, Building Management System, Fire Protection and Security System.
• Strong Ability to configure basic iLo/iDrac/remote access configuration
• Extensive Knowledge in structure cabling, cable management and testing tools
• Extensive Knowledge in physical racking and stacking of servers and network devices
• Experience in replacing components in servers and network devices

To apply for this position, please use the following URL:
https://ars2.equest.com/?response_id=13dee9232da0f242c3d36a246177b9cb",https://www.mycareersfuture.gov.sg/job/banking-finance/data-centre-engineer-associate-jpmorgan-chase-bank-na-d1f578d361fc4f01ccfe9fb006cfe6a2?source=MCF&event=Search
127,Data Engineer - ETL,SAGL CONSULTING PTE. LTD.,"Key Requirements:
Experience in banking applications using ETL, Oracle, and Teradata.
Expertise in Oracle PL/SQL and Teradata BTEQ scripting
Expertise in Informatica tools like Power Center, Data Quality, Metadata manager, BG, and BDM
Working experience in scripting using Shell script and awk programming.
Worked with CI/CD automated deployment using Bitbucket and Github.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-etl-sagl-consulting-725acdf97e2684cc4143cd96848af935?source=MCF&event=Search
128,(Senior) Data Scientist / Engineer,AMPLIFY HEALTH ASIA PTE. LIMITED,"Instructions for interested applicants
Please apply for this position via the following link:
https://aia.wd3.myworkdayjobs.com/amplifyhealthexternal/job/Singapore-SG-Amplify-Health/Data-Scientist-Engineer_JR-36539

What you will do?
We are looking for a Data Scientist / Engineer as part of our Data Management Team. The ideal candidate will leverage strong collaboration skills and ability to extract valuable insights from highly complex medical & insurance data sets to ask the right questions and find the right answers. You will have a great opportunity to work with other Data Scientists to understand and learn about how we can leverage AI/ML in the health insurance & medical field to detect fraud & waste, improve automation efficiency & promote vitality.

Duties and Responsibilities
● Analyse large scale of data: assessing quality, cleansing, structuring for downstream processing
● Be heavily involved to bring analytical prototypes to production with modelling & dev-ops teams
● Become a subject-matter expert in the health & insurance domain
● Generate actionable insights for business improvements
● Help to develop customizable reports / production-ready dashboards for clients

Requirements
● Bachelor's degree or equivalent experience in quantitative field (Statistics, Mathematics, Computer Science, Engineering, etc.)
● At least 1 - 2 years' of experience in quantitative analytics, data modelling or software engineering
● Ability to write robust code in Python and Java
● Good understanding of Database Systems (MSSQL, Postgres, MySQL) and SQL
● Deep understanding of predictive modelling, machine-learning, clustering and classification techniques, and algorithms
● A strong self-motivated and able to work with minimal supervision",https://www.mycareersfuture.gov.sg/job/healthcare/data-scientist-engineer-amplify-health-asia-116fd6a0d1bd19828f76c68ea016547d?source=MCF&event=Search
129,Senior Big Data Engineer,ONE NORTH CONSULTING PTE. LTD.,"One North Consulting is currently hiring Senior Big Data Engineers with about 5 - 8 years of experience as per details given below.
Interested Singapore Citizens / Singapore Permanent Residents can connect on email id - Jit@OneNorthConsulting.com or +65 96414152
Skills & Responsibilities
As Senior Big Data Engineer, you will focus on managing the Hadoop cluster, implementing data ingestion framework designing data models.
Your primary role will be to implement data lake & transform the data for business use.
Experience with at least one Cloud Infra provider (Azure/AWS)
Experience in building data pipelines using batch processing with Apache Spark (Spark SQL, DataSet / Dataframe API) or Hive query language (HQL)
Knowledge of Big data ETL processing tools
Experience with Hive and Hadoop file formats (Avro / Parquet / ORC)
Basic knowledge of scripting (shell / bash)
Experience with CI CD tools such as Jenkins, JIRA, Bitbucket, Artifactory, Bamboo and Azure Dev-ops.
understanding of DevOps practices using Git version control
Debug, fine tune and optimize large scale data processing jobs
Deliver big data solutions based on premise Hadoop or cloud-based systems like AWS.
Manage Hadoop cluster, participate in scale out planning & implementation.
Design ingestion layer for structured & unstructured data (text, voice, xml etc)
Implement specific data model for business & analytics use.
Deliver ELT solution including data extraction, transformation, cleansing, data integration and data management.
Augment with new sources of data including internal/external untapped data.
Contribute to the establishment and maintenance of cloud computing platform and big data services.
Provide support for analytics tools & environment like RServer etc & debug performance issues.
COMPETENCIES
Databases: RDBMS, SQL programming
ETL and Data Integration Tools: Azure Data Factory (ADF), Microsoft SQL Server Integration Service(SSIS), SAS Data Integration
Big Data: Hadoop (Hortonworks), Hive, Spark, Sqoop, etc
Programming and Scripting: Linux/Unix Shell Scripting, Java, Scala, Hive QL
BI/Dashboarding: SAS Visual Analytics, Qliksense
Working Experience:
5~8 years in data engineering and modelling.
Hands-on in managing data mapping, data quality and integrity, performance in data processing.
Experience in Agile software development.

If Interested, please email us your CV to social@OneNorthConsulting.com",https://www.mycareersfuture.gov.sg/job/information-technology/senior-big-data-engineer-one-north-consulting-22f567efe4a5a2268fd9812e421d22d4?source=MCF&event=Search
130,"Data Engineer (Python, SQL, Azure)",MANPOWER STAFFING SERVICES (SINGAPORE) PTE LTD,"Company Highlight:
Company transport provided at Tampines MRT
Good Employee benefits and Transparent career progression
Job stability for long-term career growth
Roles & Responsibilities:
Join a team responsible for building and maintaining data systems or pipelines
Set up, install, configure, troubleshoot, and upgrade commercial off-the-shelf (COTS) products
Develop and implement ways to enhance data warehouses, data lakes, or similar platforms
Contribute to the creation of documentation such as design documents and troubleshooting guides
Requirement:
Knowledge and/or experience in data management or data engineering
Familiarity with Linux commands and shell scripting
Knowledge and/or experience in relational databases (including SQL) or NoSQL databases (e.g., document, graph)
Advantageous to have experience in DataStage, Denodo, Hadoop, Python, Spark, Microsoft Azure Cloud services, Databricks, Dataiku, Data Robot
Degree/Diploma in Computer Engineering/Computer Science/Information Technology or a related technical discipline with 1-4 years of experience in related fields
No Experienced candidates are encouraged to apply

If you are interested in this opportunity, submit your application now to find out more about this position.

We regret that only shortlisted applicants will be contacted. Thank you.

Sim Wen Yih Reine
Personal Reg No: R21103357
Manpower Staffing Services (S) Pte Ltd
EA License No: 02C3423",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-manpower-staffing-services-72edc26c6856d438efb71ed129311c83?source=MCF&event=Search
131,Big Data Platform Engineer / Architect 005,U3 INFOTECH PTE. LTD.,"Responsibilities:
The main and routine tasks of this position are to:
Design and develop the Batch data processing on onprem or public cloud
Develop and maintain an advanced platform to manage Kubernetes clusters lifecycle for batch processing.
Understand the On prem VM based Bigdata ecosystem, designing and developing migration plan to on prem cloud native deployment.
Determine security and segregation of Lab and Factory/BAU workloads.
Develop tools for automated build, test, deployment and management of the platform.
Determine approach for multitenancy and capacity planning at enterprise scale.
Improve continuous integration and delivery systems.
Monitor system events to ensure health, maximum system availability and service quality
Maintain documentation regarding configurations, operations and troubleshooting procedures. Participate in the definition of standards, guidelines and best practices.
Assist in evaluating new requirements, technical design and standards.
Participate in R&D effort bringing new ideas and new technologies
Qualifications
A University Degree or equivalent experience in Computer Information Systems, Computer Science, Mathematics or a related field.
Relevant experience:
Architect: Have worked on Big Data for more than 5+ years and have hands on with Spark, Hive & Presto.
Developer: 2+ years of experience in Kubernetes/OpenShift.
Skills:
· Good with Architecture and has good understanding and in depth knowledge on distributed systems
· Professional experience building enterprise Big Data Applications using Spark, Hadoop, Hive etc.
· Hands on Knowledge on Containerisation and deploying Opensource products on K8s/ OpenShift.
· Maintaining and building inhouse based Opensource platforms like Hadoop, Spark, Hive, Presto
· Skill in developing techniques and methodologies to resolve unprecedented problems or situations
· Deep knowledge of OOPs, data structure, and algorithm
· Ability & willingness to learn technologies at pace

Knowledge:
· Expertise with Java or any coding languages.
· Linux Scripting (Bash, Python, etc.)
· Expertise with Source Control Management (Git, Bitbucket, etc.)
· Expertise with CI/CD (Jenkins/ArgoCD)
· Expertise with Configuration Management (Ansible, Terraform etc.)
· Expertise with Monitoring (Prometheus, etc.)
· In-depth knowledge with Linux environments (RHEL)
· Knowledge on Protegrity.
· Knowledge of Cloud infrastructures (AWS EKS, Google GKS, Azure AKS, etc.)
· Knowledge of Web Servers (Nginx, Apache, etc.)
· Knowledge in RESTful API design and implementation
· Knowledge in the development of high-performance and fault-tolerant systems
· Knowledge in distributed systems programming
· Experience with Java or Go programming language an asset",https://www.mycareersfuture.gov.sg/job/consulting/big-data-platform-engineer-architect-005-u3-infotech-93457e8140baa3e87ce98dd27e7cd6ef?source=MCF&event=Search
132,Big Data Engineer,BASIL TECHNOLOGIES PTE. LTD.,"· Develop data processing pipelines for ingestion, modelling, analysis, mining and reporting with Enterprise Big Data Lake
· Responsible for the code writing of the core module of the system
· Develop POC and build data pipeline architecture using of the overall technical framework of the software
· Work closely with teams ensure timely delivery of assignments
What do you need to succeed?
· Possess good communications skills to understand our customers' core business objectives and build end-to-end data centric solutions to address them
· Good critical thinking and problem-solving abilities
Must-have:
· Experience building large scale enterprise data pipelines using commercial and/or open source Big Data platforms from vendors such as Hortonworks/Cloudera, MapR, for Hadoop based platforms or NoSQL platforms such as Cassandra, HBase, DataStax, Couchbase, Elastic Search, Neo4j etc
· Hands on experience in Spark, Scala, Impala, Hive SQL, Apache Nifi necessary to build and maintain complex queries, streaming and real-time data pipelines
· Data modelling and architecting skills including strong foundation in data warehousing concepts, data normalisation, and dimensional data modelling such as OLAP
· Undergraduate or graduate degree in Computer science or equivalent",https://www.mycareersfuture.gov.sg/job/information-technology/big-data-engineer-basil-technologies-d8122ccc104cee640d3e5d0b4dc84f3e?source=MCF&event=Search
133,IT Senior Data Mgt Engineer,SOITEC MICROELECTRONICS SINGAPORE PTE. LTD.,"The person will join our Dynamic IT team to support our factory in its ramp up.

Under the responsibility of the Singapore IT HOD, the IT Senior Data Mgt Engineer will have to:
- Analyze the users requests (changes & projects) and incidents
- Define the best solution (JMP, PowerBI, etc) and implement it
- Manage the obsolescence of the legacy reports/solutions
- Interact with the rest of Singapore IT team (CIM, Business Apps) and the teams in France (functional and technical alignment, experience sharing, common corporate projects like the AWS datalake design)
- Study and implement innovative solutions with our experts and/or external partners around Machine learning, AI and image recognition
This will require autonomy, good relationship and a strong quality culture as well as the ability to understand the constraints of our environment and the specificities of the semiconductor industry.
The job is based in our Semiconductor factory in Pasir Ris (Singapore) and requires close work with people located in our headquarters in France.

SKILLS AND QUALIFICATIONS
• Senior IT engineer
• Recommended technical skills: Oracle/DB2 SQL, JMP, PowerBI, Talend, Python
• Nice to have: experience in Machine learning, AI and image recognition, AWS Cloud solutions (SageMaker, etc), Delphi, ASP, BO
• Highly organized, practical, analytical and detail oriented
• Ability to multi-task, prioritize tasks, make critical decisions
• Ability to work productively with frequent interruptions
• Flexible schedule",https://www.mycareersfuture.gov.sg/job/information-technology/senior-data-mgt-engineer-soitec-microelectronics-singapore-787964301c012f29fa98e53812bb4cd6?source=MCF&event=Search
134,Big Data Engineer (JD#8367),SCIENTE INTERNATIONAL PTE. LTD.,"Are you a Big Data Engineer? And you want to be a part of a vibrant and dynamic team?
We would like to speak to you! As a Data Engineer you will play a key role in creating, building and maintaining our client’s data infrastructure.

Mandatory Skill(s)
Degree in Computer Science or related discipline;
Minimum 5 to 8 years of experience in Data Engineering experience;
Good hands-on experience in both SQL and NoSQL databases (like MariaDB, Oracle, MongoDB) and Object-Relational Mapping (ORM) frameworks (e.g. Hibernate);
Experience with CI/CD practices and tools (Bitbucket, Jenkins, Artifactory, Veracode etc.);
Experience in Apache Kafka applications, Java, Sprint Boot and API (Microservices);
Experience building data pipelines with Apache NiFi in production scale and data streaming applications using Apache Spark and Kafka Streams;
Experience with a variety of data sources and sinks (API, MQ, Files, Databases, Hot lakes, Big data systems etc.).
Desirable Skill(s)
Experience in financial industry;
Familiarity with Agile development methodologies.
Responsibilities
Create, build and maintain the data infrastructure required for Extraction, Transformation and Loading of data from different sources;
Delivering high-quality data to support compliance FCC Model Development;
Provide high-level support of Data Analytics/Automation for Compliance and Business Team/stakeholders;
Liaise with relevant stakeholders to identify and assess suitability of data compliance/FCC data models and to ensure data meets business requirements;
Coordinate with Data Scientists after building and maintain data dictionaries/requirements for data models;
Build & maintain data dictionaries / data requirements of implemented data models and coordinate with Data Scientist(s) in developing model narratives;
Work closely with the Business Analyst in receiving/understanding business feedback in order to incorporate feedback into model performance;
Identify areas which require analytics support or future model build and include those models in development pipeline;
Work hand-in hand with Data Scientist(s) and Business Analyst, and undertake the end-to-end FCC model development.
Should you be interested in this career opportunity, please send in your updated resume to apply@sciente.com at the earliest.
When you apply, you voluntarily consent to the disclosure, collection and use of your personal data for employment/recruitment and related purposes in accordance with the SCIENTE Group Privacy Policy, a copy of which is published at SCIENTE’s website (https://www.sciente.com/privacy-policy).
Confidentiality is assured, and only shortlisted candidates will be notified for interviews.
EA Licence No. 07C5639",https://www.mycareersfuture.gov.sg/job/banking-finance/big-data-engineer-sciente-international-57141bc46136d0e4a89c58988fc36107?source=MCF&event=Search
135,Snr Consultant (Data Engineer / ETL / BI),NTT DATA BUSINESS SOLUTIONS SINGAPORE PTE. LTD.,"Job Highlights
Work Life Balance, Hybrid Work From Home
Fun Working Environment & Attractive Benefits Package
Career Development Within a MNC Company
Job Description
As the leading analytics provider in APAC and part of our Company's growth, we are looking for dynamic, motivated, and dedicated individuals to be part of our team in Singapore. If you have the right skill set, driven, willing to learn and demonstrates a can-do attitude, come join us ! We welcome candidates of all levels.

Responsibilities
· Deliver end-to-end Business Intelligence, Analytics and Data Management solutions to customer
· Work with the larger team in technical design sessions to define data definition, data and analytics solution requirements and specifications
· Analyse business requirements, designing, developing, testing & supporting application and Data warehouses from build to production (including proof-of-concept)
· Ability to develop test plans and lead testing cycles
· Provide product and application support and maintenance when needed
· Actively participates in defining solution options and selecting the appropriate BI, Analytics and Data Management solution
· Development of ETL pipelines, data management and BI platform
· Ensures appropriate documentation, customer involvement and sign-off
· Develop development framework and assign development effort to team members
· Actively leads and manages team members to a successful project

Requirements
· Diploma/Degree in Computer Science / Computer Engineering / Information Technology related field or IT equivalent
· Have 3 - 5 years’ experience in Business Intelligence/Data Warehouse/Analytics / Big Data Projects involving in requirements gathering designing, development, deployment, conducting knowledge transfer and post deployment support
· Have 3 - 5 years’ experience with ETL, Business Intelligence and Visualization Tools
· Have experience with Data Modelling using dimensional modelling techniques and designing the metadata layer for self-service analytics
· Have experience actively leading and managing a team of 3 to 5 members
· Independent with ability to work effectively in a team and who takes initiative and engages their colleagues
· Excellent communication and interpersonal skills with ability to communicate with clarity and confidence with colleagues and customers
· Likes technology, taking initiative to learn more and share knowledge with juniors and within the team
· Proven abilities to take initiative, innovative and the ability to develop creative solutions for challenging client needs

Additional knowledge it would be great to have:
· SAP related skillsets S/4 HANA, SAP Analytics Cloud, SAP BW
· Cloud and network concepts
· Databases such as MariaDB, MySQL, PostgreSQL
· Programming languages such as Java, Python, ASP.Net with C#.Net or VB.Net
· AWS, Azure or Google Cloud Platform services and products",https://www.mycareersfuture.gov.sg/job/consulting/snr-consultant-ntt-data-business-solutions-singapore-b4023c611a2a5ba094c56edf16a016b1?source=MCF&event=Search
136,Data Scientist cum Engineer,THALES SOLUTIONS ASIA PTE. LTD.,"You have a minimum of 5 years software experiences, where you would have understood the process of negotiating and unraveling the nitty gritty details of your customer or user’s datasets
You should have a good repertoire of software tools and programming languages to which you can apply to building an MVP or enterprise ready product
You have experience setting up Spark and using it for batch processing, and possibly streaming experience with Flink or Kafka.
Good to have experience with natural language processing
You should have good working knowledge about Machine Learning and or Deep Learning algorithms in the realm of supervised, unsupervised, reinforcement not limited to ANN, CNN, RNN, GAN
You should have good working knowledge in statistical classification domain eg. Logistic Regression, K-nn, Kernel SVM, Naïve Bayes, Decision Tree, Random Forest, Clustering domain e.g. K-means clustering, hierarchical clustering
You should have a good understanding of applying gradient boosting in regression and classification problems. E.g. XGBoost and in anomaly detection and outlier detection techniques e.g. DBSCAN, Gaussian Mixture Models
You would have working knowledge of Java & Python and you should be able to explain the underlying mechanics in addition to the theoretical Machine/Deep Learning model
You would have good working knowledge of the Machine Learning and Deep Learning toolkits available in OSS, commercial software
Worked in a squad or guild team setup and understand the agile processes, ceremonies and appreciates them
You are an open, strong communicator who communicates effectively across teams, locations and cultures, in-person and virtually
You are autonomous and know how to adapt quickly and drive change for the better
You bloom in a team and like working in a collaborative environment
You agree that data over opinion is a healthy and an important mentality",https://www.mycareersfuture.gov.sg/job/information-technology/data-scientist-cum-engineer-thales-solutions-asia-bfd312be8dfd9904dfcab69539d46627?source=MCF&event=Search
137,Senior Platform and Data Engineer,ENSIGN INFOSECURITY (CYBERSECURITY) PTE. LTD.,"Duties and Responsibilities
Familiar with Ensign’s business domain and objectives to develop and deploy solutions that meet internal and customer requirements
Responsible for the design, build and administration of multi-node data lakes, and data warehouses and data marts
Responsible for health monitoring, solve cluster issues, patching and upgrades
Responsible for node administration, load balancing with add/remove/recovery of nodes
Ensure cluster stability, smooth upgrade releases and solving platform issues by investigating and applying solutions/patches
Deliver detailed documentation and ensure quality throughout project lifecycle
Requirements
Bachelor’s degree in Computer Science/Information Systems/Computer Engineering
Minimum 3 years of hands-on experience on cluster installation, deployment, upgrade, maintenance, troubleshooting various cluster issues and optimizing for better performance
Hands-on experience managing multi-node big data application platforms
- HDFS, YARN, Spark, Hive, Presto, Apache Airflow
Hands-on experience managing multi-node messaging queue platforms
- Kafka, Rabbit MQ, Nifi
Hands-on experience managing multi-node containerization and orchestration platforms
- Docker, Docker Swarm, Kubernetes
Hands-on experience managing multi-node data warehousing platforms
- MongoDB, MySQL, PostgreSQL, ElasticSearch
Hands-on experience on setting up 3rd party applications
- GitLab, Arkime
Hands-on experience on setting up security features
- Kerberos, AD, LDAP, Keycloak
Strong awareness of data security, data governance and performance, with an ability to deliver these key non-functional requirements",https://www.mycareersfuture.gov.sg/job/information-technology/senior-platform-data-engineer-ensign-infosecurity-cf1703ad1aed2f1b8a03303320a333f6?source=MCF&event=Search
138,Senior Electrical Design Engineer - Data Centre,INVENIO GLOBAL SEARCH PTE. LTD.,"Invenio Global is an international recruitment specialist experienced placing candidates in some of the world’s greatest locations. We use our knowledge, experience and recruitment expertise to match the right opportunity with our candidates. Our ever growing network of global clients and database of roles will allow us to find you jobs at the best companies and in the best locations.

Our client is a leading regional Data Centre Hyperscale and Co-location provider. With a growing business in APAC and a strong pipeline of work across their client base, they are well positioned to grow their in-house team Engineering team.

As such, they have a requirement for a Senior Electrical Design Engineer in Singapore.

The successful candidates will ideally be qualified in Electrical Engineering and have a demonstrable track record in the design of data centres, pharmaceuticals or semiconductor industries amongst a wider portfolio of work. You will have experience working in a team and be comfortable managing stakeholders.

This is a fantastic opportunity to join a vibrant team of exciting talents in the Data Centre world.",https://www.mycareersfuture.gov.sg/job/design/senior-electrical-design-engineer-data-centre-invenio-global-search-21f97c9fcb9112168be5c9ab6caf29db?source=MCF&event=Search
139,"Data Center Design Engineer (Mechanical), Data Center Development",BYTEDANCE PTE. LTD.,"Responsibilities

Founded in 2012, ByteDance's mission is to inspire creativity and enrich life. With a suite of more than a dozen products, including TikTok, Helo, and Resso, as well as platforms specific to the China market, including Toutiao, Douyin, and Xigua, ByteDance has made it easier and more fun for people to connect with, consume, and create content.

Why Join Us
At ByteDance, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for millions of users across all of our products. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at ByteDance.

ByteDance Data Center Development team is responsible for building Internet Data Center and Network in the Asia Pacific region. Our work involves, but not limiting to, DC innovation, implementing advanced technologies and renewable energy to achieve carbon-neutrality, rapid project delivery, capacity planning, process and risk control, cost management, etc.

Our team's goal is to provide ByteDance with stable, reliable, efficient Data Center infrastructure services to support our businesses.

As the Data Center Design (Mechanical) Engineer, you will be responsible for the following:

- Responsible for technical evaluation of design submission by various providers
- Responsible for technical design of mechanical system for data centers
- Responsible for localisation of data center standards & critical equipment specifications
- Support site selection related task in Singapore/Malaysia & Other Non-China Regions
- Support and work closely with the design team for the optimization of data hall standards
- Support local operation team for trouble-shooting and optimizing design standards
- Support Ad-Hoc project management tasks assigned

Qualifications
- Bachelor's Degree in Mechanical/Civil Engineering or equivalent
- Familiar with local code & fire code
- With relevant experience of project delivery for at least 5000 racks project
- With relevant experience of liquid cooling deployment is an added advantage
- Certified Professional Engineer is an added advantage

ByteDance is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At ByteDance, our mission is to inspire creativity and enrich life. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.",https://www.mycareersfuture.gov.sg/job/engineering/data-center-design-engineer-data-center-development-bytedance-e248a1ae7caaf67558d23c8deaed877a?source=MCF&event=Search
140,"Big Data Engineer (Financial Services) Senior Consultant, Technology Consulting",ERNST & YOUNG ADVISORY PTE. LTD.,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.
We are the only professional services organization who has a separate business dedicated exclusively to the financial services marketplace. Join Financial Services (FSO) and you will work with multi-disciplinary teams from around the world to deliver a global perspective. Aligned to key industry groups including asset management, banking and capital markets, insurance and private equity, we provide integrated advisory, assurance, tax, and transaction services.
The Opportunity
As part of our Data and Analytics team of Financial Services Consulting practice you will work with multi-disciplinary teams to support clients in a wide range of big data initiatives aiming to generate and present new, useful and actionable insights. You will have the opportunity to work and take responsibilities in challenging engagements, gaining exposure to clients in various sectors both in Singapore and in the APAC region.
Your Key Responsibilities
Participation in large-scale client engagements.
Contribution towards, or even leading, the delivery of innovative and engaging big data solutions.
Understanding of business and technical requirements, provision of subject matter expertise, and implementation of big data engineering techniques.
Conducting of data discovery activities, performing root cause analysis, and making recommendations for the remediation of data quality issues.
Putting into practice good organizational and time management skills, with the ability to prioritize and complete multiple complex projects under tight deadlines.
Skills and Attributes for Success
Leverage technology to continually learn, improve service delivery and maintain our leading-edge best practices
Strong presentation skills and proficiency in the use of PowerPoint, Word and Excel
Good understanding of financial services industry
To Qualify for the role, you must have
Bachelor or Master’s degree in computer science, Engineering, or other related fields.
Minimally 3 years of relevant experience
Understanding or even practical experience of handling and manipulating semi-structured and unstructured data.
Deep understanding of big data technology, concepts, tools, features, functions and benefits of different approaches available.
Ability to deploy, manage, and administer Hadoop-based components.
Ability to design, build, install, configure and support Hadoop-based applications.
Experience with one of Java, C# or C++.
Hands-on experience with HiveQL.
Familiarity with data ingestion tools such as Kafka, Flume and Sqoop.
Knowledge of hadoop related workflow/scheduling tools such as Oozie.
Understanding of data modeling (ER models) techniques.
Experience with investigating and handling data quality issues.
Minimum 1-3 years hands-on experience in two (2) or more of the above areas.
Ideally, you’ll also have
Design and implementation experience of data models in physical form in one (or more) of the leading RDBMS platforms such as SQL Server, Oracle, IBM DB2/Netezza, Teradata, etc.
Experience with Business Intelligence or statistical analysis tools and techniques.
Strong communication and business relationship skills to effectively explain analysis, both verbally and in writing, to others and translate analysis into a clear business plan.
Strong time management and organizational skills to gather and make use of data (both internal and external).
What we look for
Highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry. An effective communicator, you’ll be a confident team player that collaborates with people from various teams while looking to develop your career in a dynamic organization.
What we offer
Continuous learning: You’ll develop the mindset and skills to navigate whatever comes next.
Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way.
Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs.
Diverse and inclusive culture: You’ll be embraced for who you are and empowered to use your voice to help others find theirs.
If you can demonstrate that you meet the criteria above, please contact us as soon as possible.
The exceptional EY experience. It’s yours to build.
Apply now.",https://www.mycareersfuture.gov.sg/job/banking-finance/big-data-engineer-senior-consultant-technology-consulting-ernst-young-advisory-7e1f4640d77f300105395fff85a58c81?source=MCF&event=Search
141,Data Engineer | Up to SGD$7k / month – J.T.,BGC GROUP PTE. LTD.,"What you’ll be doing:
Work closely as part of the agile product team to design, develop, test and deploy data integration products under the guidance of the DSTA Product Manager
Provide monthly progress reporting and status updates to Authority.
Deliver all required documentations (in compliance to Authority’s QMS processes and standards) including but not limited to design specifications, data specifications, user requirements, mapping documents and unit test plan.
Responsible for complying with data integration development processes and standards defined by Authority.
Develop and manage the data integration programs with Authority’s furnished software that include Informatica PowerCenter and Talend.
Maintain and perform continuous enhancements of data pipeline to ensure smooth data ingestion and good performance. This scope requires personnel to work with Oracle Database, Big Data Platform and tools such as Informatica PowerCenter and Talend.
Conduct and support requirement gathering with the Authority’s project team for new data integration program development.
Perform all required testing to ensure quality of deliverables i.e. User Acceptance Test (UAT), System Integration Test (SIT), Operational System Acceptance Test (OSAT).
Review system, application activities and database logs to detect abnormalities based on provided criteria.
Develop extractors for data in source systems including but not limited to SAP BW OpenHub, Oracle database, SQL Server database and flat file.
What you’ll need:
Degree/Diploma in Computer Science, Computing, Electrical Engineering, or IT equivalent
Experience in building and optimising data pipelines, architecture and datasets using DI/ETL technology (e.g. Informatica, Talend).
Shall have experience in supporting data transformation, data structures, metadata, dependency and workload management.
Experience in multiple data source support (e.g. flat files, SQL database, SAP database, PostgreSQL database, unstructured data not limited to text, documents, images, digitalised video, digitalised audio, sensor data) would be advantageous.
Benefits:
AL: 18 days
ML: 14 days
Medical benefit
Bonuses
Interested applicants: kindly submit your resume to joelle.tam@bgc-group.com",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-sgd7k-month-%E2%80%93-jt-bgc-group-f5396a8c565e52e9b24f7bcff51cc82a?source=MCF&event=Search
142,"AI / Data Science Junior Engineer I, DxD Hub",A*STAR RESEARCH ENTITIES,"Job Description & Responsibilities
The candidate will be attached to the Digital Health Solutions department. He/she will be Involved in development of Machine Learning (ML) AI models and software solutions through projects at DxD Hub. In this position, the candidate will gain exposure to the product development life cycle of software as medical device (SaMD), and breadth of technologies and disease states in the digital health space.

The job activities include but not limited to the list below:
• Analyze and draft software specifications and other design and develop features based on product requirements
• Quick software prototyping for test-bedding of software for use case scenarios
• Potentially working with various startups to develop AI/ML models for healthcare applications.
• Support software product development activities.
• Perform software documentation, software testing, software validation, troubleshooting and optimization to ensure requirements are met
• Liaise and coordinate with team for deployment and testing of software applications.
• Work with Project manager to conceptualize digital health products with inputs from researchers, clinicians and industry; to design novel and clinically relevant digital health applications.
• Oversee product development, verification, and validation of digital health applications.
• write design optimization and verification plans and reports for digital health applications in accordance with ISO 13485
• Compile and communicate software development progress reports for presentations with DxD Hub management.

Job Requirements (Qualification and softskills)
• A minimum bachelor’s degree in Biomedical Engineering, Computer Science/Information Technology, Engineering or equivalent.

• Technical Skills
• Some Hands-on experience software engineering and coding
• Knowledge in ML model development
• Knowledge in software development and testing
• Knowledge of cybersecurity and cloud architectures is a plus
• Knowledge in app develop on either Android or iOS platform is a plus
• Knowledge of biomedical field is a plus

• Soft Skills
• Able to communicate effectively, multi-task and able to work in a dynamic environment
• Ability to work in cross functional teams
• Well organized, with good interpersonal and written communication skills

• Abilities/Aptitudes
• Highly motivated and results driven
• Proactive and takes ownership of the projects
• Adaptable to work exigencies
• Works well as part of a team, yet able to work independently
• Prioritizes assigned tasks and manages time accordingly
• Self-learner",https://www.mycareersfuture.gov.sg/job/sciences/ai-data-science-junior-engineer-i-dxd-hub-astar-research-entities-2ccd5167b2d5cf24d867fcfe2ac90c5b?source=MCF&event=Search
143,"Urgent Hiring!!! Data Ops Engineer (Python , Azure Data Factory , SQL , Fresh Welcome , Training Provided)",TRUST RECRUIT PTE. LTD.,"Highlights:
Homeland Security Domain Provider, CAT 1 Clearance
Permanent job opportunity
Great remuneration and benefits
Great career progression
Responsibilities:
Build and maintain data systems or pipelines.
Perform setup, installation, configuration, troubleshooting and/or upgrade for COTS products.
Develop or implement ways to improve data warehouses, data lakes or equivalent platforms.
Involve in the creation of documentations e.g. design documents, troubleshooting guides etc.
Requirements:
Diploma/Degree in Computer Engineering/Computer
Preferably 1 - 4 years' of working experience in related fields.
Science/Information Technology or related technical discipline
Knowledge and/or experience in data management or data engineering
Experience with Linux commands and shell script
Knowledge and/or experience in relational (including SQL) or NoSQL database (e.g. document, graph)
Knowledge and/or experience in one or more of the following will be an advantage:
Data / Search / Automation platforms such as Hadoop, Elasticsearch, Ansible respectively
Data integration tools such as Talend, DataStage, Denodo
Programming languages such as Python, Spark
Microsoft Azure Cloud services such as Azure Data Factory, Azure Synapse Analytics
Analytics platforms such as Databricks, Dataiku, Data Robot
Good problem-solving skills
Able to work independently and as a team
HOW TO APPLY:
Interested applicants, please send your latest resume to ref19@trustrecruit.com.sg or click on “Apply Now” and provide the below details in your resume.
Last drawn salary:
Expected salary:
Notice period:
Reason for leaving:
We regret only shortlisted candidates will be notified.
Important Note: Trust Recruit Pte Ltd is committed to safeguarding your personal data in accordance with the Personal Data Protection Act (PDPA).
Please read our privacy statement on our corporate website www.trustrecruit.com.sg.
Trust Recruit Pte Ltd
EA License No: 19C9950
EA Personnel: Lim Dick Sern (Dick Sern)
EA Personnel Reg No: R22106832",https://www.mycareersfuture.gov.sg/job/information-technology/urgent-hiring-data-ops-engineer-trust-recruit-88df1e126ec9b9b86301532b5ebdded6?source=MCF&event=Search
144,"Manager, Data Centre Engineering & Solution",ST DYNAMO SG PTE. LTD.,"Responsibilities:

Design and Development
Develop next generation Mission Critical System to meet company long term strategies.
Develop concept Critical Data Centre equipment design with focus on Electrical Power System. i.e. EHT Transformer, Switch bay, Ring Main Unit, Transformers.
Develop concept designs which meet or exceed quality requirements and fall within our budgetary and meet energy efficiency requirements.
Collaborate with internal stakeholders, regional vendors and manufacturers to specify the appropriate Electrical system both upstream and downstream infrastructure.
Data centre Electrical designs and collaboration with other disciplines to create construction document set.
Review
Review RFIs documentation submittal from Consultants, Vendor and Manufacturers.
Review Data Centre commissioning scripts and ensure that systems are accurately tested to the required modes of operations.
Review design and construction drawings and engineering specification for Data Centre.
Evaluation
Evaluate industry new technology to improve power consumption, quality, and efficiencies.
Evaluate the design, construction and operation of mission-critical facilities and associated M&E components.
The Ideal candidate should possess:
Diploma /Degree in Electrical Engineering or relevant discipline.
Minimum 5+ years of M&E design experience in Mission Critical Data Centre environment.
Strong organization skills and ability to prioritize workload to meet tight deadline in a fast paced and dynamic work environment.
Experience with fast-track design/build project.
Ability to perform complex business case analysis to justify technical decisions and present the justification to Management. Ability to work on concurrent projects in multiple geographical regions.
Ability to travel oversea to support Data Centre construction and implementation.
Travel to sites for site review and work with onsite field engineers, as well as provide engineering evaluations, electrical systems audits, and start-up as needed.
Manage Electrical Power System issues during concept design, detailed design, procurement, bidding, manufacturing, delivery, and installation on site.
Knowledge of large-scale mission critical facility’s M&E infrastructure systems.",https://www.mycareersfuture.gov.sg/job/engineering/manager-data-centre-engineering-solution-st-dynamo-sg-a93a62cee3a113f8ed82c4e4bbe50134?source=MCF&event=Search
145,Solutions / Project Engineer(Data Centre),OAKTREE CONSULTING,"Responsibilities
· Understand scope of project, invite vendor quotations, collate and evaluate vendor quotes
· If required, conduct site survey and data gathering at site
· Review costing for project, prepare sales proposals and provide pre-sales support in clients' requirement analysis
· Draft tender and project documents to assist in the preparation of technical and commercial bids for company projects
· Interpret and review system drawings to identify any difference to tender requirements and raise queries against specification
· Build relationships and liaise with internal customers and external suppliers / vendors and manage daily correspondence for quantities, costs and specifications

Requirements
· Degree in Electrical/Mechanical Engineering
· Possess strong technical knowledge
· A team player with strong individual drive, sense of responsibility and task ownership, ability to plan and organize, willing and capable of multi-tasking functions.
· Excellent presentation, communication and interpersonal skill with ability to interact with people at different levels
· Proactive, resourceful, independent with good problem solving and analytical skills
· Excellent presentation, communication and interpersonal skill with ability to interact with people at different levels
· Proficient in Microsoft Office


Please submit resumes to john@oaktree.com.sg with the following

details in MS Word format:
- Position applying for
- Current remuneration
- Expected remuneration
- Notice period
John Goh Meng Chye

EA License No : 06C4642
EA Reg No : R1102621",https://www.mycareersfuture.gov.sg/job/banking-finance/solutions-project-engineer-oaktree-consulting-da84bd710d522ebc7b498e281a91e54d?source=MCF&event=Search
146,Big Data Engineer / Data Analyst (Azure Data / Informatica),RANDSTAD PTE. LIMITED,"To apply, It will be great if you could share your CV to hoonteck.tan@randstad.com.sg. Alternatively, you can apply at https://lnkd.in/guQRxtTg
Strong support from business stakeholders to invest in data
Newly created role due to business expansion
Concrete project timeline on a regional role
About the company
Our client is an end user with multiple offices across Asia. With the ongoing Data Azure project, they are looking to recruit a new Data Engineer to join their team.

About the job
Reporting to the Head of Data, you will be responsible for:
Building data ingestion pipeline. This includes maintaining optimal data pipeline architecture
Assembling large, complex data sets to be ready for data analytics to support analytics initiatives
Implementing the delivery of data solution for business stakeholders across different departments (Manufacturing, Operations and etc)
Implementing Data governance Framework (Policies, Standards and Roles). This includes driving Data governance initiative over the design and implementation of data analytics projects
Analyse current business processes, identifying and translating data requirements into business improvement through data analytics. This includes developing technical solutions in areas of big data platform to fulfil various business use cases.

Skills and experience required
As a successful applicant, you will have at least 4 years of big data experience. Exposure to Microsoft Azure Data Services will be of added advantage.

Whats on offer
This is an excellent opportunity to join a leading company with the opportunity to participate in high value Data projects with exposure to latest technology.

To apply online please use the 'apply' function, alternatively you may contact Hoon Teck TAN at 6510 3633. (EA: 94C3609/ R1219669)

Applicants must be fully vaccinated or have a valid exemption in accordance with MOM’s regulations to allow them to enter the workplace. Applicants may be required to share verifiable COVID-19 vaccination documents or proof of a valid exemption at the point of offer. Randstad Pte. Limited and/or the Client reserves the right to withdraw an offer if the applicant fails to provide verifiable COVID-19 vaccination and/or proof of exemption documents.

To apply, It will be great if you could share your CV to hoonteck.tan@randstad.com.sg. Alternatively, you can apply at https://lnkd.in/guQRxtTg (EA: 94C3609/ R1219669)",https://www.mycareersfuture.gov.sg/job/information-technology/big-data-engineer-data-analyst-randstad-94424e0a282b5e44b8de6c260b1b7ff1?source=MCF&event=Search
147,Data Security & Privacy Engineer,SEAGATE SINGAPORE INTERNATIONAL HEADQUARTERS PTE. LTD.,"As a Research Engineer, you may participate in:
Identifying new trends in cryptography and emerging algorithms
Designing software and hardware-based security features
Developing prototypes and demonstrate solutions
Fundamental and applied research, contributing to publishing of research papers, and filing invention disclosures
Job Requirements
Bachelor or Master in Computer Science, Electrical Engineering or related fields
Proficiency in C/C++, Python, Rust or other programming languages
Experience in designing and performing research experiments/prototyping
Experience development in Linux environment
Understanding and working knowledge with threat analysis and modeling
Understanding of Cloud Security and/or end-point Security
Knowledge of cryptography, software security and AI/ML
Team player who can communicate with cross-site teams",https://www.mycareersfuture.gov.sg/job/information-technology/data-security-privacy-engineer-seagate-singapore-international-headquarters-2ecd42fdd4581eabc6f40df417a07864?source=MCF&event=Search
148,Data Engineering Lead,MANPOWER STAFFING SERVICES (SINGAPORE) PTE LTD,"Role:
Understand project requirements and manage the scope and plan of the project to make sure it adheres to the timeline, budget, and scope
Translate business requirements to technical specifications, provide high-levell solution design
Drive engineering teams in building to the roadmap, managing project delivery, dependencies and risks, track deliverables, and overcome roadblocks
Handle regular stakeholder communication and project updates
Required:
5+ years of experience of managing engineering or data related projects
Work with the business users to understand business requirements and translate that to high level technical specifications
Manage and coordinate test plan, user sign off and go-live plan
Work on defining high level architecture and appreciate technical complexities required
Work with development team on effort assessment, and manage task assignments and deliverables
Comfortable working with both waterfall and agile methodologies
An understanding of data in a sophisticated enterprise system landscape, including data governance, security, quality, and standardization
Knowledge of one or more database technologies (Snowflake, Oracle, Hadoop) and experienced in Cloud Technologies
Proficiency in writing Advanced SQLs, experience with business analytics products like Tableau
Nice to have:
Experience with data science and machine learning tools and technologies is a plus
Knowledge of any programming language (Java, Python) and cloud deployments (CloudFoundry, AWS etc.) will be a plus.
Interested candidates, please share your updated resume with shirley.rajasekar@experis.com.sg or click the ""Apply now"" function.

We regret to inform you that only shortlisted candidates will be notified.

Shirley Monisha

Personnel Reg No: R22106767

Manpower Staffing Services (S) Pte Ltd

EA License No: 02C3423",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineering-lead-manpower-staffing-services-d2a1726023fe8f32e323d64930879305?source=MCF&event=Search
149,Electrical Engineer (Data Centre),PEOPLE PROFILERS PTE. LTD.,"Industry: Data Centre
Competitive remuneration package
Permanent role
Responsibilities:
Technical Supervision of the operation, maintenance and repair of all critical environment systems while maintaining 100% uptime to all critical power systems.
Adherence to all quality, health & safety, and environmental policies within the Data Centre domain.
Work with Facilities Assistant/Manager providing a yearly comprehensive periodic maintenance regime.
Inspect buildings, grounds and equipment for unsafe or malfunctioning conditions.
Troubleshoot, evaluate and recommend system upgrades.
Order parts and supplies for maintenance and repairs.
Work with vendors and contractors to ensure their work meets Client standards
Conduct Annual review of system/component End-of-Life (EOL).
Develop and keep up to date all site electrical procedures including EOPs, SOPs and MOPs. All documentation should be consistent with current client standards.
Specification and recording of the Technician Training certification program and supervision of drill and scenario training aids
Respond to customer service requests in a timely manner.
Respond to emergency calls (24x7 hrs).
Produce monthly executive reports to clients.
Requirements:
Diploma/Degree Level in Electrical Engineering with a minimum of 3-5 years direct industry experience or a minimum of 5(Degree)/8(Diploma) years' experience at Electrical Technician level in a critical environment combined with supervisory/management experience. Preference is given to data centre, hospital, pharmaceutical production or power plant experience.
An excellent understanding and experience of the electrical and mechanical systems used in a data centre environment, including: Feeders, Transformers, Switchgear, UPS systems, Battery banks, ATS/STS units, PDU units, generators, DRUPS, etc.
Experience of complex automatic control equipment, including relay logic, programmable logic controllers (PLC's), building management systems, and their integration with the data centre infrastructure.
Experience of medium voltage distribution systems and associated switch gear and protection equipment.
Experience of MV and LV switching procedures and safety protocols. Preferably a licensed electrical worker (LEW).
Job ID: QX66R483


All Successful candidates can expect a very competitive remuneration package and a comprehensive range of benefits.

Kindly email your resume in a detailed Word format to carlo@peopleprofilers.com
We regret that only shortlisted candidates will be notified

People Profilers Pte Ltd
20 Cecil Street, #08-09 PLUS Building Singapore 049705
+65 6950 9747

EA Licence Number: 02C4944
Registration Number: R1100011
EA Personnel: Carlo Antonio Dela Cruz",https://www.mycareersfuture.gov.sg/job/engineering/electrical-engineer-people-profilers-9c79f1b99d1fffd6b5f40aad8093817c?source=MCF&event=Search
150,Senior Data Engineer - Financial Services,MICHAEL PAGE INTERNATIONAL PTE LTD,"Permanent role
Multinational Organization
About Our Client
Our client is a global brand in the financial service industry. They are looking for a Senior Data Engineer who is able to handle end to end projects in Azure Cloud.
Job Description
Team up with functional group leaders and engineering team to gather and analyse business and technical data requirement needs.
Participate in data collection, analyse and utilise to design and implement the management, monitoring, security, and privacy of data using the full stack of Azure data services.
Design and build Microsoft Azure functions to optimise data extractions and ensure data validation and cleansing.
Reverse engineer existing database data models, manage and maintain existing and new logical and physical data models.
Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the Azure platform.
Support in troubleshooting and analysing the cause of failure, and quickly restore failed components or processes when they occur; Diagnose and remediate resource contention issues and failures in application logs.
The Successful Applicant
Hands on experience in Data Factory, Notifications Hub, Key Vault, DevOps, Data Lake Stores, Data Lake Analytics, Synapse Analytics, Databricks, HD Insight, SSAS, SQL Database or similar cloud infrastructure
At least 5 years of experience in data engineering Azure Cloud preferred, including Visual Studio as applied to SSAS development.
Good knowledge of concepts,practices and procedures related to database modelling, data warehousing, data lake and data mart
At least 5 years of experience in infrastucture automation for continual integration and deployment of technical solutions leveraging Azure Services and Features.
Hands-on experience in scripting languages such as R, Python etc.
What's on Offer
Working with a diverse global team
Flexible working arrangement
Career advancement opportunity",https://www.mycareersfuture.gov.sg/job/information-technology/senior-data-engineer-financial-services-michael-page-international-662403ec57b527e21d5351093630ccf7?source=MCF&event=Search
151,"Assistant Director (Data Engineer), Applications of Teaching and Learning Analytics for Students",NANYANG TECHNOLOGICAL UNIVERSITY,"The NTU education strategy 2025 is leveraging learning analytics to improve teaching and learning. This data engineer position would be critical in ensuring that we are able to achieve our learning analytics strategies and milestones on time.
The role will report to Head of Applications of Teaching and Learning Analytics for Students (ATLAS@NTU) under the Institute for Pedagogical Innovation, Research & Excellence (InsPIRE) and dotted line to Centre for IT Services (CITS) - InfraComm Infrastructure. The incumbent is responsible for supporting the learning analytics efforts at the university. The candidate plays an instrumental role in building an educational data hub with Denodo and the implementation of a new platform to manage machine leaning models.
Key Responsibilities:
Propose effective ways to continuously enhance data quality, governance and performance of educational data hub and data science machine learning platform.
Deploy, fine-tune and maintain Learning Analytics models
Review the development of Learning Analytics models
Manage the education data hub that is based on Denodo
Address technical issues relating to the education data hub, dashboards and applications
Organise learning analytics ethics committee meetings
Involve in planning activities within InsPIRE and CITS.
Requirements:
At least a bachelor’s in computer science, software or computer engineering, applied math, physics, statistics, or a related field.
At least 7 years of work experience, including at least 5 years in of technical experience in data virtualisation, data science platform, Cloud AI/ML technologies and data governance.
Certification in any analytic platform (such as Azure, AWS, Denodo, etc.) would be a bonus.
Proactive in identifying gaps and proposing solutions
Team player (willing to collaborate with others in their work, learn on the job, and support other cross department initiatives when needed)",https://www.mycareersfuture.gov.sg/job/education-training/assistant-director-applications-teaching-learning-analytics-students-nanyang-technological-university-90358f9949a7b5bdd29aa498591ee5b6?source=MCF&event=Search
152,Data Engineer(Azure & SQL),MANPOWER STAFFING SERVICES (SINGAPORE) PTE LTD,"Job Description
3+ of IT experience or working as Data Engineer.
Design and development experience on Azure Logic Apps, Azure Functions – Function Apps, Azure API Management and Azure Service Bus
High-level knowledge of how Azure private networks work and what are related aspects involved related to subnets, firewall and routing tables etc.
Programming experience on Java preferably (Python is preferred)
Experience in using Azure monitoring and logs.
Working experience with SQL Server or Oracle DB
Having exposure to application support process.
Prepare technical documentation for the projects.
Navneet Goel
navneet.goel@experis.com.sg
EA License No. : 02C3423 | Reg No. R1982194",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-manpower-staffing-services-0513eb6fc32cf61c02977c456692092d?source=MCF&event=Search
153,Python Data Engineer,ZENIKA PTE. LTD.,"In Zenika, we are looking for a Python Data Engineer with at least 5 years of experience
You may be a fit if:
You are able to develop, maintain and enhance Python applications processing high volumes of data.
You have experience in Python pandas and Python API/web frameworks such as FastAPI, Flask or Django
You have experience in writing SQL statements and optimizing Python applications performance
You are well versed in business analysis - you are able to converse with business users to understand requirements, to analyse the existing data, to identify the required data transformation and to design the data processing workflow
Who are we?
Are you passionate about complex problem solving through futuristic technology?
Zenika is a global premium IT services consultancy intending to link the organic and the digital worlds. We are a cohesive team of technology enthusiasts and experts who thrive in a collaborative and inclusive environment.
Firm believers in 'Open Source' philosophy, our developers share more than 47K contributions on over 7K projects across several communities.
Curious and pragmatic, we have multiple publications in our name. We share our knowledge by speaking at conferences and supporting companies in their digital transformation journeys through consulting, training, & IT delivery.
As fervent team members, you could join us as we adapt, test and develop innovative new applications for a fintech startup, influence the digital strategy of a banking giant, or create progressive solutions to resolve challenging problems every day for our clients.
Zenika has been recognized as the ""Great Place to Work"" in France for four years in a row (2015 -2018).
We take pride in our employee-first approach and diversity. Know about our values (Gender Equity, Equal Opportunities, Work life Balance, Handicap Mission) and perks - https://www.zenika.com/en-US/pages/values
While joining Zenika Singapore you will get:
Attractive salary package with bonuses
Attractive benefits (Eg: High health insurance coverage, transport allowances, work from home, 20 days annual leave)
Career progression and upskilling opportunities
Internal learning session and events
Monthly and yearly internal social events
Integration in our international developers community (Singapore - France - Canada)
When you join Zenika you join:
A highly qualified team of international professionals
In an outstanding people-first culture
Based on sharing, transparency and fun
Do you like challenges? Do you like freedom?
So, join our passionate team and actively contribute to ""Coding the World"".
Explore open-source technologies & the most innovative methods in the IT world with Zenika today!",https://www.mycareersfuture.gov.sg/job/information-technology/python-data-engineer-zenika-fb128b0bbcb820f8edd183aa9bb29a8e?source=MCF&event=Search
154,Oracle Data Engineer -J40417,SCIENTEC CONSULTING PTE. LTD.,"Job Title: Oracle Data Engineer
Job Type: Full-Time
Location: Tanjong Pagar
Salary up to 7k (basic) + AWS +VB

We are seeking a talented Oracle Data Engineer to join our team. The successful candidate will be responsible for designing, developing, and maintaining the company's Oracle database infrastructure.

Responsibilities:
Design, develop, and maintain Oracle database infrastructure.
Develop ETL processes to extract, transform, and load data from various sources into Oracle databases.
Optimize database performance by analyzing query performance and implementing indexing strategies.
Ensure data security and integrity by implementing access controls, backup, and recovery procedures.
Work collaboratively with cross-functional teams to ensure data availability and accuracy.
Maintain documentation related to database architecture and data models.
Stay up-to-date with emerging database technologies and incorporate them into our products where appropriate.
Requirements:
At least 3 years of experience in Oracle database design and development
Strong knowledge of Oracle database administration, including performance tuning and security.
Experience with ETL tools, such as Oracle Data Integrator or Informatica.
Experience with other databases, such as SQL Server or MySQL, is a plus
If you are excited with this opportunity and enjoy making things happen, do apply now!

OR

Email your updated resume to: speytu@scientecpersonnel.com by quoting ""J40417"" in your email subject for faster processing.

By submitting any application or resume to us, you will be deemed to have agreed & consented to us collecting, using, retaining & disclosing your personal information to prospective employers for their consideration. Please refer to ScienTec’s Privacy Policy https://www.scientecconsulting.com/privacy-policyfor full details. If you wish to withdraw your consent, please write to us at dpo@scientecconsulting.com.

(Note: Any resumes of job applications sent to this mailbox will not be attended as it is solely for the purpose of personal data protection related matters.)

Elane Yap Theng Yu- R1989397
ScienTec Consulting Pte Ltd - 11C5781",https://www.mycareersfuture.gov.sg/job/information-technology/oracle-data-engineer-j40417-scientec-consulting-b3596629afee8f58063bfde1a9125350?source=MCF&event=Search
155,AI Data Engineer,IFUN SINGAPORE PTE. LTD.,"Responsibilities
Analyze business requirements from cross functional teams and translate to technical data science problems
Optimize machine learning models for performance and scalability and deploys them into production to ensure repeatable and dependable operation
Automate the machine learning pipeline, from data ingestion to prediction generation
Collaborate with business, product and engineering teams to build end-to-end data science pipelines
Gather data from various sources and assess business utility
Perform exploratory data analysis, feature-engineering/selection
Apply data science techniques to get insights out of data
Build, deploy, and tune Machine Learning models
Develop prototypes and visuals to illustrate insights
Requirements
Minimum Bachelor’s or above degree in Applied Mathematics, Statistics, Computer Science, or Artificial Intelligent
At least 2 years or more of experience building AI/ML based products or features in Tree Based machine learning model
Evaluating machine learning models and hyperparameter tuning
Expert in Python, SQL etc
strong understanding of AI/ML frameworks or cloud services
Preferred Qualification
Basic knowledge of Machine Learning algorithm
Experiences on automotive
Experience with deploying and scaling Machine Learning models
Experience with first line or second line system operation and maintenance",https://www.mycareersfuture.gov.sg/job/entertainment/ai-data-engineer-ifun-singapore-dc155a8f23240d97063ceb8a43abc883?source=MCF&event=Search
156,Information Technology - Senior Data Sciences & Analytics Engineer (Data Science Track),SINGAPORE AIRLINES LIMITED,"Job Description

SIA Group has multiple positions for senior data scientists to drive our AI, data science and business analytics initiatives. Responsibilities include the following:
Member of the in-house AI and data science development team that works on challenging problems in machine learning (including NLP, computer vision and recommender system using deep learning methods), mathematical optimization, game theory, and experimental design.
Work closely with business stakeholders to create impactful and intelligent features/services in AI, data science and data analytics. Propose and build scalable ML/DL solutions. Deploy them as API microservices for use by software applications and business users for faster and more effective decision making.
Oversee the technical work of external technology partners and provide them datasets to deliver products/services in AI and data science. Support business users in the assessment/ validation of partner-supplied prediction models and in their deployment to production cloud.
Help business units create Tableau dashboards with relevant datasets. Extract insights through data visualization.
Work closely with application development teams to help them operationalize and integrate AI/ML capabilities to their software systems.
Note: You could be posted to any subsidiary in SIA Group.

Requirements
BS in Computer Science, Mathematics, Statistics, Physics or related discipline is required. PhD and MS degrees related to machine learning and other AI disciplines are preferred.
Advanced programming skills in Python. Conversant with algorithm design/analysis, data structure and SQL. Familiarity with functional/object-oriented software development using modern programming languages such as Scala, JavaScript, Java and C# is a plus.
At least 2 years of relevant industry experience in two or more of the following areas:
At least intermediate-level hands-on skills in shallow machine learning or information retrieval. Some exposure to GPU-accelerated deep learning frameworks (such as TensorFlow and PyTorch) for more advanced AI work is a plus.
Knowledge and working experience in workflow, map-reduce or stream processing systems such as Spark and Kafka.
Familiar with Bayesian statistics and inference. Exposure to the application of Bayesian and causal networks for probabilistic reasoning is a plus.
Knowledge and working experience with data visualization tools like Tableau or Power BI.
Some hands-on experience with AWS, GCP or similar public cloud environment.
Excellent interpersonal & communication skills for working with both technical staff and non-technical business users.
Experience with Agile/Scrum/Kanban methodologies is a plus.",https://www.mycareersfuture.gov.sg/job/information-technology/information-technology-senior-data-sciences-analytics-engineer-singapore-airlines-4a69a3fe80dec9196dd6d5e09113d8df?source=MCF&event=Search
157,"Data Centre Engineer, Analyst","JPMORGAN CHASE BANK, N.A.","As a member of our Technology Operations team, your initiative and creative problem-solving will help propel global innovation in technology and business. Working with a team of motivated collaborators, you'll develop and implement strategic technology solutions, ensuring the successful integration of network system and applications servers into existing and new technology infrastructures. You'll play a key role in the care and support of customers, including proactive incident monitoring. In addition to valuable on-the-job experience, you'll receive coaching, mentorship and a host of other development opportunities to advance your career at the firm and beyond.

This role requires a wide variety of strengths and capabilities, including:
• Bachelor’s Degree
• Minimum 1 years in data center operation
• Advanced infrastructure project, operations systems and data analytics knowledge
• Proficiency in one or more of the following: Microsoft Office, VPN, Virtual Machines, Remote Connectivity products, Security
• Understanding of technology offerings and businesses supported
• Ability to identify problems, troubleshoot and deliver strategic solutions to clients
• Genuine interest in continuous feedback, learning and growth opportunities
• Effective collaboration and communication to achieve common goals and maintain a company standard of excellence
• Good knowledge of Windows/MAC OS with the ability to carry out root cause analysis
• Strong analytical and problem resolution skills
• Knowledge of Data Centre Mechanical & Electrical infrastructures, Building Management System, Fire Protection and Security System.
• Strong Ability to configure basic iLo/iDrac/remote access configuration
• Extensive Knowledge in structure cabling, cable management and testing tools
• Extensive Knowledge in physical racking and stacking of servers and network devices
• Experience in replacing components in servers and network devices

To apply for this position, please use the following URL:
https://ars2.equest.com/?response_id=1fc6be4363a79a51f59006f1abc99d66",https://www.mycareersfuture.gov.sg/job/banking-finance/data-centre-engineer-analyst-jpmorgan-chase-bank-na-db9e4c3027b2c80fbd8fc09d07b621e5?source=MCF&event=Search
158,Asst Director (IT Data Ops Engineer),EASTSPRING INVESTMENTS (SINGAPORE) LIMITED,"ROLE
The DataOps Engineer will design, develop and maintain data solutions in Eastspring.

KEY ACCOUNTABILITIES
Build and support transformation of Eastspring’s strategic data platform, focusing on robustness, scalability, performance, flexibility, and security throughout the data lifecycle (ingest, store, process and consume).
Collaborate with business analysts to develop a good understanding of business use cases, and design / document / develop / test / deploy / administer data pipelines (batch and real-time streaming) and data models that meet both functional and non-functional requirements.
Conduct analysis / evaluation and proof-of-concept for technical solution designs to facilitate management decision.
Create detailed design from architecture solution to ensure that the solution meets business requirements and are aligned to Eastspring’s data architecture principles and technology stack.
Support SIT, UAT, release, and production operations of the data platform.
Ensure quality, integrity and accuracy of datasets through tracked, secured and auditable controls.
Collaborate with and train our business partners to create analytics dashboards.
Understand and apply security standards / guidelines / tools to adhere to the required data controls for the data platform, data pipelines, applications and access end points.
Drive data platform operations using Data Ops, ensure data quality, and monitor data system.
Drive DevOps (CI/CD) continuous improvements to automate development and release management.
QUALIFICATIONS / EXPERIENCE
Recognized degree or higher in Computer Science or related Engineering fields.
At least 5 years of demonstrated experience in designing and building high performance / resilient data platform using Azure (Azure Data Factory, Azure Data Lake, Azure Synapse Analytics, Cosmos DB, Functions, Azure DevOps, etc), traditional data technologies (ODS, ELT / ETL, data warehouse), micro-service architecture, API, Python, Java and / or .NET development.
In-depth knowledge and experience in designing and implementing commercial cloud(s) solutions (including use of DevOps practices, containerization / k8s, API, microservices, log management), integrating SaaS solutions, security frameworks (e.g. OIDC, encryption), SDLC (both agile and iterative waterfall), use of development support tools (e.g. JIRA, GitHub) and infrastructure operations.
Good knowledge on CDC, data as a product, data fabric and data mesh.
Good understanding of asset and/or wealth management businesses, including trade lifecycle and operational processes.
Certifications are encouraged and demonstrate continuous learning of technologies essential for this role e.g. Azure (data & analytics, infrastructure & security) certifications.
OTHER TRAITS
Positive attitude and collaborative mindset.
Highly motivated to keep abreast with the latest development in technology and to acquire deep technical knowledge and skills.
Excellent communication, presentation and interpersonal skills.",https://www.mycareersfuture.gov.sg/job/banking-finance/asst-director-eastspring-investments-63403df7ca1eefc50716be9ebf8839a1?source=MCF&event=Search
159,Junior AWS Data Engineer,INTELLECT MINDS PTE. LTD.,"Mandatory Skill-set
Degree in Computer Science/Computer Engineer/Data Science;
At least 5 years of experience in IT and 2 years of Data Pipeline experience in ETL (AWS Glue), Amazon S3, Amazon Redshift, Amazon RDS, Amazon Lambda, Amazon Step Functions;
Has minimum 3 years of experience in Spark / Python /Unix shell to process large scale data, big data and advanced analytics;
Should have good knowledge of AWS components, i.e. S3, Cloud Watch, Glue, Data Storages;
Good Understanding of Hadoop architecture, Big Data and RDBMS;
Good Knowledge of SDLC lifecycle, Agile development methodologies, CI/CD tools;
Strong analytical skills with the ability to analyze and resolve issues;
Excellent interpersonal and stakeholders management skills.
Desired Skill-set
Certification in AWS;
Hands-on with experience with Cloudera CDH.
Responsibilities
Design, build and support new data feeds for various data management layers and data lakes in AWS;
Support migration of the existing data transformation jobs in Oracle, Hive, Impala etc. into Spark, Python on Glue etc;
Understand the existing application and infrastructure architecture;
Collaborate with development, infrastructure and data center teams to define Continuous Integration and Continuous Delivery processes in accordance with industry standards;
Work closely with multiple stakeholders to ensure high standards are maintained.",https://www.mycareersfuture.gov.sg/job/information-technology/junior-aws-data-engineer-intellect-minds-e37ce43aad9e8b233a9f348ab9960f04?source=MCF&event=Search
160,"Associate - Technology Consulting (Financial Services), Big Data Engineer",ERNST & YOUNG ADVISORY PTE. LTD.,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.
We are the only professional services organization who has a separate business dedicated exclusively to the financial services marketplace. Join Financial Services (FSO) and you will work with multi-disciplinary teams from around the world to deliver a global perspective. Aligned to key industry groups including asset management, banking and capital markets, insurance and private equity, we provide integrated advisory, assurance, tax, and transaction services.
The Opportunity
As part of our Data and Analytics team of Financial Services Consulting practice you will work with multi-disciplinary teams to support clients in a wide range of big data initiatives aiming to generate and present new, useful and actionable insights. You will have the opportunity to work and take responsibilities in challenging engagements, gaining exposure to clients in various sectors both in Singapore and in the APAC region.
Your Key Responsibilities
Participation in large-scale client engagements.
Contribution towards, or even leading, the delivery of innovative and engaging big data solutions.
Understanding of business and technical requirements, provision of subject matter expertise, and implementation of big data engineering techniques.
Conducting of data discovery activities, performing root cause analysis, and making recommendations for the remediation of data quality issues.
Putting into practice good organizational and time management skills, with the ability to prioritize and complete multiple complex projects under tight deadlines.
Skills and Attributes for Success
Leverage technology to continually learn, improve service delivery and maintain our leading-edge best practices
Strong presentation skills and proficiency in the use of PowerPoint, Word and Excel
Good understanding of financial services industry
To Qualify for the role, you must have
Bachelor or Master’s degree in Computer Science, Engineering, or other related fields.
Understanding or even practical experience of handling and manipulating semi-structured and unstructured data.
Understanding of big data technology, concepts, tools, features, functions and benefits of different approaches available.
Ability to deploy, manage, and administer Hadoop-based components.
Ability to design, build, install, configure and support Hadoop-based applications.
Experience with one of Java, C# or C++
Understanding of data modeling (ER models) techniques.
Ideally, you’ll also have
Design and implementation experience of data models in physical form in one (or more) of the leading RDBMS platforms such as SQL Server, Oracle, IBM DB2/Netezza, Teradata, etc.
Experience with Business Intelligence or statistical analysis tools and techniques.
Strong communication and business relationship skills to effectively explain analysis, both verbally and in writing, to others and translate analysis into a clear business plan.
Strong time management and organizational skills to gather and make use of data (both internal and external).
What we look for
Highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry. An effective communicator, you’ll be a confident team player that collaborates with people from various teams while looking to develop your career in a dynamic organization.
What we offer
Continuous learning: You’ll develop the mindset and skills to navigate whatever comes next.
Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way.
Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs.
Diverse and inclusive culture: You’ll be embraced for who you are and empowered to use your voice to help others find theirs.
If you can demonstrate that you meet the criteria above, please contact us as soon as possible.
The exceptional EY experience. It’s yours to build.
Apply now.",https://www.mycareersfuture.gov.sg/job/banking-finance/associate-technology-consulting-big-data-engineer-ernst-young-advisory-5aeec0a78468da76800cdfb81db6126c?source=MCF&event=Search
161,Project Engineer / Mechanical Engineer / Data Centre / Construction - 0001,THE SUPREME HR ADVISORY PTE. LTD.,"Project Engineer (Mechanical)
Working Days: 5 Days
Working Hours: 9am - 6pm
Salary: $3000 - $5000
Location: Potong Pasir [Office] // Island-wide [Site]
Jobs Scope:
Develops project objectives by reviewing project proposals and plans; conferring with management
Determines project responsibilities by identifying project phases and elements; assigning personnel to phases and elements; reviewing offers from contractors
Determines project specifications by studying product design, customer requirements, and performance standards; completing technical studies; preparing works estimates
Confirms product performance by designing and conducting tests
Determines project schedule by studying project plan and specifications; calculating time requirements; sequencing project elements
Maintains project schedule by monitoring project progress; coordinating activities; resolving problems
Controls project plan by reviewing design, specifications, and plan and schedule changes; recommending actions
Controls project costs by approving expenditures; administering contractor contracts
Prepares project status reports by collecting, analysing, and summarizing information and trends; recommending actions
Maintains safe and clean working environment by enforcing procedures, rules, and regulations
Maintains product and company reputation by complying with regulations
Maintains and controlling of paperwork and submittals for approval requirements
Contributes to team effort by accomplishing related results as needed
Travel to project sites to witness start-up, integration, and training session
Assist in preparation of tender or pre-sales work whenever necessary
Requirements:
Degree/Diploma in Mechanical Engineering
Experience and work in data centre environment with mechanical and electrical field / engineering & building services industry will be a plus.
Proficient in Microsoft Project, Revit and Auto-Cad
The Supreme HR Advisory Pte Ltd || 14C7279
✅R22111009 Cheng Kai Ling",https://www.mycareersfuture.gov.sg/job/engineering/project-engineer-mechanical-engineer-data-centre-construction-0001-supreme-hr-advisory-52a12553d2f5099f26db9e73dbc78497?source=MCF&event=Search
162,Lead Data Engineer (AWS),INCOME INSURANCE LIMITED,"The Lead Data Engineer will be responsible for the design, develop, and maintain:
Best Practices for Data Architecture and Design Patterns for Data Engineering Use-Cases.
Real-time data feeds from database sources like MySQL, Oracle, and MS SQLServer using the “Change Data Capture Engine” aka “CDC”.
Sub-Second Real-Time Data Pipelines using AWS Kinesis, Glue, Spark, Kinesis, Lambda .
Batch Pipeline Orchestration using on Apache Airflow and Jenkins.
Auto Scalable platform using Kubernetes on EKS.
Org Wide Master Data Management, Data Catalog Engine, and Data Quality Engine.
Code Repo Pipeline to automate Continuous Integration and Continuous Deployment (CI / CD).
Structure Tables with Partitioning and Clustering to increase Cost & Performance Benefits.
Guide Data Analysts and Data Scientists to write efficient queries and workloads.
Data Sharing with On-Demand Encryption/Decryption which can operate at Scale.
Running Containerized ETL workflow at scale.
Qualifications
Bachelor Degree in Computer Science, IT or equivalent.
At least 6-7 years of data engineering experience with team leading/guiding/mentoring experience.
Have strong fundamentals in Computer Science concepts like Cloud Computing Architecture, Distributed Computing, High-Velocity Data Processing, Lambda Architecture, etc
Strong Data modeling and managing Distributed Computing Platforms for Data Processing.
Advance knowledge of SQL and writing resource-efficient queries.
Have at least 2+ years of professional programming experience in Python.
Have at least 2+ years of experience in running a data processing pipelines on either of these: Google BigQuery, Redshift, Hadoop, Presto, Spark, or KSQL.
Have at least 2+ years of experience in writing Sub-Second Real-Time pipelines using Google DataFlow(Apache Beam), PubSub, Kinesis Stream, Lamda, etc...
Have a good understanding of how Kubernetes clusters work and scale on-demand.
Have adequate experience using Containers for Data Engineering workload.
Implemented manual or automated tools for Data Quality, Catalog, and Lineage.
Uphold the sense of Frugality across Data Engineering teams.
Have Good Interpersonal and Presentation Skills to explain and promote Best Practices across the organization with both technical as well as non-technical stakeholders.",https://www.mycareersfuture.gov.sg/job/information-technology/lead-data-engineer-income-insurance-5803149e8162610c2e77c90d366b3918?source=MCF&event=Search
163,Platform and Data Associate Engineer,ENSIGN INFOSECURITY (CYBERSECURITY) PTE. LTD.,"Duties and Responsibilities

• Familiarize with Ensign’s business domain and objectives to develop and deploy big data analytics applications that meet internal business requirements and the needs of partners and customers
• Lead the design, development, testing, deployment of efficient and reliable big data processing workflows that follow secure SDLC practices
• Design, develop, manage data warehouse architecture and relational databases
• Provide monitoring, maintenance and support for system operations as part of M&S as required in commercial projects
• Embrace the challenge of dealing with terabytes to petabytes of data on a daily basis
• Manage different experimentation, development, staging, production environments to provide overall system functionality, health, scalability, resiliency, and security.
• Responsible for implementing and maintaining complex big data projects with a focus on collecting, parsing, managing, and analysing large sets of data to turn information into insights using multiple platforms
• Deliver detailed documentation and ensure quality throughout project lifecycle

Requirements

• Bachelor’s degree in Computer Science/Information Systems/Computer Engineering or equivalent
• experience developing data engineering pipelines or machine learning operations using big data platforms (e.g. Hadoop, Apache Spark, MPP DBs)
• Good in-depth knowledge of Hadoop ecosystem (e.g. HDFS, Impala, Kafka, Spark, NiFi, Elasticsearch), associated tools and cloud-based technologies (e.g. EMR, Redshift, S3).
• Extensive experience in programming (PySpark, Scala) for data engineering
• Understanding of modern software engineering tools such as Git, Bitbucket, Jenkins, Maven.
• Highly proficient at reading, profiling, parsing, transforming, cleansing and integrating data from various sources (structured, semi-structured and unstructured)
• Have strong knowledge in secure SDLC and DevSecOps to design, develop, test, and deploy applications for customer projects.

Preferred Skills /Qualities

• Knowledge in Agile and CI/CD is desirable
• Comfort and experience working in Linux environment
• Aptitude for automation and software profiling
• Experience in Cyber Security / Telco industry will be an advantage
• Proven ability to handle multiple customer projects concurrently
• Detail-oriented, solution-focused and problem solver",https://www.mycareersfuture.gov.sg/job/information-technology/platform-data-associate-engineer-ensign-infosecurity-f2a8b52fa29e3607ae79a377ccddcc83?source=MCF&event=Search
164,Principal / Snr Electrical Design Engineer(Data Centre Project),RANDSTAD PTE. LIMITED,"about the role
Assist in data centre design and construction phases for site management and construction quality control
Monitor construction activities closely on a regular basis and ensure the data centre facility is built to group's standard
Responsible for the review and approval of design consultant’s work to ensure design documents are sufficiently developed with all necessary engineering calculations in place
Responsible for communicating with design consultants to ensure all required deliverables are achieved
Responsible for maintaining internal engineering standard with particular focus on Electrical distribution, control and monitoring systems
Support project commissioning and final handover activities
skills and experience required
Master / Degree in Electrical Engineering / Building Services Engineering
Min 6 years’ working experience in building services design and construction project delivery (data centre projects preferred)
Good knowledge in Electrical HV/LV distribution Engineering with a good understanding on data centre project and protection study
Proficiency in MS Office (e.g., Word, Excel, PowerPoint, etc) with experience in Electrical software, such as Etap, Amtech & DIALux
Relevant Uptime/TIA certificates preferred
Chartered Engineer preferred
To apply online please use the apply function, alternatively you may contact yitwei kwan at yitwei.kwan(@)randstad.com.sg (EA: 94C3609 | R1325913)",https://www.mycareersfuture.gov.sg/job/engineering/principal-snr-electrical-design-engineer-randstad-c2b3b46865deb455507a79f3d225fc43?source=MCF&event=Search
165,Technical Data Engineer,OVERSEA-CHINESE BANKING CORPORATION LIMITED,"Bank of Singapore is currently looking for a qualified candidate to assist the Data Engineering Team’s operational and analytical needs. The Technical Data Enginer will work alongside Data Analytics and big data platform (Hadoop) and engineering team to provide data related support, data ingestion, data interface for unstructured/structred data, data analytics and data management. This person will also assist in building interfaces from various upstream systems and ingest the data into Micrsoft SQL server 2019 / Cloudera Hadoop data store and build the enterprise visulasation tool. This is a great opportunity for someone who is interested in innovative group with the possibility of tremendous career development in data engineering, big data management, data analytics and enterprise data visulsaisation tool.

A little more about this role:
As our Technical Data Enginer, you will be instrumental in big data coding and work in Hadoop-ecosystem. This is a brand-new position at Data Competency vertical.
· Perform extensive unstructured data ingestion into Hadoop
· StronG knowledge of Anaconda, Data visualisation BI tool, Python, SPARK, Java Scala, HIVE and Beeline with hands on experience
· Ability to organize and lead meetings with business and operational data owners
· Experience in integrating data processes with architecture requirements used across company
· Understand Hadoop-ecosystem and Data Engineering activities as well as loading data from several disparate datasets and documentation
· Strong ability to troubleshoot and resolve data issues
· Analytical skill to perform data profiling and data visulization
· Experience in Agile and Waterfall frameworkWork
· Work closely with engineering and operations to document business processes
· Work independently and with team members to understand database structure and business processes
· Help form data management and governance processes within the data engineering team

What you’ll need to have:
· Graduate degree in statistics, math, computer science, physics or other technical related fields; Master’s degree is preferred
· Minimum of 10 years working experience in technical data analysis, data science, or data warehousing with proven business analysis experience
· Experience in at least one or more languages: SPARK, Java Scala,Python
· Experience writing Java Scala, Python
· Experience with Hadoop
· Hands on expierence or knowledge of minimum one mainstream cloud infrastructures:AWS,MS Azure and GCP; ablity to implement data lake.
· Good to have Hands-on experienceon the Hadoop, MangoDB,SPARK, Scala, HIVE, Kafka ,Beelin…etc
· Excellent communication skills
· Passionate about data and analyzing business needs
· Previous experience on a data team in an agile environment preferred
· Hands-on experience on the Hadoop ecosystem, HDFS, Hadoop, Spark, Scala preferred
· Develop in-depth plans and major milestones that must be approved by top management during the planning and design phases of the project.",https://www.mycareersfuture.gov.sg/job/information-technology/technical-data-engineer-oversea-chinese-banking-corporation-ee341025249c360c91f2313cbecaf45a?source=MCF&event=Search
166,Technical Data Engineer,OVERSEA-CHINESE BANKING CORPORATION LIMITED,"Bank of Singapore is currently looking for a qualified candidate to assist the Data Engineering Team’s operational and analytical needs. The Technical Data Enginer will work alongside Data Analytics and big data platform (Hadoop) and engineering team to provide data related support, data ingestion, data interface for unstructured/structred data, data analytics and data management. This person will also assist in building interfaces from various upstream systems and ingest the data into Micrsoft SQL server 2019 / Cloudera Hadoop data store and build the enterprise visulasation tool. This is a great opportunity for someone who is interested in innovative group with the possibility of tremendous career development in data engineering, big data management, data analytics and enterprise data visulsaisation tool.

A little more about this role:
As our Technical Data Enginer, you will be instrumental in big data coding and work in Hadoop-ecosystem. This is a brand-new position at Data Competency vertical.
· Perform extensive unstructured data ingestion into Hadoop
· StronG knowledge of Anaconda, Data visualisation BI tool, Python, SPARK, Java Scala, HIVE and Beeline with hands on experience
· Ability to organize and lead meetings with business and operational data owners
· Experience in integrating data processes with architecture requirements used across company
· Understand Hadoop-ecosystem and Data Engineering activities as well as loading data from several disparate datasets and documentation
· Strong ability to troubleshoot and resolve data issues
· Analytical skill to perform data profiling and data visulization
· Experience in Agile and Waterfall frameworkWork
· Work closely with engineering and operations to document business processes
· Work independently and with team members to understand database structure and business processes
· Help form data management and governance processes within the data engineering team

What you’ll need to have:
· Graduate degree in statistics, math, computer science, physics or other technical related fields; Master’s degree is preferred
· Minimum of 10 years working experience in technical data analysis, data science, or data warehousing with proven business analysis experience
· Experience in at least one or more languages: SPARK, Java Scala,Python
· Experience writing Java Scala, Python
· Experience with Hadoop
· Hands on expierence or knowledge of minimum one mainstream cloud infrastructures:AWS,MS Azure and GCP; ablity to implement data lake.
· Good to have Hands-on experienceon the Hadoop, MangoDB,SPARK, Scala, HIVE, Kafka ,Beelin…etc
· Excellent communication skills
· Passionate about data and analyzing business needs
· Previous experience on a data team in an agile environment preferred
· Hands-on experience on the Hadoop ecosystem, HDFS, Hadoop, Spark, Scala preferred
· Develop in-depth plans and major milestones that must be approved by top management during the planning and design phases of the project.",https://www.mycareersfuture.gov.sg/job/information-technology/technical-data-engineer-oversea-chinese-banking-corporation-4fc54287583a6b11ecd32f70da4c8487?source=MCF&event=Search
167,Data Engineer (SQL),INFOCEPTS PTE. LTD.,"InfoCepts is a global leader of end-to-end data & analytics solutions with nearly 20 years of experience, also named as Gartner’s 2020, 2021 and 2022 customers’ choice for Data & Analytics providers. We continue to grow rapidly year over year, now employing more than 1,200 people in offices across the globe. As we have grown, we have stayed true to our mission—to always help our customers stay modern that help them make smart, data-driven decisions. Since 2004, we have deployed hundreds of high performance analytics applications over web and mobile platforms, built several advanced analytics models, processed petabytes of data using Big Data technologies and delivered several high impact business solutions. Driven by our vision of delivering great customer experiences, we are looking for professionals who are passionate about making the world a better place by leveraging the power of data.

We are hiring aspiring professionals passionate in the manipulation of big data and data pipelines to join us in our cause to help customers Stay Modern, ahead of the technology curve!

Roles and Responsibilities:
Foster strong understanding of assigned use cases and its respective business/operational context
Develop data pipelines in the ETL layer using SQL scripts and prescribed big data ETL tools
Create big data store scripts and big data transformation logics using SQL scripts and/or prescribed ETL tools
Develop data models, perform key restructuring and extract, transform, index and or summarize big data
Create and configure ETL workflow packages including Data Flows, Control Flows and Event Handling
Be hands-on with Python scripting for various use cases
Be the custodian of ETL to ensure that data transformation/processing batch jobs are successfully executed, and troubleshoot as well as debug upon encountering technical issues
Serve as the main point-of-contact for all technical matters for assigned use cases
Skills Required:
1 to 2 years of SQL programming experience is required
Familiarity with Python programming
Experience with at least 1 data integration tool such as SQL Server Integration Services, Informatica, Oracle Data Integrator, Google Dataflow, Azure DataFactory is highly advantageous
Knowledge of at least one database tool such as MySQL, MS SQL and/or PostgreSQL
Adept at queries with good communication and stakeholder management skills",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-infocepts-194d417453ea6ba7ff35ba1ba15ed153?source=MCF&event=Search
168,Data Engineer Lead,MANPOWER STAFFING SERVICES (SINGAPORE) PTE LTD,"This position requires candidate with strong technical background and experience in Data Engineering, and open to function as a Project Lead.

Job Description:
Understand project requirements and manage the scope and plan of the project to make sure it adheres to the timeline, budget and scope
Translate business requirements to technical specifications, provide high level solution design
Drive engineering teams in building to the roadmap, managing project delivery, dependencies and risks, track deliverables, and overcome roadblocks
Handle regular stakeholder communication and project updates
Requirements:
5+ years of experience inmanaging engineering or data related projects
Work with the business users to understand business requirements and translate that to high level technical specifications
Manage and coordinate test plan, user sign off and go-live plan
Work on defining high level architecture and appreciate technical complexities required
Strong communication skills to coordinate with project team, stakeholders and management
Comfortable working with both waterfall and agile methodologies
Knowledge of one or more database technologies (Snowflake, Oracle, Hadoop) and experienced in Cloud Technologies
Proficiency in writing Advanced SQLs, experience with business analytics products like Tableau
Nice to have:
Experience with data science and machine learning tools and technologies is a plus
Knowledge of any programming language (Java, Python) and cloud deployments (CloudFoundry, AWS etc.) will be a plus.
Interested applicants please submit your resume to claudia.kueh@experis.com.sg or click Apply Now button.
We regret to inform that only successful applicants will be contacted. Thank you.
Claudia Kueh Kee Jinq (R1880247)
Manpower Staffing Services (S) Pte Ltd
EA License No: 02C3423",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-lead-manpower-staffing-services-9a48c65357014836f69001dc1b4a9c62?source=MCF&event=Search
169,Data Engineer | $ 6000 | 1 Year Contract (Renewable) | East,APBA TG HUMAN RESOURCE PTE. LTD.,"Data Engineer | $ 6000 | 1 Year Contract (Renewable) | East

· We are looking for a Data Engineer to put together data from a variety of sources to enable large-scale processing and analysis of complex data.
· You are an experienced data wrangler who will be responsible for the design of the data model, undertaking of ETL work and design and maintenance of the databases.

Responsibilities

• Build and maintain scalable data pipelines and infrastructure for ingesting, processing, and storing data from various sources.
• Create and manage ETL processes to transform raw data into structured formats that can be analyzed by data analysts and scientists.
• Develop and maintain data warehouse architecture and design, including data modelling, schema design, and performance tuning.
• Work with cross-functional teams to ensure data accuracy, consistency, and quality across different systems and data sources.
• Monitor and troubleshoot data pipeline and ETL job failures and optimize performance and reliability.
• Develop and maintain documentation of data pipelines, ETL processes, and data warehouse architecture.
• Assemble large, complex data sets to empower exploratory and operational analytics
• Identify, design and implement internal process improvements to optimize data delivery and greater scalability.
• Build analytics tools that utilize the data pipelines to provide actionable insights into key business performance metrics.
• Work closely with business stakeholders to assist with data-related technical issues and support their data infrastructure needs.
• Recommend ways to improve data reliability, efficiency and quality.
• Interpret data, analyze results using statistical techniques and provide ongoing reports by using data visualization tools .
• Identify, analyse, and interpret trends, patterns, and insights in complex data sets.

Requirements

• Degree in Computer Science, Computer Engineering, Information Systems or other quantitative / computational discipline.
• Experience in architecting or developing an enterprise data lake or data warehouse solution on cloud services.
• Strong experience and track record in building data pipelines and databases
• Experience in design and implementation of ETL solutions
• Solid software development skills in at least one major language (e.g. Java) and scripting languages (e.g. Python).
• Experience with advanced schema design and data modelling techniques such as normalization, SCD and star schemas.
• Proficient in writing advanced and optimized SQL queries.
• Strong project management and organizational skills supporting and working with cross functional teams in a dynamic environment.
• Motivated and driven, able to work independently and a good team player as part of a multidisciplinary team

Interested candidates, please send your CVs on as@tg-hr.com

Regret to inform that only shortlisted candidates will be notified.

CEI: R1988671
EA License: 14C7275",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-6000-1-year-contract-east-apba-tg-human-resource-48d04e3314b020aee65421b19b1b3d2c?source=MCF&event=Search
170,R&D Scientist (Data Engineering and Machine Learning),LRDTECH PTE. LTD.,"Job Description – R&D Scientist (Data Engineering and Machine Learning)

Are you serious about building a long-term career in the fields of Artificial Intelligence (AI) and Machine Learning (ML)? And get well rewarded above market rate for your technical contributions and the value you create?

Then you want to work with the other highly competent software engineers at LRDTECH, where you’re given the opportunity to learn, grow and equip yourself with the hard-skills needed to take on practical, real-world challenges.

We are a Singapore-based technology company that creates breakthrough AI and ML technologies backed by a global leader in the energy sector.

We are hiring from the best and brightest scientists and engineers to conduct applied R&D and solve the biggest problems in high-stakes projects.


Responsibilities
The R&D team comprises subject matter experts in the fields such as Artificial Intelligence, Deep Learning, Data Science/Engineering, High-Performance Computing, Applied Mathematics and Physics. As a member of the R&D team, you will be:
Conducting applied R&D on core technologies of the company.
Designing and developing software libraries running on the company’s HPC infrastructure.
Applying your skills and knowledge to affect high-profile engineering projects that result in critical real world impacts.
This is a hands-on Individual Contributor role.

Why Join LRD?
LRD offers a conducive work environment in a company culture that values authenticity, integrity, technical skills, teamwork and results. Here are some of the opportunities offered by the position:
You are always presented with new challenges to solve intellectually stimulating problems. The work never gets stale, mundane or boring.
Continuous learning opportunities to develop your technical expertise in many subfields of AI, ML, HPC, geoscience, engineering, etc.
Have your work recognized with publication opportunities in top scientific conferences and journals.
Be rewarded for your contributions with high performance bonuses well above market rate.

Who Should Join LRD?
The many opportunities offered by the position come with matching expectations. To succeed in this role, you must be a hardworking person who proactively does what it takes to obtain the results on time and on target. You must also be intellectually curious, thorough in your work and strive for excellence.

Requirements
At least 3 years of software development and/or data science experience.
PhD in Computing, Science or Engineering.
Strong publication record in top-tier scientific journals and conferences in AI, ML, data engineering, scientific computing, signal processing, computer vision and/or Natural Language Processing (NLP).
Strong programming skills in Python/NumPy, C or C++.
Proficiency in development tools such as git, Linux Shell Scripting, vim/emacs, etc.
Excellent analytical skills and enjoy solving complex technical problems.

Strongly Desired
Outstanding academic background in Science, Math, Physics or Mechanics.
Experience in AI, ML, data engineering, scientific computing, signal processing, computer vision and/or Natural Language Processing (NLP).
Major contributions to technical projects including R&D or open source projects.
Publications in scientific journals and conferences as first author will be highly valued.

Interested candidates may apply by sending your resume to hiring@lrdtech.com. We regret that only shortlisted candidates will be notified.",https://www.mycareersfuture.gov.sg/job/information-technology/rd-scientist-lrdtech-d74821c023f465e62993cd9e93d09f82?source=MCF&event=Search
171,Principal / Snr / Electrical Design Engineer (Data Centre Project),RANDSTAD PTE. LIMITED,"Responsibilities:
Assist in data centre design and construction phases for site management and construction quality control
Monitor construction activities closely on a regular basis and ensure the data centre facility is built to group's standard.
Responsible for the review and approval of design consultant’s work to ensure design documents are sufficiently developed with all necessary engineering calculations in place
Responsible for communicating with design consultants to ensure all required deliverables are achieved
Responsible for maintaining internal engineering standard with particular focus on Electrical distribution, control and monitoring systems
Support project commissioning and final handover activities
Establish engineering and operation procedures
Requirements
Master / Bachelor in Electrical / Electronics / Building Services Engineering
6 years’ minimum working experience in building services design and construction project delivery (data centre projects preferred)
Good knowledge in Electrical HV/LV distribution Engineering with a good understanding on data centre project and protection study
Proficiency in MS Office (e.g., Word, Excel, PowerPoint, etc) with experience in Electrical software, such as Etap, Amtech & DIALux
Relevant Uptime/TIA certificates preferred
Chartered Engineer preferred
If you are interested in the position , kindly send your CVs in to yitwei.kwan(@)randstad.com.sg
Please include your availability, expected salary and reason for leaving your current job
We regret that only shortlisted candidates will be contacted
EA: 94C3609 / Reg: R1325913",https://www.mycareersfuture.gov.sg/job/engineering/principal-snr-electrical-design-engineer-randstad-fdd203eb764ceeae433c14ecca697ed7?source=MCF&event=Search
172,Principal Data Engineer,ST ENGINEERING IHQ PTE. LTD.,"Participate in the design, development, and testing of an open architecture, open source based, and cloud native data analytics platform product • Explore and evaluate modern data management and MLOps components for continuous improvement of data analytics platform product • Contribute to the design and integration of data management & data governance capabilities for the product • Establish best practices and guidelines to be followed by engineers working on data pipelines • Assist in the setup and maintenance of big data, machine learning and Kubernetes clusters • Work with Data Scientists, Data Analysts, and other internal stakeholders to assist with datarelated technical issues and support their data pipeline infrastructure and data preparation needs Job Requirements: • Bachelor or Master’s degree computer science, software engineering, information systems or related field. • The candidate should have at least 8 years of technical experience in Information Technology with at least 4 years, preferably 6 years in Big Data, Data Warehousing or Business Intelligence technology with knowledge of analytics and AI technologies • Broad knowledge of various aspects of Big Data with good understanding and hands-on experience in Hadoop based technologies such as HDFS, Hive, Spark, Kafka etc. • Deep understanding of relational, NoSQL, NewSQL database technologies such as PostgreSQL, Oracle DB, CitusDB, SingleStore, Cassandra, MongoDB, Neo4J etc. • Good knowledge in programming languages such as Java, Python or Scala on Linux/Windows platforms. • Experience in Kubernetes and Kubeflow is a plus point • Experience in Big Data visualization and reporting software. • Experience in designing ETL/BI solutions. • Experience in DevOps and DataOps • Familiar with Linux/UNIX system administration • Experience in operational support in delivering Big Data solutions. • Effective oral and written communication with strong analytical, problem solving, multitasking and project management skills are essential on the job.",https://www.mycareersfuture.gov.sg/job/engineering/principal-data-engineer-st-engineering-ihq-41e3deea8efc5f680bd5b613a5ddd87f?source=MCF&event=Search
173,Data Engineer Architect #SgUnitedJobs,G2 COMTECH ASIA PTE. LTD.,"• Translate business requirements to technical solutions leveraging strong business acumen.
• Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data & Analytics PaaS Services.
• Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments.
• Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies.
• Design and Build Modern Data Pipelines and Data Streams.• Design and Build Data Service APIs.
• Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics.
• Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience.
• Implement effective metrics and monitoring processes.
• Travel as needed

Skills:
1 - Microsoft SQL Server Integration Services SSIS
2 - Microsoft SQL Server Analysis Services (SSAS) (P3 - Advanced)
3 - Data Modeling Techniques and Methodologies (P3 - Advanced)
4 - Data Warehouse Tools (P3 - Advanced)
5 - Microsoft SQL Server Mobile Reports (P3 - Advanced)
• Demonstrated experience of turning business use cases and requirements to technical solutions.
• Experience in business processing mapping of data and analytics solutions.
• Ability to conduct data profiling, cataloging, and mapping for technical design and construction of technical data flows.
• The ability to apply such methods to solve business problems using one or more Azure Data and Analytics services in combination with building data pipelines, data streams, and system integration.
• Mastery of .NET C# and T-SQL with the familiarity of U-SQL is required
• Knowledge of Azure Data Factory, Azure Data Lake, Azure SQL DW, and Azure SQL, Azure App Service is required.
• Azure IoT, Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics is a plus.
• Knowledge of Python is a plus.
• Experience preparing data for Data Science and Machine Learning.
• Experience preparing data for use in Azure Machine Learning and/or Azure Databricks is a plus.
• Demonstrated experience preparing data and building data pipelines for AI Use Cases (text, voice, image, etc.…).
• Designing and building Data Pipelines using streams of IOT data.
• Knowledge of Lambda and Kappa architecture patterns.
• Knowledge of Master Data Management (MDM) and Data Quality tools and processes
• Strong team collaboration and experience working with remote teams.
• Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals.
• Working experience with Visual Studio, PowerShell Scripting, and ARM templates.
• Experience with Git/TFS/VSTS is a must.
- Preferred Certifications: MCAD .NET, MCSD .NET, MCDBA",https://www.mycareersfuture.gov.sg/job/consulting/data-engineer-architect-sgunitedjobs-g2-comtech-asia-f8545d62d7a2c4e914819341f8561dc6?source=MCF&event=Search
174,"VP, Team Lead, Data Engineering (14945)",GIC PRIVATE LIMITED,"GIC is one of the world’s largest sovereign wealth funds. With over 2,000 employees across 11 locations around the world, we invest in more than 40 countries globally across asset classes and businesses. Working at GIC gives you exposure to an extraordinary network of the world’s industry leaders. As a leading global long-term investor, we Work at the Point of Impact for Singapore’s financial future, and the communities we invest in worldwide.
Data Strategy Group
We build our data architecture in a robust operational environment with scale and efficiency. Data is meaningful in a functional, discoverable, and accessible format to power GIC’s innovative investment strategies.
Data Engineering
You will help to engineer outstanding data solutions to deliver data services at scale. Using modern and innovative data technologies, the team enables GIC colleagues to securely, and seamlessly access data.
You will strive to build a high-performance enterprise data infrastructure, and create a results-driven approach with data products.
What will you do as an VP, Team Lead, Data Engineering?
Design and deliver robust and scalable data products and services for the enterprise, to enable the ingestion, analysis, and consumption of highly varied and voluminous data
Lead a multi-functional team that adopts the working backwards approach to understand stakeholders’ challenges, and to come up with modern and robust solutions
Apply core engineering and devops concepts to create scalable and secure architectures that can support evolving business problems and needs
Manage the resources (both budget and staffing) needed for delivery
What makes you a successful candidate?
Possess Bachelor’s degree in Computer Science, Computer Engineering, or other relevant engineering degree
5+ years of experience in developing a data stack that is scalable, secure, resilient, and mission critical
Proficiency in at least one programming language (Python, Java, Scala)
Strong understanding of big data technologies, and hands-on experience of building data solutions using modern architectures e.g., containerization, Cloud services.
Good understanding of Machine Learning models and ability to manage the models is a plus
Work at the Point of Impact
We need to be forward-looking to attract the right people to help us become the Leading Global Long-term Investor. Join our ambitious, agile, and diverse teams - be empowered to push boundaries and pursue innovative ideas, share your views, and be heard. Be anchored on our PRIME Values: Prudence, Respect, Integrity, Merit and Excellence, which guides us in how we make our day-to-day decisions. We strive to inspire. To make an impact.
GIC is a Great Place to Work
At GIC, we believe sustainable high performance is driven by high expectations and a commitment to excellence, as well as empowerment and flexibility. As such, we currently operate under a hybrid model in which most employees spend 3 days in office and 2 days working from home each week. This balance allows us to preserve the ‘office as a hub’ for ideation, professional growth, and interpersonal connection, while giving our employees the flexibility to do their best work and be their best selves.
GIC is an equal opportunity employer
As an employer, we passionately believe every individual brings with them unique diversity of thought and perspectives to meaningfully enrich perspectives of GIC teams to drive competitive performance. An inclusive environment yields exceptional contribution.
Learn more about our Data Strategy Group Department here: https://gic.careers/group/data-strategy-group/

To be considered for the role, please submit a formal application through the GIC Careers site at
https://careers.gic.com.sg/job-invite/14945/",https://www.mycareersfuture.gov.sg/job/banking-finance/vp-team-lead-data-engineering-gic-94884def8c3c65c16f5e7ab1fbe3a7f7?source=MCF&event=Search
175,Mechanical Engineer (Data Centre),PEOPLE PROFILERS PTE. LTD.,"Industry: Data Centre
Competitive remuneration package
Permanent role

Responsibilities:
Technical Supervision of the operation, maintenance and repair of all critical environment systems while maintaining 100% uptime to all critical mechanical systems.
Adherence to all quality, health & safety, and environmental policies within the Data Centre domain.
Work with Facilities Manager providing a yearly comprehensive periodic maintenance regime.
Inspect buildings, grounds and equipment for unsafe or malfunctioning conditions.
Troubleshoot, evaluate and recommend system upgrades.
Order parts and supplies for maintenance and repairs.
Work with vendors and contractors to ensure their work meets Client standards
Develop and keep up to date all site mechanical procedures including EOPs, SOPs, MOPs, and APs. All documentation should be consistent with current client standards.
Specification and recording of the Technician Training certification program and supervision of drill and scenario training aids
Maintain a positive and professional working relationship with internal and external clients.
Respond to customer service requests in a timely manner.
Respond to emergency calls (24x7 hrs).
Produce monthly executive reports to clients.
Requirements:
Qualified to Diploma/Degree Level in Mechanical Engineering with a minimum of 3 years direct industry experience or a minimum of 8 years' experience at Mechanical Technician level in a critical environment combined with supervisory experience. Preference is given to data centre, hospital, pharmaceutical production or power plant experience.
An excellent understanding and experience of the mechanical and control systems used in a data centre environment, including: Fuel Systems, Building Management Systems and Controls, Chilled water cooling plant, Air handling units, Variable Frequency Drives (VSDs), Fire Alarm systems, and Fire Suppression systems (pre-action sprinklers).
Experience of complex automatic control equipment, including relay logic, programmable logic controllers (PLC's), building management systems, and their integration with the data centre infrastructure.
Extensive experience of large scale chilled water plant including chillers, chilled water distribution and storage systems, cooling towers, and chemical dosing systems
Experience of working within a Project Environment and dealing with design and construction engineering professionals
Computer literate with the ability to compile and submit monthly and annual reports, and to monitor and trend operational characteristics (load, capacity, environmental conditions etc).
Willingness to work outside of normal hours to resolve technical issues in a 24/7 industry
Job ID: LRYWYYVR

All Successful candidates can expect a very competitive remuneration package and a comprehensive range of benefits.

Kindly email your resume in a detailed Word format to carlo@peopleprofilers.com

We regret that only shortlisted candidates will be notified


People Profilers Pte Ltd
20 Cecil Street, #08-09 PLUS Building Singapore 049705
+65 6950 9747

EA Licence Number: 02C4944
Registration Number: R1100011
EA Personnel: Carlo Antonio Dela Cruz",https://www.mycareersfuture.gov.sg/job/engineering/mechanical-engineer-people-profilers-0a64f8b1518a505b5737402385024991?source=MCF&event=Search
176,Lead Data Engineer,THOUGHTWORKS PTE. LTD.,"Are you at your most vibrant when you’ve successfully distilled data into its simplest, most meaningful form?
Thoughtworks is a global software consultancy with an aim to create a positive impact on the world through technology. Our community of technologists thinks disruptively to deliver pragmatic solutions for our clients' most complex challenges. We are curious minds who come together as collaborative and inclusive teams to push boundaries, free to be ourselves and make our mark in tech.
Our developers have been contributing code to major organizations and open source projects for over 25 years. They’ve also been writing books, speaking at conferences and helping push software development forward, changing companies and even industries along the way. We passionately believe that software quality is driven by open communication, review and collaboration. That’s why we’re such vehement supporters of open source and have made significant contributions to open source tools for testing, continuous delivery (GoCD), continuous integration (CruiseControl), machine learning and healthcare.
As consultants, we work with our clients to ensure we’re evolving their technology and empowering adaptive mindsets to meet their business goals. You could influence the digital strategy of a retail giant, build a bold new mobile application for a bank or redesign platforms using event sourcing and intelligent data pipelines. You will learn to use the latest Lean and Agile thinking, create pragmatic solutions to solve mission-critical problems and challenge yourself every day.
Data Engineers develop modern data architecture approaches to meet key business objectives and provide end-to-end data solutions. You might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problems. On other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product. It could also be a software delivery project where you're equally happy coding and tech-leading the team to implement the solution.
You’ll spend time on the following:
You might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problems
You will partner with teammates to create complex data processing pipelines in order to solve our clients’ most ambitious challenges
You will collaborate with Data Scientists in order to design scalable implementations of their models
You will pair to write clean and iterative code based on TDD
Leverage various continuous delivery practices to deploy, support and operate data pipelines
Advise and educate clients on how to use different distributed storage and computing technologies from the plethora of options available
Develop and operate modern data architecture approaches to meet key business objectives and provide end-to-end data solutions
Create data models and speak to the tradeoffs of different modeling approaches
On other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product
Seamlessly incorporate data quality into your day-to-day work as well as into the delivery process
Here’s what we’re looking for:
You are equally happy coding and leading a team to implement a solution
You have a track record of innovation and expertise in Data Engineering
You’re passionate about craftsmanship and have applied your expertise across a range of industries and organizations
You have a deep understanding of data modelling and experience with data engineering tools and platforms such as Kafka, Spark, and Hadoop
You have built large-scale data pipelines and data-centric applications using any of the distributed storage platforms such as HDFS, S3, NoSQL databases (Hbase, Cassandra, etc.) and any of the distributed processing platforms like Hadoop, Spark, Hive, Oozie, and Airflow in a production setting
Hands on experience in MapR, Cloudera, Hortonworks and/or cloud (AWS EMR, Azure HDInsights, Qubole etc.) based Hadoop distributions
You are comfortable taking data-driven approaches and applying data security strategy to solve business problems
You’re genuinely excited about data infrastructure and operations with a familiarity working in cloud environments
Working with data excites you: you have created Big data architecture, you can build and operate data pipelines, and maintain data storage, all within distributed systems
Advocate your data engineering expertise to the broader tech community outside of Thoughtworks, speaking at conferences and acting as a mentor for more junior-level data engineers
Assure effective collaboration between Thoughtworks’ and the client’s teams, encouraging open communication and advocating for shared outcomes",https://www.mycareersfuture.gov.sg/job/consulting/lead-data-engineer-thoughtworks-3f813a4b3c51d719a3d749939fe92518?source=MCF&event=Search
177,Mechanical Engineer (Data Centre) JO-230221-306860,RGF TALENT SOLUTIONS SINGAPORE PTE. LTD.,"Our Client:

Our client is a well-known brand that provides complete engineering solutions for the Offshore and Marine Industry. They are actively looking to hire a Mechanical Engineer to join their team in Singapore.

The Responsibilities:

Customer Service
Maintain a positive and professional working relationship with internal and external
Respond to customer inquiries in a efficient manner
To answer emergency calls (24x7)
Prepare monthly management reports
Maintain Data Centre Systems
Technical supervision of operation, maintenance and repair of critical environmental systems while maintaining 100% uptime to critical mechanical systems
Compliance with quality, health, safety, and environmental policies within the data centre
Collaborate with the assistant / manager of the facility and ensure an extensive annual periodic maintenance regime
Inspect buildings, sites, and equipment for unsafe or malfunctioning conditions
Troubleshoot, evaluate, and recommend system updates
Order parts and accessories for maintenance and repair
Work with suppliers and contractors to ensure their work meets customer standards
Develop and update all site mechanical procedures including EOPs, SOPs, MOPs and APs. All documentation must conform to current customer standards
Specification and registration of technician training certification program and supervision of exercise and scenario training aids
The Requirements:
Diploma/Degree in Mechanical Engineering with a minimum of 3 years direct industry experience or a minimum of 8 years’ experience at Mechanical Technician level in a critical environment combined with supervisory experience
Preference is given to Data Centre, Hospital, Pharmaceutical Production or Power Plant experience
An excellent understanding and experience of the mechanical and control systems used in a data centre environment, including: Fuel Systems, Building Management Systems and Controls, Chilled water cooling plant, Air handling units, Variable Frequency Drives (VSDs), Fire Alarm systems, and Fire Suppression systems (pre-action sprinklers)
Experience of complex automatic control equipment, including relay logic, programmable logic controllers (PLC's), building management systems, and their integration with the data centre infrastructure
Extensive experience of large-scale chilled water plant including chillers, chilled water distribution and storage systems, cooling towers, and chemical dosing systems
Experience of working within a Project Environment and dealing with design and construction engineering professionals
Computer literate with the ability to compile and submit monthly and annual reports, and to monitor and trend operational characteristics
Willingness to work outside of normal hours to resolve technical issues in a 24/7 Industry
Disclaimer: The Company complies with the Tripartite Guidelines on Fair Employment Practices (TGFEP), including the prevailing guidelines on recruitment. All qualified applicants will be considered for the position regardless of their age, race, religion, nationality, marital status, or family responsibilities. A more detailed discussion of the TGFEP is available on the Tripartite Alliance for Fair and Progressive Employment Practices (TAFEP) website at https://www.tal.sg/tafep.",https://www.mycareersfuture.gov.sg/job/engineering/mechanical-engineer-jo-230221-306860-rgf-talent-solutions-singapore-851b8da324f737f30c3742db7db9061a?source=MCF&event=Search
178,DATA ENGINEER / ANALYST (PART TIME),SHING LECK ENGINEERING SERVICE PTE. LTD.,"Includes but is not limited to the following.
- Carry out data preparation (extract data from company systems & cleanse data).
- Analyse data and derive insights by using Power BI that derive productivity, quality, and safety improvements. Produce meaningful reports and present to Company management for recommendations and call to action.
- Propose and implement changes to the company website, which may include User Interface and Design (UI/UX).
- Assist senior management in integration and digitalisation initiatives.
- Assist management team with methodically archiving signature project works based on an internally aligned framework. Present showcase projects in engaging graphical detail.
- Assist management for the preparation of various certification processes, audits and award submissions.

Skills
- Proficient in MS Office, especially PowerPoint and Excel
- SQL
- Microsoft PowerBI
- Quick and Adaptable

Qualifications
- Local Polytechnic Diploma, Advanced Diploma in IT or equivalent
- Student pursuing an undergraduate degree in IT or equivalent are welcome.
- Experience in Data Analytics is welcome but not necessary.
- Demonstrated ability to self-learn, is a team player and task oriented.
- Hybrid working hour, work remotely
- Singaporeans and PRs only",https://www.mycareersfuture.gov.sg/job/others/data-engineer-analyst-shing-leck-engineering-service-eef65782426c8321bac5392d4e203ceb?source=MCF&event=Search
179,Data Center Operations Engineer,RUNCHUN INFOTECH (SINGAPORE) PTE. LTD.,"· To follow the operation procedures and roll out for site staff.
· Ensure compliance with all local statutory regulations
· To support and site attendance for troubleshooting
· Prepare monthly and weekly reports about customer power consumption, duty report, access report, etc.
· Managing all vendors to carry out server installations, fiber & cable maintenance, and any other related maintenance
· Execute service level based on standards and requirement
· Assist manager in preparing Management report, Powerpoint presentation, SOP/EOP, and Critical activities planning
· Escort customer/vendor to work or deliver network equipment
· Remote hand service for customers like fiber patching, equipment installation, and configuration
· Update technical drawing regularly / Inventory list / Asset list …etc.
· Cabling works in MDF, TEL room, MMR and data halls, including cabling and testing
· Network equipment installation and configurations",https://www.mycareersfuture.gov.sg/job/information-technology/data-center-operations-engineer-runchun-infotech-68813ddf0fc00627b2d157b4508c1e1d?source=MCF&event=Search
180,Technical Project Manager - Data Engineering - RSM,MANPOWER STAFFING SERVICES (SINGAPORE) PTE LTD,"Role:
Understand project requirements and manage the scope and plan of the project to make sure it adheres to the timeline, budget, and scope
Translate business requirements to technical specifications, provide high-levell solution design
Drive engineering teams in building to the roadmap, managing project delivery, dependencies and risks, track deliverables, and overcome roadblocks
Handle regular stakeholder communication and project updates
Required:
5+ years of experience of managing engineering or data related projects
Work with the business users to understand business requirements and translate that to high level technical specifications
Manage and coordinate test plan, user sign off and go-live plan
Work on defining high level architecture and appreciate technical complexities required
Work with development team on effort assessment, and manage task assignments and deliverables
Comfortable working with both waterfall and agile methodologies
An understanding of data in a sophisticated enterprise system landscape, including data governance, security, quality, and standardization
Knowledge of one or more database technologies (Snowflake, Oracle, Hadoop) and experienced in Cloud Technologies
Proficiency in writing Advanced SQLs, experience with business analytics products like Tableau
Nice to have:
Experience with data science and machine learning tools and technologies is a plus
Knowledge of any programming language (Java, Python) and cloud deployments (CloudFoundry, AWS etc.) will be a plus.
Interested candidates, please share your updated resume with shirley.rajasekar@experis.com.sg or click the ""Apply now"" function.
We regret to inform you that only shortlisted candidates will be notified.

Shirley Monisha
Personnel Reg No: R22106767
Manpower Staffing Services (S) Pte Ltd
EA License No: 02C3423",https://www.mycareersfuture.gov.sg/job/engineering/technical-project-manager-data-engineering-rsm-manpower-staffing-services-94c47a03c30ae3ab7a18efe625819892?source=MCF&event=Search
181,Assoc Data Engineer,INTEGRATED HEALTH INFORMATION SYSTEMS PTE. LTD.,"Role and Responsibilities
Obtain and confirm the Budgetary Quotations from the source systems and vendors
Review and critique vendors’ quotations
Write funding / requirement approval papers
Review the data designs, ETL design, table designs and perform data analysis
To ensure the interface specifications meet the IHiS data governance, guidelines and policies
Monitor the data deliverables and ensure timely availability of data for development, UAT and production
Plan and coordinate end-user training for any system implementations / enhancements / Change Requests (CRs)
Manage vendors to achieve Key Performance Indicators / Service Level Agreements and reviews of contractual Terms & Conditions (when necessary)
Assist manager in formulating application implementation strategies / best practices
Identify data and business gaps within organization’s information systems by analyzing existing systems and workflows.
Recommend effective and cost saving solutions
Support positive project-vendor relationships and resolve conflicts
Support the team in defining project requirements, tracking and documentation
Manage and track project risk and issues
For each project, support the following tasks:
Develop an application Project Charter / variation charter for source system's integration and Module Schedule
Develop risk assessment and mitigation plans
Work closely with other source systems to assess the impact and dependencies
Review project progress and ensure that the project meet the project milestones on time
Review plan, conduct and co-ordinate the data UAT by working with the end-users
Assist the managers and users to sign-off the deliverables
Ensure audit conformance throughout the project life cycle
Prepare post implementation review
Requirements / Qualifications
At least 3 years’ experience in IT Projects
Experience in all phases of project lifecycle
Experience in budgeting (costing, cost evaluation analysis etc.)
Experience in various procurement methodology e.g. RFQ, RFP etc.
Experience in writing approval papers
Must have the knowledge and experience to perform root cause analysis",https://www.mycareersfuture.gov.sg/job/information-technology/assoc-data-engineer-integrated-health-information-systems-8eab9518f6f03760c7e8b8d13b5749e1?source=MCF&event=Search
182,Cloud Data Engineer,AXRAIL PTE. LTD.,"About Axrail
We are a leading company in providing analytics and machine learning services to help enterprise be more data driven. We are looking for passionate, hardworking and talented data architects to be part of our team in creating and building innovative websites that customers love.
We hire only builders – people who like to invent, enjoy problem-solving and are outcome driven. If you are a builder yourself, we are keen to hear from you!
What will I be doing?
Lead and complete work projects with resourcefulness on right timeline for customers and internal product team
Participate pre-sales on-site visits, understand customer requirements, creating consulting proposals
Coordinating and execute pilots, prototypes and POCs while providing validation for business enhancements
Will work with other team members to investigate design approaches, prototype new technology and evaluate technical feasibility.


Do I have what it takes?
Strong attention to detail. You will be responsible for end to end implementation of your design
Experience in leading a team to solve business problems using technologies.
Knowledge and skills in Python language.
Expert hands on experience and architectural design with AWS Big stack (S3, EMR, Redshift, Kinesis, Glue, Athena).
Deep knowledge on Spark
Ability to achieve stretch goals in a highly innovative and fast paced environment
Curious and have a passion for learning
Motivated fresh grad with good attitude are welcome
Preferred Qualifications
Strong Computer Science fundamentals
Understanding on deep learning framework like pytorch and tensorflow
Excellence in technical communication with peers and non-technical cohorts
Strong sense of ownership, urgency, and drive
If this sounds interesting, we would love to hear from you. Please include whatever info you believe is relevant: resume, GitHub profile, code samples, links to personal projects, etc.",https://www.mycareersfuture.gov.sg/job/information-technology/cloud-data-engineer-axrail-8b8b636fa5837a05283a519be3d44aa0?source=MCF&event=Search
183,Data Center Engineer (Data Center Operations & critical facilities operations),SOFTENGER (SINGAPORE) PTE. LTD.,"Job Description:
Responsible for HW installation, requirement analysis, design, OS & SW Config, Pre & Post implementation engr for Project & Onsite Support. Preparation work at ELV room
- Rack & device RU adjustment to support the HW installation, ATS, power cable labelling, rack iPDU modification & update
- Update DCO Design, Rack Elevation & other apps (i.e DCE, DCO, ITA, PIQ, OBS)
- Certified Raritan, DCP & EcoX product SW suite & linux (Min k5+)
- Work status report submission
- Other Ad-hoc work assigned
- Including overnight & weekends
- Grounding resistance measurement


Scope of Work:
1. - Install, configure, operate & manage Datacenter & ELV room Raritan products
- Assist in rack & stack of devices at DC & ELV rooms
- Installaiton of temperature sensor, water detections, door handles, dry contact, power cord preparation at the DC & ELV rooms
- Work with other IT team, suppliers & contractors for the deployments
- Manage the inventory & asset for Critical Environment & update the record for the rack elevation & other monitoring tool
- Adjustment the rack units, power strips & do the preparational work for the project
- Provide weekly & montly report for all works completed & outstanding
- Ability to do the grounding connections on the IT devices to the rack ground
- Operate & Maintain the Data Center Operations Monitoring Tools & Infrastructure Management Tools
- Timely respond to all alarms related to Power, Cooling, Fire Protection & Water Leak in Data Centers & all other IT Rooms
- Perform all other tasks at the direction of Supervisor or Manager

Key Qualifications / Requirements:
- Electrical/Mechanical/Computer Engineering Degree or Diploma & additional experience in lieu of a degree
- Min. 2-4 years hands-on experience in Data Center Operations & critical facilities operations
- Data center skills such as installing or moving equipment & cabling on a large-scale basis
- Exposure in a high-pressure critical environment & able to handle multiple tasks & work independantly
- Hands-on experience in intelligent Power Distribution Units & Automatic Transfer switch installaiton, configure, operate & manage
- Working knowledge on the Autocad, Building Management System, StruxureWare DCE/DCO/PIQ/Observium & any other Critical Environment Management Tools.
- Analysis, Design, OS & Software Configuration, Implementation & Post Implementation Engineer for Project & Onsite Support
- General experience in Data Center IT Infrastructure & knowledge of common Datacenter, Network & project management
- Good communication skill & able to do multiple task",https://www.mycareersfuture.gov.sg/job/information-technology/data-center-engineer-softenger-9ec9d1e000e190e060cc4709e6cbeb67?source=MCF&event=Search
184,Data Center Facility Engineer (Junior),EZSVS SINGAPORE (PTE.) LTD.,"- Responsible for critical facility operation of Alibaba data centers.
- Responding the emergent failure and tracking preventative maintenance.
- Responsible for capacity management of facility systems including power and cooling, etc.
- Manage availability risk of facility systems and drive the resolution.
- Support IT manager (IT) on their project and operations.
- Support design and project teams on new site/data-hall construction and commissioning.

Minimum Qualifications:
- Diploma in engineering of electrical, mech or related field.
- 1 year of critical facility management or operation experience in large scale data center or 2+ years large scale production facility management experience in large scale plant.
- Experience and knowledge of MEP equipment such as UPS, generator, Chiller, Pump, cooling tower, etc.
- Good sense of building and maintain a safety and high efficiency working environment in daily work.
- Strong written and verbal communication skill in English.
- High attention to details to identify the risk and drive to resolve them.",https://www.mycareersfuture.gov.sg/job/engineering/data-center-facility-engineer-ezsvs-singapore-68ef65465741f19d390a5443bbc99520?source=MCF&event=Search
185,Application Developer (Data Engineering),MAVENTREE TECHNOLOGY PTE. LTD.,"Tertiary Education in relevant fields is preferred.
Understand key concepts in data modelling, data processing, data warehouse, data management and data security.
Hands-on experience in SQL programming language is a must.
Hands-on experience in a data warehouse project.
Hands-on experience in visual analytics, preferably using Power BI and Tableau.
Experience in Data Engineering:
a) Data Engineering on AWS Cloud platform, including Lambda, Step Functions, ECS, ECR, Glue,
Athena, RDS, SSM, Eventbridge, API Gateway, SQS.
b) Python & containers development.
c) Creating tables, views and partitioning in SQL and PostgreSQL database.
d) Creating ingestion scripts using Microsoft SQL Server Integration Services (SSIS).
e) Data modelling, preferably in ER Studio.
Advantageous to have experience in the following skillset:
a) Denodo, SQL Polybase
b) Azure DevOps, GitLab, JIRA, Confluence
c) Microsoft Sharepoint development
d) Unix scripting for secure file transfers
e) Dot Net programming (e.g. C#)
f) Kafka / AWS Kinesis
Strong analytical, logical thinking and problem-solving skills.
Willingness to learn and adapt.
A good team player with excellent communication skills, both oral and written.",https://www.mycareersfuture.gov.sg/job/information-technology/application-developer-maventree-technology-e72c4efee1999511ac87002757a9b70d?source=MCF&event=Search
186,Data Engineer (Permanent),ZENITH INFOTECH (S) PTE LTD.,"Job Responsibilities:
Work closely as part of the agile product team to design, develop, test and deploy data integration products under the guidance of the Product Manager
The project activities include:
Provide monthly progress reporting and status updates to Authority.
Deliver all required documentations (in compliance to Authority’s QMS processes and standards) including but not limited to design specifications, data specifications, user requirements, mapping documents and unit test plan.
Responsible for complying with data integration development processes and standards defined by Authority.
Develop and manage the data integration programs with Authority’s furnished software
Maintain and perform continuous enhancements of data pipeline to ensure smooth data ingestion and good performance. This scope requires personnel to work with Oracle Database, Big Data Platform and tools
Conduct and support requirement gathering with the Authority’s project team for new data integration program development.
Perform all required testing to ensure quality of deliverables i.e. User Acceptance Test (UAT), System Integration Test (SIT), Operational System Acceptance Test (OSAT).
Review system, application activities and database logs to detect abnormalities based on provided criteria.
Develop extractors for data in source systems including but not limited to SAP BW OpenHub, Oracle database, SQL Server database and flat file.
Job Requirements:
Degree/Diploma in IT, Computer Science, Data Analytics or related disciplines preferred
Experience in building and optimising data pipelines, architecture and datasets using DI/ETL technology (e.g. Informatica, Talend).
Shall have experience in supporting data transformation, data structures, metadata, dependency and workload management.
Experience in multiple data source support (e.g. flat files, SQL database, SAP database, PostgreSQL database, unstructured data not limited to text, documents, images, digitalised video, digitalised audio, sensor data) would be advantageous.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-zenith-infotech-997e0704326c8c2647c8d5bc9f711717?source=MCF&event=Search
187,Lead AWS Data Infrastructure Engineer,INCOME INSURANCE LIMITED,"Income is looking for Lead Data Infrastructure Engineer to join our Data Engineering team in Singapore. Our team owns and runs the Enterprise Datalake used by thousands of users and hosted across AWS, GCP and On-Premises servers.
As a Data Infrastructure Engineer, you will design, build, maintain and improve our data infrastructure on Cloud, which enables us to make Income data driven organisation. In this role, you would also get the opportunity to work with world-class big data and cloud services, such as: AWS/GCP, Glue, Spark, DBT, Airflow, Tableau and PowerBI.
Responsibilities
Work with data engineering and machine learning teams to improve our data infrastructure for increased reliability, maintainability, and scalability.
Architect and design solutions to improve our data delivery capabilities, data quality monitoring, and data pipeline lifecycle.
Architect and administer our cloud applications such as AWS Glue, Sagemaker, LakeFormation, Iceberg Lakehouse, etc.
Managing Regression Testing Suite, Continuous Integration and Continuous deployment Pipelines.
Qualifications
Bachelors Degree in Computer Science, Information Technology or other relevant fields
6-7 years of designing and building Large Scale Infrastructure and ETL deployment and management pipelines using Terraform, Jenkins, AWS CodePipeline and AWS CodeBuild.
At least 1-2 years of team leading experience
Broad experience in SQL and Python.
Hands-on experience of writing, building and deploying Containerised applications using ECS or EKS or GKE.
Experience in cloud application architecture & administration in AWS with the stacks such as: EC2 instances, Glue, Terraform (build & manage script), Jenkins, CodePipeline, CodeBuild, RDS (PostGres) instances, S3, Airflow
Experience in Deployment and implementation of AWS Glue with basic knowledge of SQL and Python - able to read and understand.
Hands-on experience designing, building, and operationalizing large-scale enterprise data solutions and applications.
Background in in custom ETL design, implementation, and maintenance.
Hands-on experience with strong exposure to AWS CLI and BOTO3 Python libraries.",https://www.mycareersfuture.gov.sg/job/information-technology/lead-aws-data-infrastructure-engineer-income-insurance-6c9d2ec9f7d7edbbf5bfbb247d9306fd?source=MCF&event=Search
188,Snr Principal Data Engineer,ST ENGINEERING IHQ PTE. LTD.,"Participate in the design, development, and testing of an open architecture, open source based, and cloud native data analytics platform product • Explore and evaluate modern data management and MLOps components for continuous improvement of data analytics platform product • Contribute to the design and integration of data management & data governance capabilities for the product • Establish best practices and guidelines to be followed by engineers working on data pipelines • Assist in the setup and maintenance of big data, machine learning and Kubernetes clusters • Work with Data Scientists, Data Analysts, and other internal stakeholders to assist with datarelated technical issues and support their data pipeline infrastructure and data preparation needs Job Requirements: • Bachelor or Master’s degree computer science, software engineering, information systems or related field. • The candidate should have at least 11 years of technical experience in Information Technology with at least 6 years, preferably 8 years in Big Data, Data Warehousing or Business Intelligence technology with knowledge of analytics and AI technologies • Broad knowledge of various aspects of Big Data with good understanding and hands-on experience in Hadoop based technologies such as HDFS, Hive, Spark, Kafka etc. • Deep understanding of relational, NoSQL, NewSQL database technologies such as PostgreSQL, Oracle DB, CitusDB, SingleStore, Cassandra, MongoDB, Neo4J etc. • Good knowledge in programming languages such as Java, Python or Scala on Linux/Windows platforms. • Experience in Kubernetes and Kubeflow is a plus point • Experience in Big Data visualization and reporting software. • Experience in designing ETL/BI solutions. • Experience in DevOps and DataOps • Familiar with Linux/UNIX system administration • Experience in operational support in delivering Big Data solutions. • Effective oral and written communication with strong analytical, problem solving, multitasking and project management skills are essential on the job.",https://www.mycareersfuture.gov.sg/job/engineering/snr-principal-data-engineer-st-engineering-ihq-16808a03f804025e7c7525e5fef6614d?source=MCF&event=Search
189,"Senior Manager / Manager, Data Engineering",AGENCY FOR INTEGRATED CARE PTE. LTD.,"To ensure that source data generated via AIC’s multiple business-specific systems are organized and transformed in ways that support business users’ needs and Business Intelligence applications.
To work closely with Business Intelligence (BI) and Advance Analytics and Modelling (AAM) colleagues in the Research Department, and partner with program development, sector development, outreach, and grants divisions in AIC to understand the business requirements and translate them into long-term data solutions.
To work with key external partners within the existing IT development processes, monitor and provide input to influence the;
Design, development, and optimization of scalable data warehouses;
Building of data pipelines across data systems both internal and external to AIC’s data ecosystem; and
Optimizing of existing data structures so that it supports self-service reporting requirements
Job Requirements:
Bachelor degree in Computer Science, Applied Mathematics, or Engineering.
Professional Data Engineer certification will be considered favorably.
At least 5 years of relevant experience developing, testing, and maintaining data warehouses, preferably in health or social care settings.
Experience in
Data mapping and integration processes;
Building and managing ETL processes;
Handling large data systems with relational databases;
Building pipelines to automate data interface pipelines; and
Familiarity with Excel, SQL, Informatica, Python, Tableau;
Be an advocate for best practices and lifelong learning;
Able to work well independently and in teams;
Excellent written and oral communication skills; and
Flexible, self-motivating, and able to manage multiple projects efficiently.",https://www.mycareersfuture.gov.sg/job/engineering/senior-manager-manager-data-engineering-agency-integrated-care-fcb8ab3230cdfccf9f5599395a33d5d2?source=MCF&event=Search
190,Data Engineering Architect,APAR TECHNOLOGIES PTE. LTD.,"Responsibilities
As a Data Engineering Architect, you will use comprehensive modern data engineer techniques and methods with Advanced Analytics to support business decisions for client.
Translate business requirements to technical solutions leveraging strong business acumen.
Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data & Analytics PaaS Services.
Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments.
Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies.
Design and Build Modern Data Pipelines and Data Streams.
Design and Build Data Service APIs.
Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics.
Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience.
Implement effective metrics and monitoring processes.
Requirements
Demonstrated experience of turning business use cases and requirements to technical solutions.
Experience in business processing mapping of data and analytics solutions.
Ability to conduct data profiling, cataloging, and mapping for technical design and construction of technical data flows.
The ability to apply such methods to solve business problems using one or more Azure Data and Analytics services in combination with building data pipelines, data streams, and system integration.
Mastery of .NET C# and T-SQL with the familiarity of U-SQL is required Knowledge of Azure Data Factory, Azure Data Lake, Azure SQL DW, and Azure SQL, Azure App Service is required.
Azure IoT, Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics is a plus.
EA Number: 11C4879",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineering-architect-apar-technologies-9df2610263e09a84e1129b899eae4ce8?source=MCF&event=Search
191,Senior Platform and Data Engineer,ENSIGN INFOSECURITY (CYBERSECURITY) PTE. LTD.,"Responsibilities:
Familiarize with Ensign’s business domain and objectives to develop and deploy big data analytics applications that meet internal business requirements and the needs of partners and customers
Lead the design, development, testing, deployment of efficient and reliable big data processing workflows that follow secure SDLC practices
Design, develop, manage data warehouse architecture and relational databases
Provide monitoring, maintenance and support for system operations as part of M&S as required in commercial projects
Embrace the challenge of dealing with terabytes to petabytes of data on a daily basis
Manage different experimentation, development, staging, production environments to provide overall system functionality, health, scalability, resiliency, and security
Responsible for implementing and maintaining complex big data projects with a focus on collecting, parsing, managing, and analysing large sets of data to turn information into insights using multiple platforms
Deliver detailed documentation and ensure quality throughout project lifecycle
Requirements:
Bachelor’s degree in Computer Science/Information Systems/Computer Engineering or equivalent
Minimum 5 years of experience developing data engineering pipelines or machine learning operations using big data platforms (e.g. Hadoop, Apache Spark, MPP DBs)
Good in-depth knowledge of Hadoop ecosystem (e.g. HDFS, Impala, Kafka, Spark, NiFi, Elasticsearch), associated tools and cloud-based technologies (e.g. EMR, Redshift, S3)
Extensive experience in programming (PySpark, Scala) for data engineering
Understanding of modern software engineering tools such as Git, Bitbucket, Jenkins, Maven
Highly proficient at reading, profiling, parsing, transforming, cleansing and integrating data from various sources (structured, semi-structured and unstructured)
Have strong knowledge in secure SDLC and DevSecOps to design, develop, test, and deploy applications for customer projects
Knowledge in Agile and CI/CD is desirable
Comfort and experience working in Linux environment
Aptitude for automation and software profiling
Experience in Cyber Security / Telco industry will be an advantage
Proven ability to handle multiple customer projects concurrently
Detail-oriented, solution-focused and problem solver",https://www.mycareersfuture.gov.sg/job/information-technology/senior-platform-data-engineer-ensign-infosecurity-acb9721a699b15e2f5006e148d67d4a0?source=MCF&event=Search
192,Information Technology - Senior Data Sciences & Analytics Engineer (Machine Learning Track),SINGAPORE AIRLINES LIMITED,"Job Description

SIA has multiple positions for machine learning/deep learning experts to drive our AI and data science initiatives.

Key Responsibilities:
Member of the in-house AI Center-of-Excellence team that works on challenging problems in machine learning (including areas on NLP, computer vision, recommender system, transfer learning and reinforcement learning), mathematical optimization, game theory, and experimental design.
Research and develop statistical machine learning and deep learning algorithms to meet complex product requirements. The scope includes defining hypotheses, executing necessary tests and experiments; evaluating, tuning and optimizing algorithms and methods; and having an eye towards cloud implementation ease, scalability, and robustness in a live customer-facing production environment.
Provide technical direction and guidance to a small and highly skilled team of junior and senior data scientists embedded in Kanban data squads. These squads deliver products/services in AI, data science and data analytics to stakeholders in a large number of business units. Serve as a go-to expert in your area of ML/DL expertise.
Work closely with business stakeholders to create impactful and intelligent features/products. Collaborate with other team members including data scientists, data engineers and data strategists. Strategic ownership of all critical end-to-end AI processes.
Administer/maintain performant cloud and on-premises GPU compute resources that train large ML models and provide inference microservices in production.
Requirements
PhD degree related to computer science, advanced machine learning or other AI disciplines is required. Consideration will be given to exceptional candidates without advanced degrees.
Advanced programming skills in Python. Strong technical skills in algorithm design/analysis, data structure and SQL. Intermediate-level mastery of functional/object-oriented software development using modern programming languages such as Scala, JavaScript, Java and C#.
At least 3 years of relevant industry experience in two or more of the following areas:
Expert-level hands-on skills in shallow and deep machine learning. Highly conversant with GPU-accelerated deep learning frameworks (such as TensorFlow and PyTorch).
Demonstrated ability in rapidly adapting, training and deploying state-of-the-art AI models in production based on the latest published research papers and code.
Knowledge and working experience in workflow, map-reduce or stream processing systems such as Spark and Kafka.
Strong skills in Bayesian statistics and inference. Comfortable with the application of Bayesian and causal networks for probabilistic reasoning.
Significant hands-on experience with AWS, GCP or similar public cloud environment.
Excellent mentoring, interpersonal and communication skills for working with both technical staff and non-technical business users.
Demonstrated intellectual firepower as a rapid problem-solver and tech lead.
Experience with Agile/Scrum/Kanban methodologies is a plus.",https://www.mycareersfuture.gov.sg/job/information-technology/information-technology-senior-data-sciences-analytics-engineer-singapore-airlines-3d7d479affce974f5ec741d819e14e6e?source=MCF&event=Search
193,Senior Systems Engineer (Data Security),EPAM SYSTEMS PTE. LTD.,"About EPAM
EPAM is a leading global provider of digital platform engineering and development services. EPAM has been expanding in Singapore since 2013 and delivering the best solutions to our customers.
As a recognized leader, EPAM Singapore achieved Great Place to Work Certification in 2021 and is committed to providing our team with inspiring careers. You will have the opportunity to work with fellow talented technologists and accelerate your career by participating in our numerous upskilling, training, and certification programs. That is why EPAM Singapore was awarded Silver in the SkillsFuture Employers Awards 2022 for our efforts in championing employees' skills development and building a lifelong learning culture at the workplace. You can also look forward to developing holistically with the multiracial festivals and various wellness and cultural activities organized by our passionate colleagues here.
Why EPAM?
By choosing EPAM, you're getting a job at one of the most loved workplaces according to Newsweek 2021 & 2022.
Employee ideas are the main driver of our business. We have a very supportive environment where your voice matters.
You will be challenged while working side-by-side with the best talent globally. We work with top-notch technologies, constantly seeking new industry trends and best practices.
We offer a transparent career path and an individual roadmap to engineer your future & accelerate your journey.
At EPAM, you can find vast opportunities for self-development: online courses and libraries, mentoring programs, partial grants of certification, and experience exchange with colleagues around the world. You will learn, contribute, and grow with us.
What You’ll Do
Contribute to the production of tactical, operational and/or strategic cyber threat intelligence assessments
Perform all-source cyber intelligence collection and analysis with your knowledge of intelligence operations fundamentals and how they support the firm’s cyber defence posture
Provide intelligence support to all teams across the cyber defence and strategy function
Become highly familiar with the evolving cyber threat landscape, adversarial tactics, techniques, and procedures (TTPs) as well as areas of concern/targeting that could impact our environment
Develop a nuanced understanding of cyber threats and the potential impact they may have on an organization
Use analytic frameworks for intelligence analysis, such as analysis of competing hypotheses (ACH), what-if analysis, alternative futures analysis, intelligence preparation of the operating environment (IPOE), and others
What Will Make You Shine
Bachelor’s Degree in Computer Science, Computer Engineering, or Computer Application
Minimum 4 years of experience in a threat intelligence role with good knowledge of common cyber threats, threat actors, and the TTPs used by cyber adversaries
Good knowledge of analytical tradecraft
Ability to demonstrate critical thinking and research acumen with a quick response to requests for information
Ability to manage competing priorities and work effectively under pressure
Ability to work seamlessly with analysts across a global team, helping to enhance and strengthen the team’s efforts
Preferred experience:
Advanced knowledge of the politics, sociocultural, or economic conditions of a region or country
Knowledge of qualitative or quantitative analysis frameworks and techniques
Possess an entry-level security certification, such as Security+ or Certified Ethical Hacker
How We Hire:
Here, we summarize the typical journey to finding a job within EPAM:
Apply and tell us about yourself
Go through some standard interviews:
General interview with a recruiter
Technical interview with our technology experts
Manager interview or Offer interview with a hiring manager
Get ready to join the team
Not sure if you meet all the requirements? No problem. Let’s talk anyway and find out more.
It takes 1 min of application to start the journey with us. Apply now!",https://www.mycareersfuture.gov.sg/job/information-technology/senior-systems-engineer-epam-systems-8c0ac1dc720d1d498091e7a81231824f?source=MCF&event=Search
194,Senior Data Network Engineer,SMART INFORMATION MANAGEMENT SYSTEMS PRIVATE LIMITED,"What you will be doing :

• To act as a LAN/WAN specialist and participate in network solution design discussion with external support partners and internal technical teams.
• To provide governance overview to ensure the solution in line with the Bank network
infrastructure and security standards and processes.
• Participate in large scale and complex network implementation initiatives to implement the network changes together with support partners.
• Design, Development and Support of systems used to automate network deployment and
operational management processes across both cloud and enterprise networks.
• Validate existing systems and recommend changes to optimize the design and performance of network automation and management systems.
• Use Automation and Management Systems to collect data, provide reports & dashboards and deploy changes to the production network.
• Provide escalation support for network related incidents from operations team.
• Document designs and operational procedures for managed systems and provide hand-off and training for operations teams.
• Automate the existing/new features using TCL / Python / Robot frame works is desirable.
• Conduct and participate in design reviews and test plan reviews.
• Provide coordination and act as a team interface between Network Operations and the Engineering, Deployment, and Security teams.

Must Have Skillsets :
• In-depth understanding of L2 switching and L3 routing protocol BGP OSPF, MultiCast.
Good-To-Have :
• Scripting experience (shell, PERL, Python, etc) is desirable.
Skills Required :
• 6 to 8 Years of Relevant Experience.
• Must be familiar with L2/L3 network device function, configuration and protocols (VLAN, TCP/IP, DHCP, IPv4, etc).
• Familiarity with common industry test equipment (Cisco Switches/Routers, IXIA traffic generator etc.) is required.
• Should have good hands-on experience in design test beds / topologies, handling various traffic equipment/tools also help in reproduce customer issues etc.
• Possess good knowledge on Test Automation Development using TCL / Python / Robot
Framework.
• Global Maintenance of device configuration as per certified standards and Engineering
recommendations.
• Degree educated or equivalent in Information Technology, Computer Science or related
disciplines.
• In-depth understanding of L2 switching and L3 routing protocols OSPF, EIGRP, RIP, BGP, Multicast, MPLS (LAN, TCP/IP, DHCP, L3 VPN, L2 VPN, VPLS, preferably from a provider point of view).
• Understanding of Wireless technologies and devices (CAPWAP, WLC, FlexConnect, etc.)
• Hands on working experience in the design of complex networks supporting data, voice and video, WLAN in a converge environment.
• Device platforms including Cisco, Arista, etc.
• Management tool – Netscout, HPNA, NNMi etc.
• Broad IT and network related knowledge on DHCP/DNS, TACACS/RADIUS would be an
advantage.
• CCIE R&S / CCNP R&S certification is preferable.
• Scripting experience (shell, PERL, Python, etc) is desirable.",https://www.mycareersfuture.gov.sg/job/information-technology/senior-data-network-engineer-smart-information-management-systems-052c41f8daf5477b2214cc95b5e59f07?source=MCF&event=Search
195,Senior Data Engineer / Scientist,AIDA TECHNOLOGIES PTE. LTD.,"AiDA Technologies (AIDA) is a specialist AI/Machine Learning company focused on providing products and solutions to the banking and insurance industry. The company was started by leaders from Singapore’s top Research Institutes and they have over 100 years of working experience among themselves.Our solutions assist our customers to increase Revenue, automate processes and manage Risks and Compliance using AI/­ML. The team has delivered over 35 predictive analytics solutions and have established a name for ourselves in the FSI sector as a leading provider of advanced AI/ML solutions for the industry.
We are looking for a Data Scientist as part of our Machine Learning Team. The ideal candidate will leverage strong collaboration skills and ability to extract valuable insights from highly complex medical & insurance data sets to ask the right questions and find the right answers. You will have great opportunity to work with Data Scientist to understand and learn about how we can leverage AI/ML in the health insurance & medical field to detect fraud & waste, improve automation efficiency & promote vitality.
Duties and Responsibilities
Analyze raw data: assessing quality, cleansing, structuring for downstream processing
Be heavily involved to bring analytical prototypes to production with the data engineering & dev-ops teams
Become a subject-matter expert in the health & insurance domain
Generate actionable insights for business improvements
Help to develop customizable reports / production-ready dashboards for clients
Requirements
· Bachelor's degree or equivalent experience in quantitative field (Statistics, Mathematics, Computer Science, Engineering, etc.)
· At least 3 years' of experience in quantitative analytics or data modeling
· Ability to write robust code in Python
· Good understanding of Database Systems and SQL
· Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms
· A strong self-starter and able to work with minimal supervision
· Ability to work in a dynamic, fast moving and growing environment
· Critical thinker with problem-solving skills
Good to have:
· Experience in troubleshooting, debugging, analysing logs and tracing of logs.
Familiarization with CI/CD systems such as GitLab
Experience with cloud infrastructure and services, and resources administration (i.e. AWS, Azure)
Experience in Plotly / Dash, Evidently or any other open-sourced dashboarding & performance monitoring tools deployable in production",https://www.mycareersfuture.gov.sg/job/information-technology/senior-data-engineer-scientist-aida-technologies-333fbaf8a1e1fed944ae3b621f579ea9?source=MCF&event=Search
196,Snr Data Engineer,ST ENGINEERING IHQ PTE. LTD.,"Participate in the design, development, and testing of an open architecture, open source based, and cloud native data analytics platform product • Explore and evaluate modern data management and MLOps components for continuous improvement of data analytics platform product • Contribute to the design and integration of data management & data governance capabilities for the product • Establish best practices and guidelines to be followed by engineers working on data pipelines • Assist in the setup and maintenance of big data, machine learning and Kubernetes clusters • Work with Data Scientists, Data Analysts, and other internal stakeholders to assist with datarelated technical issues and support their data pipeline infrastructure and data preparation needs Job Requirements: • Bachelor or Master’s degree computer science, software engineering, information systems or related field. • The candidate should have at least 5 years of technical experience in Information Technology with at least 2 years, preferably 2 years in Big Data, Data Warehousing or Business Intelligence technology with knowledge of analytics and AI technologies • Broad knowledge of various aspects of Big Data with good understanding and hands-on experience in Hadoop based technologies such as HDFS, Hive, Spark, Kafka etc. • Deep understanding of relational, NoSQL, NewSQL database technologies such as PostgreSQL, Oracle DB, CitusDB, SingleStore, Cassandra, MongoDB, Neo4J etc. • Good knowledge in programming languages such as Java, Python or Scala on Linux/Windows platforms. • Experience in Kubernetes and Kubeflow is a plus point • Experience in Big Data visualization and reporting software. • Experience in designing ETL/BI solutions. • Experience in DevOps and DataOps • Familiar with Linux/UNIX system administration • Experience in operational support in delivering Big Data solutions. • Effective oral and written communication with strong analytical, problem solving, multitasking and project management skills are essential on the job.",https://www.mycareersfuture.gov.sg/job/engineering/snr-data-engineer-st-engineering-ihq-c8a68b1e345b86b47cf25484000fbcd4?source=MCF&event=Search
197,Data Engineer - ref: CBL,ST ENGINEERING ADVANCED NETWORKS & SENSORS PTE. LTD.,"Job Overview
The Data Engineer supports the design, build, implementation and maintenance of Big Data processing systems to collect, parse and process large datasets and transform them into useful information and insights.
The Data Engineer focuses on sourcing of open source technologies, data cleaning and data transformation.

Job Responsibilities
Identify suitable data structures based on business needs to ensure availability and accessibility of data.
Determine technical system requirements based on data needs.
Keep abreast of latest technologies and products in open source technologies, database and data processing software.
Develop codes and scripts to process structured and unstructured data in real-time from a variety of data sources.
Consolidate and create data storage solutions for storage and retrieval of information.
Assist in the integration of data systems with existing infrastructure.
Requirements
Master / Degree in Computer Science, Computer Engineering, Information Systems, Information Engineering, or equivalent
At least 2 years of data engineering experience, fresh graduates are welcome to apply
Experience in open source technologies, data cleaning
Experience in programming languages such as Java, Python, C++
Experience in building and optimizing architectures and data sets
Experience working with stakeholders to identify business needs and analytics opportunities
Singaporean only
Location: Jurong East",https://www.mycareersfuture.gov.sg/job/engineering/data-engineer-ref-cbl-st-engineering-advanced-networks-sensors-6e261e01b6ca8e2f93dea2a2f73201c2?source=MCF&event=Search
198,Senior / Data Engineer,INCOME INSURANCE LIMITED,"The Senior Data Engineer will be responsible for the design, develop, and maintain:
Best Practices for Data Architecture and Design Patterns for Data Engineering Use-Cases.
Real-time data feeds from database sources like MySQL, Oracle, and MS SQLServer using the “Change Data Capture Engine” aka “CDC”.
Sub-Second Real-Time Data Pipelines using AWS Kinesis, Glue, Spark, Kinesis, Lambda .
Batch Pipeline Orchestration using on Apache Airflow and Jenkins.
Auto Scalable platform using Kubernetes on EKS.
Org Wide Master Data Management, Data Catalog Engine, and Data Quality Engine.
Code Repo Pipeline to automate Continuous Integration and Continuous Deployment (CI / CD).
Structure Tables with Partitioning and Clustering to increase Cost & Performance Benefits.
Guide Data Analysts and Data Scientists to write efficient queries and workloads.
Data Sharing with On-Demand Encryption/Decryption which can operate at Scale.
Running Containerized ETL workflow at scale.
Qualifications:
Bachelor Degree of Computer Science, IT or equivalent
at least 3 - 4 years of data engineering experience
Have strong fundamentals in Computer Science concepts like Cloud Computing Architecture, Distributed Computing, High-Velocity Data Processing, Lambda Architecture, etc…
Strong Data modeling and managing Distributed Computing Platforms for Data Processing.
Advance knowledge of SQL and writing resource-efficient queries.
Have at least 2+ years of professional programming experience in Python.
Have at least 2+ years of experience in running a data processing pipelines on either of these: Google BigQuery, Redshift, Hadoop, Presto, Spark, or KSQL.
Have at least 2+ years of experience in writing Sub-Second Real-Time pipelines using Google DataFlow(Apache Beam), PubSub, Kinesis Stream, Lambda, etc...
Have a good understanding of how Kubernetes clusters work and scale on-demand.
Have adequate experience using Containers for Data Engineering workload.
Implemented manual or automated tools for Data Quality, Catalog, and Lineage.
Uphold the sense of Frugality across Data Engineering teams.
Have Good Interpersonal and Presentation Skills to explain and promote Best Practices across the organization with both technical as well as non-technical stakeholders.",https://www.mycareersfuture.gov.sg/job/information-technology/senior-data-engineer-income-insurance-c40a7ae8679e2c46a0c50c38fa3c038a?source=MCF&event=Search
199,"DevOps Engineer, Data Platform",TIKTOK PTE. LTD.,"About TikTok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul, and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About the team
TikTok and affiliate are developing the next-generation high-performance analytical database, with a mission to enable efficient and real-time data-driven decision-making on PB-level data sets. The initial product was forked from Clickhouse, after which large re-architecture had been taken place. The product now not only improves the efficiency of Clickhouse but also fits into the elastic cloud-native infrastructure with better scalability and resource utilization. With years of polishment in the internal EB-level scenarios, we are now ready to serve our business partners via various cloud vendors.

What you will be doing:
- Responsible for the high availability of OLAP engine, ability to handle complex online issue trouble shooting and guarantee SLA.
- Build tools, automation, monitoring for distributed OLAP engine running as SaaS and on-premises deployment.
- Collaborate with engineering, infrastructure, security, and product teams to implement DevOps solutions to ensure scalability and reliability of the system.
- Contribute to the architecture, design, and improvement of our DevOps processes.

Qualifications
- Bachelor's degree in Computer Science or a related technical background involving software/system engineering, or equivalent working experience.
- At least 1 year experience of managing and trouble shooting large-scale distributed systems - At least 1 year experience of containerization technologies, including Docker and Kubernetes, and experience of managing stateful services on K8S would be a plus
- Expertise in DevOps technologies like Terraform, Skaffold, Bash Scripting, Ansible etc.
- Expertise in either Go, Python or Java and have experience of building production services with either of them.
- Familiar with building solutions with AWS, Google, Azures, AliCloud or other cloud services. -
Familiar with Unix/Linux operating systems.

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.",https://www.mycareersfuture.gov.sg/job/engineering/devops-engineer-data-platform-tiktok-dbf25ee5130370e24afd5a2a1e2bc7e2?source=MCF&event=Search
200,DevOps Engineer - Data Platform,TIKTOK PTE. LTD.,"About TikTok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul, and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About the team
TikTok and affiliate are developing the next-generation high-performance analytical database, with a mission to enable efficient and real-time data-driven decision-making on PB-level data sets. The initial product was forked from Clickhouse, after which large re-architecture had been taken place. The product now not only improves the efficiency of Clickhouse but also fits into the elastic cloud-native infrastructure with better scalability and resource utilization. With years of polishment in the internal EB-level scenarios, we are now ready to serve our business partners via various cloud vendors.

What you will be doing:
- Responsible for the high availability of OLAP engine, ability to handle complex online issue trouble shooting and guarantee SLA.
- Build tools, automation, monitoring for distributed OLAP engine running as SaaS and on-premises deployment.
- Collaborate with engineering, infrastructure, security, and product teams to implement DevOps solutions to ensure scalability and reliability of the system.
- Contribute to the architecture, design, and improvement of our DevOps processes.

Qualifications
- Bachelor's degree in Computer Science or a related technical background involving software/system engineering, or equivalent working experience.
- At least 3 years experience of managing and trouble shooting large-scale distributed systems
- At least 2 years experience of containerization technologies, including Docker and Kubernetes, and experience of managing stateful services on K8S would be a plus
- Expertise in DevOps technologies like Terraform, Skaffold, Bash Scripting, Ansible etc.
- Expertise in either Go, Python or Java and have experience of building production services with either of them.
- Familiar with building solutions with AWS, Google, Azures, AliCloud or other cloud services.
- Familiar with Unix/Linux operating systems.

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.",https://www.mycareersfuture.gov.sg/job/engineering/devops-engineer-data-platform-tiktok-c576e09c48075f585f1f1ecbf5f5e5b1?source=MCF&event=Search
201,AWS ETL Cloud Data Engineer (IFRS 17),INCOME INSURANCE LIMITED,"We are looking to hire a AWS ETL Data Engineer. This is an exciting opportunity to use and further expand your AWS cloud skill set, and join Income Data Team to build Hybrid Datalake as part of key IFRS project
Responsibilities:
Design, build and operationalize large scale enterprise data solutions and applications using one or more of AWS data and analytics services in combination with 3rd parties – Spark/Python on Glue, DMS, S3, Athena, RDS-PostgreSQL, Airflow, Lambda, Code Commit, Code Pipeline, Code build, etc.
Design and build production ETL data pipelines from ingestion to consumption within a big data architecture, using DMS, DataSync & Glue.
Understand the existing applications(including on-premise Cloudera Datalake) and infrastructure architecture.
Analyze, re-architect and re-platform on-premise data warehouses to data platforms on AWS cloud using AWS or 3rd party services.
Design and implement data engineering, ingestion and curation functions on AWS cloud using AWS native or custom programming.
Perform detail assessments of current state data platforms and create an appropriate transition path to AWS cloud.
Collaborate with development, infrastructure and data center teams to define Continuous Integration and Continuous Delivery processes in accordance with industry standards.
Work on hybrid Datalake.
Work closely with multiple stakeholders to ensure high standards are maintained.
Mandatory Skill-set
Bachelors Degree in Computer Science, Information Technology or other relevant fields
5+ years of work experience with ETL, Data Modelling, Data Architecture to build Datalake. Proficient in ETL optimization, designing, coding, and tuning big data processes using Pyspark.
3+ yrs of extensive experience in working on AWS platform using core services like S3, Athena, Glue (ETL), DataSync, Airflow, RDS (PostGres), CodeCommit, CodePipeline, CodeBuild, SQL & Spark/Python
Good to have Skill-set
Fundamental of Insurance domain
Functional knowledge on IFRS17",https://www.mycareersfuture.gov.sg/job/information-technology/aws-etl-cloud-data-engineer-income-insurance-e21c123fc07b421dd5c040127391b18f?source=MCF&event=Search
202,Lead AWS ETL Cloud Data Engineer (IFRS 17),INCOME INSURANCE LIMITED,"We are looking to hire a Lead AWS ETL Data Engineer. This is an exciting opportunity to use and further expand your AWS cloud skill set, and join Income Data Team to build Hybrid Datalake as part of key IFRS project.
Responsibilities:
Design, build and operationalize large scale enterprise data solutions and applications using one or more of AWS data and analytics services in combination with 3rd parties – Spark/Python on Glue, DMS, S3, Athena, RDS-PostgreSQL, Airflow, Lambda, Code Commit, Code Pipeline, Code build, etc.
Design and build production ETL data pipelines from ingestion to consumption within a big data architecture, using DMS, DataSync & Glue.
Understand the existing applications(including on-premise Cloudera Datalake) and infrastructure architecture.
Analyze, re-architect and re-platform on-premise data warehouses to data platforms on AWS cloud using AWS or 3rd party services.
Design and implement data engineering, ingestion and curation functions on AWS cloud using AWS native or custom programming.
Perform detail assessments of current state data platforms and create an appropriate transition path to AWS cloud.
Collaborate with development, infrastructure and data center teams to define Continuous Integration and Continuous Delivery processes in accordance with industry standards.
Work on hybrid Datalake.
Work closely with multiple stakeholders to ensure high standards are maintained.
Mandatory Skill-set
Bachelors Degree in Computer Science, Information Technology or other relevant fields
8+ years of work experience with ETL, Data Modelling, Data Architecture to build Datalake. Proficient in ETL optimization, designing, coding, and tuning big data processes using Pyspark.
5+ yrs of extensive experience in working on AWS platform using core services like S3, Athena, Glue (ETL), DataSync, Airflow, RDS (PostGres), CodeCommit, CodePipeline, CodeBuild, SQL & Spark/Python
Good to have Skill-set
Fundamental of Insurance domain
Functional knowledge on IFRS17",https://www.mycareersfuture.gov.sg/job/information-technology/lead-aws-etl-cloud-data-engineer-income-insurance-1942eb074d754c4a2c04f33723d7f6ec?source=MCF&event=Search
203,"Engineer, Data Center Infrastructure Management",NTT GLOBAL DATA CENTERS HOLDING ASIA PTE. LTD.,"Designs, plans, installs, and/or maintains mechanical, electrical, plumbing, and other infrastructure systems in mission-critical, high-risk, or high-reliability environments such as data centers, medical facilities, laboratories or utilities infrastructure. Has proficient understanding of sensitive facility components that may be impacted by failures or malfunctions of infrastructure systems. Analyzes current operating conditions and recommends new preventative and proactive methods for maintaining and monitoring facilities systems. Evaluates facility standards and practices to improve maintenance procedures and ensure optimal operational efficiency. Complies with organizational and governmental safety standards. Coordinates response to emergency situations and ensures that corrective measures are rapid and thorough. Participates in the planning and installation of new facility systems. May work with multiple components including HVAC systems, air or liquid cooling systems, CRAC/CRAH units, power distribution units, fire systems, life safety systems, etc.

Policy & Procedures
Establish, maintain and review operating and emergency procedures regularly
Standardize front line operation, maximize operation efficiency across all NTT site
Provide a continuous improvement plan to increase the efficiency of the operation process

Data Center Management
Perform capacity management on critical components to ensure system efficiency and to improve PUE
Perform change management to ensure changes will not disrupt daily operation
Perform risk management to ensure all risks are considered and mitigated during operation
Provide continuous improvement plan to enhance system performance and efficiency
Annual Shutdown Maintenance Management (Procedure review, communication, status tracking)
Critical systems asset and life cycle management

Operation Management
Manage and ensure all service delivery, corrective and preventive maintenance are performed flawlessly and in a timely manner
To provide prompt notification to clients utilizing a centralized BMS monitoring system
Perform vendor management by using DCFMS to ensure vendor performance is according to contract requirements and industry best practice

Incident Management
Restore operation to normal working state promptly taking into account all operational risks
Report and perform escalation according to incident management/group policy
Perform root cause analysis on failures and implement preventive measures

Client KPI / SLA Management
Ensure Clients' SLA are tracked correctly and achievable

Technical support
Building Modification & Customization Work Support
Response to Customer RFQ / Inquiries
Response to Internal teams Inquiries

Audit/Certification
Manage and support all Audit/Certification activities

Environmental Health
Fire Safety Management
Workplace safety and health

Administrations
Service Quality Assurance
License / Certificate renewal, etc. e.g. Lifts Permit to Operate, Fire Certificate, etc
Proper documentation to ensure smooth handling / taking over of tasks and duties

Others
Major A&A construction consultation and support
IT Security Management for critical systems

Contract Management
Technical Support / Outsourced contract
Electrical Power Supply Contract
Fuel Management Contract
Consignment Contract

Additional Requirements:
Diploma, degree, or relevant qualification in Electrical, Mechanical (or demonstrated equivalent work experience)
Seasoned and experienced professional
Has full understanding of specialisation area
Resolves wide range of issues in creative ways
Fully qualified, career level, career journey-orientated
Uses good judgement in selecting tools and methods to solve problems
Networks with senior internal and external people in own area of expertise
Receives little instruction on day-to-day work, receives general instructions on new assignments",https://www.mycareersfuture.gov.sg/job/engineering/engineer-data-center-infrastructure-management-ntt-global-data-centers-holding-asia-89b62ebd598ea1892eb48d11f885250e?source=MCF&event=Search
204,Data Infrastructure Engineer,INCOME INSURANCE LIMITED,"Income is looking for a Data Infrastructure Engineer to join our Data Engineering team in Singapore. Our team owns and runs the Enterprise Datalake used by thousands of users and hosted across AWS, GCP and On-Premises servers.
As a Data Infrastructure Engineer, you will design, build, maintain and improve our data infrastructure on Cloud, which enables us to make Income data driven organisation. In this role, you would also get the opportunity to work with world-class big data and cloud services, such as: AWS/GCP, Glue, Spark, DBT, Airflow, Tableau and PowerBI.
Responsibilities
Work with data engineering and machine learning teams to improve our data infrastructure for increased reliability, maintainability, and scalability.
Architect and design solutions to improve our data delivery capabilities, data quality monitoring, and data pipeline lifecycle.
Architect and administer our cloud applications such as AWS Glue, Sagemaker, LakeFormation, Iceberg Lakehouse, etc.
Managing Regression Testing Suite, Continuous Integration and Continuous deployment Pipelines.
Qualifications
Bachelors Degree in Computer Science, Information Technology or other relevant fields
5 years of designing and building Large Scale Infrastructure and ETL deployment and management pipelines using Terraform, Jenkins, AWS CodePipeline and AWS CodeBuild.
Broad experience in SQL and Python.
Hands-on experience of writing, building and deploying Containerised applications using ECS or EKS or GKE.
Experience in cloud application architecture & administration in AWS with the stacks such as: EC2 instances, Glue, Terraform (build & manage script), Jenkins, CodePipeline, CodeBuild, RDS (PostGres) instances, S3, Airflow
Experience in Deployment and implementation of AWS Glue with basic knowledge of SQL and Python - able to read and understand.
Hands-on experience designing, building, and operationalizing large-scale enterprise data solutions and applications.
Background in in custom ETL design, implementation, and maintenance.
Hands-on experience with strong exposure to AWS CLI and BOTO3 Python libraries.",https://www.mycareersfuture.gov.sg/job/information-technology/data-infrastructure-engineer-income-insurance-26ef4448aea823e01658e111dee092be?source=MCF&event=Search
205,Operations Engineer (Data Center),BDX (SINGAPORE) PTE. LTD.,"Responsibilities:
This role will be responsible for a variety of data center functions, including:
Assist with incident, change, and problem management
Manage Data Centre inventories – equipment, testers, consumables, etc.
Fault troubleshooting and rectification
Support Planned Activities such as network / facilities upgrade, new installation
Maintain documentation / records, procedures and communication
Manage & Supervise subcontractors and third-party vendors
Project Management for special network & facilities implementation
Compliance with standards of Data Center – PCI-DSS & ISO27001
Implement physical security access control
Handle customers’ requirement such as delivery acceptance, remote hand supports, etc.
Handle customers’ order such as provisioning of cages, racks and cross connects
Monitor and supervise data centre facilities maintenance
Review and improve operational processes
Able to perform day and night shift duty
Work directly with the Global Service Operations Center, Global Service Desk, Security, and Facilities Management teams to maintain data center hosting integrity, during provisioning and troubles resolution
Work closely with various departments such as DC Engineering, Sales and Finance
Work closely with colocation clients to ensure their remote hand requests are carried out & met
Work closely with security and facility team to deliver good customer experience and to ensure our SLAs are met
Requirement:
Degree or Diploma in Engineering, Data Centers, Telecommunication, IT discipline
2 - 4 years’ experience in Data Centers or similar environment experience.
Knowledgeable of building facilities Electrical & Mechanical (HVAC, CCTV, security access, BMS Fire protection system).
Knowledge of PCI-DSS & ISO 27001
Relevant network certifications (e.g. CCNA, CCNP)
Establish and maintain effective working relationships with peer groups and key internal stakeholders and maintain agreed external stakeholders relationships relevant to the achievement of business objectives
Knowledge of test equipment such as circuit tester, Optical Power Meter etc.
Knowledge in using Data Center Infrastructure Management Systems & Building Management System
Project & Inventories Management
Strong process, procedural, analytical and problem-solving skills
Good customer facing skills
Able to works shifts and under minimum supervision
Able to work independently and under stress
Excellent interpersonal, influencing and negotiation skills.
Excellent written and verbal skills required",https://www.mycareersfuture.gov.sg/job/engineering/operations-engineer-bdx-bfb33aca11977c55bd64a98df84f446c?source=MCF&event=Search
206,Data Solution Electrical Engineer / Architect,EATON ELECTRIC (SINGAPORE) PTE. LTD.,"If you desire to be part of something special, to be part of a winning team, to be part of a fun team – winning is fun. We are looking forward to a Data Center Electrical Engineer in Eaton’s Electrical business, based in Singapore. In Eaton, making our work exciting, engaging, meaningful; ensuring safety, health, wellness; and being a model of inclusion & diversity are already embedded in who we are - it’s in our values, part of our vision, and our clearly defined aspirational goals.
The solution architect acts as a bridge between the client operations, Direct Sales and Channel Teams and third-party technology providers. Internally, in bringing together an end-to-end hardware and software solution that translates the client business problems to technical design requirements, this person works closely with Eaton sales teams and subject matter experts, the focus of this role will be on “solutions” design, development and assisting with solution selling for the region. These solutions are an integrated package of Eaton hardware (PQ & PD) software content, Eaton digital platform, third party software technology, Eaton equipment and associated implementation/customization.
This exciting role offers opportunity to:
· Lead Eaton technical engagement with clients in APAC, consultative and solution opportunities. Be able to articulate the solution to Consultants, Facilities and Operations teams as well as Procurement teams for clients.
· Provide pre-sales technical support for clients: work with internal Eaton teams and third-party technology providers to identify client business problems, facilitate requirements design thinking and evangelizing sessions, architecture presentations, product feature descriptions and value propositions, and solution demos and presentations.
· Work with the sales teams, Bid Management Team and Key Account Managers within the region and globally to develop value propositions for key stakeholders: executives, operators, finance leaders and IT leaders, and be able to put together compelling proposals for Eaton solutions
· Assist Bid Management Team respond to RFP documents, put together solution requirements and design, system customization and configuration, align service offerings and ultimately be the client’s point of contact for maintaining the solution roadmap.
· Collaborate and coordinate with Eaton factories and regional technical stakeholders to ensure alignment in solution and technical offering to global clients
· Develop templates and best practices for solution deployment into data center client accounts, working with the regional professional services/delivery team.
· Help with existing and new account planning and strategy, to bring in Eaton hardware and software content and grow hardware and software revenue in the region. Provides technical and sales consulting, support for major account opportunities.
· Develop a broad network of industry technology contacts, stay current with latest technologies in the data center space, including detailed understanding of competitive solutions.
· Position Eaton value through our hardware and software content: position appropriate Eaton products, services, third party technologies as part of a solution that fits the client needs
· To be committed & responsible for Quality Management System:
· Implement the process approach and risk-based thinking
· Provide the necessary support to fully implement and sustain the QMS
· Communicating to the organization the importance of conforming to QMS requirements
· Ensuring the QMS meets its goals
· Engage, direct, and support individuals contributing to the QMS
· Create a culture of continuous improvement
Basic Qualifications & Experience
· 5+ years of deep domain expertise with the data center industry, designing and deploying hardware for data centers.
· 5+ years of technical sales experience with Medium Voltage and Low Voltage Switchgear, Exposure to UPS and data center software suites a plus.
Preferred Qualifications & Experience
· 5+ years of consultative engagement with executive and technical teams in developing and translating business use cases to solution requirements and architecture documentation.
· Bachelor’s degree in computer science/electrical or mechanical engineering
· CAD and Visio
· TCP/IP, Linux O/S MS SQL Server, Relational Database
· Scada systems, industrial automations or BMS systems
Yes! Because you are the one we are looking for, we hope to hear from you now!",https://www.mycareersfuture.gov.sg/job/engineering/data-solution-electrical-engineer-architect-eaton-electric-0ec40f0d227e65c4521f6af9929b4658?source=MCF&event=Search
207,Systems Engineer (Data and BI),INFOCEPTS PTE. LTD.,"InfoCepts is a global leader of end-to-end data & analytics solutions with nearly 20 years of experience, also named as Gartner’s 2020, 2021 and 2022 customers’ choice for Data & Analytics providers. We continue to grow rapidly year over year, now employing more than 1,200 people in offices across the globe. As we have grown, we have stayed true to our mission—to always help our customers stay modern that help them make smart, data-driven decisions. Since 2004, we have deployed hundreds of high performance analytics applications over web and mobile platforms, built several advanced analytics models, processed petabytes of data using Big Data technologies and delivered several high impact business solutions. Driven by our vision of delivering great customer experiences, we are looking for professionals who are passionate about making the world a better place by leveraging the power of data.

We are hiring aspiring professionals who are keen in data related systems and infrastructure to join us in our cause to help customers Stay Modern, ahead of the technology curve!

Roles and Responsibilities:
Foster strong understanding of assigned use cases and its respective business/operational context
Handle a plethora of technical work across the end-to-end systems engineering spectrum including but not limiting to installation, configuration, development, testing, debugging, deployment, maintenance
Provide technical and engineering support as required including but not limiting to resolving technical issues, patching, applying hotfixes, creating/configuring user access management policies
Collaborate with the Project team to identify opportunities for performance optimization
Serve as the main point-of-contact for all technical matters for assigned use cases
Develop technical knowledge in systems and infrastructure in the data and/or AI domain (e.g. Qlik), as well as supporting services (e.g. file transfer technologies)
Skills Required:
At least 2 years of experience in Systems Engineering / Server Administration using any BI related software is required
Experience with Linux-based operating systems
Familiarity with quality assurance including end-to-end system testing
Experience with Qlik technologies is highly advantageous
Familiarity with any additional BI software (e.g. Tableau, PowerBI) on the server-side is a plus
Adept at queries with good communication and stakeholder management skills",https://www.mycareersfuture.gov.sg/job/information-technology/systems-engineer-infocepts-b7cbda6be7dc16e533652657c9156407?source=MCF&event=Search
208,Jr Data Engineering(Snowflake),ARYAN SOLUTIONS PTE. LTD.,"Key Roles & Responsibilities:
Purpose
● Place client value and human experience at the center of everything we do
● Develop and deliver value to clients by building large scale enterprise data pipelines to capture, transform and store date to support reporting, automated systems and AI/ML
Team
● Be a part of a world-class team of experts in Data engineering
● Be a part of a culture of excellence and with confidence, charisma, context, and humility, working effectively at all levels
Delivery
● Delivery of data pipelines to drive material impact and drive disruptive transformation across our clients in public and private sectors
● Support thought leadership developnent as a team for data engineering and scaling deployments
Partnership
● Work with client’s ecosystem of partners to deliver client value
● Adopt a cloud-first strategy to enhance agility and elasticity by partnering with vendors to support specific public sector needs

Requirements & Qualifications:
● 5+ years of experience in software development
● Minimum 2 years of experience with Snowflake
● Bachelor’s degree/Diploma in Computer Science, Computer Studies, Information Technology, or related disciplines
● Minimum 3 years of designing, building and operationalizing data solutions and applications (with batch or streaming data)
● Excellent understanding on SQL data storage structures and storage/query optimizations
● Mastered SQL querying to build any data presentations using joins, reference tables, groupings, statistics etc.
● Proficient in at least one core language: Python, Scala, Java
● Exposure to concepts like Serverless computing, CI/CD, Containerization, Infrastructure as Code, code version control and automated testing
● Exposure to one of more of cloud services like AWS, Azure or GCP
● Awareness of a broad range of tools to assist in the data engineering: Databricks, Snowflake, dbt, Alteryx, Datameer, dataform, Informatica, Talend, Docker, Kubernetes, Kafka, Kinesis, Spark, Flink, MongoDB, Cassandra, HBase, Redis, PostgreSQL, MySQL, DB2, Neo4j, S3, KSQL, Terraform, Ansible & Datadog
● Strong ability to communicate with a broad range of clients, colleagues, and partners across a variety of contexts and formats.
● Strong ability to develop and maintain relationships amongst clients, colleagues, and partners
● Show active tracks of improving knowledge and skills (e.g. courses, podcasts, books, experimentation, open source volunteering, tech meetups etc.)
● Ability to work independently with minimal guidance
● Ability to work as part of a large team
● Ability to work within an unstructured environment with ability to multitask well",https://www.mycareersfuture.gov.sg/job/information-technology/jr-data-engineering-aryan-solutions-243fe530c4aa969015ebd0122645776d?source=MCF&event=Search
209,Jr Data Engineering(Integration Engineer),ARYAN SOLUTIONS PTE. LTD.,"Key Roles & Responsibilities:
Purpose
● Place client value and human experience at the center of everything we do
● Develop and deliver value to clients by building large scale enterprise data pipelines to capture, transform and store date to support reporting, automated systems and AI/ML
Team
● Be a part of a world-class team of experts in Data engineering
● Be a part of a culture of excellence and with confidence, charisma, context, and humility, working effectively at all levels
Delivery
● Delivery of data pipelines to drive material impact and drive disruptive transformation across our clients in public and private sectors
● Support thought leadership development as a team for data engineering and scaling deployments
Partnership
● Work with cient’s ecosystem of partners to deliver client value
● Adopt a cloud-first strategy to enhance agility and elasticity by partnering with vendors to support specific public sector needs

Requirements & Qualifications:
● Bachelor’s Degree/Masters Degree in computer science or any engineering discipline
● Minimum 3 years of designing, building and operationalizing data solutions and applications (with batch or streaming data)
● Experience with ServiceNow strongly preferred
● Excellent understanding on SQL data storage structures and storage/query optimizations
● Mastered SQL querying to build any data presentations using joins, reference tables, groupings, statistics etc.
● Proficient in at least one core language: Python, Scala, Java
● Exposure to concepts like Serverless computing, CI/CD, Containerization, Infrastructure as Code, code version control and automated testing
● Exposure to one of more of cloud services like AWS, Azure or GCP
● Awareness of a broad range of tools to assist in the data engineering: Databricks, Snowflake, dbt, Alteryx, Datameer, dataform, Informatica, Talend, Docker, Kubernetes, Kafka, Kinesis, Spark, Flink, MongoDB, Cassandra, HBase, Redis, PostgreSQL, MySQL, DB2, Neo4j, S3, KSQL, Terraform, Ansible & Datadog
● Strong ability to communicate with a broad range of clients, colleagues, and partners across a variety of contexts and formats.
● Strong ability to develop and maintain relationships amongst clients, colleagues, and partners
● Show active tracks of improving knowledge and skills (e.g. courses, podcasts, books, experimentation, open source volunteering, tech meetups etc.)
● Ability to work independently with minimal guidance
● Ability to work as part of a large team
Ability to work within an unstructured environment with ability to multitask well",https://www.mycareersfuture.gov.sg/job/information-technology/jr-data-engineering-aryan-solutions-ab1b12c55f5c0e03c7c9a945f35b920d?source=MCF&event=Search
210,"Senior VP, SRE Lead (SRE for Data Analytics, Chaos Engineering), Banking",CHARTERHOUSE PTE. LTD.,"Min. 12 years of SRE experience with good understanding of the maturity level of the different stage of the SRE setup (looking at Data & Analytics)
Focusing on improving the reliability of critical applications, works in tandem with Kitchen Sink, Infrastructure or Tools SRE teams for applications with high reliability needs OR Hands-on in changing code & configuration of services, providing recommendations to team or to scale another implementation (driving adoption from Infrastructure/tools teams)
Practical experience in maintenance of large-scale distributed systems architectures, hybrid cloud/on-premise environments, and event-driven or event stream systems. (i.e. distributed storage, scheduling, big data computing system)

As the Senior VP, SRE Lead (SRE for Data Analytics, Chaos Engineering), you will be looking at maturity level of the different stage of the SRE setup and be responsible for leading and building a team of software/system engineers (including team recruitment, new talent training, system operation/maintenance/ coordination and team culture building), developing a long-term technical plan, have a clear implementation path and milestones, continuously ensure the competitiveness of the team and technology, designing and implementing software platforms as well as monitoring frameworks for efficient, automated, and intelligent event driven / service-oriented architecture governance, and monitoring, troubleshooting & analyse application & underlying infrastructure performance issues as part of the performance engineering exercises and derive gold-configuration parameters.

You are expected to set up necessary processes for efficient execution and advocate good engineering practices, including formulating process specifications and plans with regards to access, configuration, disaster recovery as well as fault handling for all critical paths of the operating platform, promoting the evolution of business architecture design through reduction of customer anxiety.

You will work with the bank infrastructure and software development teams to ensure services reliability (i.e.: system development team to ensure system reliability throughout the entire life cycle from system design to launch (Cradle to Grave), solution architects, application development team to ensure adherence to best practices in design and coding w.r.t SRE & CRE principles, and other business teams, improve cross-team coordination, ensure continuous improvement and optimization of business flows) and uptime appropriate to the needs of users and fast iterations of improvement, and assisting development team to tune the applications/ configurations for critical systems to comply with the NFR before going live in production and ensure the performance recommendations are part of the change request process.

You will also identify opportunities for continuous improvement in the full lifecycle of a large distributed system. (i.e. Design, development, configuration, testing, deployment, monitoring, and operations) Continuously evolve automated operation, maintenance facilities and platforms (automation of various manual tasks w.r.t performance monitoring, alerting, analysis, reporting, capacity planning etc to improve application observability, resiliency & operational efficiency), and ensuring appropriate governance w.r.t framework usage across multiple delivery streams and enhance the framework capability to meet the upcoming requirements.
You will drive thorough performance analysis of microservices code by using single-user code profiling techniques, participate & contribute to resiliency validation exercises and create proper reporting to the stakeholders and define critical performance KPIs, set alert rules and roll-out monitoring dashboards for Production with timely reporting to the stakeholders.


To qualify, individuals must possess:

- Min.12 years of SRE experience (3-5 years hands-on experience in Python, JAVA/J2EE, Spring Boot, JavaScript, SQL/PostgreSQL in terms of writing maintenable, testable code)
- 2 years hands-on experience in any of the technology such as Red Hat OpenShift/Kubernetes, Docker, Kafka, ELK, Redis and DevOps Tools such as Jenkins, Bitbucket, JIRA)
- Practical experience in maintenance of large-scale distributed systems architectures, hybrid cloud/on-premise environments, and event-driven or event stream systems. (i.e. distributed storage, scheduling, big data computing system)

Must have:
- Good understanding of the maturity level of the different stage of the SRE setup
- Hands-on experience in Chaos Engineering

- Experienced with project and team management.
- Systematic in operation and maintenance thinking with the ability to find the balance between when to be tactical vs. strategic. Familiar with Linux systems and networking.
- Familiarity with Helm / Terraform
- Positive attitude towards continuous learning with a passion for software development and pays great attention to optimizing existing systems, building infrastructure as well as reducing/eliminating toil through automation.

Good to have:
- Hands-on experience in application monitoring with Grafana, Kibana, Prometheus, AppDynamics or Dynatrace
- R&D experience

Please reach out to Vyon Ng at 69500385 or VyonN@charterhouse.com.sg for a confidential discussion.

Only successful candidates will be notified.

EA License no.: 16S8066 I Reg no.: R1110857",https://www.mycareersfuture.gov.sg/job/banking-finance/senior-vp-sre-lead-banking-charterhouse-96bd9ea331d61a5008b08c620d815154?source=MCF&event=Search
211,Lead Data Engineer (Cloud),INCOME INSURANCE LIMITED,"Description:
Best Practices for Data Architecture and Design Patterns for Data Engineering Use-Cases.
Real-time data feeds from database sources like MySQL, Oracle, and MS SQLServer using the “Change Data Capture Engine” aka “CDC”.
Sub-Second Real-Time Data Pipelines using AWS Kinesis, Glue, Spark, Kinesis, Lambda.
Batch Pipeline Orchestration using on Apache Airflow and Jenkins.
Auto Scalable platform using Kubernetes on EKS.
Org Wide Master Data Management, Data Catalog Engine, and Data Quality Engine.
Code Repo Pipeline to automate Continuous Integration and Continuous Deployment (CI / CD).
Structure Tables with Partitioning and Clustering to increase Cost & Performance Benefits.
Guide Data Analysts and Data Scientists to write efficient queries and workloads.
Data Sharing with On-Demand Encryption/Decryption which can operate at Scale.
Running Containerized ETL workflow at scale.
Qualifications:
Bachelor Degree of Computer Science, IT or equivalent.
At least 6-7 years of data engineering experience with team leading/guiding/mentoring experience.
Have strong fundamentals in Computer Science concepts like Cloud Computing Architecture, Distributed Computing, High-Velocity Data Processing, Lambda Architecture, etc.
Strong Data modeling and managing Distributed Computing Platforms for Data Processing.
Advance knowledge of SQL and writing resource-efficient queries.
Have at least 2+ years of professional programming experience in Python.
Have at least 2+ years of experience in running a data processing pipelines on either of these: Google BigQuery, Redshift, Hadoop, Presto, Spark, or KSQL.
Have at least 2+ years of experience in writing Sub-Second Real-Time pipelines using Google DataFlow(Apache Beam), PubSub, Kinesis Stream, Lamda, etc.
Have a good understanding of how Kubernetes clusters work and scale on-demand.
Have adequate experience using Containers for Data Engineering workload.
Implemented manual or automated tools for Data Quality, Catalog, and Lineage.
Uphold the sense of Frugality across Data Engineering teams.
Have Good Interpersonal and Presentation Skills to explain and promote Best Practices across the organization with both technical as well as non-technical stakeholders.",https://www.mycareersfuture.gov.sg/job/information-technology/lead-data-engineer-income-insurance-7829ecd6e45aae3ff4f4cf6891928973?source=MCF&event=Search
212,"Associate / AVP, Data Engineer, Investment Insights Group",GIC PRIVATE LIMITED,"Investment Insights Group (IIG)
The Investment Insights Group (IIG) uses advanced quantitative techniques and cutting-edge technological tools to generate insights that drive outstanding investment outcomes for GIC.
We are a multi-disciplinary team of Quantitative Researchers and Software Developers that work closely with each of our investment departments – from Public Markets like Equities and Fixed Income, to Private Markets like Private Equity and Real Estate – to drive superior returns.
Our team of software developers, whom we call “Alpha Technologists”, develop platforms for investment teams and quantitative researchers, allowing GIC to harness our differentiated quantitative methods at scale. They also drive synergy across departments to enhance cross-asset investment capabilities at GIC.
We are hiring a Data Engineer/Analyst to join a multi-disciplinary application team supporting the research, development, and integration of sustainable analytics into our investment processes, strategies and platforms. You will be responsible for the analysis, design, development, testing and maintenance of our data architecture and pipelines to ensure a stable, robust and resilient data environment, and also contribute to generating data-driven insights.
We’re looking for a proven problem-solver and team player who enjoys learning about investment management and research with a passion in applying technology to investments and portfolio analytics, and driving continuous improvement.
Responsibilities
Leverage large-scale enterprise data platforms to meet the analytical and operational needs of sustainability research and investment capabilities
Drive consistent methodology and framework in developing cross-asset and top-down/bottom-up integration of sustainability data and analytics across various investment management platforms
Review and assess data frameworks and technology platforms with the goal of suggesting and implementing improvements
Understand the quality of data used to suggest process improvements and data quality routines
Conduct detailed analysis on business requirements and develop solutions to enhance or add new analytical capabilities
Take an agile and pragmatic approach, ensure quick time-to-market and code reusability
Collaborate with stakeholders from various departments
Requirements
1 to 4 years of relevant experience in data engineering or backend development, and hands on experience in solution designing, software testing and production support
Experience or knowledge in the following technologies is advantageous:Data Virtualization – Denodo
Database & Big Data Platforms – Oracle, MS SQL, Snowflake, JDBC/ODBC
Programming and Scripting – Python, Java, REST API
AWS services – S3, RDS, Athena, Airflow
React.js and other JavaScript framework/libraries
Experience with Agile software development methodologies and practices such as Scrum, Kanban and Test-Driven Development
Good knowledge in financial and risk modelling
Familiarity with ESG data and analytics is desirable
Keen learner, independent problem solver with strong communication and interpersonal skills

To be considered for the role, please submit a formal application through the GIC Careers site at
https://careers.gic.com.sg/job-invite/14957/",https://www.mycareersfuture.gov.sg/job/banking-finance/associate-avp-data-engineer-investment-insights-group-gic-3c0f0d3bb836cc9fe21c2e90649b5b42?source=MCF&event=Search
213,Data Center Engineer,EZSVS SINGAPORE (PTE.) LTD.,"Responsibilities
Responsible for the management &technical support of servers/routers/switches/network in Data Center environment
Configuration changes of the network and debugs of Data Center network, fault troubleshooting, system installation and configuration, equipment operation in Data Center
Management of DC Capacity Specification and proactively detect & resolve the potential issues related to DC Network or Servers
Perform changes to system services and configuration
Requirements
Higher Diploma or above in Computer Science/ Telecommunication/ Engineering or a related subject
Minimum 1-year relevant experience
Basic knowledge in Data Centre domain
Able to speak Mandarin in order to liaise with Mandarin speaking associates and customers
Shift operation is required (7x24）
Immediately available is preferred",https://www.mycareersfuture.gov.sg/job/engineering/data-center-engineer-ezsvs-singapore-df4ab9799423999a7a8180c7f244d141?source=MCF&event=Search
214,data engineers,ELLIOTT MOSS CONSULTING PTE. LTD.,"Job Description:
As a Data Engineering Architect, you will use comprehensive modern data engineer techniques and methods with Advanced Analytics to support business decisions for client.
You can collect, aggregate, and analyze structured/unstructured data from multiple internal and external sources and patterns, insights, and trends to decision-makers.
Your goal is to support the use of data-driven insights to help our Clients achieve business outcomes and objectives. In this role, you will collect, aggregate, store, and reconcile data in support of Client business decisions. You will help design and build data pipelines, data streams, reporting tools, information dashboards, data service APIs, data generators and other end-user information portals and insight tools. You will be a critical part of the data supply chain, ensuring that stakeholders can access and manipulate data for routine and ad hoc analysis to drive business outcomes using Advanced Analytics.

• Translate business requirements to technical solutions leveraging strong business acumen.
• Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data & Analytics PaaS Services.
• Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments.
• Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies.
• Design and Build Modern Data Pipelines and Data Streams.• Design and Build Data Service APIs.
• Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics.
• Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience.
• Implement effective metrics and monitoring processes.
• Travel as needed

Additional Job Details

1 - Microsoft SQL Server Integration Services SSIS 2 - Microsoft SQL Server Analysis Services (SSAS) (P3 - Advanced) 3 - Data Modeling Techniques and Methodologies (P3 - Advanced) 4 - Data Warehouse Tools (P3 - Advanced) 5 - Microsoft SQL Server Mobile Reports (P3 - Advanced) • Demonstrated experience of turning business use cases and requirements to technical solutions. • Experience in business processing mapping of data and analytics solutions. • Ability to conduct data profiling, cataloging, and mapping for technical design and construction of technical data flows. • The ability to apply such methods to solve business problems using one or more Azure Data and Analytics services in combination with building data pipelines, data streams, and system integration. • Mastery of .NET C# and T-SQL with the familiarity of U-SQL is required • Knowledge of Azure Data Factory, Azure Data Lake, Azure SQL DW, and Azure SQL, Azure App Service is required. • Azure IoT, Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics is a plus. • Knowledge of Python is a plus. • Experience preparing data for Data Science and Machine Learning. • Experience preparing data for use in Azure Machine Learning and/or Azure Databricks is a plus. • Demonstrated experience preparing data and building data pipelines for AI Use Cases (text, voice, image, etc.…). • Designing and building Data Pipelines using streams of IOT data. • Knowledge of Lambda and Kappa architecture patterns. • Knowledge of Master Data Management (MDM) and Data Quality tools and processes • Strong team collaboration and experience working with remote teams. • Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals. • Working experience with Visual Studio, PowerShell Scripting, and ARM templates. • Experience with Git/TFS/VSTS is a must.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineers-elliott-moss-consulting-23067bb0245ae04b6b3b15a28591d23a?source=MCF&event=Search
215,System Engineer [Data Protection / Up to $6000],GOOD JOB CREATIONS (SINGAPORE) PTE. LTD.,"[Order Number:2301-64217]

Responsibilities
Project deployment, configuration, maintenance, and optimization of Hybrid IT Solutions such as Cloud Backup and Enterprise Backup Solution.
Project planning which includes creation of project documentation such as Statement of Work, Build Document, UAT Test & etc.
Design, install and configuration of backup solution which includes data restoration and disaster recovery, data migration and backup of clients and servers.
Work with Project Managers and customers to manage project deliverables and timelines.
Conducts / leads POC workshop to meet customer, business and technical objectives.
Provide technical expertise in project implementation and field support.
Work closely with vendors to address, track, execute and ensure proper closure of technical support cases.
Requirements
Min 3 years of relevant experience in implementing enterprise backup solutions.
Strong implementation experience in deploying Enterprise Backup solutions like Veritas NetBackup and DellEMC Networker, and Data Domain appliances.
Good OS Administration (Redhat preferred)
Good experience in deploying storage SAN switches (Brocade/MDS) and tape libraries.
Experience in deploying high availability (HA) clustering and Disaster Recovery (DR).
Must have at least TWO certifications of the following backup credentials:
Networker (Dell EMCIE)
Data Domain (Dell EMCIE)
NetBackup (Veritas)
Commvault Simpana
400Veeam / Cohesity
To Apply, please kindly email your updated resume to yicheng(at)goodjobcreations.com.sg
We regret that only shortlisted candidates will be notified.
However, rest assured that all applications will be updated to our resume bank for future opportunities.

EA Personnel Name: Tan Yi Cheng
EA Personnel Registration Number: R22109865
EA Licence No.: 07C5771",https://www.mycareersfuture.gov.sg/job/information-technology/system-engineer-data-protection-6000-good-job-creations-29a8ca62a122b17e877c1254b05cea88?source=MCF&event=Search
216,System Engineer [Data Protection / Up to $6000],GOOD JOB CREATIONS (SINGAPORE) PTE. LTD.,"[Order Number:2301-64217]

Responsibilities
Project deployment, configuration, maintenance, and optimization of Hybrid IT Solutions such as Cloud Backup and Enterprise Backup Solution.
Project planning which includes creation of project documentation such as Statement of Work, Build Document, UAT Test & etc.
Design, install and configuration of backup solution which includes data restoration and disaster recovery, data migration and backup of clients and servers.
Capacity planning, performance analysis and optimization of HA solutions.
Work with Project Managers and customers to manage project deliverables and timelines.
Conducts / leads POC workshop to meet customer, business and technical objectives.
Provide technical expertise in project implementation and field support.
Work closely with vendors to address, track, execute and ensure proper closure of technical support cases
To stay abreast of new rapidly changing technologies and new product releases by regularly participating in technology training & certifications
Any other ad-hoc duties assigned

Requirements
Min 3 years of relevant experience in implementing enterprise backup solutions.
Strong implementation experience in deploying Enterprise Backup solutions like Veritas NetBackup and DellEMC Networker, and Data Domain appliances.
Good OS Administration (Redhat preferred)
Good experience in deploying storage SAN switches (Brocade/MDS) and tape libraries.
Experience in deploying high availability (HA) clustering and Disaster Recovery (DR).
Must have at least TWO certifications of the following backup credentials:
-Networker (Dell EMCIE)
-Data Domain (Dell EMCIE)
-NetBackup (Veritas)
-Commvault Simpana
-Veeam / Cohesity
To Apply, please kindly email your updated resume to yicheng@goodjobcreations.com.sg
We regret that only shortlisted candidates will be notified.
However, rest assured that all applications will be updated to our resume bank for future opportunities.

EA Personnel Name: Tan Yi Cheng
EA Personnel Registration Number: R22109865
EA Licence No.: 07C5771",https://www.mycareersfuture.gov.sg/job/information-technology/system-engineer-data-protection-6000-good-job-creations-7c63b9ea9c934084f13e3878c12cd102?source=MCF&event=Search
217,IT Infra Engineer (Data Center),TANGSPAC CONSULTING PTE LTD,"Position: Senior IT Infrastructure Engineer (Datacentre)
Employment Type: Permanent
Location: Central

Responsibilities:
You will work with Infrastructure Engineering Lead to develop technology vision and strategy for infrastructure architecture.
You will partner with key stakeholders and participate in requirements gathering, analysis and design activities.
You will provide architectural design in accordance with business requirement
You will implement and maintain data, network and technical architecture(s) requirements for development, execution, and operations environments.
You will collaborate with project teams to provide infrastructure implementation estimates.
You will support the systems and service client platforms for system management, ad-hoc operational request and problem / defect resolution.
You will design, maintain, and enhance data dictionaries, physical and logical database models.
You will perform hardware sizing, update logical and physical database designs with changes.
You will support project teams during the design phase.
You will work with Enterprise Architects to align designs with the enterprise roadmaps.
You will identify trends and analyse risks and impact to Data Centre operations.
You will review and streamline workflows, processes and throughput for efficiency gain and solution quality improvement.
You will drive innovation and automation within the Data Centre operations while ensuring safety of Infra equipment and peripherals
You will manage all maintenance and repair contracts and ensure compliance with maintenance standards and operational requirements.
You will develop and implement a preventive maintenance program and provide regular training for operation team.

Requirements:
You will need a degree in Computer Science / Engineering, Information Science, or other IT-related disciplines.
You will need Minimum 5+ years of experience in application and technical architecture work.
You should have proven architecture modelling skills and experience in infrastructure design and management.
You should have good understanding of the infrastructure architecture standards.
You should have knowledge and experience in Data Centre operation is preferred.
Certification in ITIL and project management will be advantageous.
You should be able to communicate effectively in verbal and written mediums with internal and external stakeholders.
You should have knowledge on networking, data centre design, database management and information security.
You should have ability to work effectively with diverse teams within and outside the Group IT including multiple third-party vendors.

If keen, kindly apply or forward your application to stefan.olsem@tangspac.com

Do take note only shortlisted candidates will be contacted.


Tangspac Consulting Pte Ltd
#03-02 The Octagon, 105 Cecil Street, Singapore 069534
EA Personnel Name: Olsem Stefanus Emmanuel
EA License: 07C3635 | EA Registration: R2094432",https://www.mycareersfuture.gov.sg/job/information-technology/infra-engineer-tangspac-consulting-375e0ce2b309f38bf3f3b7e17acf1a7c?source=MCF&event=Search
218,Senior Data Engineer-Top consultancy company,MICHAEL PAGE INTERNATIONAL PTE LTD,"MNC in SG
Work-life balance
About Our Client
The largest global insurance consultancy.
Job Description
Build efficient data pipelines across multiples endpoints that support a variety of data types and formats while following established development and security best practices
* Assess existing data architecture and identify issues or opportunities for improvement. Recommend data architecture for new projects.
* Recommend, design, and implement solutions/components to address identified issues
* Working with Event data, unstructured data, and related technology such as NoSQL and document database
* Define, oversee, and maintain platforms, tools, and best practices that enable specific projects and improve the overall framework
* Utilize cloud services to improve end-to-end data pipeline performance, availability, and security
* Communicate and work directly with internal stakeholders to develop critical data solutions, make data-driven decisions, and achieve key business goals
* Collaborate with the project team to develop reliable, cost-effective, and high-quality solutions and provide timely communications around project progress and issue resolutions
* Provide mentorship and train peers on standards around data engineering best practices, including documentation
The Successful Applicant
More than 7 years data engineering experience with at least 2 years of data architecture exposure
* Solid understanding of SQL and experience working with relational databases and data warehouses
* Good understanding of NoSQL database types and implementations (i.e.. document, key-value, column, graph)
* Extensive experience with modern ELT/ETL tools and frameworks
* Experience working with various data types and formats, both structured and unstructured (e.g. JSON, XML, text, Excel, csv, parquet, etc.)
* Ability to design, lead, implement, and support data engineering projects with minimal oversight
* Ability to explore and assess new tools and technologies as need, including creating and demonstrating proof-of-concepts
* Proficient in at least one cloud technology stack with a focus on services that relate to data engineering, such as:
* Azure (e.g. SQL/PostgreSQL Database, CosmosDB, Blob/Data Lake Storage, DMS, Data Factory, Synapse, Functions, VMs, Container Apps)
* AWS (e.g. RDS, Aurora, S3, EMR, DynamoDB, DMS, Glue, Athena, Redshift, Lambda, EC2, ECS Fargate)
* Experience handling sensitive data (e.g. PII) and deploying solutions to maintain data privacy and security
* Experience in Big Data/distributed data processing (e.g. Spark, Hadoop, Flink)
* Understanding of version control (e.g. GitLab, GitHub, BitBucket)
* Expertise in at least one programming language (Python preferred, Golang, Scala, Java, etc.)

Strong written and verbal communication, including the ability to effectively communicate with both business and technical audiences
* Fluent in English (both written and spoken). Good/ knowledge of mandarin is a plus.
What's on Offer
* APAC focus, Supporting North Asia and Southeast Asia
* Working in a highly collaborative team with open culture
* Great career progress potential, as we are expanding
* Competitive Salary
* Private insurance plan
* Training & professional development opportunities",https://www.mycareersfuture.gov.sg/job/telecommunications/senior-data-engineer-top-consultancy-company-michael-page-international-60ee935094ca536a82f35f3bd2b39228?source=MCF&event=Search
219,Manager - Data Engineering (Ref 25201b),JOBLINE RESOURCES PTE. LTD.,"Key Roles & Responsibilities:

● Place client value and human experience at the center of everything we do
● Develop and deliver value to clients by building large scale enterprise data pipelines to capture, transform and store date to support reporting, automated systems and AI/ML
Team
● Build a world-class team with experts in Data engineering
● Create a culture of excellence and lead with confidence, charisma, context, and humility, working effectively at all levels
● Lead design & delivery of Data pipelines to drive material impact and drive disruptive transformation across our clients in public and private sectors
● Support development of go-to-market plans for Data engineering, understand strategic opportunities, develop trusted partnerships, and deliver social progress
● Thought leadership for data engineering and scaling deployments
Partnership
● Educate, enable, and coach teams on Data Machine Learning Engineers in Temus, clients and in the broader community
● Adopt a cloud-first strategy to enhance agility and elasticity by partnering with vendors to support specific public sector needs
● Harness cutting-edge research through a triple helix partnership between research, industry, and government to drive state-of-the-art with bi-directional rotations

Requirements
● Bachelor’s Degree/Masters Degree in Computer Science/Data Analytics or similar technology field
● Minimum 7 years of designing, building and operationalizing large scale enterprise data solutions and applications (both with batch and streaming data)
● Experience using one or more of AWS / Azure / GCP data and analytics services in combination with custom solutions - Spark, Azure Data Lake, Databricks, Snowflake, HDInsights, SQL DW, DocumentDB, Glue, Athena, Elastic Pool etc.
● Experience with Stream platforms and real-time aggregation platforms like Kafka, Kinesis, Spark, Flink, KSQL etc.
● Experience with multiple data storage solutions for analytics, operational and archival purposes like MongoDB, Cassandra, HBase, Redis, PostgreSQL, MySQL, DB2, Neo4j, S3 etc.
● Experience with data transformation tools/platforms like: dbt, Alteryx, Datameer, dataform, Informatica, Talend etc. and their data quality management features
● Mastered at least one core language: Python, Scala, Java
● Good exposure to concepts like Serverless computing, CI/CD, Containerization, Infrastructure as Code, code version control and automated testing
● Experience building historical and real-time operational ‘feature layers’ to support AI/ML teams
● Excellent understanding of the state of Data Engineering evolution in the industry through active tracks of improving knowledge and skills (e.g. courses, podcasts, books, experimentation, open source volunteering, tech meetups etc.)
● Track record of delivering scalable Data pipeline services running in production.
● Strong ability to communicate with a broad range of clients, colleagues, and partners across a variety of contexts and formats.
● Strong ability to explain design decisions and provide alternatives supported by analysis like pro/con, past experiences etc.

Licence No: 12C6060",https://www.mycareersfuture.gov.sg/job/information-technology/manager-data-engineering-jobline-resources-d7778403647dbb117bb6b80448a05890?source=MCF&event=Search
220,Data center engineer,TITANICOM TECH (SINGAPORE) PTE. LTD.,"Job Description:
1. Coordinating with team members and clients in order to identify issues, resolve tickets and troubleshoot faulty servers and network switches;
2. Replace faulty parts for servers and network switches, including devices, hard drives, motherboards or memory cards, etc.;
3. On-site to the client data center with spare parts;
4. Check server information (Location / SN / Warranty) to make sure info is correct;
5. Perform firmware upgrade and configure If it is necessary;
6. Return failed parts to centralize place;

Job Requirement:
1. Diploma/Bachelor’s degree or above in Engineering, Computer Science, Information Technology, Security, or equivalent;
2. Proficient in Chinese and English to liaise with clients from China;
3. 1-3 years of IT experience; outstanding fresh graduates are totally welcomed;
4. Basic network knowledge, such as TCP/IP protocol stacks, basic routing and switching knowledge;
5. Basic server knowledge and familiarity with Linux CLI;",https://www.mycareersfuture.gov.sg/job/information-technology/data-center-engineer-titanicom-tech-03866e70b6679090fca6bebb2644e20e?source=MCF&event=Search
221,Data Engineer (Power BI) - Contract = 12 months,ZENITH INFOTECH (S) PTE LTD.,"This is a 12 months contract assigned to our client

Work Location: To be confirmed
Salary Range : $7,000-$9,500


Primary Skill: Microsoft Power BI

Job Description
1. Enables full stack solutions through multi-disciplinary team planning and ecosystem integration to
accelerate delivery and drive quality across the application lifecycle.
2. Performs continuous testing for security, API, and regression suite.
3. Creates automation strategy, automated scripts and supports data and environment configuration.
4. Participates in code reviews, monitors, and reports defects to support continuous improvement activities
for the end-to-end testing process.


Skills Requirement
1. Microsoft Power BI
2. Extract Transform & Load (ETL) Tools
3. Microsoft Azure Data Factory
4. Enterprise Application Integration (EAI)
5. Extract Transform and Load (ETL)
6. Microsoft Azure Databricks",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-contract-12-months-zenith-infotech-686274b49c505a4f2723c9026556b8d5?source=MCF&event=Search
222,Data Engineer (Power BI) - Contract = 12 months,ZENITH INFOTECH (S) PTE LTD.,"This is a 12 months contract assigned to our client

Work Location: To be confirmed
Salary Range : $7,000-$9,500


Primary Skill: Microsoft Power BI

Job Description
1. Enables full stack solutions through multi-disciplinary team planning and ecosystem integration to accelerate delivery
and drive quality across the application lifecycle.
2. Performs continuous testing for security, API, and regression suite.
3. Creates automation strategy, automated scripts and supports data and environment configuration.
4. Participates in code reviews, monitors, and reports defects to support continuous improvement activities
for the end-to-end testing process.


Skills Requirement
1. Microsoft Power BI
2. Extract Transform & Load (ETL) Tools
3. Microsoft Azure Data Factory
4. Enterprise Application Integration (EAI)
5. Extract Transform and Load (ETL)
6. Microsoft Azure Databricks",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-contract-12-months-zenith-infotech-498793d8a5021816eb5c6831740b14bb?source=MCF&event=Search
223,Junior Data Engineering Consultant - Graduate Programme,FDM SINGAPORE CONSULTING PTE. LTD.,"About The Role

The demand for big data professionals has never been higher. If you’re a graduate with a strong interest in data, finding patterns in data, and are drawn to programming this could be your opportunity to embark on an exciting future as a Data Engineer.

About The FDM Data Engineering Graduate Programme

Over 11 weeks you will gain many advanced tools and frameworks which you will use to solve various complex data problems. You’ll receive industry relevant training in diverse languages including SQL, Hive QL, Python and Spark. And you will learn how to process massive amounts of data, create data flows, manage data lakes, design real time streaming and batch type data ingestion pipelines.
Working individually and on group projects, you’ll build collaboration skills and get a feel for the real working environment.

What will I be doing?
Upon training completion through the awards-winning Singapore Academy, you will become an FDM Consultant and begin two years’ invaluable experience working with one or more of our global clients.
This crucial role involves the design and creation of data-centric scalable solutions which are vital to helping an organisation understand their data and use it to facilitate growth. You will be involved in exciting projects, managing and processing huge datasets, and become an expert in distributed data storage and computing frameworks.

What we offer you:
A full-time contract with a salary from Day 1 of training
Training is provided by industry experts, covering both technical and professional skills to ensure you are job-ready
Ongoing career support throughout your entire FDM journey, including professional development, mentoring, and social networking events with a community of peers
A chance to launch a career in one of the most in-demand tech fields
Minimum Qualifications
Educated to a university degree level (bachelor or higher), no STEM degree required
Demonstrable interest and desire to work in technology
Ability to commit to completing our full 2.5-year graduate programme
Eligible to work in Singapore
About FDM
Our people are our passion and that's why we make your training and career growth our priority. We are a global professional services provider focusing on IT and one of the Singapore's leading graduate employers, recruiting the brightest talent to become the innovators of tomorrow. With centres across Europe, North America and Asia-Pacific, and nearly 5000 consultants currently placed on client site around the world, FDM
has shown exponential growth throughout the years, firmly establishing itself as an award-winning FTSE 250 employer.

Diversity and Inclusion
FDM Group is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, national origin, age, disability, veteran status or any other status protected by federal, provincial or local laws",https://www.mycareersfuture.gov.sg/job/consulting/junior-data-engineering-consultant-graduate-programme-fdm-singapore-consulting-d32795d29b11daa9996f2b662f316166?source=MCF&event=Search
224,2812 - Buyer [ Full Set / Engineering / Data Centre / PO / Material ],THE SUPREME HR ADVISORY PTE. LTD.,"Buyer
Working Hours: 5 Days [9am - 6pm]
Salary: Up To $5,000
Location: Potong Pasir
Requirements:
Diploma / Degree holder in Supply Chain Management
1 - 2 years of relevant working experience / relevant industries
Jobs Scope:
Handles full set of purchasing process (Sourcing, RFQ, shipping and follow up on
deliveries)
Prepare Purchase Orders to suppliers ensure all deliveries are in time to meet site schedules
Ensures timely PO execution and address supplier’s capacity, materials issues that may affect supply
Works closely with vendors to schedule delivery and pick-up of equipment
Coordination with vendors on scheduling & expediting of deliveries or resolution of purchase discrepancies if any
Analyses and maintained an accurate cost per site (equipment and labour)
Supports all Engineering programs in identifying and qualifying Suppliers, auditing new Vendors using both
Technical and commercial knowledge to support company requirements
Maintain procurements database
Works closely with Finance to resolve invoice discrepancies and verified correct shipment/purchase orders on packing lists
Exercise good vendor management and monitor performance of suppliers to meet objectives in the area of quality, inventory control and actively engages suppliers
To perform any other duties that may be assigned by the immediate supervisor from time to time.
Interested applicants can also send your resume to shannon_chew@thesupremehr.com and allow our Consultant to match you with our Clients. No Charges will be incurred by Candidates for any service rendered.

Chew Xing Shan Reg No: R22107044
The Supreme HR Advisory Pte Ltd EA No: 14C7279",https://www.mycareersfuture.gov.sg/job/purchasing/2812-buyer-full-set-engineering-data-centre-po-material-supreme-hr-advisory-2fd9f49f623f115834d273c42d7061cc?source=MCF&event=Search
225,Senior / Data Engineer (IFRS 17),INCOME INSURANCE LIMITED,"We are looking to hire Data Engineers (AWS). This is an exciting opportunity to use and further expand your AWS cloud skill set, and join Income Data Team to build Hybrid Datalake as part of key IFRS project
Responsibilities:
Design, build and operationalize large scale enterprise data solutions and applications using one or more of AWS data and analytics services in combination with 3rd parties – Spark/Python on Glue, DMS, S3, Athena, RDS-PostgreSQL, Airflow, Lambda, Code Commit, Code Pipeline, Code build, etc.
Design and build production ETL data pipelines from ingestion to consumption within a big data architecture, using DMS, DataSync & Glue.
Understand the existing applications(including on-premise Cloudera Datalake) and infrastructure architecture.
Analyze, re-architect and re-platform on-premise data warehouses to data platforms on AWS cloud using AWS or 3rd party services.
Design and implement data engineering, ingestion and curation functions on AWS cloud using AWS native or custom programming.
Perform detail assessments of current state data platforms and create an appropriate transition path to AWS cloud.
Collaborate with development, infrastructure and data center teams to define Continuous Integration and Continuous Delivery processes in accordance with industry standards.
Work on hybrid Datalake.
Work closely with multiple stakeholders to ensure high standards are maintained.
Mandatory Skill-set
Bachelors Degree in Computer Science, Information Technology or other relevant fields
5 years of work experience with ETL, Data Modelling, Data Architecture to build Datalake. Proficient in ETL optimization, designing, coding, and tuning big data processes using Pyspark.
3 yrs of extensive experience in working on AWS platform using core services like S3, Athena, Glue (ETL), DataSync, Airflow, RDS (PostGres), CodeCommit, CodePipeline, CodeBuild, SQL & Spark/Python.
Good to have Skill-set
Fundamental of Insurance domain
Functional knowledge on IFRS17",https://www.mycareersfuture.gov.sg/job/information-technology/senior-data-engineer-income-insurance-7c3e45ee4feaea4973ef56ddb3cb2567?source=MCF&event=Search
226,Senior Electrical Engineer / Data Centre / M&E Design - JL,RK RECRUITMENT PTE. LTD.,"Benefits Summary:
• Engineering Industry
• 5 Days work week: Monday – Friday: 9am – 6pm
• Basic up to $8000 + VB +Medical Claim + Transport Claim + Mobile Claim
• Harbourfront

Responsibilities:
• Perform engineering duties such as planning, engineering design, load & fault calculations, tender preparation/evaluation, QA and testing & commissioning to support the M&E Project Director/Manager.
• Liaise with clients, project managers, contractors, lead projects and produce designs and tender documents.

Additional Information:
• Degree in electrical engineering with minimum 6 years' relevant experiences working in M&E design & consultancy firm. Candidates with design knowledge in Data Centre project will be an added advantage.
• Well versed in local codes of practice and standards.
• Able to work independently and a team player with a good interpersonal skill.
• Willing to travel overseas for few days per trip

Please submit your updated resume by using the APPLY NOW BUTTON

By submitting your personal data and/or resume to us in connection with your job application, you will be deemed to have agreed and consented to us in collecting, using, retaining, and disclosing your personal data and/or resume to prospective employers for the purpose of the evaluating, processing and administration by company relating to this job application.

*We regret to inform you that only shortlisted candidates would be notified*

We wish you all the best in your career search.

You are welcome to visit our website at http://www.rkgroup.sg/

RK Recruitment Pte Ltd | EA License No.: 20C0280
Joceline Lim Shuet Er | EA Personnel No.: R22108933",https://www.mycareersfuture.gov.sg/job/engineering/senior-electrical-engineer-data-centre-me-design-jl-rk-recruitment-0cc403433fcdc217194a86c555601d9f?source=MCF&event=Search
227,Field Service Engineer (Data Center & IT Solutions),DATUMSTRUCT (S) PTE LTD,"Responsibilities
Installation of Data Center hardware, software applications and network monitoring solutions
Responsible for Post-sales technical support roles
Repair, service, maintenance, troubleshoot and install Environment Tech and Data Center equipment at site
Project coordinators for efficient project execution to meet customer’s requirement and expectation, project schedule and quality standard.
Support on project sizing and consultation
Assist in project implementation
Work with customers, suppliers and internal resources on development of new programs.
Ensuring timely execution and delivery of proto-tools, prototypes and information flow.
Requirements
Minimum ITE/Diploma in Computer, Engineering or equivalent
At least 2 years of Technical Support/ System deployment experience in IT Industry
Knowledge of installation of electrical product such as power meter and maintenance will be an added advantage.
Knowledge of Basic Networking Windows (IP Configuration, Firewall, Remote Access and Topology Drawing) will be an added advantage
Knowledge of Basic Linux Command (CENTOS, RHEL and UBUNTU)
Knowledge of Wiring (RJ45, Dry Contact, RS485)
Experience in Network/ Data Center Infrastructure support
Good communication and interpersonal skill
Passionate and team work environment
Possess Class 3 driving license will be an added advantage",https://www.mycareersfuture.gov.sg/job/engineering/field-service-engineer-datumstruct-574950da0ec8a8edefb775a4df6b980c?source=MCF&event=Search
228,"Software Engineer (Data Express), Data Platform",TIKTOK PTE. LTD.,"3About TikTok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul, and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About the team
TikTok and affiliate are developing the next-generation high-performance analytical database, with a mission to enable efficient and real-time data-driven decision-making on PB-level data sets. The initial product was forked from Clickhouse, after which large re-architecture had been taken place. The product now not only improves the efficiency of Clickhouse but also fits into the elastic cloud-native infrastructure with better scalability and resource utilization. With years of polishment in the internal EB-level scenarios, we are now ready to serve our business partners via various cloud vendors.

The product will:
- Enable users to manage large scale data assets in the underlying data engine securely and effortlessly
- Improve the overall system observability, helping our users gain more transparency in the healthiness, resource utilization of the system

What you will be doing:
- Responsible for building core functionalities in the data loading domain
- Drive the design, development, and delivery of data loading features to integrate with mainstream upstream ecosystems
- Lead the optimization of both streaming and batch loading engines to provide low-latency and high-throughput in respective scenarios
- Lead the solution design on data loading resource management over hundreds of thousands of loading jobs
- Ensure service quality through the whole software development lifecycle

Qualifications

What you should have:
- Bachelor's Degree or Post Graduate in Computer Science.
- At least 3 years of backend experience
- Good coding skills in mainstream languages such as GoLang, Java, or Scala
- Good domain knowledge of ETL and data warehousing
- In-depth knowledge in distributed real-time or batch data processing systems, such as Spark, Flink, Kafka, etc
- Experience in optimizing systems like Spark, Flink, Storm, Kafka.
- Knowledge of big data ecosystems such as Kafka, Redpanda, Kinesis, Redshift, Hive is a plus
- Good communication and interpersonal skills

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.",https://www.mycareersfuture.gov.sg/job/information-technology/software-engineer-data-platform-tiktok-970f1bfe960443aa4845a1faf7046e58?source=MCF&event=Search
229,Software Engineer (Data Express) - Data Platform,TIKTOK PTE. LTD.,"About TikTok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul, and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About the team
TikTok and affiliate are developing the next-generation high-performance analytical database, with a mission to enable efficient and real-time data-driven decision-making on PB-level data sets. The initial product was forked from Clickhouse, after which large re-architecture had been taken place. The product now not only improves the efficiency of Clickhouse but also fits into the elastic cloud-native infrastructure with better scalability and resource utilization. With years of polishment in the internal EB-level scenarios, we are now ready to serve our business partners via various cloud vendors.

The product will:
- Enable users to manage large scale data assets in the underlying data engine securely and effortlessly
- Improve the overall system observability, helping our users gain more transparency in the healthiness, resource utilization of the system

What you will be doing:
- Responsible for building core functionalities in the data loading domain
- Drive the design, development, and delivery of data loading features to integrate with mainstream upstream ecosystems
- Lead the optimization of both streaming and batch loading engines to provide low-latency and high-throughput in respective scenarios
- Lead the solution design on data loading resource management over hundreds of thousands of loading jobs
- Ensure service quality through the whole software development lifecycle

Qualifications

What you should have:
- Bachelor's Degree or Post Graduate in Computer Science.
- At least 5 years of backend experience
- Good coding skills in mainstream languages such as GoLang, Java, or Scala
- Good domain knowledge of ETL and data warehousing
- In-depth knowledge in distributed real-time or batch data processing systems, such as Spark, Flink, Kafka, etc
- Experience in optimizing systems like Spark, Flink, Storm, Kafka.
- Knowledge of big data ecosystems such as Kafka, Redpanda, Kinesis, Redshift, Hive is a plus
- Good communication and interpersonal skills

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.",https://www.mycareersfuture.gov.sg/job/information-technology/software-engineer-data-platform-tiktok-34b79d3ac958862b18a6cab972735dbd?source=MCF&event=Search
230,Data Engineer - LW,DYNAMIC HUMAN CAPITAL PTE. LTD.,"Our Client is looking for talented Data Engineers, who will join their Data Science Team and help them to build the state-of-the-art data analytics capabilities powering the future of their platforms.

Position: Data Engineer
Salary: $7,000 to $8,000
Location: Changi
Working Hours / Days: 9AM to 6PM / Mondays to Fridays
Work Hybrid Arrangements , 30% office 70% home after probation.
Job Responsibilities
Collaborate with DevOps and Business Intelligence teams to establish a common data processing and analytics platform and best practices.
Work closely with data scientists and software engineers to support the analysis of data, and the development and validation of models.
Design and implement data storage solutions to ensure data quality, availability, and scalability.
Monitor the performance of the data infrastructure and implement optimizations to improve efficiency and reduce costs.
Participate in technical discussions across the team through code reviews, RFC, or architecture review sessions.
Job Requirements
At least 2 years of experience working as a data engineer or similar.
Good understanding of Agile and DevOps practices: version control, CI/CD, Infrastructure-as-Code, containerization, observability/monitoring.
Experience building data infrastructure to address the needs of business and data teams. Strong knowledge of data architecture, data modeling, and data warehousing.
Deep familiarity with data processing systems such as Airflow, Dagster, Flyte, Spark, DBT, or similar and data cataloging tools such as Atlas, Amundsen, DataHub, or similar.
Deep familiarity with SQL (PostgreSQL preferred) and NoSQL databases (Redis, Elasticsearch preferred).
Familiarity data analytics services and databases, e.g., Redshift, Athena, Glue, EMR, etc. Also, familiarity with data platforms such as Sagemaker, Dataiku, Databricks, Datarobot, or similar.
Experience with data visualization and reporting tools like Metabase, Tableau, PowerBI, or Looker.
Data science, MLOps, or related education or work experience
By submitting any application or resume to us, you will be deemed to have agreed and consented to us disclosing your personal information to prospective employers for their consideration
Under the revised Employment Agencies Licence Condition 5(b), employment agencies (EAs) are required to collect the personal data (e.g. NRIC, FIN) of applicants referred to employers for permanent or contract job positions of at least 6 months with a fixed monthly salary of $3,300 and above. PDPA requirements on collection, use and disclosure of personal data are not applicable to EAs that are collecting such information, as it is a regulatory requirement
https://www.mom.gov.sg/employment-agencies/submit-quarterly-referral-info

Lionel Wang

Dynamic Human Capital Pte Ltd
Registration Number: R22109915
EA License: 12C6253",https://www.mycareersfuture.gov.sg/job/engineering/data-engineer-lw-dynamic-human-capital-5f382766e983723881bc12f82fd4ccf1?source=MCF&event=Search
231,Senior Software Engineer – Data Platform,VENTI TECHNOLOGIES PTE. LTD.,"A world empowered by autonomy. We build robotic vehicles to improve logistics safety, forge a greener Earth, and enhance human lives.

We are a closely-knit team aspiring to change the world through disruptive technology. We are innovators. We are tinkerers. We are problem-solvers. And we have a fair amount of magic dust up our sleeves. We have a plan for fleet-level deployment of autonomous vehicles, and we are looking for the best-of-the-best to join us in making this a reality.
About Venti Technologies
Based in the U.S. and Asia, Venti Technologies is the leader in safe-speed autonomous logistics systems, developing the future of goods transportation. Using rigorous mathematics, deep learning, and theoretically-grounded algorithms, Venti has a proprietary collection of autonomy technologies including a suite of powerful logistics algorithms. Venti’s proven value proposition of saving costs, increasing vehicle utilization, and improving safety is recognized by customers and driving growth. Launched in 2018, Venti brings together an unsurpassed team internationally. The company has autonomous systems deployed in Asia for industrial and logistics sites and a growing pipeline. Venti has offices in Cambridge (Massachusetts, USA), Suzhou (China), and Singapore – our Asian headquarters.
Role responsibilities
Be part of the team to architect and bring up the new data platform for the autonomous prime mover (APM) business.
Architect proper data models to meet all business needs in APM R&D and production operation scenarios.
Design and develop scalable and robust data platform backend services to serve data to developers, operators, and customers for creating dashboards, reports, supporting machine learning needs and triage and troubleshooting.
Bring up universal auth integration and best security practice.
Provide common client SDK for all data platform backend services.
Required experience
Bachelor’s or master's degree in computer science or related relevant field.
5+ years' experience in backend implementation and RESTful API implementation.
Experience with RESTful API framework in Python, Java, or Golang.
Experience with high-performance backend implementation, profiling, and monitoring.
Experience with data modelling with relational database and NoSQL database.
Experience with docker, K8s or other containerization techniques.
Experience with proper CI/CD setup.
Excellent communication skills.
Bonus experience
Experience with real-world robotics or autonomous driving data systems.
Experience with data infrastructure and open-source data pipeline frameworks.

Salary is commensurate with experience. We also offer world-class benefits, fantastic culture, flexible working arrangements, and a great international working environment. Come and join us!",https://www.mycareersfuture.gov.sg/job/information-technology/senior-software-engineer-%E2%80%93-data-platform-venti-technologies-4de475626140edb9a12e5be452a21a71?source=MCF&event=Search
232,Data Engineer - Contract = 12 months,ZENITH INFOTECH (S) PTE LTD.,"This is a 12 months contract assigned to our client

Work Location: To be confirmed
Salary Range : $7,000-$9,500


Primary Skill: Microsoft Power BI

Job Description
1. Enables full stack solutions through multi-disciplinary team planning and ecosystem integration to accelerate delivery
and drive quality across the application lifecycle.
2. Performs continuous testing for security, API, and regression suite.
3. Creates automation strategy, automated scripts and supports data and environment configuration.
4. Participates in code reviews, monitors, and reports defects to support continuous improvement activities
for the end-to-end testing process.


Skills Requirement
1. Microsoft Power BI
2. Extract Transform & Load (ETL) Tools
3. Microsoft Azure Data Factory
4. Enterprise Application Integration (EAI)
5. Extract Transform and Load (ETL)
6. Microsoft Azure Databricks",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-contract-12-months-zenith-infotech-c23bd9b87a31b6563ce81aa270d70724?source=MCF&event=Search
233,Data Engineer - Contract = 12 months,ZENITH INFOTECH (S) PTE LTD.,"This is a 12 months contract assigned to our client

Work Location: To be confirmed
Salary Range : $7,000-$9,500


Primary Skill: Microsoft Power BI

Job Description
1. Enables full stack solutions through multi-disciplinary team planning and ecosystem integration to accelerate delivery
and drive quality across the application lifecycle.
2. Performs continuous testing for security, API, and regression suite.
3. Creates automation strategy, automated scripts and supports data and environment configuration.
4. Participates in code reviews, monitors, and reports defects to support continuous improvement activities
for the end-to-end testing process.


Skills Requirement
1. Microsoft Power BI
2. Extract Transform & Load (ETL) Tools
3. Microsoft Azure Data Factory
4. Enterprise Application Integration (EAI)
5. Extract Transform and Load (ETL)
6. Microsoft Azure Databricks",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-contract-12-months-zenith-infotech-9ca45f3c27a684199a2b848f98cc0f0a?source=MCF&event=Search
234,"Data Engineering Lead @ Labrador Park MRT, Up to $10,000",SUCCESS RESOURCE CENTRE PTE. LTD.,"Commitment Period: Permanent
Working Hours: Mon to Fri, 9am to 6:30pm
Salary: Up to $10,000
Location: Labrador Park MRT

Job Responsibilities:
Lead the team to build and delivered data engineering project.
To provide better solutions for designing data warehouse, reporting as well as data pipeline and processing;
Play a key role in driving project deliveries and execution, architecture design and reviews
Being able to present the solution both to internal and external (customers)
Define long term technical training for self and for the team, including demonstrate technical leadership as go-to person
Recruit, manage, mentor, and provide technical leadership for team of data engineers
Period:
Permanent
Working Hours:
Mon to Fri, 9am to 6:30pm
Salary:
Up to $10,000
Location:
Labrador Park MRT
Requirements:
BS/MS Degree in Computer Science
5+ years of data engineering experience, 3+ year of tech leadership experience
Deep understanding about ETL/ELT, data processing, data quality, reporting and visualization
Expert in data engineering principle as well as data related changes
Expert in working on one or more of these technologies is a plus: Talend, Jaspersoft, TIBCO,
Confluent, MongoDB and any other RDBS
Expert in SQL, semi structured data as well as deep understanding of data lake and data warehouse
concept
Interested applicants, kindly email your detailed resume (MS Word format is preferred):
jansen@successhrc.com.sg (Registration no: R1327243)
Please ensure that applications sent through email are no bigger than 1Mb.
We thank all applicants for your interest but regret to inform that only shortlisted candidates would be notified.
Success Resource Centre Pte Ltd (EA License Number: 04C3201)
3 Shenton Way, #19-01 Shenton House, Singapore 068805
T: 6337 3183 | F: 6337 0329 | W: www.successhrc.com.sg",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineering-lead-labrador-park-mrt-10000-success-resource-centre-4b8bf86336d8acd220c8396d11ae4111?source=MCF&event=Search
235,Data Automation Engineer,ASE SINGAPORE PTE. LTD.,"Responsibilities
To develop & deploy of data automation engineering software
Create and manage database systems
Plan engineering software deliverable to meet project’s requirement within the schedule
Plan and collaborate with equipment expert to manage technical dependencies of the solution
Plan, monitor and manage risks/issues related to data automation engineering software.
System administrator – to setup & maintain Windows & Linux systems, including hardware and software maintenance
Requirements
Degree / Diploma in Information Technology / Computer Science.
Preferably at least 2 years working experience in related field.
Strong scripting language skill i.e. Perl, Python, MSSQL etc.
Experience with web application development.
Knowledge on system backup for data / system (Windows, UNIX/Linux).
Experience in system administration.
Ability to diagnose problem in several areas including Hardware, Operating system, network connectivity",https://www.mycareersfuture.gov.sg/job/engineering/data-automation-engineer-ase-singapore-10f83f7a9e65c2ed6a91caa0b5829216?source=MCF&event=Search
236,Data Engineer (12 Months Contract),PERSOLKELLY SINGAPORE PTE. LTD.,"1. Minimum 3 to 5 Years’ experience in the ETL domain
2. Strong knowledge on SQL
3. Develop and maintain database stored procedures, views, and functions that supports ETL
4. Troubleshoot and resolve data quality issues, database performance issues, database capacity issues
5. Software development experience on Microsoft BI Platform – SSIS, SSRS, MS SQL Server


For Interested parties, click the ""Apply Now"" below.

We regret that only shortlisted applicants would be notified.

Seah Irvin | REG No : R23112821

PERSOLKELLY SINGAPORE PTE LTD | EA License No : 01C4394

By sending us your personal data and curriculum vitae (CV), you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its affiliates collecting, using and disclosing my personal data for the purposes set out in the Privacy Policy which is available at www.persolkelly.com.sg I also acknowledge that I have read, understood, and agree to the said Privacy Policy.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-persolkelly-singapore-654e733c77f99d8ac3bd4afbef0f34b4?source=MCF&event=Search
237,Data Engineer (Video Infrastructure) - 2023 Start,TIKTOK PTE. LTD.,"TikTok will be prioritizing applicants who have a current right to work in Singapore, and do not require TikTok's sponsorship of a visa.

TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

We are looking for talented individuals to join us for this future position in 2023. As a graduate, you will get unparalleled opportunities for you to kickstart your career, pursue bold ideas and explore limitless growth opportunities. Co-create a future driven by your inspiration with TikTok.

Candidates can apply to a maximum of two positions and will be considered for jobs in the order you apply. The application limit is applicable to TikTok and its affiliates' jobs globally. Applications will be reviewed on a rolling basis - we encourage you to apply early.

About the Team
Video Infrastructure is a world-leading video platform that provides multi-media storage, delivery, transcoding, and streaming services. We are building the next generation video processing platform and the largest live streaming network, which provides excellent experiences for billions of users around the world.
Popular video products of TikTok and its affiliates are all empowered by our cutting-edge cloud technologies. Working in this team, you will have the opportunity to tackle challenges of large-scale networks all over the world, while leveraging your expertise in coding, algorithms, complexity analysis, and large-scale system design.

Responsibilities
- Collaborating with the front-end developers and other team members to establish objectives and design more functional, cohesive codes to enhance the user experience.
- Craft optimal data processing architecture and systems for new data and ETL pipelines.
- Design and implement reliable, scalable, robust and extensible big data systems that support core products and business.
- Work with different cross-functional partners including CDN, Video Understanding, Video Transcoding, Live Streaming, and Real-Time Communication.

Qualifications
- Final year or recent graduate with a background in Software Development, Computer Science, Computer Engineering, or a related technical discipline.
- Good programming experience with at least one of the following languages: C, C++, Java, Python, or Go.
- Experience in Big Data technologies (Hadoop, M/R, Hive, Spark, Flink, Kafka, ClickHouse etc).
- Excellent problem analysis and problem-solving skills, able and willing to seek challenges, acquire new knowledge.

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https://careers.tiktok.com/legal/privacy.

If you have any questions, please reach out to us at apac-earlycareers@tiktok.com",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-2023-start-tiktok-4bbfa3915fe9868161386d8fc1d56de4?source=MCF&event=Search
238,Research Engineer (Data-driven understanding of compound hydroclimate extremes),NATIONAL UNIVERSITY OF SINGAPORE,"Job Description
Applications are requested for Research Engineer position on climate change, risk assessment of compound droughts and floods using the latest AI techniques and complex network theory under the supervision of Prof. He Xiaogang, Assistant Professor in the Department of Civil and Environmental Engineering at the National University of Singapore (NUS).
Job Requirements
• At least a bachelor degree in civil engineering, hydrology, water resources engineering, optimization, seasonal forecasting, machine learning, or from similar programs.
• Extensive experience in developing complex computer codes, e.g. in Python, R, or Shell.
• Ability to construct and write papers for leading research journals and conferences.
• Good written and spoken communication.
• Open to fixed-term contract.
Interested applicants are invited to apply directly at our NUS Career Portal.
We regret that only shortlisted candidates will be notified.
Covid-19 Message
At NUS, the health and safety of our staff and students are one of our utmost priorities, and COVID-vaccination supports our commitment to ensure the safety of our community and to make NUS as safe and welcoming as possible. Many of our roles require a significant amount of physical interactions with students/staff/public members. Even for job roles that may be performed remotely, there will be instances where on-campus presence is required.
Taking into consideration the health and well-being of our staff and students and to better protect everyone in the campus, applicants are strongly encouraged to have themselves fully COVID-19 vaccinated to secure successful employment with NUS.",https://www.mycareersfuture.gov.sg/job/engineering/research-engineer-national-university-singapore-6beb307314e5e76528c7e38a3d92a294?source=MCF&event=Search
239,"Site Reliability Engineers (Risk Engineering & Enterprise Data Engineering), Investment Management",CHARTERHOUSE PTE. LTD.,"Min. 4 years of software development backgrounds with experience in system analysis and programming. Python preferred (C++, C#, Java, Javascript, and HTML5 technologies or Unix scripting)(preferably from leading or major Banks/ Investment firms/ Technology firms)
Hands-on experience engineering to optimize the monitoring, availability & reliability of the system and operating environment
Strong background in computer science fundamentals, data structures, algorithms, distributed systems
As Site Reliability Engineers, you will have the opportunity to be part of SRE Singapore teams covering Trading/ Treasury Engineering development, Portfolio Risk Engineering & Enterprise Data Engineering development, work closely with developers of different business & applications on a range of initiatives, including automation, system design, and deployment of next-generation software infrastructure.

You will apply industry standard tooling and best practices to improve reliability, institute performance improvements, and improve the software development process, including the buildout of testing environments, of current and future risk architecture (including engineering solutions for ensuring the reliability of the platform, including mandating a BCP strategy and following sound DevOps practices), delivering stability and resiliency to a suite of high-performance financial applications.

You will also lead the day-to-day support operations for the global risk technology platform, reducing the team’s daily support by automating monitoring and data quality checks for the team’s upstream dependencies, balancing feature development velocity and platform reliability, responsible for production risk environment by monitoring availability and developing metrics for measuring platform health.

You will have the opportunity to work closely with global developers (application development teams on automation, application refactor, (and in certain cases there will be movement between the SRE team and app dev team to allow for maximum cross-pollination0, quantitative research, and risk managers and partner with global peers and forge links with the growing SRE community to drive transformation of Operational & Development culture to best-in-class platform.


To qualify, individuals must possess:

- Min. 4 years of software development backgrounds with experience in system analysis and programming. Python preferred (C++, C#, Java, Javascript, and HTML5 technologies or Unix scripting), preferably from leading or major Banks/ Investment firms/ Technology firms

Must have:
- Hands-on experience engineering to optimize the monitoring, availability & reliability of the system and operating environment
- Strong background in computer science fundamentals, data structures, algorithms, distributed systems

- Comfortable with a range of current software development tools and practices (testing, source control, build systems, CI/CD, etc.)
- Strong track record of supporting financial systems (ideally trading &/or risk systems)
- SQL, database data manipulation experience


Good to have:
- Prior experience with major risk vendor products (e.g. RiskMetrics or Barra)
- Web UI experience (JavaScript, CSS, React)
- interests, including but not limited to: chaos engineering, production engineering, networking, UNIX internals and large-scale system design


Please reach out to Vyon Ng at 69500385 or VyonN@charterhouse.com.sg for a confidential discussion.

Only successful candidates will be notified.

EA License no.: 16S8066 I Reg no.: R1110857",https://www.mycareersfuture.gov.sg/job/banking-finance/site-reliability-engineers-investment-management-charterhouse-f15f9f6675b907305ef628394f4a18fb?source=MCF&event=Search
240,"Mechanical Engineer (Data Management)- Tuas| Bill Of Material| Up $3,800",WORKSTONE PTE. LTD.,"Responsibilities

· Create and maintain Bill of Material structure.
· Enhance BOM structure and drawing system to increase productivity.
· Assist in setting up new BOM line-up in SAP and drawing system.
· Create documents using Microsoft Office to manage products' materials and drawings.



Requirements

· ITE / Diploma in Engineering.
· At least 1 year relevant experience.
· Knowledge in ERP system, SAP preferred.
· Experience in BOM structure.
· Proficient in SOLIDWORKS & AutoCAD
· Able to read basic mechanical drawing.
· Good MS Excel and Access skills.



Interested applicants, please send in your updated resume by clicking “Apply Now”


Lin Weikang
Registration Number: R21102570
Workstone Pte Ltd
EA License Number: 19C9998",https://www.mycareersfuture.gov.sg/job/engineering/mechanical-engineer-tuas-bill-material-3800-workstone-a08ec95c46312802cf8c33efab11f3e6?source=MCF&event=Search
241,Mechanical Engineer / Data Centre Design - JL,RK RECRUITMENT PTE. LTD.,"• Engineering Industry
• 5 Days work week: Monday – Friday: 9am – 6pm
• Basic up to $4500 + VB +Medical Claim + Transport Claim + Mobile Claim
• Harbourfront

Responsibilities:
• Perform engineering duties such as heat load/hydraulic calculations, planning, engineering design, tender preparation/evaluation, QA and testing and commissioning to support the M&E Project Director/Manager.
• Liaise with clients, project manager, contractors, lead projects and produce designs and tender documents.

Additional Information:
• Degree in mechanical engineering with minimum 3 years' relevant experience in M&E design and consultancy firm. Candidate who has data centre design experience an advantage.
• Well versed in local codes of practice and standards.
• Able to work independently and a team player with good interpersonal skills.
• Willing to travel for few days per trip.

Please submit your updated resume by using the APPLY NOW BUTTON

By submitting your personal data and/or resume to us in connection with your job application, you will be deemed to have agreed and consented to us in collecting, using, retaining, and disclosing your personal data and/or resume to prospective employers for the purpose of the evaluating, processing and administration by company relating to this job application.

*We regret to inform you that only shortlisted candidates would be notified*

We wish you all the best in your career search.

You are welcome to visit our website at http://www.rkgroup.sg/

RK Recruitment Pte Ltd | EA License No.: 20C0280
Joceline Lim Shuet Er | EA Personnel No.: R22108933",https://www.mycareersfuture.gov.sg/job/engineering/mechanical-engineer-data-centre-design-jl-rk-recruitment-ae3ce5f775eb1c365795aa3a5793cbe8?source=MCF&event=Search
242,Data Production Engineer,ROC TECH PTE. LTD.,"Overview
As a data engineer, you need to have a deep insight into data usage across the entire company and support trading, risk management, and product operations.
The job requires the candidate to take on the challenge of keeping curious about cutting-edge technologies in the fields of quantitative trading and data mining, as we are continually looking for new potentially valuable data and leverage them to benefit our trading.

What you’ll do
•Maintain and oversee internal data production pipelines;
•Develop data ETL pipelines, data management platform, and other relevant data systems;
•Explore alternative data and perform preliminary data mining

We expect you to have
•A bachelor’s degree in computer science, financial engineering, or related field;
•Experience in developing data extraction, transformation, and load (ETL) pipelines in Python;
•Experience with big data or data modeling is preferred;
•Comprehensive knowledge of relational databases (MySQL/SqlServer/Oracle) and experience with big data infrastructure;",https://www.mycareersfuture.gov.sg/job/banking-finance/data-production-engineer-roc-tech-dc6331e1cae0a7690c9623984eac2db2?source=MCF&event=Search
243,Sr Mechanical Design Engineer (Data Centre),PEOPLE PROFILERS PTE. LTD.,"Industry: Data Centre
Competitive remuneration package
Permanent role

Responsibilities:
Execute technical qualification, planning and development of technical solutions for pre-deals, as the Technical Solutions Manager and/or Head of Department may direct
Manage and generate technical solutions, project cost and planning structure for prospective deal engagements and investment approvals
Obtain proposals and carry out assessment, selection, appointment, and management of consultants for the development of design and cost estimation
Support project team during the whole course of project execution, such as executing projects’ quotation and tendering process for various packages, such as main contractors, sub-contractors, vendors, suppliers etc., in accordance with the approved procurement process
Organize and conduct meetings with stakeholders, such as clients, asset owners, consultants, contractors, vendors, suppliers etc., to address all technical related matters during the whole course of project execution and client’s engagement
Perform tracking on the progress of solutions development and project cost, against the approved schedule during pre-project investment approval stage, for timely handover to client, asset owners and operations team respectively
Perform assessment on technical solutions, such as potential risks and mitigation measures, compliance to the requirements and standards etc.
Requirements:
Bachelor’s Degree, preferably in Mechanical Engineering
Minimum 1-2 years of working experience in mission critical environment or M&E QS background
Ability to carry out high level review of design drawings & documentations
Familiar with design and procurement processes
Ability to manage internal and external stakeholders, technical & non-technical
Genuine interest in problem-solving and proactive in exploring solutions
Strong critical thinking skills with good communication skills, both spoken and written
Job ID: QW65X999

All Successful candidates can expect a very competitive remuneration package and a comprehensive range of benefits.

Kindly email your resume in a detailed Word format to carlo@peopleprofilers.com

We regret that only shortlisted candidates will be notified


People Profilers Pte Ltd
20 Cecil Street, #08-09 PLUS Building Singapore 049705
+65 6950 9747

EA Licence Number: 02C4944
Registration Number: R1100011
EA Personnel: Carlo Antonio Dela Cruz",https://www.mycareersfuture.gov.sg/job/engineering/sr-mechanical-design-engineer-people-profilers-6c993c2c136ef82ae71ab5a944c72d4b?source=MCF&event=Search
244,Data Analytics Platform Engineer #IKR,RECRUIT EXPRESS PTE LTD,"Responsibilities
Design and install software solutions for Data Management, Data Visualisation, Data Warehouses or Big Data platforms.
Collaborate closely with hardware and infrastructure stakeholders to deploy solutions in enterprise environments such as data centres or cloud providersApply security and network design best practices for data analytics solutions to minimise the risk of data exposure
Integrate data analytics platforms to peripheral applications for monitoring, authentication, alert management and log management etc
Work closely with project manager and technical leads to provide regular status reporting and support them to refine issues/problem statements and propose/evaluate relevant analytics solutions
Bring your experience and ideas to effective and innovative engineering, such as automation of routine monitoring and maintenance tasks
Work in interdisciplinary teams that combine technical, business and data science competencies that deliver work in waterfall or agile software development lifecycle methodologies
The range of accountability, responsibility and autonomy will depend on your experience and seniority, including:
Contributing to our internal networks and special interest groups
Mentoring to upskill peers and juniors
Possess good communications skills to understand our customers' core business objectives and build end-to-end data centric solutions to address them
Good critical thinking and problem-solving abilities
Requirements
Must-have:
Prior experience deploying large scale enterprise data analytics platforms from vendors such as SAS, Informatica, Talend, Microsoft, IBM, Tableau, Qlik, Oracle etc
Technical expertise in hardware, network and integration of platform software such as user authentication stores, enterprise application/system monitoring tools, mail servers etc
Service-delivery mindset to propose automation and preventive maintenance solutions
Undergraduate or graduate degree in Computer science or equivalent
Nice to have:
Experience with other aspects of data centre operations such as high availability and disaster recovery designs for resiliency and business continuity planning
Large scale data loading experience moving enterprise or operational data from source systems to new applications or data analytics solutions
Experience in leveraging on loud-based data analytics platform such as:
AWS serverless architecture in Lambda on AWS DynamoDB, EMR Redshift
Azure Data Factory or SQL Data Warehouse
GCP BigQuery/BigTable, Cloud Dataprep/Dataflow/Dataproc
Interested applicants, please email your resume to Karin Chan Wei Kien
Email: karinchan@recruitexpress.com.sg
CEI Reg No: R1104584
EA Licence No: 99C4599
Recruit Express Pte Ltd",https://www.mycareersfuture.gov.sg/job/information-technology/data-analytics-platform-engineer-ikr-recruit-express-7e8a8518c72ddd108f64fb88bdc48c59?source=MCF&event=Search
245,Senior Software QA Engineer - Data Plaform,VENTI TECHNOLOGIES PTE. LTD.,"A world empowered by autonomy. We build robotic vehicles to improve logistics safety, forge a greener Earth, and enhance human lives.
We are a closely-knit team aspiring to change the world through disruptive technology. We are innovators. We are tinkerers. We are problem-solvers. And we have a fair amount of magic dust up our sleeves. We have a plan for fleet-level deployment of autonomous vehicles, and we are looking for the best-of-the-best to join us in making this a reality.
About Venti Technologies
Based in the U.S. and Asia, Venti Technologies is the leader in safe-speed autonomous logistics systems, developing the future of goods transportation. Using rigorous mathematics, deep learning, and theoretically-grounded algorithms, Venti has a proprietary collection of autonomy technologies including a suite of powerful logistics algorithms. Venti’s proven value proposition of saving costs, increasing vehicle utilization, and improving safety is recognized by customers and driving growth. Launched in 2018, Venti brings together an unsurpassed team internationally. The company has autonomous systems deployed in Asia for industrial and logistics sites and a growing pipeline. Venti has offices in Cambridge (Massachusetts, USA), Suzhou (China), and Singapore – our Asian headquarters.

Role responsibilities
Be part of the team to architect and bring up the new data platform and backend services, frontend applications for autonomous prime mover (APM) business.
Taking full responsibility for QA functions for services and frontend applications.
Works with product owner and development team to provide clear user stories and requirements for test cases and end-to-end testing.
Clarifies and discusses requirements throughout the development life cycle.
Implements testing strategies for new features, system stability, load, and regression.
Design and develop test plans, test cases based upon functional and design specifications.
Work closely with the development team to analyze, debug, and resolve any issues.
Review design documents to ensure expectations are clear and testable.
Required experience
Bachelor's or master's degree in computer science or related relevant field.
5+ years' experience in application QA testing
Team player, excellent problem-solving skills, and ability to learn new technologies.
Experience in black box white box testing.
Able to estimate timelines, task breakdown.
Experience in maintaining and executing regression tests.
Experience on any Automation/Regression Testing/Load Testing tools and frameworks, e. g. selenium, Cypress.
Experience on bash scripting and Python.
Excellent communication skills.
Bonus experience
Experience with real world robotics or autonomous driving data systems.
Experience with data validation.

Salary is commensurate with experience. We also offer world-class benefits, fantastic culture, flexible working arrangements, and a great international working environment. Come and join us!",https://www.mycareersfuture.gov.sg/job/information-technology/senior-software-qa-engineer-data-plaform-venti-technologies-b469dbc7b7d914400c10f2d364ad983f?source=MCF&event=Search
246,DevOps Data Engineer,SAKSOFT PTE LIMITED,"Expereince: 5+yrs
The DevOps Tools Administrator is responsible for installing, administrating and configuring the CI/CD tools in the project teams.
This role will be responsible and accountable to deliver all technical implementations in-line with DevOps objectives.
Additional qualities of infra administration including WAS administration, Aix / Linux commands knowledge, IBM toold administration (Datacap / Filenet / BAW) are handy.
We’re looking for a hands engineer who will be:
• Supporting and maintaining the entire DevOps platform and toolset.
• Maintain the DevOps platform and toolset matching the enterprise standard.
• Coordinate with the stakeholders from requirements gathering until successful implementation DevOps pipeline on boarding. Work with the vendors to setup centralized DevOps solutions considering market best practice, Industry standard and ease of support.
• Work with the vendors to upgrade the DevOps tools farm and Integrating with tools.
• Configuring SSO, SSL, Load Balancer, Auto Scaling and DNS setup for the DevOps Toolset with naming convention.
• Lead analysis and resolution of root cause for Test Orchestration / Environment related issues
• Ability to multitask and work in a fast-paced, collaborative team environment
• Excellent written and oral communication skills; writing, publishing and conference-level presentation skills • Stays current with industry trends and leads development of key DevOps, Runtime, and Operational innovation platforms",https://www.mycareersfuture.gov.sg/job/information-technology/devops-data-engineer-saksoft-44ed0730397a36926e6ca511f6bb2aa8?source=MCF&event=Search
247,Data Labelling Engineer | Yearly Contract,PERSOLKELLY SINGAPORE PTE. LTD.,"Job Responsibilities:
Support data classification and taxonomy methods and standards, understand business, cooperate with data team. Support analysis, identification and marking various data samples in storage, and ensure accuracy and recall rate.
Support R&D team to improve algorithm recognition and machine learning ability, analyze badcase of algorithm recommended data labels, put forward suggestions and basis for annotation/labelling, and participate in the discussion of algorithm model improvement solutions
Deeply understand the business, investigate the data samples of each business line, and improve the classification standard of data labels and sample database
Improve the data annotation operation process, optimize the label sampling and review mechanism, and improve the efficiency of manual standards
Participate in the functional optimization design of the annotation platform
Requirements:
Majored in Computer Science or IT related, with research and development in testing, data analyst or DBA experience, familiar with all kinds of data samples in storage
Excellent communication and analysis skills and good reasoning skills, able to quickly understand the business and judge the sample type according to the business attributes
Be able to effectively do repetitive tasks and effectively with a minimum of errors
Knowledge of artificial intelligence and machine learning.
Interested candidates, click the ""APPLY NOW"" button

Only shortlisted applications will be notified by our consultants.

PERSOLKELLY Singapore Pte Ltd | EA License No : 01C4394
Bautista Gia Grace De Guzman | REG No : R23111973

By sending us your personal data and curriculum vitae (CV), you are
deemed to consent to PERSOLKELLY Singapore Pte Ltd and its local and overseas subsidiaries and affiliates collecting, using and disclosing your personal data to prospective employers/companies based in any country for purposes of evaluating suitability for employment, conducting reference checks, administering employment related services and such other purposes stated in our privacy policy. Our full privacy policy is available at www.persolkelly.com.sg. If you wish to withdraw your consent, please drop us an email to let us know. Please feel free to contact us if you have any queries.",https://www.mycareersfuture.gov.sg/job/information-technology/data-labelling-engineer-yearly-contract-persolkelly-singapore-5e6b96fe791205abe7aa4beb3618928d?source=MCF&event=Search
248,Infrastructure Engineer (Data Systems) - 2023 Start,BYTEDANCE PTE. LTD.,"ByteDance will be prioritizing applicants who have a current right to work in Singapore, and do not require ByteDance's sponsorship of a visa.

Founded in 2012, ByteDance's mission is to inspire creativity and enrich life. With a suite of more than a dozen products, including TikTok, Helo, and Resso, as well as platforms specific to the China market, including Toutiao, Douyin, and Xigua, ByteDance has made it easier and more fun for people to connect with, consume, and create content.

Why Join Us
At ByteDance, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for millions of users across all of our products. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at ByteDance.

We are looking for talented individuals to join us for this future position in 2023. As a graduate, you will get unparalleled opportunities for you to kickstart your career, pursue bold ideas and explore limitless growth opportunities. Co-create a future driven by your inspiration with ByteDance.

Candidates can apply to a maximum of two positions and will be considered for jobs in the order you apply. The application limit is applicable to all ByteDance and its affiliates' jobs globally. Applications will be reviewed on a rolling basis - we encourage you to apply early.

About the Team
The Data Center Infrastructure Engineering team supports the company's fast growth by building and operating hyperscale datacenters. The team manages the end to end lifecycle of server fleet, providing cloud solutions and various infrastructure services ensuring that they are scalable and are reliable.

Responsibilities
- Design and build infrastructure services, systems, and platforms;
- Develop tools, automation, and monitors to operate infrastructure efficiently;
- Work in a fast-paced environment and be responsible end-to-end to the production environment by responding to performance and reliability issues and participating rotational on calls;
- Help improve the whole lifecycle of infrastructure services from inception and design throughout development, to deployment, user support and refinement.

Qualifications
- Final year or recent graduate with a background in Software Development, Computer Science, Computer Engineering, or a related technical discipline;
- Experience in one or more programming languages such as Java, C++, Go, or scripting experience in Shell and Python.

Preferred Qualifications
- Experience or knowledge in: Unix/Linux systems from kernel to shell and beyond;
- Experience or knowledge in: Infrastructure solutions, AWS, Google, Azures, and other cloud services;
- Experience or knowledge in: Networking systems (TCP/IP, BGP, DNS, etc.);
- Experience or knowledge in: Traffic systems such as load balancers, NAT, and proxies, etc.;
- Experience or knowledge in: Big data solutions such as Elasticsearch, Spark and Hadoop, which handle Terabytes of data;
- Experience or knowledge in: Building platform, automation, and tools to manage server fleet, their life cycles and systems running on top;
- Self-driven and capable of coping with ambiguity and move projects from concept to delivery;
- Strong in analytical skills and the ability to solve real world problems in a fast-moving environment;
- Experience or knowledge in: Developing and operating one or more following systems - OpenStack, Kubernetes, Nginx, ipvs, ELK stack, Hadoop, etc.

ByteDance is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At ByteDance, our mission is to inspire creativity and enrich life. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https://jobs.bytedance.com/en/legal/privacy.

If you have any questions, please reach out to us at apac-earlycareer@bytedance.com.",https://www.mycareersfuture.gov.sg/job/information-technology/infrastructure-engineer-2023-start-bytedance-b06de4b135dd032222bb01a9800adaa9?source=MCF&event=Search
249,Senior / Data Infra Engineer,INCOME INSURANCE LIMITED,"Description:
Income is looking for a Senior/Data Infrastructure Engineer to join our Data Engineering team in Singapore. Our team owns and runs the Enterprise Datalake used by thousands of users and hosted across AWS, GCP and On-Premises servers.
As a Senior/Data Infrastructure Engineer, you will be at the design, build, maintain and improve our data infrastructure on Cloud, which enables us to make Income data driven organization. In this role, you would also get the opportunity to work with world-class big data and cloud services, such as: AWS/GCP, Glue, Spark, DBT, Airflow, Tableau and PowerBI. Apply now to start taking your career to the next level.
Responsibilities
Work with data engineering and machine learning teams to improve our data infrastructure for increased reliability, maintainability, and scalability.
Architect and design solutions to improve our data delivery capabilities, data quality monitoring, and data pipeline lifecycle.
Architect and administer our cloud applications such as AWS Glue, Sagemaker, LakeFormation, iceberg lakehouse, etc.
Managing Regression Testing Suite , Continuous Integration and Contnuous deployment Pipelines.
Qualifications:
Bachelor Degree in Computer Science or equivalent
4+ years of designing and building production data pipelines from ingestion to consumption in a cloud environment using SQL and Python.
Experience in cloud application architecture & administration in AWS or Azure.
Hands-on experience designing, building and operationalizing large-scale enterprise data solutions and applications. (Airflow, Databricks, Snowflake, Serverless Functions, Cloud storage preferred).
Background in in custom ETL design, implementation, and maintenance.
Hands-on experience with Unix/Linux Command Line Interface (CLI).",https://www.mycareersfuture.gov.sg/job/information-technology/senior-data-infra-engineer-income-insurance-3d6208e41113dcaca1379a3f5fa8d6f3?source=MCF&event=Search
250,Data Labelling Engineer,MANPOWER STAFFING SERVICES (SINGAPORE) PTE LTD,"Job Responsibilities:

1. Support data classification and taxonomy methods and standards, understand business and cooperate with the data team. Support analysis, identification, and marking of various data samples in storage, and ensure accuracy and recall rate.
2. Support the R&D team to improve algorithm recognition and machine learning ability, analyze badcase of algorithm-recommended data labels, put forward suggestions and basis for annotation/labeling, and participate in the discussion of algorithm model improvement solutions
3. Deeply understand the business, investigate the data samples of each business line, and improve the classification standard of data labels and sample database
4. Improve the data annotation operation process, optimize the label sampling and review mechanism, and improve the efficiency of manual standards
5. Participate in the functional optimization design of the annotation platform.

Ability requirements:
1. Majored in Computer Science or IT-related, with research and development in testing, data analyst or DBA experience, familiar with all kinds of data samples in storage
2. Excellent communication and analysis skills and good reasoning skills, able to quickly understand the business and judge the sample type according to the business attributes
3. Be able to effectively do repetitive tasks and effectively with a minimum of errors
4. Knowledge of artificial intelligence and machine learning.

Interested applicants, please share your updated resume to shirley.rajasekar@experis.com.sg or click ""Apply now"" function.
We regret to inform you that only shortlisted candidates will be notified.

Shirley Monisha
EA Personnel no: R22106767
Manpower Staffing Services (S) Pte Ltd
EA License No: 02C3423",https://www.mycareersfuture.gov.sg/job/information-technology/data-labelling-engineer-manpower-staffing-services-5d79b5f885b752c68d3d193021694555?source=MCF&event=Search
251,Data Centre Engineer (12 hours Shift),PEOPLE PROFILERS PTE. LTD.,"· Location: Woodlands or Chai Chee
· Remuneration: Basic (up to $6000) + AWS
· 12 hours Shift

Responsibilities
· Manage the maintenance and daily operations of the DC facilities with the objective of achieving uninterrupted availability at all times and to ensure the fulfillment of our service commitment to customers.
· Support service delivery to ensure contracted service level agreements and key performance indicators are met or exceeded.
· Perform routine facilities activities including inventory control. Critical systems checks and functional testing. Able to respond and take action in response to facilities crisis management activities including: power outages, fire alarms, HVAC outages. Analyze data and identify trends with facility issues to determine root cause and take appropriate action.
· Respond to BMS/EMS alerts, investigate and feedback on any outstanding issues or events and respond to emergency situations and be on standby duty as required.
· Provide technical support to all aspects of data center operations including the operation, maintenance and repair of all mission critical equipment and systems supporting a 24x7 data center operation to achieve 100% uptime and 100% compliance with all customer SLAs.
· Assist in all site construction activities and installations, in coordination with external contractors to ensure system design, installation and testing adhere to operational standards. Witness testing of all equipment during commissioning and validate sequence of operations and receipt of all operational documentation.
· Support for customer installations, in coordination with the design & construction as well as operations requirements to coordinate customer move-in and turn-on, and other service request & deliveries.
· Maintain compliance with local workplace safety & health (WHS) standards and local electrical and building codes.
· Ensure adherence to all standard operating procedures (SOP), method of procedures (MOP), and emergency response procedures (ERP) established for the critical environments, as well as the formal change control process.
· Participate in the scheduling, coordination and completion all significant planned and emergency maintenance events for the facility and ensure these activities are executed in a controlled and proven method to ensure the reliability of the critical loads supported by these systems.
· Support various accreditation, certification and compliance initiatives such as BCA-IDA Green Mark DC/QMS/ISMS/BCMS/PCIDSS/OSPAR, etc as may be required.

Requirements
· Preferably with minimum 1 year experience in Data Center Facilities Management & Operations environment and service delivery.
· ITE/Diploma in Electrical or Mechanical engineering or equivalent qualification
· 24x7 rotating shift duty
· Able to comprehend, analyse and interpret complex project documents, including AutoCAD, Visio and PDF documents
· General technical and functional knowledge of data center infrastructure to include electrical and mechanical systems, fire detection and protection systems, building management systems, equipment maintenance, space planning, construction of critical facilities environment
· Working location : 1-Net (East) at Chai Chee / 1-Net (North) Woodlands

All Successful candidates can expect a very competitive remuneration package and a comprehensive range of benefits.

Alternatively, you may wish to email your resume in a detailed Word format to debbie@peopleprofilers.com

We regret that only shortlisted candidates will be notified
People Profilers Pte Ltd, 50 Raffles Place, #19-12, Singapore Land Tower, Singapore 048623
Tel: 6950 9748
http://www.peopleprofilers.com
debbie@peopleprofilers.com

Consultant in charge: So Boon Shyen, Debbie
EA Licence Number: 02C4944
Registration Number: R1111376

ID: L5YRY453",https://www.mycareersfuture.gov.sg/job/information-technology/data-centre-engineer-people-profilers-0dd81cec56fe3c7ca4106a650a887623?source=MCF&event=Search
252,Data Labelling Engineer,HAYS SPECIALIST RECRUITMENT PTE. LTD.,"Job Responsibilities:
Support data classification and taxonomy methods and standards, understandd business, cooperate with data team. Support analysis, identification and marking various data samples in storage, and ensure accuracy and recall rate.
Support R&D team to improve algorithm recognition and machine learning ability, analyze badcase of algorithm recommended data labels, put forward suggestions and basis for annotation/labelling, and participate in the discussion of algorithm model improvement solutions
Deeply understand the business, investigate the data samples of each business line, and improve the classification standard of data labels and sample database
Improve the data annotation operation process, optimize the label sampling and review mechanism, and improve the efficiency of manual standards
Participate in the functional optimization design of the annotation platform

Ability requirements:
Majored in Computer Science or IT related, with research and development in testing, data analyst or DBA experience, familiar with all kinds of data samples in storage
Excellent communication and analysis skills and good reasoning skills, able to quickly understand the business and judge the sample type according to the business attributes
Be able to effectively do repetitive tasks and effectively with a minimum of errors
Knowledge of artificial intelligence and machine learning.


If you're interested in this role, click 'apply now' to forward an up-to-date copy of your CV, or call Amir at Hays on +65 6303 0726 or email amir.hamzah@hays.com.sg for a confidential discussion.
Referrals are welcome.
Registration ID No. R1984348| EA License number: 07C3924 | Company Registration No. 200609504D",https://www.mycareersfuture.gov.sg/job/information-technology/data-labelling-engineer-hays-specialist-recruitment-1dea5ea2b4097d59c700e4a854c07f4d?source=MCF&event=Search
253,Data Engineer | Informatica Yearly Contract | Up to $8000,PERSOLKELLY SINGAPORE PTE. LTD.,"Job Description:
Participate in migration from On Prem to AWS, as well as operational support.
Creating, enhancing and maintaining Framework Manager models to support business requirements
To design and develop reports using Cognos or other reporting tools
Manages daily and monthly processing and maintenance of Data Warehouse and ETL workflow jobs
To provide production support for the existing Cognos reports and dashboards
To resolve production tickets raised by users within SLA.
Interested candidates, click the ""APPLY NOW"" button

Only shortlisted applications will be notified by our consultants.

PERSOLKELLY Singapore Pte Ltd | EA License No : 01C4394
Bautista Gia Grace De Guzman | REG No : R23111973

By sending us your personal data and curriculum vitae (CV), you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its local and overseas subsidiaries and affiliates collecting, using and disclosing your personal data to prospective employers/companies based in any country for purposes of evaluating suitability for employment, conducting reference checks, administering employment related services and such other purposes stated in our privacy policy. Our full privacy policy is available at www.persolkelly.com.sg. If you wish to withdraw your consent, please drop us an email to let us know. Please feel free to contact us if you have any queries.",https://www.mycareersfuture.gov.sg/job/information-technology/data-engineer-informatica-yearly-contract-8000-persolkelly-singapore-c05b0e5d7c7bb77388748f3819ce2ad1?source=MCF&event=Search
254,SERVICE TECHNICIAN / ENGINEER (DATA CENTRE INDUSTRY),DATA-SPHERE (S) PTE. LTD.,"JOB DESCRIPTION:
1. Carry out preventive maintenance for electrical power system – UPS System and computer room/data centre equipment.
2. Attending to service calls, perform trouble shooting and resolve technical problems at customer site.
3. Hands-on field service work for installation, testing and commissioning of UPS, batteries and electrical power system equipment.
4. Coordinate site logistics and arrangement.
5. Preparation and submission of relevant technical and safety documentation.
6. Any other duties as deemed necessary from time to time

JOB REQUIREMENTS:
1. NITEC/Diploma/Degree in Electrical, Electronics Engineering or equivalent
2. Minimum 3 years of hands-on working experience in electrical power systems.
3. Familiar with electrical, mechanical and WSH guidelines and procedures
4. Possess Class 2B and/or Class 3 license
5. Good communication skills, customer oriented and able to work as a team
6. Able to perform rostered 24/7 on call standby.

OTHERS:
1. Positive working environment
2. Training will be provided
3. Immediate vacancies available",https://www.mycareersfuture.gov.sg/job/engineering/service-technician-engineer-data-sphere-8dbaff522a60acd407816cd4eb17b5ac?source=MCF&event=Search
255,Data Centre Resident Engineer,KERRY INTERIM PTE. LTD.,"Description
Kerry Interim is currently hiring a Data Centre Resident Engineer for our client who is a leading Technology MNC to work on-site at a data centre under a telecommunication conglomerate. You will undertake the role of maintaining and managing the lifecycle of the computer hardware.

Responsibilities
You will be responsible for IMAC (Installation, Move (within the same DC), Add & Change activities
Carry out preventive maintenance and perform periodic firmware updates where applicable
Participate in the maintenance of the data center, inspections, and troubleshooting of HPE computer hardware.

Skills and experiences required
· Min. Degree in Computer Science or related disciplines
· At least 3 years of relevant working experience as a resident engineer at a Datacentre
· Relevant working experience with HPE Computer hardware such as ProLiant, Synergy Blades
· Having knowledge of Azure HCI is an advantage

To Apply
Should you be interested to learn more about the above opportunity, please kindly share your CV (Word doc preferably) with Jun Hao at Junhao@kerryinterim.com. We regret that only shortlisted candidates will be notified.

Reg: R22110394 Lic: 22C0942",https://www.mycareersfuture.gov.sg/job/information-technology/data-centre-resident-engineer-kerry-interim-f00bb6ff0d261f84c136d12877f5c358?source=MCF&event=Search
256,6606 - Buyer [ Data Centre / Construction / Engineering / Infrastructure / Procurement / Purchasing / Sourcing / Supply Chain ],THE SUPREME HR ADVISORY PTE. LTD.,"(Data Centre / Engineering & Building Services Industry)
Buyer
Working Hours: 5 Days [9am - 6pm]
Salary: Up To $5,000 (Based on Experience & Last Drawn)
Location: Lor Bakar Batu, Potong Pasir
Requirements:
Diploma / Degree holder in Supply Chain Management
1 - 2 years of relevant working experience / relevant industries
Jobs Scope:
Handles full set of purchasing process (Sourcing, RFQ, shipping and follow up on
deliveries)
Prepare Purchase Orders to suppliers ensure all deliveries are in time to meet site schedules
Ensures timely PO execution and address supplier’s capacity, materials issues that may affect supply
Works closely with vendors to schedule delivery and pick-up of equipment
Coordination with vendors on scheduling & expediting of deliveries or resolution of purchase discrepancies if any
Analyses and maintained an accurate cost per site (equipment and labour)
Supports all Engineering programs in identifying and qualifying Suppliers, auditing new Vendors using both
Technical and commercial knowledge to support company requirements
Maintain procurements database
Works closely with Finance to resolve invoice discrepancies and verified correct shipment/purchase orders on packing lists
Exercise good vendor management and monitor performance of suppliers to meet objectives in the area of quality, inventory control and actively engages suppliers
To perform any other duties that may be assigned by the immediate supervisor from time to time.
If you are interested to apply, kindly WhatsApp me your updated resume in DOC file and allow our Consultant to match you with our Clients.
Whatsapp: +65 8204 7336
✉liki_wong@thesupremehr.com",https://www.mycareersfuture.gov.sg/job/purchasing/6606-buyer-data-centre-construction-engineering-infrastructure-procurement-purchasing-sourcing-supply-chain-supreme-hr-advisory-a8bb219278383e3ca6ea14b766e53c28?source=MCF&event=Search
257,"Computer Vision Engineer, Data Monetization Technology",TIKTOK PTE. LTD.,"Responsibilities
1. Be responsible for business content understanding of ads, e-commerce, short video, live streaming, and other related content understanding, including images, text, video, audio, etc.
2. Be responsible for data mining, feature engineering, and building machine learning models to build monetization ecology.
3. Optimize model computation efficiency and improve model stability when facing tens of millions of business data and restricted resources.
4. Based on billion scale business data, explore and implement various cutting-edge technologies, such as pre-training, self-supervised learning, few-shot learning, etc.


Qualifications
1. Bachelor's degree or above, majoring in Computer Science, Computer Engineering, Electrical Engineering, or other related fields.
2. Have a solid foundation with common machine learning and deep learning related techniques and algorithms (e.g. classification, clustering, regression, etc.). Be proficient with at least one deep learning framework (e.g. PyTorch, TensorFlow).
3. Be familiar with computer vision related tasks. Have rich experience in at least one aspect, such as image/video classification, object detection, image/video retrieval, OCR, image segmentation, etc.
4. Related experience in at least one of the following areas is a plus:
- Be familiar with NLP-related tasks. Have experience in at least one aspect, such as text classification, semantic analysis, sentiment analysis, NER, etc.
- Be familiar with audio-related tasks. Have experience in at least one aspect, such as ASR, AED, LID, etc.
- Be familiar with multimodal machine learning, large-scale pre-training, etc.
- Be familiar with the theory and application of graph neural networks, knowledge graphs, and have relevant experience;
- Be familiar with model acceleration techniques such as pruning, quantization, distillation, etc.; Have relevant experience in deploying models using frameworks such as TensorRT.
5. Solid programming foundation. Be familiar with basic data structures and algorithms.
6. Have excellent analytical and problem-solving skills, logical thinking skills, communication and collaboration skills. Maintain curiosity about new things, and have a strong sense of responsibility, integrity and reliability.
7. Having published papers in top AI conferences or journals is a plus.",https://www.mycareersfuture.gov.sg/job/others/computer-vision-engineer-data-monetization-technology-tiktok-e1efb5f595d4b8aa21e32e81b68103e6?source=MCF&event=Search
258,2812 - Global Market System Engineer [ Data Center / DC / Network / IT / OS / Software ],THE SUPREME HR ADVISORY PTE. LTD.,"Global Market System Engineer
Working day / time: Monday to Friday | 9am to 6pm
Salary: $3k to $3.5k
Location: Ubi

Job Description:
Supervises, directs, and leads T&C works. You are responsible for overall project engineering and system configuration of assigned projects. The opportunities are expected to be but not limited to the followings:
• Working for the large data center operators.
• Working with multiple global leading providers & vendors.
• Chance to be involved in multi-million-dollar project management.
• Involve in fastest growing DC market, collaborate with regional partners.
• Communicate with different level of managements.

What you will perform:
• Performs and lead in assigned project testing and commissioning to ensure the system, as designed and built meet the specific requirements, conduct of customer training and ensure customer acceptance on the system.
• Creates the high-level system architecture and design and selects major components for assigned project.
• Translating customer needs into specific, well-written requirements to which systems and subsystems (subelements, pieces, software and hardware, control items, etc.) can be architected and designed.

Requirements duties include understanding all external interfaces and ensuring the functional architecture correctly capture the need.
• Directs and organises the preparation of engineering submittals
• Perform all engineering configuration, programming and setting up for all system equipment including server and controllers
• Assist in attending technical meetings with consultant and main con and owner.
• Testing of new products and solutions
• Overseas travel for project implementation may be requested
• Provide training and project deliverables such as documentation
• Deploy and implement Data Center Software.

Requirement:
• At least 5 years relevant working experience is preferred (e.g. Network Engineer)
• Degree in Engineering
• Experience in IT networking and data centre.
• Knowledge in OS (Windows, Linux), Database",https://www.mycareersfuture.gov.sg/job/engineering/2812-global-market-system-engineer-data-center-dc-network-os-software-supreme-hr-advisory-320c871471ca4225ea3b92c2651b08e0?source=MCF&event=Search
259,Data Center Capacity Engineer,MALKOHA PTE. LTD.,"The Capacity Team is responsible for managing the growth and life-cycle of computing resources and data center capacity at Meta, as part of a global production footprint. The Data Center Capacity Engineer is responsible for planning and delivering the end-to-end server and hardware capacity requirements in a hyperscale data center campus. Collectively and globally, these roles plan and build one of the largest Internet services in the world with tens of billions of user requests, tens of exabytes of data, thousands of giga bps of network flow while maintaining operational and resource allocation efficiency.

The Capacity Engineer will drive planning, ownership and delivery of capacity within our data center locations. They will manage complex infrastructure projects within the data center, often in parallel; including capacity planning, installations, retrofits, and service migrations.

This role will interact closely with many cross-functional partners including capacity and performance engineers, data scientists, optimization and process engineers, capacity planners, supply chain, logistics, finance, data center construction, facility operations, security, network engineering, network operations, hardware engineering, NPI, software engineering and systems & tooling engineering.
RESPONSIBILITIES
Plan, lead and collaborate with cross-functional data center teams to deliver complex data center infrastructure capacity projects in support of Meta’s growth, taking into account the interdependencies of production resiliency, power, cooling, network, server and application layers.
Create/improve global standards for processes, workflow and automation roadmaps for software automation that facilitate deployment, maintaining and decommissioning of server hardware at scale.
Work with Meta hardware and software engineering teams and vendors to help resolve complex technical issues that affect Meta's computing infrastructure.
Data trending, analysis and interpretation of systemic issues that impact fleet uptime and utilization. Perform root cause analysis of complex technical and engineering issues and drive resolution.
Build cross-functional relationships and influence policies and procedures to improve regional/global data center operations.
MINIMUM QUALIFICATIONS
5+ years of experience in a combination of capacity planning, demand and supply management, production planning, operations planning or infrastructure management.
Knowledge of enterprise level networking, server and storage installs.
Experience of process ownership and development and systems development.
Experience in communications across stakeholders and presenting to senior executives.
Comprehensive cross-discipline engineering and technical knowledge of data center infrastructure systems and applications, or a directly compatible industry such as pharma, nuclear or large scale manufacturing.
BS, BA or BEng in technical field or commensurate experience.
PREFERRED QUALIFICATIONS
Strong project management and delivery experience. Agile, Prince2 or PMP certification are a benefit.
Experience in the application of data-driven continuous improvement through lean 6 Sigma data and process analysis, visualization and modeling using Excel, Tableau and Minitab.
SQL, R, Python or other programming knowledge is a benefit.
Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.",https://www.mycareersfuture.gov.sg/job/engineering/data-center-capacity-engineer-malkoha-3af6d7db49fa920ade1ece95f8d0e368?source=MCF&event=Search
260,Data Center Capacity Engineer,MALKOHA PTE. LTD.,"The Capacity Team is responsible for managing the growth and life-cycle of computing resources and data center capacity at Meta, as part of a global production footprint. The Data Center Capacity Engineer is responsible for planning and delivering the end-to-end server and hardware capacity requirements in a hyperscale data center campus. Collectively and globally, these roles plan and build one of the largest Internet services in the world with tens of billions of user requests, tens of exabytes of data, thousands of giga bps of network flow while maintaining operational and resource allocation efficiency.

The Capacity Engineer will drive planning, ownership and delivery of capacity within our data center locations. They will manage complex infrastructure projects within the data center, often in parallel; including capacity planning, installations, retrofits, and service migrations.

This role will interact closely with many cross-functional partners including capacity and performance engineers, data scientists, optimization and process engineers, capacity planners, supply chain, logistics, finance, data center construction, facility operations, security, network engineering, network operations, hardware engineering, NPI, software engineering and systems & tooling engineering.
RESPONSIBILITIES
Plan, lead and collaborate with cross-functional data center teams to deliver complex data center infrastructure capacity projects in support of Meta’s growth, taking into account the interdependencies of production resiliency, power, cooling, network, server and application layers.
Create/improve global standards for processes, workflow and automation roadmaps for software automation that facilitate deployment, maintaining and decommissioning of server hardware at scale.
Work with Meta hardware and software engineering teams and vendors to help resolve complex technical issues that affect Meta's computing infrastructure.
Data trending, analysis and interpretation of systemic issues that impact fleet uptime and utilization. Perform root cause analysis of complex technical and engineering issues and drive resolution.
Build cross-functional relationships and influence policies and procedures to improve regional/global data center operations.
MINIMUM QUALIFICATIONS
5+ years of experience in a combination of capacity planning, demand and supply management, production planning, operations planning or infrastructure management.
Knowledge of enterprise level networking, server and storage installs.
Experience of process ownership and development and systems development.
Experience in communications across stakeholders and presenting to senior executives.
Comprehensive cross-discipline engineering and technical knowledge of data center infrastructure systems and applications, or a directly compatible industry such as pharma, nuclear or large scale manufacturing.
BS, BA or BEng in technical field or commensurate experience.
PREFERRED QUALIFICATIONS
Strong project management and delivery experience. Agile, Prince2 or PMP certification are a benefit.
Experience in the application of data-driven continuous improvement through lean 6 Sigma data and process analysis, visualization and modeling using Excel, Tableau and Minitab.
SQL, R, Python or other programming knowledge is a benefit.
Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.",https://www.mycareersfuture.gov.sg/job/engineering/data-center-capacity-engineer-malkoha-29ef024f6298b47c89767fe1da6a8fc7?source=MCF&event=Search
261,Data Labelling Engineer - CL,MANPOWER STAFFING SERVICES (SINGAPORE) PTE LTD,"Role:
Support data classification and taxonomy methods and standards, understand business, cooperate with data team. Support analysis, identification and marking various data samples in storage, and ensure accuracy and recall rate.
Support R&D team to improve algorithm recognition and machine learning ability, analyze bad case of algorithm recommended data labels, put forward suggestions and basis for annotation/labelling, and participate in the discussion of algorithm model improvement solutions
Deeply understand the business, investigate the data samples of each business line, and improve the classification standard of data labels and sample database
Improve the data annotation operation process, optimize the label sampling and review mechanism, and improve the efficiency of manual standards
Participate in the functional optimization design of the annotation platform

Required
Majored in Computer Science or IT related, with research and development in testing, data analyst or DBA experience, familiar with all kinds of data samples in storage
Excellent communication and analysis skills and good reasoning skills, able to quickly understand the business and judge the sample type according to the business attributes
Be able to effectively do repetitive tasks and effectively with a minimum of errors
Knowledge of artificial intelligence and machine learning.




Charles, Lau Ngie Hao License No. 02C3423 Personnel Registration No. R1656741

Please note that your response to this advertisement and communications with us pursuant to this advertisement will constitute informed consent to the collection, use and/or disclosure of personal data by ManpowerGroup Singapore for the purpose of carrying out its business, in compliance with the relevant provisions of the Personal Data Protection Act 2012. To learn more about ManpowerGroup's Global Privacy Policy, please visit https://www.manpower.com.sg/privacy-policy",https://www.mycareersfuture.gov.sg/job/advertising/data-labelling-engineer-cl-manpower-staffing-services-4303d16716ad9e621f8047b91f4cf827?source=MCF&event=Search
262,Data Labelling Engineer | Yearly Contract,PERSOLKELLY SINGAPORE PTE. LTD.,"Job Responsibilities:
Support data classification and taxonomy methods and standards, understand business, cooperate with data team. Support analysis, identification and marking various data samples in storage, and ensure accuracy and recall rate.
Support R&D team to improve algorithm recognition and machine learning ability, analyze badcase of algorithm recommended data labels, put forward suggestions and basis for annotation/labelling, and participate in the discussion of algorithm model improvement solutions
Deeply understand the business, investigate the data samples of each business line, and improve the classification standard of data labels and sample database
Improve the data annotation operation process, optimize the label sampling and review mechanism, and improve the efficiency of manual standards
Participate in the functional optimization design of the annotation platform
Requirements:
Majored in Computer Science or IT related, with research and development in testing, data analyst or DBA experience, familiar with all kinds of data samples in storage
Excellent communication and analysis skills and good reasoning skills, able to quickly understand the business and judge the sample type according to the business attributes
Be able to effectively do repetitive tasks and effectively with a minimum of errors
Knowledge of artificial intelligence and machine learning.
Interested candidates, click the ""APPLY NOW"" button

Only shortlisted applications will be notified by our consultants.

PERSOLKELLY Singapore Pte Ltd | EA License No : 01C4394
Bautista Gia Grace De Guzman | REG No : R23111973

By sending us your personal data and curriculum vitae (CV), you are
deemed to consent to PERSOLKELLY Singapore Pte Ltd and its local and overseas subsidiaries and affiliates collecting, using and disclosing your personal data to prospective employers/companies based in any country for purposes of evaluating suitability for employment, conducting reference checks, administering employment related services and such other purposes stated in our privacy policy. Our full privacy policy is available at www.persolkelly.com.sg. If you wish to withdraw your consent, please drop us an email to let us know. Please feel free to contact us if you have any queries.",https://www.mycareersfuture.gov.sg/job/information-technology/data-labelling-engineer-yearly-contract-persolkelly-singapore-c859ccec1b82201414a9018af0f1b5c3?source=MCF&event=Search
263,Data Labelling Engineer | Yearly Contract,PERSOLKELLY SINGAPORE PTE. LTD.,"Job Responsibilities:
Support data classification and taxonomy methods and standards, understand business, cooperate with data team. Support analysis, identification and marking various data samples in storage, and ensure accuracy and recall rate.
Support R&D team to improve algorithm recognition and machine learning ability, analyze badcase of algorithm recommended data labels, put forward suggestions and basis for annotation/labelling, and participate in the discussion of algorithm model improvement solutions
Deeply understand the business, investigate the data samples of each business line, and improve the classification standard of data labels and sample database
Improve the data annotation operation process, optimize the label sampling and review mechanism, and improve the efficiency of manual standards
Participate in the functional optimization design of the annotation platform
Requirements:
Majored in Computer Science or IT related, with research and development in testing, data analyst or DBA experience, familiar with all kinds of data samples in storage
Excellent communication and analysis skills and good reasoning skills, able to quickly understand the business and judge the sample type according to the business attributes
Be able to effectively do repetitive tasks and effectively with a minimum of errors
Knowledge of artificial intelligence and machine learning.
Interested candidates, click the ""APPLY NOW"" button

Only shortlisted applications will be notified by our consultants.

PERSOLKELLY Singapore Pte Ltd | EA License No : 01C4394
Bautista Gia Grace De Guzman | REG No : R23111973

By sending us your personal data and curriculum vitae (CV), you are
deemed to consent to PERSOLKELLY Singapore Pte Ltd and its local and overseas subsidiaries and affiliates collecting, using and disclosing your personal data to prospective employers/companies based in any country for purposes of evaluating suitability for employment, conducting reference checks, administering employment related services and such other purposes stated in our privacy policy. Our full privacy policy is available at www.persolkelly.com.sg. If you wish to withdraw your consent, please drop us an email to let us know. Please feel free to contact us if you have any queries.",https://www.mycareersfuture.gov.sg/job/information-technology/data-labelling-engineer-yearly-contract-persolkelly-singapore-350d5e359f60f6ef9273c2eb73f6a4c4?source=MCF&event=Search
264,Data Labelling Engineer | Yearly Contract,PERSOLKELLY SINGAPORE PTE. LTD.,"Job Responsibilities:
Support data classification and taxonomy methods and standards, understand business, cooperate with data team. Support analysis, identification and marking various data samples in storage, and ensure accuracy and recall rate.
Support R&D team to improve algorithm recognition and machine learning ability, analyze badcase of algorithm recommended data labels, put forward suggestions and basis for annotation/labelling, and participate in the discussion of algorithm model improvement solutions
Deeply understand the business, investigate the data samples of each business line, and improve the classification standard of data labels and sample database
Improve the data annotation operation process, optimize the label sampling and review mechanism, and improve the efficiency of manual standards
Participate in the functional optimization design of the annotation platform
Requirements:
Majored in Computer Science or IT related, with research and development in testing, data analyst or DBA experience, familiar with all kinds of data samples in storage
Excellent communication and analysis skills and good reasoning skills, able to quickly understand the business and judge the sample type according to the business attributes
Be able to effectively do repetitive tasks and effectively with a minimum of errors
Knowledge of artificial intelligence and machine learning.
Interested candidates, click the ""APPLY NOW"" button

Only shortlisted applications will be notified by our consultants.

PERSOLKELLY Singapore Pte Ltd | EA License No : 01C4394
Bautista Gia Grace De Guzman | REG No : R23111973

By sending us your personal data and curriculum vitae (CV), you are
deemed to consent to PERSOLKELLY Singapore Pte Ltd and its local and overseas subsidiaries and affiliates collecting, using and disclosing your personal data to prospective employers/companies based in any country for purposes of evaluating suitability for employment, conducting reference checks, administering employment related services and such other purposes stated in our privacy policy. Our full privacy policy is available at www.persolkelly.com.sg. If you wish to withdraw your consent, please drop us an email to let us know. Please feel free to contact us if you have any queries.",https://www.mycareersfuture.gov.sg/job/information-technology/data-labelling-engineer-yearly-contract-persolkelly-singapore-0ce365fc55e691b045337ffcfe336e04?source=MCF&event=Search
