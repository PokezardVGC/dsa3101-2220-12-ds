,Title,Company,Description,URL
0,"Data Engineer (ETL-ELT-Oracle/CBD/Up to $7,000)",Good Job Creations (Singapore) Pte Ltd,"[Order Number: 2302-64386 ] Job Brief We are looking for Data Engineer to join our team of analytics experts. The hire will be responsible for expanding and optimising data and data pipeline architecture, as well as optimising data flow and collect for cross-function teams. Data Engineer will develop, construct, test and maintain analytical data warehouse and build up data pipelines based on business requirements. Data Engineer will design, develop, deploy and continuously improve ETL/ELT tasks and be involved in data preparation for descriptive and prescriptive modelling. Data Engineer requires the ability to understand database infrastructure and schema designing and perform optimisation. Data Engineer will design, develop, review and optimize the core database store procedures in batch job scripts and java scripts. Responsibilities Develop, construct, test and maintain data architectures such as databases, data warehouses and large-scale data processing systems. Design and develop data pipelines/systems for data modelling, mining and production Ensure the data architecture is in place to support routine and ad-hoc requirements of data analytics team, stakeholders and the business Leverage on variety of programming languages and data crawling/processing tools to make raw data clean and highly available for use in descriptive and predictive modelling. Recommend and implement ways to improve data quality, reliability, flexibility and efficiency. Ensure data assets and data catalogs are organized and stored in an efficient way so that information is easy to access and retrieve. PL/SQL and SQL Tuning and optimization of newly develop and existing applications Requirements At least 3 years' working experience in data architecture, data warehousing, data processing, data modelling and ETL/ELT At least 3 years' work experience in database development (Oracle SQL/PLSQL) Working experience in AWS cloud environment, familiar with solutions such as EC2, S3, EMR, Redshift, Athena, Kinesis Advanced programming knowledge in Java, Hadoop, HDFS, Apache Airflow, Apache Spark, Scala, Hive, Pig Hands-on experience in data crawling, data modeling, data lake formation and data warehouse construction Hands-on experience in collecting and massaging structured/unstructured/semi-structured data Programming knowledge in Python, R, SQL for data cleaning, processing and aggregation Basic knowledge of Oracle database architecture Ability to build thorough algorithms and deploy machine learning &amp; statistical models will be a plus. Be proactive in work. Strong communication skills Excellent time management skills Team player To Apply, please kindly email your updated resume to CV_Edward(at)goodjobcreations.com.sg We regret that only shortlisted candidates will be notified. However, rest assured that all applications will be updated to our resume bank for future opportunities. EA Personnel Name: Lim Shen Chee EA Personnel Reg. no.: R1660557 EA License no.: 07C5771",https://www.jobstreet.com.sg/en/job/data-engineer-etl-elt-oracle-cbd-up-to-%247-000-10532533?jobId=jobstreet-sg-job-10532533&sectionRank=1&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
1,"Data Engineer (BOM Structure, EPR/SAP) PX",TRUST RECRUIT PTE. LTD.,"Job Responsibilities Create and maintain BOM structure in SAP. Create documents using Microsoft Office (Excel, Access, etc) to manage products' materials and drawings. Enhance BOM structure and drawing system to increase productivity and mitigate human error. Assist in setting up new BOM lineup in SAP and drawing system. Job Requirements ITE / Diploma in Engineering. 1 to 3 years related experience. Knowledge in ERP system, SAP preferred. Experience in BOM structure. Able to read basic mechanical drawing. Good MS Excel and Access skills. Self-motivated and is a teamwork player HOW TO APPLY: Interested applicants, kindly send your resume in MS WORD format to ref21#trustrecruit.com.sg or please click on “Apply Now” and provide the below details in your resume. We regret only shortlisted candidates will be notified. Important Note: Trust Recruit Pte Ltd is committed to safeguarding your personal data in accordance with the Personal Data Protection Act (PDPA). Please read our privacy statement on our corporate website www.trustrecruit.com.sg. Trust Recruit Pte Ltd EA License No: 19C9950 EA Personnel: Chia Fooi Xin (Peisly) EA Personnel Reg No: R22106518",https://www.jobstreet.com.sg/en/job/data-engineer-bom-structure-epr-sap-px-10531073?jobId=jobstreet-sg-job-10531073&sectionRank=2&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
2,Data Engineer ( Linux / Python / Spark / Talend / CAT 1/ Tampines ),TRUST RECRUIT PTE. LTD.,"Job Description: Be part of a team to build and maintain data systems or pipelines. Perform setup, installation, configuration, troubleshooting and/or upgrade for COTS products. Develop or implement ways to improve data warehouses, data lakes or equivalent platforms. Involve in the creation of documentations e.g. design documents, troubleshooting guides etc. Job Requirements: Knowledge and/or experience in data management or data engineering Experience with Linux commands and shell script Knowledge and/or experience in relational (including SQL) or NoSQL database (e.g. document, graph)Data / Search / Automation platforms such as Hadoop, Elasticsearch, Ansible respectively Data integration tools such as Talend, DataStage, Denodo Programming languages such as Python, Spark Microsoft Azure Cloud services such as Azure Data Factory, Azure Synapse Analytics o Analytics platforms such as Databricks, Dataiku, Data Robot Good problem-solving skills Able to work independently and as a team HOW TO APPLY: Interested applicants, please click on “Apply Now” and provide the below details in your resume. We regret only shortlisted candidates will be notified. Important Note: Trust Recruit Pte Ltd is committed to safeguarding your personal data in accordance with the Personal Data Protection Act (PDPA). Please read our privacy statement on our corporate website www.trustrecruit.com.sg. Trust Recruit Pte Ltd EA License No: 19C9950 EA Personnel: Jordan Fung Si Jong EA Personnel Reg No: R23112945",https://www.jobstreet.com.sg/en/job/data-engineer-linux-python-spark-talend-cat-1-tampines-10532574?jobId=jobstreet-sg-job-10532574&sectionRank=3&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
3,"Research Engineer II, - (Big Data &amp; IoT) (R00009221) - #JobsThatMatter #WorkNow-#JobsThatMatter | #LetsGoToWork",Nanyang Technological University,"The Energy Research Institute NTU (ERIAN) invites applications for the position of Research Engineer II. Key Responsibilities: Data Engineer (Big Data &amp; IoT) for Data fusion project Job Requirements: Masters from a reputed institute Must have a minimum 4 years of hands-on experience in building the data pipeline using Python, Kafka &amp; Spark Must have solid concepts on IoT &amp; Sensors Must have experience in pulling data from Gateways / Edge Devices Must have done minimum 2 end to end Big Data Pipeline implementations, either on cloud or on-premise Experience in configuring or developing custom code components for data ingestion, data processing, and data provisioning, using Big data &amp; distributed computing platforms such as Python Spark, and Cloud platforms such as AWS or Azure. Must have hands-on knowledge of Spark RDD, DataFrame, MLLib and Streaming API Must have solid experience in advance python programming Knowledge of Python ML will be an added advantage Proficiency in data modelling, for both structured and unstructured data, for various layers of storage Must have ability to collaborate closely with business analysts, architects, and client stakeholders to create technical specifications. Must have expertise in building the CI / CD Pipeline &amp; Automatics deployment of jobs Skills and Proficiency Solid Python Programming skills Spark, Kafka, Spark RDD, Streaming API Pandas, Numpy, MatplotLib, Scikit-learn Git-lab, CI / CD Pipeline Docker Excellent Communication Skills We regret that only shortlisted candidates will be notified. Hiring Institution: NTU In line with Singapore’s nationwide Vaccination-Differentiated Safe Management Measures (VDS), employees must be fully vaccinated to return to the workplace, unless certified to be medically ineligible. For Information on VDS, please click here.",https://www.jobstreet.com.sg/en/job/research-engineer-ii-big-data-iot-r00009221-jobsthatmatter-worknow-jobsthatmatter-%7C-letsgotowork-10532420?jobId=jobstreet-sg-job-10532420&sectionRank=4&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
4,Oracle Data Engineer -J40417,ScienTec Personnel,"Job Title: Oracle Data Engineer Job Type: Full-Time Location: Tanjong Pagar Salary up to 7k (basic) + AWS +VB We are seeking a talented Oracle Data Engineer to join our team. The successful candidate will be responsible for designing, developing, and maintaining the company's Oracle database infrastructure. Responsibilities: Design, develop, and maintain Oracle database infrastructure. Develop ETL processes to extract, transform, and load data from various sources into Oracle databases. Optimize database performance by analyzing query performance and implementing indexing strategies. Ensure data security and integrity by implementing access controls, backup, and recovery procedures. Work collaboratively with cross-functional teams to ensure data availability and accuracy. Maintain documentation related to database architecture and data models. Stay up-to-date with emerging database technologies and incorporate them into our products where appropriate. Requirements: At least 3 years of experience in Oracle database design and development Strong knowledge of Oracle database administration, including performance tuning and security. Experience with ETL tools, such as Oracle Data Integrator or Informatica. Experience with other databases, such as SQL Server or MySQL, is a plus If you are excited with this opportunity and enjoy making things happen, do apply now! OR Email your updated resume to: speytu(at)scientecpersonnel.com by quoting ""J40417"" in your email subject for faster processing. By submitting any application or resume to us, you will be deemed to have agreed &amp; consented to us collecting, using, retaining &amp; disclosing your personal information to prospective employers for their consideration. Please refer to ScienTec’s Privacy Policy https://www.scientecconsulting.com/privacy-policy for full details. If you wish to withdraw your consent, please write to us at dpo(at)scientecconsulting.com. (Note: Any resumes of job applications sent to this mailbox will not be attended as it is solely for the purpose of personal data protection related matters.) Elane Yap Theng Yu- R1989397 ScienTec Consulting Pte Ltd - 11C5781",https://www.jobstreet.com.sg/en/job/oracle-data-engineer-j40417-10529960?jobId=jobstreet-sg-job-10529960&sectionRank=5&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
5,Data Engineer | $ 6000 | 1 Year Contract (Renewable) | East,APBA TG Human Resource Pte Ltd,"Data Engineer | $ 6000 | 1 Year Contract (Renewable) | East · We are looking for a Data Engineer to put together data from a variety of sources to enable large-scale processing and analysis of complex data. · You are an experienced data wrangler who will be responsible for the design of the data model, undertaking of ETL work and design and maintenance of the databases. Responsibilities • Build and maintain scalable data pipelines and infrastructure for ingesting, processing, and storing data from various sources. • Create and manage ETL processes to transform raw data into structured formats that can be analyzed by data analysts and scientists. • Develop and maintain data warehouse architecture and design, including data modelling, schema design, and performance tuning. • Work with cross-functional teams to ensure data accuracy, consistency, and quality across different systems and data sources. • Monitor and troubleshoot data pipeline and ETL job failures and optimize performance and reliability. • Develop and maintain documentation of data pipelines, ETL processes, and data warehouse architecture. • Assemble large, complex data sets to empower exploratory and operational analytics • Identify, design and implement internal process improvements to optimize data delivery and greater scalability. • Build analytics tools that utilize the data pipelines to provide actionable insights into key business performance metrics. • Work closely with business stakeholders to assist with data-related technical issues and support their data infrastructure needs. • Recommend ways to improve data reliability, efficiency and quality. • Interpret data, analyze results using statistical techniques and provide ongoing reports by using data visualization tools . • Identify, analyse, and interpret trends, patterns, and insights in complex data sets. Requirements • Degree in Computer Science, Computer Engineering, Information Systems or other quantitative / computational discipline. • Experience in architecting or developing an enterprise data lake or data warehouse solution on cloud services. • Strong experience and track record in building data pipelines and databases • Experience in design and implementation of ETL solutions • Solid software development skills in at least one major language (e.g. Java) and scripting languages (e.g. Python). • Experience with advanced schema design and data modelling techniques such as normalization, SCD and star schemas. • Proficient in writing advanced and optimized SQL queries. • Strong project management and organizational skills supporting and working with cross functional teams in a dynamic environment. • Motivated and driven, able to work independently and a good team player as part of a multidisciplinary team Interested candidates, please send your CVs. Regret to inform that only shortlisted candidates will be notified. CEI: R1988671 EA License: 14C7275",https://www.jobstreet.com.sg/en/job/data-engineer-%7C-%24-6000-%7C-1-year-contract-renewable-%7C-east-10525989?jobId=jobstreet-sg-job-10525989&sectionRank=6&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
6,*Perm* Government Software Engineer / Data Engineer | Senior &amp; Head Available | Office Hours | Central,Cornerstone Global Partners,"Data Engineer: Be part of a team of data engineers deriving business insights from large and real-time datasets for strategic planning and operational efficiency. Responsible for the team’s projects to identify and explore suitable technologies, strategies and solutions for advanced data engineering. Maintaining a data warehouse and analytics environment, developing data integration pipelines and devising data models. Work close with stakeholders to define requirements, mine and analyse data, integrate data from various data sources, and deploy data pipelines in support of the organisation analytical needs. Software Engineer: Responsible for developing, implementing and maintaining IT applications systems. Skills required include software development, understanding of Agile principles, DevSecOps, Microservices, and Cloud-based technologies. Leading projects to identify and explore suitable technologies and solutions and designing IT application architectures to meet organizational needs. Need to be customer oriented, understand business needs and be able to communicate well with different stakeholders. Salary: $4,500 - $6,000 21 AL &amp; 14 MC Medical Coverage $120 Dental Benefit AWS VB (Up to 2 months) Permanent Staff Working Hours &amp; Days: Mon - Fri 7am - 4.30pm OR 8.30am - 6pm Location: Hampshire Requirements: Tertiary qualification in a relevant technical field Candidates with more experience might be considered for more senior roles Strong knowledge in data management, relational databases, SQL and ETL. Strong passion for empirical research and extensive experience solving analytical problems using quantitative approaches Strong analytical, communication and presentation skills to communicate complex data quality issues in a clear, precise, and actionable manner Good knowledge in statistical modelling and machine learning algorithms in data quality applications Good knowledge in data visualisation tools like Tableau, and data analysis/processing tools like Python Experience working with large and real-time datasets Experience with distributed computing for data processing (like Spark) is a plus Experience in the development of data pipelines on the cloud For Faster Response: Quote ""GovPermIT"" and Contact Ian Tham: +6593888043 *OR* Email me: ian.tham#cgptalent.com Tham Check Lam (Ian) Registration Number: R22104884 Cornerstone Global Partners (CGP) EA License No: 19C9859",https://www.jobstreet.com.sg/en/job/*perm*-government-software-engineer-data-engineer-%7C-senior-head-available-%7C-office-hours-%7C-central-10526759?jobId=jobstreet-sg-job-10526759&sectionRank=7&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
7,"Big Data Engineer, Recommendation Architecture #UrgentHire",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-urgenthire-10523794?jobId=jobstreet-sg-job-10523794&sectionRank=8&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
8,Data Engineer - TikTok #Immediate,TikTok,"Responsibilities About TikTok TikTok is the world's leading destination for short-form mobile videos. Our mission is to capture and present the world's creativity, knowledge, and moments that matter in everyday life. TikTok empowers everyone to be a creator directly from their smartphones and is committed to building a community by encouraging users to share their passion and creative expression through their videos. TikTok has offices in Beijing, Berlin, Jakarta, London, Los Angeles, Moscow, Mumbai, Sao Paulo, Seoul, Shanghai, Singapore, and Tokyo. In 2018, TikTok was one of the most downloaded apps in the world. TikTok is available worldwide for iOS and Android. Visit tiktok.com. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Translate business requirements &amp; end to end designs into technical implementations and responsible for building batch and real-time data warehouse Manage data modeling design, writing, and optimizing ETL jobs Collaborate with the business team to building data metrics based on data warehouse Responsible for building and maintaining data products Involvement in rollouts, upgrades, implementation, and release of data system changes as required for streamlining of internal practices Qualifications At least 5 years in software engineering and 2 years of relevant experience in data engineering Proficient in creating and maintaining complex ETL pipelines end-to-end while maintaining high reliability and security Familiar with data warehouse concept and have production experience in modeling design Familiar with at least 1 distributed computing engine (e.g. Hive, Spark, Flink) Familiar with at least 1 NoSQL database is a plus (e.g. HBase) Excellent interpersonal and communication skills with the ability to engage and manage internal and external stakeholders across all levels of seniority Strong collaboration skills with the ability to build rapport across teams and stakeholders",https://www.jobstreet.com.sg/en/job/data-engineer-tiktok-immediate-10524707?jobId=jobstreet-sg-job-10524707&sectionRank=9&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
9,Big Data Engineer - Recommendation Architecture #Immediate,TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g. Hadoop, Hive, Flink, FlinkSQL, Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability Willing to challenge questions that have no obvious answers, and have a strong enthusiasm for learning new technologies Experience of Peta Byte level data processing is a plus At least 3 years of relevant experience TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-immediate-10524543?jobId=jobstreet-sg-job-10524543&sectionRank=10&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
10,Data Engineer / Architect,IBM Singapore Pte. Ltd,"Introduction At IBM, work is more than a job – it’s a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you’ve never thought possible. Are you ready to lead in this new era of technology and solve some of the world’s most challenging problems? If so, lets talk. Your Role and Responsibilities As a DTT Engineer/Architect, you will guide the technical evaluation phase as well as during the design and development phase in a hands-on environment in the area of Data Platform, Internet of Things (IoT) and Automation, Analytics including AI and Machine Learning, as well as Blockchain. You will be a technical advisor internally to the sales and delivery team, and work with the product (analytics or data) team as an advocate of your customers in the field. You’ll grow as a leader in your field, while finding solutions to our customers’ biggest challenges in big data, IoT, automation, data engineering and data science and analytics problems. As a Data engineer or Solution Architect you will provide services to clients in the analytics or data related solutioning and delivery of complex projects/programs for cloud and non-cloud environments, including complex application and/or system integration projects. You will help our customers to achieve tangible data-driven outcomes through the use of Data Engineering frameworks or Data Platform or in the area of Automation and Blockchain, helping data and analytics teams complete projects and integrate our platform into their enterprise Ecosystem. You will be responsible in terms of stitching together architectural landscape starting from data acquisition, ingestion and transformation before loading the same in the desire data warehouses in form of datamarts as per the requirement. You will also facilitate the process of how the curated data could be consumed by downstream application in order to meet the business requirement in form of Management Information System or Analytics solutions. The solution architect will build architectures &amp; coordinate with other architects to build an end to end prescriptive guidance across network, storage, operating systems, virtualization, RDBMS &amp; NoSQL databases, and mid-tier technologies that include application integration, in-memory caches, and security. Required Technical and Professional Expertise Overall 12+ years of (consulting) experience focused in data and analytics. Have a good understanding of data warehousing, ETL, complex event processing, data engineering, Big Data principles and data visualization, Data Sciences, Business Intelligence, Analytics products etc Experienced in working in a hybrid cloud environment and exposure to Big Data framework is a must. Proficient understanding of distributed computing principles Deep experience with distributed systems, large scale non-relational data stores, map-reduce systems, data modelling, database performance, and multi-terabyte data warehouses Knowledge in the area of internet of things including IoT related device knowledge is a must for the role Desired knowledge in the area of containerization framework like Kubernetes or Red Hat Open Shift is an added advantage for the role Desired knowledge in the area of API/ Microservices development is a good to have skills Exposure in managing and implement integrations between internal and external solutions Demonstrated experience in collaborating with domain architecture leadership Extensive development expertise in Spark and other Big Data processing frameworks (Hadoop, Storm, Kafka etc) Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala Knowledge of various ETL techniques and frameworks, such as Flume and stream processing systems like Storm or Spark-Streaming Programming knowledge and skill with SQL, NoSQL, Python and PySpark Working knowledge of other BI / Analytics / Big Data tools (IBM Cognos, QlikView, HortonWorks, Cloudera, Azure Data Factory, Automation Anywhere, BluePrism) is a plus Experience in creating end to end blueprint, estimating the effort, pricing and risk assessment of the solution Excellent communication skills with an ability to lead right level conversations",https://www.jobstreet.com.sg/en/job/data-engineer-architect-10524230?jobId=jobstreet-sg-job-10524230&sectionRank=11&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
11,Govt Perm Engineering Or IT Roles (Assistant - Manager) | Monday - Friday (Office Hours),Cornerstone Global Partners,"Various Roles: Engineer: Deputy/Assistant Manager, Principal/Senior/Executive Engineer, Senior/Assistant Project Engineer, Executive/Project Manager IT: Senior/Executive Data Engineer, Senior/Executive Software Engineer, Head Database System Job Scope for Engineers: Managing the contracts for the implementation of the infrastructure projects Responsible for the supervision and completion of projects, ensuring that works are carried out in accordance with the specified quality and safety standards Involved in the overall process of ensuring that the design and development of multi-disciplinary interfaces among the different electrical and mechanical systems are compatible with the overall performance requirement Job Scope for IT Data Engineers: Deriving business insights from large and real-time datasets for strategic planning and operational efficiency Responsible for developing, implementing and maintaining IT applications systems . Skills required include software development, understanding of Agile principles , DevSecOps , Microservices and Cloud-based technologies Participate in Cloud migration projects and collaborate with business users, IT vendors and application teams on database design/ data architectures Salary Range and other benefits: $4000 - $8000/Month+(Depends on Experiences and Position) 21 AL (18 AL + 2 Family Leave + 1 Birthday Leave) 14 MC $120 Dental Medical Coverage AWS VB (0-2 Months) Location: Little India Working Days and Hours: Mon - Fri (8.30am - 6pm) For faster application: Whatapp Sharica Tan with your resume at 83022018 EA Personnel: Sharica Tan EA Licence: 19C9859 Cornerstone Global Partners",https://www.jobstreet.com.sg/en/job/govt-perm-engineering-or-it-roles-assistant-manager-%7C-monday-friday-office-hours-10523592?jobId=jobstreet-sg-job-10523592&sectionRank=12&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
12,Senior Data Engineer,Hudson Global Resources ( HQ ),"Major European-based Chemical Manufacturing Organisation in Singapore Newly Created role Key Strategic Data Engineering Role Our client is one of the prominent organisation in the Chemical manufacturing industry with a household name globally . Now, it is looking to hire a Senior Data Engineer. Responsibilities: Collaborating across the business and working with heterogeneous data sources to build, manage and optimise data pipelines in maximising the business value from data. Creative and collaborative working with Data Architects, Data Scientists, Analytics Developers, IT experts as well as directly with key business stakeholders. Evangelizing effective data management practices and promoting better understanding of data and analytics. Requirement: Degree holder with at least 5 to 8 years of extensive programming and/or systems analysis experience with Python, Java and SQL languages within an established multi-nationals organisation. Prior experience with heterogeneous datasets in building and optimizing data pipelines, pipeline architectures and integrated datasets using Talend and Azure Data Lake Good work experience with Snowflake to build data warehouses / data marts Work experience with back-end/software engineering solutions including API ) Experience working in a virtual team setting and self-driven with desire to take the lead and drive tasks to completion in a remote environment Detail-oriented and strict attention to details and the ability to quickly spot and fix problems MUST be currently based in Singapore and has relevant working experience in Singapore NOTE: Please do attach your latest resume in your submission. We will not be able to process your application without your resume attachment. Please rest assured that your interest will be treated with strictest confidentiality. Chua Keow Por|Reg. #:R1105253|Hudson Global Resources (Singapore) Pte Ltd| EA Licence #:18S9265",https://www.jobstreet.com.sg/en/job/senior-data-engineer-10520923?jobId=jobstreet-sg-job-10520923&sectionRank=13&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
13,"Data Engineer, Data Platform",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo. Why Join Us At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! As a data engineer in the data platform team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users. What you'll do: Design and build data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, and multi-dimensional analysis) Design and implement reliable, scalable, robust and extensible big data systems that support core products and business Establish solid design and best engineering practice for engineers as well as non-technical people Qualifications Bachelor's or Master's degree in Computer Science or related technical field or equivalent practical experience At least 1 year of experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.) Experience with performing data analysis, data ingestion and data integration Experience with schema design and data modeling Experience with ETL (Extraction, Transformation &amp; Loading) and architecting data systems Experience in writing, analyzing and debugging SQL queries Experience in data privacy and security related projects. Deep understanding of various Big Data technologies Passionate and self-motivated about technologies in the Big Data area Solid communication and collaboration skills TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/data-engineer-data-platform-10521301?jobId=jobstreet-sg-job-10521301&sectionRank=14&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
14,Data Engineer - Data Platform,TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo. Why Join Us At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! As a data engineer in the data platform team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users. What you'll do: Design and build data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, and multi-dimensional analysis) Design and implement reliable, scalable, robust and extensible big data systems that support core products and business Establish solid design and best engineering practice for engineers as well as non-technical people Qualifications Bachelor's or master's degree in computer science or related technical field or equivalent practical experience At least 3 years of experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.) Experience with performing data analysis, data ingestion and data integration Experience with schema design and data modeling Experience with ETL (Extraction, Transformation &amp; Loading) and architecting data systems Experience in writing, analyzing and debugging SQL queries Experience in data privacy and security related projects. Deep understanding of various Big Data technologies Passionate and self-motivated about technologies in the Big Data area Solid communication and collaboration skills TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/data-engineer-data-platform-10521048?jobId=jobstreet-sg-job-10521048&sectionRank=15&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
15,"Research Fellow, - (Computer Sci./IT), - (R00006578)",Nanyang Technological University,"A Research Fellow position is currently available in the College of Business, Nanyang Business School. We are looking for an experienced data engineer to join our team and you will use various methods to transform raw data into useful data systems. This includes developing algorithms and conducting statistical analysis. Overall, your goal is to develop data systems in alignment with business goals. Job Responsibilities Co-evaluate business s and objectives Identify opportunities for data acquisition Build data systems and pipelines Build algorithms and prototypes Analyze and organize raw data Interpret trends and patterns Conduct data analysis, working independently or with data analysts, and report on results Prepare data for prescriptive and predictive modeling Combine raw information different sources Explore ways to enhance data quality and reliability Develop analytical tools and programs Collaborate with data scientists and architects Job Requirements Minimally Phd degree in Computer Science, IT, or similar field Candidates with a Masters Degree with more than 6 years of relevant experience post Masters-degree are also welcome to apply Previous experience as a data engineer or in a similar role Technical expertise with data models, data mining, and segmentation techniques Knowledge of programming languages (e.g. Java and Python) Hands-on experience with SQL database design Great numerical and analytical skills Ability to integrate data /data streams different sources Familiarity with apt programming languages and knowledge of machine learning methods If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear you. We regret to inform that only shortlisted candidates will be ified.",https://www.jobstreet.com.sg/en/job/research-fellow-computer-sci.-it-r00006578-10521340?jobId=jobstreet-sg-job-10521340&sectionRank=16&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
16,Data Engineer | Contract | West,People Advantage Pte Ltd,"Government, Contract Location: West 5 Days work week Responsibilities: Engage business stakeholders to identify, design, and implement Data Analytics (DA)/Data Science (DS) projects, including problem scoping, use case formulation, data sourcing, development, and maintenance of analytical models. Provide guidance to business units on the application of DA/DS (including solution) to help drive business initiatives e.g., improving the students’ journey and University operations. Conduct data-driven analysis to drive process improvements or draw out actionable insights, including designing and building data visualization to support management decision making, and aid learning outcomes, as well as enhancing the experience of students’ end-to-end journey Apply analytical techniques such as data mining, statistical analysis, machine learning etc., and build predictive models to address business challenges, support Learning ecosystems, and enhance administration. Work closely with relevant teams to productionize analytical models, including tracking and improving its performance. Familiar with setting up end-to-end processing platform to automate data processing, dashboarding and machine learning will be an added advantage. Requirements: Degree in Mathematics, Statistics, Operations Research, Computer Science, Engineering or other related discipline. Poly graduates with relevant experiences are welcome to apply. Minimally 3-5 years of in-depth experience in implementing end-to-end analytics/data science solutions. Experience in data Extraction / Transformation / Load using SQL, Excel or any other applications. Experience in using data analytical and visualization tools such as Qlik Sense, Power BI, Python. Experience in using data mining tool such as Orange or any other applications. Ability to work collaboratively across teams and quickly breakdown problems and find innovative solutions. Experience with analytical modelling, predictive analytics, AI and machine learning would be an added advantage. Experience with using Microsoft Azure AI Platform to deploy automated data processing and machine learning would be an added advantage.",https://www.jobstreet.com.sg/en/job/data-engineer-%7C-contract-%7C-west-10517279?jobId=jobstreet-sg-job-10517279&sectionRank=17&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
17,Data Engineer | Yearly Contract | Up to $6500 | West,PERSOLKELLY Singapore Pte Ltd (Formerly Kelly Services Singapore Pte Ltd),"KEY JOB PURPOSE As a member of the Analytics and AI team, the incumbent will collaborate with cross-functional teams to analyze, design, and implement analytics/data science solutions and innovations that will enhance COMPANY’s business operations and performance. KEY RESPONSIBILITIES • Engage business stakeholders to identify, design, and implement Data Analytics (DA)/Data Science (DS) projects, including problem scoping, use case formulation, data sourcing, development, and maintenance of analytical models. Examples of DA/DS projects in COMPANY includes Learning analytics for the COMPANY Learn ecosystems, Analytics for Administration • Support the development of COMPANY’s data strategy and in-house analytics capabilities. • Provide guidance to business units on the application of DA/DS (including solution) to help drive business initiatives e.g., improving the journey and University operations. • Conduct data-driven analysis to drive process improvements or draw out actionable insights, including designing and building data visualization to support management decision making, and aid learning outcomes, as well as enhancing the experience of end-to-end journey in COMPANY. • Apply analytical techniques such as data mining, statistical analysis, machine learning etc., and build predictive models to address business challenges, support COMPANY Learning ecosystems, and enhance administration. • Work closely with relevant teams to productionize analytical models, including tracking and improving its performance. • Familiar with setting up end-to-end processing platform to automate data processing, dashboarding and machine learning will be an added advantage. KEY DECISIONS / DIMENSIONS • Participate in the design and implementation of DA/DS projects of various scales. • Participate in the identification, evaluation, and recommendation of DA/DS solutions for COMPANY. • Participate in the identification of potential use cases for analytics/data science. • Evaluate applications and tools for data analytics, mining and machine learning. COMPETENCIES AND QUALIFICATION REQUIREMENTS RELEVANT EXPERIENCE • Minimally 3-5 years of in-depth experience in implementing end-to-end analytics/data science solutions. Renumeration and appointment grades will be based on experience. • Experience in data Extraction / Transformation / Load using SQL, Excel or any other applications. • Experience in using data analytical and visualization tools such as Qlik Sense, Power BI, Python. • Experience in using data mining tool such as Orange or any other applications. • Ability to work collaboratively across teams and quickly breakdown problems and find innovative solutions. • Experience with analytical modelling, predictive analytics, AI and machine learning would be an added advantage. • Experience with using Microsoft Azure AI Platform to deploy automated data processing and machine learning would be an added advantage. EDUCATIONAL QUALIFICATIONS • Degree in Mathematics, Statistics, Operations Research, Computer Science, Engineering or other related discipline. • Specialization in Data Analytics or Data Science will be an added advantage. FUNCTIONAL COMPETENCIES • Ability to communicate data-driven findings and ideas to technical and non-technical stakeholders. • Knowledge in deploying solutions in a cloud environment, and in implementing DA/DS solutions will be an added advantage. CORE COMPETENCIES • Good communication, written and presentation skills. • Good analytical, problem solving and critical thinking skills and meticulous attitude. • Ability to work independently or in a team with minimal supervision. To Apply: Interested candidates, who wish to apply for the above position; please click the ""Apply Now"" below. We regret that only shortlisted applicants would be notified. Teh Chee Hoong | REG No : R22110511 PERSOLKELLY SINGAPORE PTE LTD | EA License No : 01C4394 By sending us your personal data and curriculum vitae (CV), you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its affiliates to collect, use and disclose your personal data for the purposes set out in the Privacy Policy which is available at https://www.persolkelly.com.sg/policies. You also acknowledge that you have read, understood, and agree to the said Privacy Policy.",https://www.jobstreet.com.sg/en/job/data-engineer-%7C-yearly-contract-%7C-up-to-%246500-%7C-west-10515857?jobId=jobstreet-sg-job-10515857&sectionRank=18&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
18,Project Officer - (Programmer/Data Engineer) #UrgentHire,Nanyang Technological University,"The Rehabilitation Research Institute of Singapore (RRIS) invites applications for the position of Project Officer. Key Responsibilities: The successful candidate will work on a research project to implement the core biomechanical analysis plugins on top of the measurement layers from the markerless motion capture system. To have a proper set of features, the job also includes communicating with potential users of the system to find the needs and requirements for the plugin development. Those features may include automatic event detection, normative comparison, self-comparison, and their visualizations. The job also includes the development of a flexible plugin system to allow a third-party developer to develop their own plugin for the analysis layer. The job also includes the development of software to scan through the results from the trained model to find its weakness and regularly perform training data patching or algorithmic patching. Job Requirements: Degree (MS or BS) in Computer Science, Computer Engineering, Electrical/Electronic Engineering, Mechanical Engineering, engineering, or equivalent industry experience. Python programming Experiences in machine learning for image processing with PyTorch Experiences in articulated human modelling or biomechanics Experiences in camera calibration, digital image processing and OpenCV. Experiences in 3D visualization library such as OpenGL, PyOpenGL, or Vispy will be an advantage. Experiences in at least one human motion capture system. We regret that only shortlisted candidates will be notified.",https://www.jobstreet.com.sg/en/job/project-officer-programmer-data-engineer-urgenthire-10531645?jobId=jobstreet-sg-job-10531645&sectionRank=19&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
19,"Data Engineer (EDW), Group Operations &amp; Technology - (220000Z5)",OCBC Bank (Singapore),"Job Details Collaborate with End Users, Business Analysts, and translate requirements into robust, scalable, operable solutions. Build, Test, Deploy Data Pipelines for both Real time , Batch and Hybrid Frameworks Implement Best Practices and Performance Optimization on Big Data Pipelines to achieve the best data engineering outcomes Troubleshoot &amp; Resolve Issues across various toolsets and services on the Big Data Platform Work with various stakeholders within IT and Business and Support the Projects Life Cycle (Agile &amp; SDLC) Employ DevOps to deliver Codes from Development to Production using relevant technologies Qualifications Overall, 7-10 years of relevant working experience in Data Management / Integration / Modelling the data warehouse in a Banking environment 5+ Years’ Experience with Teradata FSL-DM 5+ Years as a hands-on technologist familiar with SQL, UNIX and Teradata tools and technologies 5+ Years’ experience, Designing, Architecting, Implementing, and optimizing high throughput fault tolerant data pipelines for Batch (ETL/ELT) 3+ Years’ experience with Architecting Frameworks for Self Service Platforms/Data Market Place/ data at Scale 4+ Years’ experience with collaborating and fronting business users for gathering Requirements and translating to Technical Outcomes 3+ Years’ experience with Performance Tuning on Teradata or other MPP data pipelines Demonstrable automation experience on Unix Shell Scripting Collaborate with diverse cross functional teams within IT and Business to Independently drive outcomes Possess Good Communication Skills",https://www.jobstreet.com.sg/en/job/data-engineer-edw-group-operations-technology-220000z5-10530133?jobId=jobstreet-sg-job-10530133&sectionRank=20&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
20,Technical Data Engineer - (220002B0),OCBC Bank (Singapore),"Bank of Singapore is currently looking for a qualified candidate to assist the Data Engineering Team’s operational and analytical needs. The Technical Data Enginer will work alongside Data Analytics and big data platform (Hadoop) and engineering team to provide data related support, data ingestion, data interface for unstructured/structred data, data analytics and data management. This person will also assist in building interfaces from various upstream systems and ingest the data into Micrsoft SQL server 2019 / Cloudera Hadoop data store and build the enterprise visulasation tool. This is a great opportunity for someone who is interested in innovative group with the possibility of tremendous career development in data engineering, big data management, data analytics and enterprise data visulsaisation tool. A little more about this role: As our Technical Data Enginer, you will be instrumental in big data coding and work in Hadoop-ecosystem. This is a brand-new position at Data Competency vertical. Perform extensive unstructured data ingestion into Hadoop StronG knowledge of Anaconda, Data visualisation BI tool, Python, SPARK, Java Scala, HIVE and Beeline with hands on experience Ability to organize and lead meetings with business and operational data owners Experience in integrating data processes with architecture requirements used across company Understand Hadoop-ecosystem and Data Engineering activities as well as loading data from several disparate datasets and documentation Strong ability to troubleshoot and resolve data issues Analytical skill to perform data profiling and data visulization Experience in Agile and Waterfall frameworkWork Work closely with engineering and operations to document business processes Work independently and with team members to understand database structure and business processes Help form data management and governance processes within the data engineering team Qualifications What you’ll need to have: Graduate degree in statistics, math, computer science, physics or other technical related fields; Master’s degree is preferred Minimum of 10 years working experience in technical data analysis, data science, or data warehousing with proven business analysis experience Experience in at least one or more languages: SPARK, Java Scala,Python Experience writing Java Scala, Python Experience with Hadoop Hands on expierence or knowledge of minimum one mainstream cloud infrastructures:AWS,MS Azure and GCP; ablity to implement data lake. Good to have Hands-on experienceon the Hadoop, MangoDB,SPARK, Scala, HIVE, Kafka ,Beelin…etc Excellent communication skills Passionate about data and analyzing business needs Previous experience on a data team in an agile environment preferred Hands-on experience on the Hadoop ecosystem, HDFS, Hadoop, Spark, Scala preferred Develop in-depth plans and major milestones that must be approved by top management during the planning and design phases of the project.",https://www.jobstreet.com.sg/en/job/technical-data-engineer-220002b0-10531810?jobId=jobstreet-sg-job-10531810&sectionRank=21&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
21,Research Engineer II (Big Data &amp; IoT) -- [R00009221],Nanyang Technological University,"The Energy Research Institute at NTU (ERIAN) invites applications for the position of Research Engineer II. Key Responsibilities: Data Engineer (Big Data &amp; IoT) for Data fusion project Job Requirements: Masters from a reputed institute Must have a minimum 4 years of hands-on experience in building the data pipeline using Python, Kafka &amp; Spark Must have solid concepts on IoT &amp; Sensors Must have experience in pulling data from Gateways / Edge Devices Must have done minimum 2 end to end Big Data Pipeline implementations, either on cloud or on-premise Experience in configuring or developing custom code components for data ingestion, data processing, and data provisioning, using Big data &amp; distributed computing platforms such as Python Spark, and Cloud platforms such as AWS or Azure. Must have hands-on knowledge of Spark RDD, DataFrame, MLLib and Streaming API Must have solid experience in advance python programming Knowledge of Python ML will be an added advantage Proficiency in data modelling, for both structured and unstructured data, for various layers of storage Must have ability to collaborate closely with business analysts, architects, and client stakeholders to create technical specifications. Must have expertise in building the CI / CD Pipeline &amp; Automatics deployment of jobs Skills and Proficiency Solid Python Programming skills Spark, Kafka, Spark RDD, Streaming API Pandas, Numpy, MatplotLib, Scikit-learn Git-lab, CI / CD Pipeline Docker Excellent Communication Skills We regret that only shortlisted candidates will be notified. Hiring Institution: NTU In line with Singapore’s nationwide Vaccination-Differentiated Safe Management Measures (VDS), employees must be fully vaccinated to return to the workplace, unless certified to be medically ineligible. For Information on VDS, please click here.",https://www.jobstreet.com.sg/en/job/research-engineer-ii-big-data-iot-%5Br00009221%5D-10527890?jobId=jobstreet-sg-job-10527890&sectionRank=22&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
22,Data Engineer | Yearly Contract | Up to $6500 | West,PERSOLKELLY Singapore Pte Ltd (Formerly Kelly Services Singapore Pte Ltd),"• Engage business stakeholders to identify, design, and implement Data Analytics (DA)/Data Science (DS) projects, including problem scoping, use case formulation, data sourcing, development, and maintenance of analytical models. • Support the development of data strategy and in-house analytics capabilities. • Provide guidance to business units on the application of DA/DS (including solution) to help drive business initiatives • Conduct data-driven analysis to drive process improvements or draw out actionable insights, including designing and building data visualization to support management decision making, and aid learning outcomes • Apply analytical techniques such as data mining, statistical analysis, machine learning etc., and build predictive models to address business challenges, support Learning ecosystems, and enhance administration. • Work closely with relevant teams to productionize analytical models, including tracking and improving its performance. • Familiar with setting up end-to-end processing platform to automate data processing, dashboarding and machine learning will be an added advantage. To Apply Interested candidates, who wish to apply for the above position; please click the ""Apply Now"" below. We regret that only shortlisted applicants would be notified. Yee Hong Ling Emelda | REG No : R22109572 PERSOLKELLY SINGAPORE PTE LTD | EA License No : 01C4394 By sending us your personal data and curriculum vitae (CV), you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its affiliates to collect, use and disclose your personal data for the purposes set out in the Privacy Policy which is available at https://www.persolkelly.com.sg/policies. You also acknowledge that you have read, understood, and agree to the said Privacy Policy.",https://www.jobstreet.com.sg/en/job/data-engineer-%7C-yearly-contract-%7C-up-to-%246500-%7C-west-10513365?jobId=jobstreet-sg-job-10513365&sectionRank=23&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
23,"Data Engineer, Growth -- #Immediate - | #LetsGoToWork | #Seekbetter",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. The Growth team plays a core role in acquisition, activation, and retention of billions of users, through our globally popular products such as TikTok, Resso, CapCut, Helo, etc. We are building platform foundation, leveraging data and ML models, and providing end-to-end solutions to power global growth of ByteDance products. Typical Growth projects including referral, notifications, paid ads, etc. You will: Build data pipelines to portray business status, based on a deep understanding of our fast changing business and data-driven approach; Extract information and signals from a broad range of data and build hierarchies to accomplish analytical and mining goals for “Packaged Business Capability” such as user-growth, gaming and searching; Keep improving the integrity of data pipelines to provide a comprehensive data service. Qualifications Bachelor's degree in Computer Science, Statistic, Data Science or a related field; Skilled in SQL and additional object-oriented programming language (e.g. Scala, Java, or Python); Experience in issue tracking and problem solving on data pipelines; Fast business understanding and collaborative in teamwork.",https://www.jobstreet.com.sg/en/job/data-engineer-growth-immediate-%7C-letsgotowork-%7C-seekbetter-10525474?jobId=jobstreet-sg-job-10525474&sectionRank=24&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
24,Data Engineer - Growth`,TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. The Growth team plays a core role in acquisition, activation, and retention of billions of users, through our globally popular products such as TikTok, Resso, CapCut, Helo, etc. We are building platform foundation, leveraging data and ML models, and providing end-to-end solutions to power global growth of ByteDance products. Typical Growth projects including referral, notifications, paid ads, etc. You will: Build data pipelines to portray business status, based on a deep understanding of our fast changing business and data-driven approach; Extract information and signals from a broad range of data and build hierarchies to accomplish analytical and mining goals for “Packaged Business Capability” such as user-growth, gaming and searching; Keep improving the integrity of data pipelines to provide a comprehensive data service. Qualifications Bachelor's degree in Computer Science, Statistic, Data Science or a related field; Skilled in SQL and additional object-oriented programming language (e.g. Scala, Java, or Python); Experience in issue tracking and problem solving on data pipelines; Fast business understanding and collaborative in teamwork. Preferred Qualifications: Industry experience working with user growth.",https://www.jobstreet.com.sg/en/job/data-engineer-growth-10522888?jobId=jobstreet-sg-job-10522888&sectionRank=25&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
25,Data Engineer - Growth #UrgentHire,TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. The Growth team plays a core role in acquisition, activation, and retention of billions of users, through our globally popular products such as TikTok, Resso, CapCut, Helo, etc. We are building platform foundation, leveraging data and ML models, and providing end-to-end solutions to power global growth of ByteDance products. Typical Growth projects including referral, notifications, paid ads, etc. You will: Build data pipelines to portray business status, based on a deep understanding of our fast changing business and data-driven approach; Extract information and signals from a broad range of data and build hierarchies to accomplish analytical and mining goals for “Packaged Business Capability” such as user-growth, gaming and searching; Keep improving the integrity of data pipelines to provide a comprehensive data service. Qualifications Bachelor's degree in Computer Science, Statistic, Data Science or a related field; Skilled in SQL and additional object-oriented programming language (e.g. Scala, Java, or Python); Experience in issue tracking and problem solving on data pipelines; Fast business understanding and collaborative in teamwork. Preferred Qualifications: Industry experience working with user growth.",https://www.jobstreet.com.sg/en/job/data-engineer-growth-urgenthire-10524501?jobId=jobstreet-sg-job-10524501&sectionRank=26&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
26,Data Engineer - LW,Dynamic Human Capital Pte Ltd,"Our Client is looking for talented Data Engineers, who will join their Data Science Team and help them to build the state-of-the-art data analytics capabilities powering the future of their platforms. Position: Data Engineer Salary: $7,000 to $8,000 Location: Changi Working Hours / Days: 9AM to 6PM / Mondays to Fridays Work Hybrid Arrangements , 30% office 70% home after probation. Job Responsibilities Collaborate with DevOps and Business Intelligence teams to establish a common data processing and analytics platform and best practices. Work closely with data scientists and software engineers to support the analysis of data, and the development and validation of models. Design and implement data storage solutions to ensure data quality, availability, and scalability. Monitor the performance of the data infrastructure and implement optimizations to improve efficiency and reduce costs. Participate in technical discussions across the team through code reviews, RFC, or architecture review sessions. Job Requirements At least 2 years of experience working as a data engineer or similar. Good understanding of Agile and DevOps practices: version control, CI/CD, Infrastructure-as-Code, containerization, observability/monitoring. Experience building data infrastructure to address the needs of business and data teams. Strong knowledge of data architecture, data modeling, and data warehousing. Deep familiarity with data processing systems such as Airflow, Dagster, Flyte, Spark, DBT, or similar and data cataloging tools such as Atlas, Amundsen, DataHub, or similar. Deep familiarity with SQL (PostgreSQL preferred) and NoSQL databases (Redis, Elasticsearch preferred). Familiarity data analytics services and databases, e.g., Redshift, Athena, Glue, EMR, etc. Also, familiarity with data platforms such as Sagemaker, Dataiku, Databricks, Datarobot, or similar. Experience with data visualization and reporting tools like Metabase, Tableau, PowerBI, or Looker. Data science, MLOps, or related education or work experience By submitting any application or resume to us, you will be deemed to have agreed and consented to us disclosing your personal information to prospective employers for their consideration Under the revised Employment Agencies Licence Condition 5(b), employment agencies (EAs) are required to collect the personal data (e.g. NRIC, FIN) of applicants referred to employers for permanent or contract job positions of at least 6 months with a fixed monthly salary of $3,300 and above. PDPA requirements on collection, use and disclosure of personal data are not applicable to EAs that are collecting such information, as it is a regulatory requirement https://www.mom.gov.sg/employment-agencies/submit-quarterly-referral-info Lionel Wang Dynamic Human Capital Pte Ltd Registration Number: R22109915 EA License: 12C6253",https://www.jobstreet.com.sg/en/job/data-engineer-lw-10509064?jobId=jobstreet-sg-job-10509064&sectionRank=27&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
27,"Data Engineer Intern, TikTok #Urgent*'",TikTok,"About TikTok TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul, and Tokyo. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok e-commerce business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Responsibilities Responsible for providing end to end solutions to enable business; Responsible for data warehouse modeling design &amp; implementation; Responsible for data pipeline &amp; services development for data products; Responsible for developing and optimizing ETL processes; Responsible for enriching &amp; optimizing technical documents; Qualifications Undergraduate, or Postgraduate who is currently pursuing a degree in Computer Science, related engineering discipline, or equivalent practical experience; Proficiency in SQL with related project experience; Software development experience in one or more general-purpose programming languages, such as Java/Go/C++/C#/Python; Good understanding of the Hadoop ecosystem, open-source big data tech stacks like Hive, MapReduce, Spark, etc; Familiar with large-scale data warehouse architecture design, data model design, and ETL; Good understanding of streaming pipeline development, open-source OLAP engines, or Machine Learning/Data Mining is a plus; Strong analytical thinking and exceptional attention to detail; Working proficiency in verbal and written English; Able to commit at least 3 days a week.",https://www.jobstreet.com.sg/en/job/data-engineer-intern-tiktok-urgent*%27-10522854?jobId=jobstreet-sg-job-10522854&sectionRank=28&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
28,"Big Data Engineer, Recommendation Architecture #Immediate #UrgentHire",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-immediate-urgenthire-10524582?jobId=jobstreet-sg-job-10524582&sectionRank=29&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
29,"Big Data Engineer, Recommendation Architecture #WorkNow #Immediate | #Seekbetter",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-worknow-immediate-%7C-seekbetter-10525316?jobId=jobstreet-sg-job-10525316&sectionRank=30&token=0~6d4f9451-d53b-46a8-a927-0e575f25771d&fr=SRP%20Job%20Listing
30,"Big Data Engineer, Recommendation Architecture #UrgentHire #WorkNow #Immediate - | #LetsGoToWork",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-urgenthire-worknow-immediate-%7C-letsgotowork-10522850?jobId=jobstreet-sg-job-10522850&sectionRank=31&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
31,Data Engineer/ Developer / Informatica |Yearly Contract,PERSOLKELLY Singapore Pte Ltd (Formerly Kelly Services Singapore Pte Ltd),"Job Description: Participate in migration from On Prem to AWS, as well as operational support. Creating, enhancing and maintaining Framework Manager models to support business requirements To design and develop reports using Cognos or other reporting tools Manages daily and monthly processing and maintenance of Data Warehouse and ETL workflow jobs To provide production support for the existing Cognos reports and dashboards To resolve production tickets raised by users within SLA. Interested candidates, click the ""APPLY NOW"" button Only shortlisted applications will be notified by our consultants. PERSOLKELLY Singapore Pte Ltd | EA License No : 01C4394 Bautista Gia Grace De Guzman | REG No : R23111973 By sending us your personal data and curriculum vitae (CV), you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its local and overseas subsidiaries and affiliates collecting, using and disclosing your personal data to prospective employers/companies based in any country for purposes of evaluating suitability for employment, conducting reference checks, administering employment related services and such other purposes stated in our privacy policy. Our full privacy policy is available at www.persolkelly.com.sg. If you wish to withdraw your consent, please drop us an email to let us know. Please feel free to contact us if you have any queries.",https://www.jobstreet.com.sg/en/job/data-engineer-developer-informatica-%7Cyearly-contract-10501024?jobId=jobstreet-sg-job-10501024&sectionRank=32&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
32,Data Engineer - TikTok #Immediate |- #UrgentHire,TikTok,"Responsibilities About TikTok TikTok is the world's leading destination for short-form mobile videos. Our mission is to capture and present the world's creativity, knowledge, and moments that matter in everyday life. TikTok empowers everyone to be a creator directly from their smartphones and is committed to building a community by encouraging users to share their passion and creative expression through their videos. TikTok has offices in Beijing, Berlin, Jakarta, London, Los Angeles, Moscow, Mumbai, Sao Paulo, Seoul, Shanghai, Singapore, and Tokyo. In 2018, TikTok was one of the most downloaded apps in the world. TikTok is available worldwide for iOS and Android. Visit tiktok.com. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Translate business requirements &amp; end to end designs into technical implementations and responsible for building batch and real-time data warehouse Manage data modeling design, writing, and optimizing ETL jobs Collaborate with the business team to building data metrics based on data warehouse Responsible for building and maintaining data products Involvement in rollouts, upgrades, implementation, and release of data system changes as required for streamlining of internal practices Qualifications At least 5 years in software engineering and 2 years of relevant experience in data engineering Proficient in creating and maintaining complex ETL pipelines end-to-end while maintaining high reliability and security Familiar with data warehouse concept and have production experience in modeling design Familiar with at least 1 distributed computing engine (e.g. Hive, Spark, Flink) Familiar with at least 1 NoSQL database is a plus (e.g. HBase) Excellent interpersonal and communication skills with the ability to engage and manage internal and external stakeholders across all levels of seniority Strong collaboration skills with the ability to build rapport across teams and stakeholders",https://www.jobstreet.com.sg/en/job/data-engineer-tiktok-immediate-%7C-urgenthire-10522910?jobId=jobstreet-sg-job-10522910&sectionRank=33&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
33,Data Engineer - TikTok #Immediate |- #UrgentHire | #Seekbetter,TikTok,"Responsibilities About TikTok TikTok is the world's leading destination for short-form mobile videos. Our mission is to capture and present the world's creativity, knowledge, and moments that matter in everyday life. TikTok empowers everyone to be a creator directly from their smartphones and is committed to building a community by encouraging users to share their passion and creative expression through their videos. TikTok has offices in Beijing, Berlin, Jakarta, London, Los Angeles, Moscow, Mumbai, Sao Paulo, Seoul, Shanghai, Singapore, and Tokyo. In 2018, TikTok was one of the most downloaded apps in the world. TikTok is available worldwide for iOS and Android. Visit tiktok.com. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Translate business requirements &amp; end to end designs into technical implementations and responsible for building batch and real-time data warehouse Manage data modeling design, writing, and optimizing ETL jobs Collaborate with the business team to building data metrics based on data warehouse Responsible for building and maintaining data products Involvement in rollouts, upgrades, implementation, and release of data system changes as required for streamlining of internal practices Qualifications At least 5 years in software engineering and 2 years of relevant experience in data engineering Proficient in creating and maintaining complex ETL pipelines end-to-end while maintaining high reliability and security Familiar with data warehouse concept and have production experience in modeling design Familiar with at least 1 distributed computing engine (e.g. Hive, Spark, Flink) Familiar with at least 1 NoSQL database is a plus (e.g. HBase) Excellent interpersonal and communication skills with the ability to engage and manage internal and external stakeholders across all levels of seniority Strong collaboration skills with the ability to build rapport across teams and stakeholders",https://www.jobstreet.com.sg/en/job/data-engineer-tiktok-immediate-%7C-urgenthire-%7C-seekbetter-10525041?jobId=jobstreet-sg-job-10525041&sectionRank=34&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
34,Data Engineer - TikTok - #Seekbetter #Immediate | #Seekbetter,TikTok,"Responsibilities About TikTok TikTok is the world's leading destination for short-form mobile videos. Our mission is to capture and present the world's creativity, knowledge, and moments that matter in everyday life. TikTok empowers everyone to be a creator directly from their smartphones and is committed to building a community by encouraging users to share their passion and creative expression through their videos. TikTok has offices in Beijing, Berlin, Jakarta, London, Los Angeles, Moscow, Mumbai, Sao Paulo, Seoul, Shanghai, Singapore, and Tokyo. In 2018, TikTok was one of the most downloaded apps in the world. TikTok is available worldwide for iOS and Android. Visit tiktok.com. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Translate business requirements &amp; end to end designs into technical implementations and responsible for building batch and real-time data warehouse Manage data modeling design, writing, and optimizing ETL jobs Collaborate with the business team to building data metrics based on data warehouse Responsible for building and maintaining data products Involvement in rollouts, upgrades, implementation, and release of data system changes as required for streamlining of internal practices Qualifications At least 5 years in software engineering and 2 years of relevant experience in data engineering Proficient in creating and maintaining complex ETL pipelines end-to-end while maintaining high reliability and security Familiar with data warehouse concept and have production experience in modeling design Familiar with at least 1 distributed computing engine (e.g. Hive, Spark, Flink) Familiar with at least 1 NoSQL database is a plus (e.g. HBase) Excellent interpersonal and communication skills with the ability to engage and manage internal and external stakeholders across all levels of seniority Strong collaboration skills with the ability to build rapport across teams and stakeholders",https://www.jobstreet.com.sg/en/job/data-engineer-tiktok-seekbetter-immediate-%7C-seekbetter-10525291?jobId=jobstreet-sg-job-10525291&sectionRank=35&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
35,Data Engineer - TikTok #Immediate |- #JobsThatMatter #UrgentHire #JobsThatMatter,TikTok,"Responsibilities About TikTok TikTok is the world's leading destination for short-form mobile videos. Our mission is to capture and present the world's creativity, knowledge, and moments that matter in everyday life. TikTok empowers everyone to be a creator directly from their smartphones and is committed to building a community by encouraging users to share their passion and creative expression through their videos. TikTok has offices in Beijing, Berlin, Jakarta, London, Los Angeles, Moscow, Mumbai, Sao Paulo, Seoul, Shanghai, Singapore, and Tokyo. In 2018, TikTok was one of the most downloaded apps in the world. TikTok is available worldwide for iOS and Android. Visit tiktok.com. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Translate business requirements &amp; end to end designs into technical implementations and responsible for building batch and real-time data warehouse Manage data modeling design, writing, and optimizing ETL jobs Collaborate with the business team to building data metrics based on data warehouse Responsible for building and maintaining data products Involvement in rollouts, upgrades, implementation, and release of data system changes as required for streamlining of internal practices Qualifications At least 5 years in software engineering and 2 years of relevant experience in data engineering Proficient in creating and maintaining complex ETL pipelines end-to-end while maintaining high reliability and security Familiar with data warehouse concept and have production experience in modeling design Familiar with at least 1 distributed computing engine (e.g. Hive, Spark, Flink) Familiar with at least 1 NoSQL database is a plus (e.g. HBase) Excellent interpersonal and communication skills with the ability to engage and manage internal and external stakeholders across all levels of seniority Strong collaboration skills with the ability to build rapport across teams and stakeholders",https://www.jobstreet.com.sg/en/job/data-engineer-tiktok-immediate-%7C-jobsthatmatter-urgenthire-jobsthatmatter-10523298?jobId=jobstreet-sg-job-10523298&sectionRank=36&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
36,"Research Engineer, II [Big Data &amp; IoT] #WorkNow #JobsThatMatter #Seekbetter",Nanyang Technological University,"The Energy Research Institute @ NTU (ERIAN) invites applications for the position of Research Engineer II. Key Responsibilities: Data Engineer (Big Data &amp; IoT) for Data fusion project Job Requirements: Masters from a reputed institute Must have a minimum 4 years of hands-on experience in building the data pipeline using Python, Kafka &amp; Spark Must have solid concepts on IoT &amp; Sensors Must have experience in pulling data from Gateways / Edge Devices Must have done minimum 2 end to end Big Data Pipeline implementations, either on cloud or on-premise Experience in configuring or developing custom code components for data ingestion, data processing, and data provisioning, using Big data &amp; distributed computing platforms such as Python Spark, and Cloud platforms such as AWS or Azure. Must have hands-on knowledge of Spark RDD, DataFrame, MLLib and Streaming API Must have solid experience in advance python programming Knowledge of Python ML will be an added advantage Proficiency in data modelling, for both structured and unstructured data, for various layers of storage Must have ability to collaborate closely with business analysts, architects, and client stakeholders to create technical specifications. Must have expertise in building the CI / CD Pipeline &amp; Automatics deployment of jobs Skills and Proficiency Solid Python Programming skills Spark, Kafka, Spark RDD, Streaming API Pandas, Numpy, MatplotLib, Scikit-learn Git-lab, CI / CD Pipeline Docker Excellent Communication Skills We regret that only shortlisted candidates will be notified.",https://www.jobstreet.com.sg/en/job/research-engineer-ii-%5Bbig-data-iot%5D-worknow-jobsthatmatter-seekbetter-10523057?jobId=jobstreet-sg-job-10523057&sectionRank=37&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
37,Research Engineer II (Computer Science/Electrical Engineering) #JobsThatMatter #LetsGoToWork #UrgentHire,Nanyang Technological University,"undefinedThe Energy Research Institute NTU (ERIAN) invites applications for the position of Research Engineer II. Key Responsibilities: Data Engineer (Big Data &amp; IoT) for Data fusion project Job Requirements: B.E. / B.Tech / MTech (Computer Science/Electrical Engineering) from a reputed institute Must have a minimum 3 years of hands-on experience in building the data pipeline using Python, Kafka &amp; Spark Must have solid concepts on IoT &amp; Sensors Must have experience in pulling data from Gateways / Edge Devices Must have done minimum 2 end to end Big Data Pipeline implementations, either on cloud or on-premise Experience in configuring or developing custom code components for data ingestion, data processing, and data provisioning, using Big data &amp; distributed computing platforms such as Python Spark, and Cloud platforms such as AWS or Azure. Must have hands-on knowledge of Spark RDD, DataFrame, MLLib and Streaming API Must have solid experience in advance python programming Knowledge of Python ML will be an added advantage Proficiency in data modelling, for both structured and unstructured data, for various layers of storage Must have ability to collaborate closely with business analysts, architects, and client stakeholders to create technical specifications. Must have expertise in building the CI / CD Pipeline &amp; Automatics deployment of jobs Skills and Proficiency Solid Python Programming skills Spark, Kafka, Spark RDD, Streaming API Pandas, Numpy, MatplotLib, Scikit-learn Git-lab, CI / CD Pipeline Docker Excellent Communication Skills ​We regret that only shortlisted candidates will be notified.",https://www.jobstreet.com.sg/en/job/research-engineer-ii-computer-science-electrical-engineering-jobsthatmatter-letsgotowork-urgenthire-10525150?jobId=jobstreet-sg-job-10525150&sectionRank=38&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
38,"Data Engineer, Growth #Urgent --| #LetsGoToWork #JobsThatMatter",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. The Growth team plays a core role in acquisition, activation, and retention of billions of users, through our globally popular products such as TikTok, Resso, CapCut, Helo, etc. We are building platform foundation, leveraging data and ML models, and providing end-to-end solutions to power global growth of ByteDance products. Typical Growth projects including referral, notifications, paid ads, etc. You will: Build data pipelines to portray business status, based on a deep understanding of our fast changing business and data-driven approach; Extract information and signals from a broad range of data and build hierarchies to accomplish analytical and mining goals for “Packaged Business Capability” such as user-growth, gaming and searching; Keep improving the integrity of data pipelines to provide a comprehensive data service. Qualifications: Bachelor's degree in Computer Science, Statistic, Data Science or a related field; Skilled in SQL and additional object-oriented programming language (e.g. Scala, Java, or Python); Experience in issue tracking and problem solving on data pipelines; Fast business understanding and collaborative in teamwork.",https://www.jobstreet.com.sg/en/job/data-engineer-growth-urgent-%7C-letsgotowork-jobsthatmatter-10518563?jobId=jobstreet-sg-job-10518563&sectionRank=39&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
39,Big Data Engineer - Recommendation Architecture #Urgent #Seekbetter,TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications: Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability Willing to challenge questions that have no obvious answers, and have a strong enthusiasm for learning new technologies Experience of Peta Byte level data processing is a plus At least 3 years of relevant experience TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-urgent-seekbetter-10520041?jobId=jobstreet-sg-job-10520041&sectionRank=40&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
40,"Research Engineer II, - (Big Data &amp; IoT), [R00009221] #UrgentHire",Nanyang Technological University,"The Energy Research Institute NTU (ERIAN) invites applications for the position of Research Engineer II. Key Responsibilities: Data Engineer (Big Data &amp; IoT) for Data fusion project Job Requirements: Masters from a reputed institute Must have a minimum 4 years of hands-on experience in building the data pipeline using Python, Kafka &amp; Spark Must have solid concepts on IoT &amp; Sensors Must have experience in pulling data from Gateways / Edge Devices Must have done minimum 2 end to end Big Data Pipeline implementations, either on cloud or on-premise Experience in configuring or developing custom code components for data ingestion, data processing, and data provisioning, using Big data &amp; distributed computing platforms such as Python Spark, and Cloud platforms such as AWS or Azure. Must have hands-on knowledge of Spark RDD, DataFrame, MLLib and Streaming API Must have solid experience in advance python programming Knowledge of Python ML will be an added advantage Proficiency in data modelling, for both structured and unstructured data, for various layers of storage Must have ability to collaborate closely with business analysts, architects, and client stakeholders to create technical specifications. Must have expertise in building the CI / CD Pipeline &amp; Automatics deployment of jobs Skills and Proficiency Solid Python Programming skills Spark, Kafka, Spark RDD, Streaming API Pandas, Numpy, MatplotLib, Scikit-learn Git-lab, CI / CD Pipeline Docker Excellent Communication Skills We regret that only shortlisted candidates will be notified. Hiring Institution: NTU In line with Singapore’s nationwide Vaccination-Differentiated Safe Management Measures (VDS), employees must be fully vaccinated to return to the workplace, unless certified to be medically ineligible. For Information on VDS, please click here.",https://www.jobstreet.com.sg/en/job/research-engineer-ii-big-data-iot-%5Br00009221%5D-urgenthire-10519159?jobId=jobstreet-sg-job-10519159&sectionRank=41&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
41,"Assistant Director (Data Engineer), Applications of Teaching and Learning Analytics for Students",Nanyang Technological University,"The NTU education strategy 2025 is leveraging learning analytics to improve teaching and learning. This data engineer position would be critical in ensuring that we are able to achieve our learning analytics strategies and milestones on time. The role will report to Head of Applications of Teaching and Learning Analytics for Students (ATLAS@NTU) under the Institute for Pedagogical Innovation, Research &amp; Excellence (InsPIRE) and dotted line to Centre for IT Services (CITS) - InfraComm Infrastructure. The incumbent is responsible for supporting the learning analytics efforts at the university. The candidate plays an instrumental role in building an educational data hub with Denodo and the implementation of a new platform to manage machine leaning models. Key Responsibilities: Propose effective ways to continuously enhance data quality, governance and performance of educational data hub and data science machine learning platform. Deploy, fine-tune and maintain Learning Analytics models Review the development of Learning Analytics models Manage the education data hub that is based on Denodo Address technical issues relating to the education data hub, dashboards and applications Organise learning analytics ethics committee meetings Involve in planning activities within InsPIRE and CITS. Requirements: At least a bachelor’s in computer science, software or computer engineering, applied math, physics, statistics, or a related field. At least 7 years of work experience, including at least 5 years in of technical experience in data virtualisation, data science platform, Cloud AI/ML technologies and data governance. Certification in any analytic platform (such as Azure, AWS, Denodo, etc.) would be a bonus. Proactive in identifying gaps and proposing solutions Team player (willing to collaborate with others in their work, learn on the job, and support other cross department initiatives when needed) Hiring Institution: NTU",https://www.jobstreet.com.sg/en/job/assistant-director-data-engineer-applications-of-teaching-and-learning-analytics-for-students-10509273?jobId=jobstreet-sg-job-10509273&sectionRank=42&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
42,Data Engineer,Biofourmis Singapore Pte. Ltd.,"Roles &amp; Responsibilities Responsibilities: Creation and maintenance of optimal Data lake pipeline architectures. Stay abreast of industry trends and enable successful data solutions by leveraging best practices. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability. Partnering effectively with inhouse Products, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources and AWS ‘big data’ technologies. Assemble large, complex data sets that meet functional / non-functional business requirements. Keep our data separated and secure within national boundaries through multiple AWS regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader Experience / Training: 7+ years of experience in software engineering and Big Data Analytics. Prior experience on AWS cloud services EC2, Glue, Athena, S3, EKS, RDS, Redshift, Data pipeline, EMR, DynamoDB, cloud watch. Experience in creating and maintain Data lake on AWS cloud. Experience in Big Data analytics tools like Hadoop, Spark, Kafka etc. Strong experience in collecting data from different source systems and create ETL pipelines to handle complex data sets &amp; uncertain schema changes in data. Strong experience in Python programming and analytics libraries like Pandas, NumPy etc... Strong experience on Analytics skills and complex SQL based queries implementation. Data engineer also need to very passionate about efficient/accurate code development, optimizing performance of organization Data lake. Good experience in UNIX based shell scripting. Support to Data scientist team for data availability, extract &amp; provide required data sets. Coordinating with various teams and clients to provide data based on specific requirements. Education: Bachelor/Master/Engineering in IT/Computer science/software engineering or relevant experience.",https://www.jobstreet.com.sg/en/job/data-engineer-10517799?jobId=jobstreet-sg-job-10517799&sectionRank=43&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
43,"Data Engineer Intern, Growth #Urgent*#JobsThatMatter",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. The Growth team plays a core role in acquisition, activation, and retention of billions of users, through our globally popular products such as TikTok, Resso, CapCut, Helo, etc. We are building platform foundation, leveraging data and ML models, and providing end-to-end solutions to power global growth of our products. Typical Growth projects include referral, notifications, paid ads, etc. Responsibilities Build data pipelines and reports to portray business status, based on a deep understanding of our fast changing business with data-driven approaches; Extract information and signals from a broad range of data and build hierarchies to accomplish analytical and mining goals for “Packaged Business Capability” such as growth, gaming and search; Continually improve the integrity of data pipelines to provide a comprehensive data service. Qualifications Undergraduate, or Postgraduate who is currently pursuing a degree/master in Engineering, Computer Science, Statistics, Data Science or a related technical discipline from a university; Experience in SQL and an additional object-oriented programming language (e.g., Python, Java, or Scala); Experience in issue tracking and problem-solving on data pipelines; Strong analytical thinking and exceptional attention to details.",https://www.jobstreet.com.sg/en/job/data-engineer-intern-growth-urgent*-jobsthatmatter-10516359?jobId=jobstreet-sg-job-10516359&sectionRank=44&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
44,Data Engineer - Video Infrastructure #Immediate #JobsThatMatter,TikTok,"Responsibilities Video Infrastructure is a world-leading video platform that provides multi-media storage, delivery, transcoding, and streaming services. We are building the next generation video processing platform and the largest live streaming network, which provides excellent experiences for billions of users around the world. Popular video products of TikTok and its affiliates are all empowered by our cutting-edge cloud technologies. Working in this team, you will have the opportunity to tackle challenges of large-scale networks all over the world, while leveraging your expertise in coding, algorithms, complexity analysis, and large-scale system design. Responsibilities: Craft optimal data processing architecture and systems for new data and ETL pipelines. Design, build, and maintain efficient and reliable data pipelines to move and transform data (both large and small amounts). Drive internal process improvements and automate manual processes for data quality and SLA management. Work with different cross-functional partners including CDN, Video Understanding, Video Transcoding, Live Streaming, and Real-Time Communication. Qualifications: Bachelor's degree in Computer Science or a related technical background involving software/system engineering, or equivalent working experience. Good programming experience with at least one of the following languages: C, C++, Java, Python, or Go. Experience in custom ETL/data pipeline design, implementation, and maintenance. Experience with data processing software (Hadoop, Spark, Pig, Hive) and algorithms (MapReduce, Flume). Experience in troubleshooting in large scale distributed systems.",https://www.jobstreet.com.sg/en/job/data-engineer-video-infrastructure-immediate-jobsthatmatter-10516406?jobId=jobstreet-sg-job-10516406&sectionRank=45&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
45,"Big Data Engineer, Recommendation Architecture #Immediate",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-immediate-10516216?jobId=jobstreet-sg-job-10516216&sectionRank=46&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
46,"Research Associate, - [Computer Science/IT] - [R00007075] #Seekbetter#WorkNow",Nanyang Technological University,"A Research Associate position is currently available in the College of Business, Nanyang Business School. We are looking for an experienced data engineer to join our team and you will use various methods to transform raw data into useful data systems. This includes developing algorithms and conducting statistical analysis. Overall, your goal is to develop data systems in alignment with business goals. To succeed in this data engineering position, you should have strong analytical skills and the ability to integrate data /data streams from different sources. Data engineer skills also include familiarity with apt programming langus and knowledge of machine learning methods. If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear from you. Job Responsibilities Co-evaluate business needs and objectives Identify opportunities for data acquisition Build data systems and pipelines Build algorithms and prototypes Analyze and organize raw data Interpret trends and patterns Conduct data analysis, working independently or with data analysts, and report on results Prepare data for prescriptive and predictive modeling Combine raw information from different sources Explore ways to enhance data quality and reliability Develop analytical tools and programs Collaborate with data scientists and architects Job Requirements ﻿ Master in Computer Science, IT, or similar field Previous experience as a data engineer or in a similar role Technical expertise with data models, data mining, and segmentation techniques Knowledge of programming langus (e.g. Java and Python) Hands-on experience with SQL database design Great numerical and analytical skills We regret to inform that only shortlisted candidates will be notified.",https://www.jobstreet.com.sg/en/job/research-associate-%5Bcomputer-science-it%5D-%5Br00007075%5D-seekbetter-worknow-10517330?jobId=jobstreet-sg-job-10517330&sectionRank=47&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
47,Data Engineer (E-Commerce) - 2023 Start #Seekbetter - #JobsThatMatter #UrgentHire,TikTok,"Responsibilities TikTok will be prioritizing applicants who have a current right to work in Singapore, and do not require TikTok's sponsorship of a visa. TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. Why Join Us At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok. We are looking for talented individuals to join us for this future position in 2023. As a graduate, you will get unparalleled opportunities for you to kickstart your career, pursue bold ideas and explore limitless growth opportunities. Co-create a future driven by your inspiration with TikTok. Candidates can apply to a maximum of two positions and will be considered for jobs in the order you apply. The application limit is applicable to all TikTok and its affiliates' jobs globally. Applications will be reviewed on a rolling basis - we encourage you to apply early. About the team The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Responsibilities Translate business requirements &amp; end-to-end designs into technical implementations and responsible for building batch and real-time data warehouse; Manage data modeling design, writing and optimizing ETL jobs - collaborate with business teams to build data metrics based on data warehouse; Responsible for building and maintaining data products; Involvement in rollouts, upgrades, implementation and release of data system changes as required for streamlining of internal practices. Qualifications Final year or entry level with a background in Software Development, Computer Science, Computer Engineering, or a related technical discipline; Solid computer basic knowledge (e.g. data structure &amp; algorithms, SQL and networks); Strong coding capabilities and mastering at least one programming language (e.g. C/C++/Java/Python/Golang); Passionate about data warehouse, ETL development, data analysis and eCommerce; Good communication skills and a fast learner of new business and technology knowledge. TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https://careers.tiktok.com/legal/privacy.",https://www.jobstreet.com.sg/en/job/data-engineer-e-commerce-2023-start-seekbetter-jobsthatmatter-urgenthire-10517089?jobId=jobstreet-sg-job-10517089&sectionRank=48&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
48,Research Fellow [Computer Science/IT] (R00006578) - #JobsThatMatter -#UrgentHire #Worknow,Nanyang Technological University,"A Research Fellow position is currently available in the College of Business, Nanyang Business School. We are looking for an experienced data engineer to join our team and you will use various methods to transform raw data into useful data systems. This includes developing algorithms and conducting statistical analysis. Overall, your goal is to develop data systems in alignment with business goals. Job Responsibilities Co-evaluate business s and objectives Identify opportunities for data acquisition Build data systems and pipelines Build algorithms and prototypes Analyze and organize raw data Interpret trends and patterns Conduct data analysis, working independently or with data analysts, and report on results Prepare data for prescriptive and predictive modeling Combine raw information different sources Explore ways to enhance data quality and reliability Develop analytical tools and programs Collaborate with data scientists and architects Job Requirements Minimally Phd degree in Computer Science, IT, or similar field Candidates with a Masters Degree with more than 6 years of relevant experience post Masters-degree are also welcome to apply Previous experience as a data engineer or in a similar role Technical expertise with data models, data mining, and segmentation techniques Knowledge of programming languages (e.g. Java and Python) Hands-on experience with SQL database design Great numerical and analytical skills Ability to integrate data /data streams different sources Familiarity with apt programming languages and knowledge of machine learning methods If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear you. We regret to inform that only shortlisted candidates will be ified.",https://www.jobstreet.com.sg/en/job/research-fellow-%5Bcomputer-science-it%5D-r00006578-jobsthatmatter-urgenthire-worknow-10509307?jobId=jobstreet-sg-job-10509307&sectionRank=49&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
49,Research Fellow [Computer Science/IT] [R00006578] - #JobsThatMatter -#UrgentHire #Worknow,Nanyang Technological University,"A Research Fellow position is currently available in the College of Business, Nanyang Business School. We are looking for an experienced data engineer to join our team and you will use various methods to transform raw data into useful data systems. This includes developing algorithms and conducting statistical analysis. Overall, your goal is to develop data systems in alignment with business goals. Job Responsibilities Co-evaluate business s and objectives Identify opportunities for data acquisition Build data systems and pipelines Build algorithms and prototypes Analyze and organize raw data Interpret trends and patterns Conduct data analysis, working independently or with data analysts, and report on results Prepare data for prescriptive and predictive modeling Combine raw information different sources Explore ways to enhance data quality and reliability Develop analytical tools and programs Collaborate with data scientists and architects Job Requirements Minimally Phd degree in Computer Science, IT, or similar field Candidates with a Masters Degree with more than 6 years of relevant experience post Masters-degree are also welcome to apply Previous experience as a data engineer or in a similar role Technical expertise with data models, data mining, and segmentation techniques Knowledge of programming languages (e.g. Java and Python) Hands-on experience with SQL database design Great numerical and analytical skills Ability to integrate data /data streams different sources Familiarity with apt programming languages and knowledge of machine learning methods If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear you. We regret to inform that only shortlisted candidates will be ified.",https://www.jobstreet.com.sg/en/job/research-fellow-%5Bcomputer-science-it%5D-%5Br00006578%5D-jobsthatmatter-urgenthire-worknow-10509310?jobId=jobstreet-sg-job-10509310&sectionRank=50&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
50,"Research Engineer II, - (Big Data &amp; IoT) - [R00009221] #Immediate",Nanyang Technological University,"The Energy Research Institute NTU (ERIAN) invites applications for the position of Research Engineer II. Key Responsibilities: Data Engineer (Big Data &amp; IoT) for Data fusion project Job Requirements: Masters from a reputed institute Must have a minimum 4 years of hands-on experience in building the data pipeline using Python, Kafka &amp; Spark Must have solid concepts on IoT &amp; Sensors Must have experience in pulling data from Gateways / Edge Devices Must have done minimum 2 end to end Big Data Pipeline implementations, either on cloud or on-premise Experience in configuring or developing custom code components for data ingestion, data processing, and data provisioning, using Big data &amp; distributed computing platforms such as Python Spark, and Cloud platforms such as AWS or Azure. Must have hands-on knowledge of Spark RDD, DataFrame, MLLib and Streaming API Must have solid experience in advance python programming Knowledge of Python ML will be an added advantage Proficiency in data modelling, for both structured and unstructured data, for various layers of storage Must have ability to collaborate closely with business analysts, architects, and client stakeholders to create technical specifications. Must have expertise in building the CI / CD Pipeline &amp; Automatics deployment of jobs Skills and Proficiency Solid Python Programming skills Spark, Kafka, Spark RDD, Streaming API Pandas, Numpy, MatplotLib, Scikit-learn Git-lab, CI / CD Pipeline Docker Excellent Communication Skills We regret that only shortlisted candidates will be notified. Hiring Institution: NTU In line with Singapore’s nationwide Vaccination-Differentiated Safe Management Measures (VDS), employees must be fully vaccinated to return to the workplace, unless certified to be medically ineligible. For Information on VDS, please click here.",https://www.jobstreet.com.sg/en/job/research-engineer-ii-big-data-iot-%5Br00009221%5D-immediate-10516604?jobId=jobstreet-sg-job-10516604&sectionRank=51&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
51,"Assistant Director (Data Engineer), Applications of Teaching and Learning Analytics for Students - R00012552",Nanyang Technological University,"The NTU education strategy 2025 is leveraging learning analytics to improve teaching and learning. This data engineer position would be critical in ensuring that we are able to achieve our learning analytics strategies and milestones on time. The role will report to Head of Applications of Teaching and Learning Analytics for Students (ATLAS@NTU) under the Institute for Pedagogical Innovation, Research &amp; Excellence (InsPIRE) and dotted line to Centre for IT Services (CITS) - InfraComm Infrastructure. The incumbent is responsible for supporting the learning analytics efforts at the university. The candidate plays an instrumental role in building an educational data hub with Denodo and the implementation of a new platform to manage machine leaning models. Key Responsibilities: Propose effective ways to continuously enhance data quality, governance and performance of educational data hub and data science machine learning platform. Deploy, fine-tune and maintain Learning Analytics models Review the development of Learning Analytics models Manage the education data hub that is based on Denodo Address technical issues relating to the education data hub, dashboards and applications Organise learning analytics ethics committee meetings Involve in planning activities within InsPIRE and CITS. Requirements: At least a bachelor’s in computer science, software or computer engineering, applied math, physics, statistics, or a related field. At least 7 years of work experience, including at least 5 years in of technical experience in data virtualisation, data science platform, Cloud AI/ML technologies and data governance. Certification in any analytic platform (such as Azure, AWS, Denodo, etc.) would be a bonus. Proactive in identifying gaps and proposing solutions Team player (willing to collaborate with others in their work, learn on the job, and support other cross department initiatives when needed)",https://www.jobstreet.com.sg/en/job/assistant-director-data-engineer-applications-of-teaching-and-learning-analytics-for-students-r00012552-10511284?jobId=jobstreet-sg-job-10511284&sectionRank=52&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
52,"5 x Data Engineer (Up to $10,000, Perm) - Ref: FC",Search Index Pte Ltd,"Government-Linked Company Lead Multi-Million projects with Top Companies Up to $10,000 monthly salary + Competitive Bonus Multiple Permanent Positions Available Responsibilities Work with Product, Data Science and Business groups to gather data requirements Translate data requirements into technical specifications and documentation Design and implement reliable, scalable, robust and extensible big data systems Extract, transform and load (ETL) various data sources into Data Lake Design, execute and automate ETL jobs Contribute to data architecture standards and coding conventions Requirement Bachelor’s degree in Computer Science, Software Engineering or a related field 3-4 years of experience in managing data warehouse or data engineering systems Proficient in programming and scripting language (e.g. SQL, Python, Java/Scala, Golang). Experience with ETL (Extraction, Transformation &amp; Loading) and architecting data systems Hands-on experience with any of the cloud-based systems eg: Snowflake, GCP, AWS and Azure Familiarity with working on Big Data technologies like Spark, Kafka, and distributed system. Ability to explain technical solutions to the business users and partners Salary will commensurate according to Candidates’ Work Experience &amp; Qualifications To apply for this job opportunity, click on APPLY NOW. We regret that only short-listed candidates will be contacted shortly. EA License No: 14C7092 EA Registration No: R2199193 (Frieda Chan)",https://www.jobstreet.com.sg/en/job/5-x-data-engineer-up-to-%2410-000-perm-ref%3A-fc-10495804?jobId=jobstreet-sg-job-10495804&sectionRank=53&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
53,"Big Data Engineer, Recommendation Architecture",BYTEDANCE PTE. LTD.,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-10496046?jobId=jobstreet-sg-job-10496046&sectionRank=54&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
54,Big Data Engineer - Recommendation Architecture,BYTEDANCE PTE. LTD.,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability Willing to challenge questions that have no obvious answers, and have a strong enthusiasm for learning new technologies Experience of Peta Byte level data processing is a plus At least 3 years of relevant experience TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-10496070?jobId=jobstreet-sg-job-10496070&sectionRank=55&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
55,Data Engineer,Illumina Singapore Pte Ltd,"What if the work you did every day could impact the lives of people you know? Or all of humanity? At Illumina, we are expanding access to genomic technology to realize health equity for billions of people around the world. Our efforts enable life-changing discoveries that are transforming human health through the early detection and diagnosis of diseases and new treatment options for patients. Working at Illumina means being part of something bigger than yourself. Every person, in every role, has the opportunity to make a difference. Surrounded by extraordinary people, inspiring leaders, and world changing projects, you will do more and become more than you ever thought possible. What if the work you did every day could impact the lives of people you know? Or all of humanity? At Illumina, we are expanding access to genomic technology to realize health equity for billions of people around the world. Our efforts enable life-changing discoveries that are transforming human health through the early detection and diagnosis of diseases and new treatment options for patients. Working at Illumina means being part of something bigger than yourself. Every person, in every role, has the opportunity to make a difference. Surrounded by extraordinary people, inspiring leaders, and world-changing projects, you will do more and become more than you ever thought possible. Position Summary: This position works closely with the software engineers, data scientists and manufacturing supervisors. The ideal candidate for this position will be responsible for delivering data needs of consumables manufacturing department. Requires attention to detail when making judgments and recommendations based on the analysis of information. Applies professional judgment when interpreting data and results. You will be required to constantly learn/explore new front tier technology and innovatively apply/deliver solutions to Manufacturing operation. Responsibilities: Design, implement and maintain data pipelines in existing system Understand business requirement and solution design to cater enterprise level data needs Fine tuning of new and existing data pipelines To help in building scalable and robust data infrastructure to support business continuity and operation excellence Demonstrates attention to quality and timeliness of service to ensure the effectiveness of the team Applies analytical thinking and knowledge of data analysis tools and methodologies. Communicate and collaborate with product and software development teams to understand and deliver optimal data solution Listed responsibilities are an essential, but not exhaustive list, of the usual duties associated with the position. Changes to individual responsibilities may occur due to business needs. Requirements: Bachelor’s Degree in IT, Software Development, Computer Science, Computer Engineering, or a related technical discipline with 3-4 years of experience in managing data warehouse or data engineering systems. Experience in relational databases like MS SQL server, Oracle, MySQL. Able to code data engineering flows in C#, Python, or any programming language. Hands-on experience with any of the cloud-based systems viz. Snowflake, GCP, AWS and Azure. Familiarity with working on Big Data technologies like Spark, Kafka, and distributed system. Ability to communicate clearly and effectively. Ability to explain technical information in business terms. Strong in User Requirement Gathering, Maintenance and Support. High level of discipline and integrity. Willing to undertake multiple tasks. Possess a positive attitude and sense of urgency. Meticulous, keen attention to details and organized. All listed requirements are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional task and responsibilities. Illumina believes that everyone has the ability to make an impact, and we are proud to be an equal opportunity employer committed to providing employment opportunity regardless of , race, creed, color, gender, religion, marital status, domestic partner status, age, national origin or ancestry, physical or mental disability, medical condition, sexual orientation, pregnancy, military or veteran status, citizenship status, and genetic information.",https://www.jobstreet.com.sg/en/job/data-engineer-10511121?jobId=jobstreet-sg-job-10511121&sectionRank=56&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
56,Data Engineer,Sourcebynet,"Job Description Data Engineer (AWS/AZURE) In this role, the Data Engineer will be exposed to many aspects of data collection and data pipeline to serve stakeholders requirements. Stakeholders can range from Business Analysts, Product Analysts, Data Analyst to Data Scientists who need datasets for modelling, visualization and decision making. The Data Engineer should have a proven track record of delivering data pipeline solutions and architecture. He/She should also understand business requirement and able to build reliable data infrastructure using big data technologies. Ideally, you are someone who enjoys optimizing data pipeline, automating and building from scratch. Responsibilities: Expanding data collection as well as optimizing data pipelines for cross-functional teams Work closely with data analysts and business end-users to implement and support data platforms Tuning, troubleshooting and scaling identified big data technologies. Analyse, tackle and resolve day-to-day operational incidents related to data provision Build suitable tools to provide data through acquiring, monitoring and analyzing root cause of data issues Identify, design, and implement process improvements and tools to automate data processing with data integrity Work with data scientist and business analytics to assist in data ingestion and data-related technical issues Design, build and maintain the batch or real time data pipeline in production using big data technology Design, build and manage data warehouse such as designing data model Create data views from big data platform to feed into analysis engines or visualization engines Requirement: Bachelor degree in Computer Science, Computer Engineering, Software Engineering or equivalent At least 2 years of relevant working experience in ETL/data integration and data modelling Experience with Data Engineering and Data Quality Cloud experience, ideally with Azure and AWS Understanding of Big data technologies like HDFS, Hive, Spark Experience of relational or NoSQL database (e.g. Oracle) and using database technologies (PL/SQL, SQL) Experience in data warehousing / distributed system Experience in data ingestion, cleaning and processing tools Experience in data acquiring, data processing using Scala/Python/Java",https://www.jobstreet.com.sg/en/job/data-engineer-10500815?jobId=jobstreet-sg-job-10500815&sectionRank=57&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
57,"Research Associate (Computer Science/IT), [R00007075] #Urgent |- #LetsGoToWork #JobsThatMatter",Nanyang Technological University,"A Research Associate position is currently available in the College of Business, Nanyang Business School. We are looking for an experienced data engineer to join our team and you will use various methods to transform raw data into useful data systems. This includes developing algorithms and conducting statistical analysis. Overall, your goal is to develop data systems in alignment with business goals. To succeed in this data engineering position, you should have strong analytical skills and the ability to integrate data /data streams from different sources. Data engineer skills also include familiarity with apt programming langus and knowledge of machine learning methods. If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear from you. Job Responsibilities Co-evaluate business needs and objectives Identify opportunities for data acquisition Build data systems and pipelines Build algorithms and prototypes Analyze and organize raw data Interpret trends and patterns Conduct data analysis, working independently or with data analysts, and report on results Prepare data for prescriptive and predictive modeling Combine raw information from different sources Explore ways to enhance data quality and reliability Develop analytical tools and programs Collaborate with data scientists and architects Job Requirements Master in Computer Science, IT, or similar field Previous experience as a data engineer or in a similar role Technical expertise with data models, data mining, and segmentation techniques Knowledge of programming langus (e.g. Java and Python) Hands-on experience with SQL database design Great numerical and analytical skills We regret to inform that only shortlisted candidates will be notified.",https://www.jobstreet.com.sg/en/job/research-associate-computer-science-it-%5Br00007075%5D-urgent-%7C-letsgotowork-jobsthatmatter-10501746?jobId=jobstreet-sg-job-10501746&sectionRank=58&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
58,Research Associate (Computer Science/IT) - [R00007075] | #LetsGoToWork#UrgentHire,Nanyang Technological University,"A Research Associate position is currently available in the College of Business, Nanyang Business School. We are looking for an experienced data engineer to join our team and you will use various methods to transform raw data into useful data systems. This includes developing algorithms and conducting statistical analysis. Overall, your goal is to develop data systems in alignment with business goals. To succeed in this data engineering position, you should have strong analytical skills and the ability to integrate data /data streams from different sources. Data engineer skills also include familiarity with apt programming langus and knowledge of machine learning methods. If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear from you. Job Responsibilities Co-evaluate business needs and objectives Identify opportunities for data acquisition Build data systems and pipelines Build algorithms and prototypes Analyze and organize raw data Interpret trends and patterns Conduct data analysis, working independently or with data analysts, and report on results Prepare data for prescriptive and predictive modeling Combine raw information from different sources Explore ways to enhance data quality and reliability Develop analytical tools and programs Collaborate with data scientists and architects Job Requirements Master in Computer Science, IT, or similar field Previous experience as a data engineer or in a similar role Technical expertise with data models, data mining, and segmentation techniques Knowledge of programming langus (e.g. Java and Python) Hands-on experience with SQL database design Great numerical and analytical skills We regret to inform that only shortlisted candidates will be notified.",https://www.jobstreet.com.sg/en/job/research-associate-computer-science-it-%5Br00007075%5D-%7C-letsgotowork-urgenthire-10503460?jobId=jobstreet-sg-job-10503460&sectionRank=59&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
59,Data Architect - 12 Months Contract,Morgan McKinley,"As a Data Engineering Architect , you will use comprehensive modern data engineer techniques and methods with Advanced Analytics to support business decisions for client. Your goal is to support the use of data-driven insights to help our Clients achieve business outcomes and objectives. Responsibilities Translate business requirements to technical solutions leveraging strong business acumen. Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data &amp; Analytics PaaS Services. Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments. Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies. Design and Build Modern Data Pipelines, Data Streams and Data Service APIs Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics. Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience. Implement effective metrics and monitoring processes. Must Haves:- Experience in Database Architecture Microsoft SQL Server Integration Services SSIS Data Modeling Techniques and Methodologies Data &amp; AI Strategy Extract Transform and Load (ETL) Microsoft SQL Server Analysis Services (SSAS) Mastery of .NET C# and T-SQL with the familiarity of U-SQL is required Knowledge of Azure Data Factory, Azure Data Lake, Azure SQL DW, and Azure SQL, Azure App Service is required. Experience with Git/TFS/VSTS is a must. Ideal Requirements Python, Azure IoT, Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics is a plus. Experience preparing data for use in Azure Machine Learning and/or Azure Databricks is a plus. *** Very competitive salary awaits successful candidate. Only shortlisted candidate will be notified. Morgan McKinley Pte Ltd Koh Boon Sien EA Licence No: 11C5502 EA Registration No. R1110345",https://www.jobstreet.com.sg/en/job/data-architect-12-months-contract-10485104?jobId=jobstreet-sg-job-10485104&sectionRank=60&token=0~0fe51df3-ab7f-44cb-8dab-c33d8f2d2aff&fr=SRP%20Job%20Listing
60,"Research Fellow, - (Computer Science/IT) - (R00006578) -#UrgentHire |- #LetsGoToWork -- #JobsThatMatter",Nanyang Technological University,"A Research Fellow position is currently available in the College of Business, Nanyang Business School. We are looking for an experienced data engineer to join our team and you will use various methods to transform raw data into useful data systems. This includes developing algorithms and conducting statistical analysis. Overall, your goal is to develop data systems in alignment with business goals. Job Responsibilities Co-evaluate business s and objectives Identify opportunities for data acquisition Build data systems and pipelines Build algorithms and prototypes Analyze and organize raw data Interpret trends and patterns Conduct data analysis, working independently or with data analysts, and report on results Prepare data for prescriptive and predictive modeling Combine raw information different sources Explore ways to enhance data quality and reliability Develop analytical tools and programs Collaborate with data scientists and architects Job Requirements Minimally Phd degree in Computer Science, IT, or similar field Candidates with a Masters Degree with more than 6 years of relevant experience post Masters-degree are also welcome to apply Previous experience as a data engineer or in a similar role Technical expertise with data models, data mining, and segmentation techniques Knowledge of programming languages (e.g. Java and Python) Hands-on experience with SQL database design Great numerical and analytical skills Ability to integrate data /data streams different sources Familiarity with apt programming languages and knowledge of machine learning methods If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear you. We regret to inform that only shortlisted candidates will be ified.",https://www.jobstreet.com.sg/en/job/research-fellow-computer-science-it-r00006578-urgenthire-%7C-letsgotowork-jobsthatmatter-10503575?jobId=jobstreet-sg-job-10503575&sectionRank=61&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
61,Research Engineer II (Big Data &amp; IoT) [R00009221] #Immediate#Seekbetter,Nanyang Technological University,"The Energy Research Institute at NTU (ERIAN) invites applications for the position of Research Engineer II. Key Responsibilities: Data Engineer (Big Data &amp; IoT) for Data fusion project Job Requirements: Masters from a reputed institute Must have a minimum 4 years of hands-on experience in building the data pipeline using Python, Kafka &amp; Spark Must have solid concepts on IoT &amp; Sensors Must have experience in pulling data from Gateways / Edge Devices Must have done minimum 2 end to end Big Data Pipeline implementations, either on cloud or on-premise Experience in configuring or developing custom code components for data ingestion, data processing, and data provisioning, using Big data &amp; distributed computing platforms such as Python Spark, and Cloud platforms such as AWS or Azure. Must have hands-on knowledge of Spark RDD, DataFrame, MLLib and Streaming API Must have solid experience in advance python programming Knowledge of Python ML will be an added advantage Proficiency in data modelling, for both structured and unstructured data, for various layers of storage Must have ability to collaborate closely with business analysts, architects, and client stakeholders to create technical specifications. Must have expertise in building the CI / CD Pipeline &amp; Automatics deployment of jobs Skills and Proficiency Solid Python Programming skills Spark, Kafka, Spark RDD, Streaming API Pandas, Numpy, MatplotLib, Scikit-learn Git-lab, CI / CD Pipeline Docker Excellent Communication Skills We regret that only shortlisted candidates will be notified. Hiring Institution: NTU In line with Singapore’s nationwide Vaccination-Differentiated Safe Management Measures (VDS), employees must be fully vaccinated to return to the workplace, unless certified to be medically ineligible. For Information on VDS, please click here.",https://www.jobstreet.com.sg/en/job/research-engineer-ii-big-data-iot-%5Br00009221%5D-immediate-seekbetter-10500452?jobId=jobstreet-sg-job-10500452&sectionRank=62&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
62,"Research Engineer II, - (Big Data &amp; IoT) [R00009221] -- #UrgentHire #LetsGoToWork",Nanyang Technological University,"The Energy Research Institute NTU (ERIAN) invites applications for the position of Research Engineer II. Key Responsibilities: Data Engineer (Big Data &amp; IoT) for Data fusion project Job Requirements: Masters from a reputed institute Must have a minimum 4 years of hands-on experience in building the data pipeline using Python, Kafka &amp; Spark Must have solid concepts on IoT &amp; Sensors Must have experience in pulling data from Gateways / Edge Devices Must have done minimum 2 end to end Big Data Pipeline implementations, either on cloud or on-premise Experience in configuring or developing custom code components for data ingestion, data processing, and data provisioning, using Big data &amp; distributed computing platforms such as Python Spark, and Cloud platforms such as AWS or Azure. Must have hands-on knowledge of Spark RDD, DataFrame, MLLib and Streaming API Must have solid experience in advance python programming Knowledge of Python ML will be an added advantage Proficiency in data modelling, for both structured and unstructured data, for various layers of storage Must have ability to collaborate closely with business analysts, architects, and client stakeholders to create technical specifications. Must have expertise in building the CI / CD Pipeline &amp; Automatics deployment of jobs Skills and Proficiency Solid Python Programming skills Spark, Kafka, Spark RDD, Streaming API Pandas, Numpy, MatplotLib, Scikit-learn Git-lab, CI / CD Pipeline Docker Excellent Communication Skills We regret that only shortlisted candidates will be notified. Hiring Institution: NTU In line with Singapore’s nationwide Vaccination-Differentiated Safe Management Measures (VDS), employees must be fully vaccinated to return to the workplace, unless certified to be medically ineligible. For Information on VDS, please click here.",https://www.jobstreet.com.sg/en/job/research-engineer-ii-big-data-iot-%5Br00009221%5D-urgenthire-letsgotowork-10505011?jobId=jobstreet-sg-job-10505011&sectionRank=63&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
63,Data Engineer | Yearly Contract | Up to $9500,PERSOLKELLY Singapore Pte Ltd (Formerly Kelly Services Singapore Pte Ltd),"• Translate business requirements to technical solutions leveraging strong business acumen. • Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data &amp; Analytics PaaS Services. • Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments. • Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies. • Design and Build Modern Data Pipelines and Data Streams. • Design and Build Data Service APIs. • Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics. • Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience. • Implement effective metrics and monitoring processes. To Apply Interested candidates, who wish to apply for the above position; please click the "" Apply Now "" below. We regret that only shortlisted applicants would be notified. Yee Hong Ling Emelda | REG No : R22109572 PERSOLKELLY SINGAPORE PTE LTD | EA License No : 01C4394 By sending us your personal data and curriculum vitae (CV), you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its affiliates to collect, use and disclose your personal data for the purposes set out in the Privacy Policy which is available at https://www.persolkelly.com.sg/policies. You also acknowledge that you have read, understood, and agree to the said Privacy Policy.",https://www.jobstreet.com.sg/en/job/data-engineer-%7C-yearly-contract-%7C-up-to-%249500-10481715?jobId=jobstreet-sg-job-10481715&sectionRank=64&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
64,Project Officer (Programmer/Data Engineer) #UrgentHire --| #UrgentHire #LetsGotoWork.,Nanyang Technological University,"The Rehabilitation Research Institute of Singapore (RRIS) invites applications for the position of Project Officer. Key Responsibilities: The successful candidate will work on a research project to implement the core biomechanical analysis plugins on top of the measurement layers from the markerless motion capture system. To have a proper set of features, the job also includes communicating with potential users of the system to find the needs and requirements for the plugin development. Those features may include automatic event detection, normative comparison, self-comparison, and their visualizations. The job also includes the development of a flexible plugin system to allow a third-party developer to develop their own plugin for the analysis layer. The job also includes the development of software to scan through the results from the trained model to find its weakness and regularly perform training data patching or algorithmic patching. Job Requirements: Degree (MS or BS) in Computer Science, Computer Engineering, Electrical/Electronic Engineering, Mechanical Engineering, engineering, or equivalent industry experience. Python programming Experiences in machine learning for image processing with PyTorch Experiences in articulated human modelling or biomechanics Experiences in camera calibration, digital image processing and OpenCV. Experiences in 3D visualization library such as OpenGL, PyOpenGL, or Vispy will be an advantage. Experiences in at least one human motion capture system. We regret that only shortlisted candidates will be notified.",https://www.jobstreet.com.sg/en/job/project-officer-programmer-data-engineer-urgenthire-%7C-urgenthire-letsgotowork.-10497825?jobId=jobstreet-sg-job-10497825&sectionRank=65&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
65,Data Engineer / Architect #Urgent,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills: Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-urgent-10478980?jobId=jobstreet-sg-job-10478980&sectionRank=66&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
66,Data Engineer / Architect #Immediate,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills: Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-immediate-10477937?jobId=jobstreet-sg-job-10477937&sectionRank=67&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
67,Data Engineer / Architect #Urgent #WorkNow,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills: Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-urgent-worknow-10479061?jobId=jobstreet-sg-job-10479061&sectionRank=68&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
68,Data Engineer / Architect #Seekbetter #Urgent,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills: Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-seekbetter-urgent-10479040?jobId=jobstreet-sg-job-10479040&sectionRank=69&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
69,Data Engineer / Architect - #WorkNow #Urgent,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills: Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-worknow-urgent-10477807?jobId=jobstreet-sg-job-10477807&sectionRank=70&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
70,"Research Fellow, - (Computer Science/IT), - [R00006578]",Nanyang Technological University,"A Research Fellow position is currently available in the College of Business, Nanyang Business School. We are looking for an experienced data engineer to join our team and you will use various methods to transform raw data into useful data systems. This includes developing algorithms and conducting statistical analysis. Overall, your goal is to develop data systems in alignment with business goals. Job Responsibilities Co-evaluate business s and objectives Identify opportunities for data acquisition Build data systems and pipelines Build algorithms and prototypes Analyze and organize raw data Interpret trends and patterns Conduct data analysis, working independently or with data analysts, and report on results Prepare data for prescriptive and predictive modeling Combine raw information different sources Explore ways to enhance data quality and reliability Develop analytical tools and programs Collaborate with data scientists and architects Job Requirements Minimally Phd degree in Computer Science, IT, or similar field Candidates with a Masters Degree with more than 6 years of relevant experience post Masters-degree are also welcome to apply Previous experience as a data engineer or in a similar role Technical expertise with data models, data mining, and segmentation techniques Knowledge of programming languages (e.g. Java and Python) Hands-on experience with SQL database design Great numerical and analytical skills Ability to integrate data /data streams different sources Familiarity with apt programming languages and knowledge of machine learning methods If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear you. We regret to inform that only shortlisted candidates will be ified.",https://www.jobstreet.com.sg/en/job/research-fellow-computer-science-it-%5Br00006578%5D-10496875?jobId=jobstreet-sg-job-10496875&sectionRank=71&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
71,Senior Data Engineer,Comfort Transportation Pte Ltd &amp; CityCab Pte Ltd,"In this role, Senior Data Engineer will be exposed to many aspects of data collection and data pipeline to serve stakeholders requirements. Stakeholders can range from Business Analysts, Product Analysts, Data Analyst to Data Scientists who need datasets for modelling, visualization and decision making. The Senior Data Engineer should have a proven track record of delivering data pipeline solutions and architecture. He/She should also understand business requirement and able to build reliable data infrastructure using big data technologies. Ideally, you are someone who enjoys optimizing data pipeline, automating and building from scratch. Responsibilities: Expanding data collection as well as optimizing data pipelines for cross-functional teams Work closely with data analysts and business end-users to implement and support data platforms Tuning, troubleshooting and scaling identified big data technologies. Analyse, tackle and resolve day-to-day operational incidents related to data provision Build suitable tools to provide data through acquiring, monitoring and analyzing root cause of data issues Identify, design, and implement process improvements and tools to automate data processing with data integrity Work with data scientist and business analytics to assist in data ingestion and data-related technical issues Design, build and maintain the batch or real time data pipeline in production using big data technology Design, build and manage data warehouse such as designing data model Create data views from big data platform to feed into analysis engines or visualization engines Requirements: Bachelor degree in Computer Science, Computer Engineering, Software Engineering or equivalent Minimum 2 years of relevant working experience in ETL / data integration and data modelling Experience with Data Engineering and Data Quality Cloud experience, ideally with Azure and AWS Understanding of Big data technologies like HDFS, Hive, Spark Experience of relational or NoSQL database (e.g. Oracle) and using database technologies (PL/SQL, SQL) Experience in data warehousing / distributed system Experience in data ingestion, cleaning and processing tools Experience in data acquiring, data processing using Scala/Python/Java Highly organized, self-motivated, pro-active, and desire to learn new technology",https://www.jobstreet.com.sg/en/job/senior-data-engineer-10476496?jobId=jobstreet-sg-job-10476496&sectionRank=72&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
72,Research Engineer II (Computer Science/Electrical Engineering) #JobsThatMatter -- #LetsGoToWork,Nanyang Technological University,"undefinedThe Energy Research Institute NTU (ERIAN) invites applications for the position of Research Engineer II. Key Responsibilities: Data Engineer (Big Data &amp; IoT) for Data fusion project Job Requirements: B.E. / B.Tech / MTech (Computer Science/Electrical Engineering) from a reputed institute Must have a minimum 3 years of hands-on experience in building the data pipeline using Python, Kafka &amp; Spark Must have solid concepts on IoT &amp; Sensors Must have experience in pulling data from Gateways / Edge Devices Must have done minimum 2 end to end Big Data Pipeline implementations, either on cloud or on-premise Experience in configuring or developing custom code components for data ingestion, data processing, and data provisioning, using Big data &amp; distributed computing platforms such as Python Spark, and Cloud platforms such as AWS or Azure. Must have hands-on knowledge of Spark RDD, DataFrame, MLLib and Streaming API Must have solid experience in advance python programming Knowledge of Python ML will be an added advantage Proficiency in data modelling, for both structured and unstructured data, for various layers of storage Must have ability to collaborate closely with business analysts, architects, and client stakeholders to create technical specifications. Must have expertise in building the CI / CD Pipeline &amp; Automatics deployment of jobs Skills and Proficiency Solid Python Programming skills Spark, Kafka, Spark RDD, Streaming API Pandas, Numpy, MatplotLib, Scikit-learn Git-lab, CI / CD Pipeline Docker Excellent Communication Skills ​We regret that only shortlisted candidates will be notified.",https://www.jobstreet.com.sg/en/job/research-engineer-ii-computer-science-electrical-engineering-jobsthatmatter-letsgotowork-10497646?jobId=jobstreet-sg-job-10497646&sectionRank=73&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
73,DATA ENGINEER,Paradigm Recruitment Pte. Ltd.,"Our clients Local IT homeland security provider that has more than 20 years of presence in the industry Highlights Competitive compensation structure Great team working environment Responsibility Assisting in maintaining system data, setup, installation and configurations Responsible for troubleshooting, upgrading COTS products, Develop and implementing data warehouses improvements and Etc. Handling documents creation and guides for troubleshooting Requirements Possess diploma or degree in Information technology or any relevant discipline. 3 years of working experience in Data engineering or data management Knowledge and or experience in Automation platforms, Programming languages E.g (Python, Spark), Analytics platforms Etc. Interested applicants, please Click on Apply Now or send your CV to kenny.lee(AT)paradigmrecruitment.com.sg We regret to inform you that only shortlisted applicants will be contacted. EA Reg No.: R2199565 // EA License No.: 21C0434",https://www.jobstreet.com.sg/en/job/data-engineer-10478709?jobId=jobstreet-sg-job-10478709&sectionRank=74&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
74,Data Engineer | Yearly Contract | Up to $9500,PERSOLKELLY Singapore Pte Ltd (Formerly Kelly Services Singapore Pte Ltd),"• Translate business requirements to technical solutions leveraging strong business acumen. • Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data &amp; Analytics PaaS Services. • Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments. • Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies. • Design and Build Modern Data Pipelines and Data Streams. • Design and Build Data Service APIs. • Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics. • Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience. To Apply Interested candidates, who wish to apply for the above position; please click the "" Apply Now "" below. We regret that only shortlisted applicants would be notified. Yee Hong Ling Emelda | REG No : R22109572 PERSOLKELLY SINGAPORE PTE LTD | EA License No : 01C4394 By sending us your personal data and curriculum vitae (CV), you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its affiliates to collect, use and disclose your personal data for the purposes set out in the Privacy Policy which is available at https://www.persolkelly.com.sg/policies. You also acknowledge that you have read, understood, and agree to the said Privacy Policy.",https://www.jobstreet.com.sg/en/job/data-engineer-%7C-yearly-contract-%7C-up-to-%249500-10478525?jobId=jobstreet-sg-job-10478525&sectionRank=75&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
75,[WD45601] Market Data Engineer #JobsThatMatter,DBS Bank Limited,"Job Duties &amp; responsibilities L1/L2 Support and troubleshooting of Refinitiv Real Time Distribution System (RTDS), including real-time, reference data and vendor data feeds both in AWS and on-premise Coordinate with and escalate to market data vendors and exchanges for the data content, technical issues and changes Plan and implement production changes after training hours, and conduct testing to verify the changes are successful Implement and constantly improve monitoring tools to ensure comprehensive and effectiveness Ensure market data systems are functioning with sufficient capacity and resiliency for high availability Manage vendor and exchange driven changes, technical activities and relationships. Technical Experience Experience with Market Data delivery platform such as Refinitiv RTDS and direct exchange feeds Experience with DevOps tools such as Git, Jenkins, JIRA, Bitbucket and Nexus Experience with AWS Services such as EC2, S3, IAM, RDS, CloudWatch and API Gateway Experience with Relational databases such as PostgreSQL and Sybase Experience with Incident, Problem and Change management. Experience with Bash, Python, PowerShell Scripting Non-technical Experience Must have resilience and the ability to work well under pressure Should be hard working and ready to put extra efforts as per project need Strong working knowledge of SDLC &amp; Agile practices and procedures Ability to handle multiple concurrent activities and projects Ability to work along with team distributed across geographies Strong sense of ownership for assigned projects Able to articulate well on solution(s) Able to work as a team player",https://www.jobstreet.com.sg/en/job/%5Bwd45601%5D-market-data-engineer-jobsthatmatter-10493871?jobId=jobstreet-sg-job-10493871&sectionRank=76&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
76,Data Engineer | Contract (Renewable/ Convertible) | Salary up to $9500,PERSOLKELLY Singapore Pte Ltd (Formerly Kelly Services Singapore Pte Ltd),"Responsibilities: • Translate business requirements to technical solutions leveraging strong business acumen. • Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data &amp; Analytics PaaS Services. • Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments. • Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies. • Design and Build Modern Data Pipelines and Data Streams. • Design and Build Data Service APIs. • Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics. • Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience. • Implement effective metrics and monitoring processes. • Travel as needed To Apply: Interested parties, please click the button ""Apply Now"" below. We regret that only shortlisted applicants would be notified. Nguyen Quynh Nhu | REG No : R1768000 PERSOLKELLY SINGAPORE PTE LTD | EA License No : 01C4394 By sending us your personal data and curriculum vitae (CV), you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its affiliates collecting, using and disclosing my personal data for the purposes set out in the Privacy Policy which is available at www.persolkelly.com.sg I also acknowledge that I have read, understood, and agree to the said Privacy Policy.",https://www.jobstreet.com.sg/en/job/data-engineer-%7C-contract-renewable-convertible-%7C-salary-up-to-%249500-10477687?jobId=jobstreet-sg-job-10477687&sectionRank=77&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
77,Vice President - Data Scientist/Data Engineer - (Hybrid),Citibank N.A.,"Responsibilities The Vice President - Data Scientist/Data Engineer accomplishes results through the management of professional team(s) and department(s). Integrates subject matter and industry expertise within a defined area. Contributes to standards around which others will operate. Requires in-depth understanding of how areas collectively integrate within the sub-function as well as coordinate and contribute to the objectives of the entire function. Requires basic commercial awareness. Developed communication and diplomacy skills are required to guide, influence, and convince others, in particular colleagues in other areas and occasional external customers. Has responsibility for volume, quality, timeliness, and delivery of end results of an area. May have responsibility for planning, budgeting, and policy formulation within area of expertise. Involved in short-term resource planning. Full management responsibility of a team, which may include management of people, budget, and planning, to include duties such as performance evaluation, compensation, hiring, disciplinary and terminations and may include budget approval. A highly capable machine learning engineer to optimize our machine learning platforms, this role will be evaluating existing machine learning development lifecycle, driving the development of the AI technology roadmap and ensure successful MLOps capabilities to support the production of AI models for key business functions. Responsibilities: Design, implement and take ownership for the AI technology roadmap for APAC - enabling the capabilities of innovative AI solutions. Hands on with data engineering and MLOps support for successful ML solution deployment Enhance existing data science techniques by promoting new methodologies and best practices in the field Work with data scientists, ML engineers, business stakeholders and other technology teams to ensure that best practice MLOps is followed. Provide thought leadership by researching standard methodologies and collaborating with external partners. Contributes to data analytics standards around which others will operate. Applies in-depth understanding of how data analytics collectively integrate within the sub-function as well as coordinates and contributes to the objectives of the entire function. Employs developed communication and diplomacy skills to guide, influence and convince other colleagues in other areas and occasionally external entities. Resolves occasionally complex and highly variable issues. Produces detailed analysis of issues where the best course of action is not evident from the information available, but actions must be recommended/taken. Responsible for volume, quality, timeliness, and delivery of data science projects along with short-term planning resource planning. Oversees management of people, budget, and planning, to include duties such as performance evaluation, compensation, hiring, disciplinary action and terminations and may include budget approval. Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency, as well as effectively supervise the activity of others and create accountability with those who fail to maintain these standards. Requirements: Bachelor’s Degree (Masters would be an advantage) in quantitative field such as Statistics, Mathematics, Operational Research, Computer Science, Economics, or engineering or equivalent experience Minimum 8+years of experience in data-based quantitative analysis and predictive modeling Experience on programming languages (Python and/or C or Java or Spark) Experience with extracting and aggregating data from large data sets using SQL, Hive, Spark, or other tools Must have experience with Kubernetes, CI/CD automation, Docker, and microservice architecture. Demonstrated ability on data science innovation, newer ways/techniques of solving business problems with data Self-motivated individual with the ability to progress on multiple priorities concurrently #LI-Hybrid",https://www.jobstreet.com.sg/en/job/vice-president-data-scientist-data-engineer-hybrid-10495186?jobId=jobstreet-sg-job-10495186&sectionRank=78&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
78,"Big Data Engineer, Recommendation Architecture",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-10476473?jobId=jobstreet-sg-job-10476473&sectionRank=79&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
79,Data Engineer - TikTok,TikTok,"Responsibilities About TikTok TikTok is the world's leading destination for short-form mobile videos. Our mission is to capture and present the world's creativity, knowledge, and moments that matter in everyday life. TikTok empowers everyone to be a creator directly from their smartphones and is committed to building a community by encouraging users to share their passion and creative expression through their videos. TikTok has offices in Beijing, Berlin, Jakarta, London, Los Angeles, Moscow, Mumbai, Sao Paulo, Seoul, Shanghai, Singapore, and Tokyo. In 2018, TikTok was one of the most downloaded apps in the world. TikTok is available worldwide for iOS and Android. Visit tiktok.com. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Translate business requirements &amp; end to end designs into technical implementations and responsible for building batch and real-time data warehouse Manage data modeling design, writing, and optimizing ETL jobs Collaborate with the business team to building data metrics based on data warehouse Responsible for building and maintaining data products Involvement in rollouts, upgrades, implementation, and release of data system changes as required for streamlining of internal practices Qualifications At least 5 years in software engineering and 2 years of relevant experience in data engineering Proficient in creating and maintaining complex ETL pipelines end-to-end while maintaining high reliability and security Familiar with data warehouse concept and have production experience in modeling design Familiar with at least 1 distributed computing engine (e.g. Hive, Spark, Flink) Familiar with at least 1 NoSQL database is a plus (e.g. HBase) Excellent interpersonal and communication skills with the ability to engage and manage internal and external stakeholders across all levels of seniority Strong collaboration skills with the ability to build rapport across teams and stakeholders",https://www.jobstreet.com.sg/en/job/data-engineer-tiktok-10477592?jobId=jobstreet-sg-job-10477592&sectionRank=80&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
80,Data Engineer,Julian Grey Corporate Advisory Pte. Ltd.,"Company’s profile Julian Grey’s client is a local solution provider for high quality IT security products to value add to their MNC clients &amp; channel partners and has been in the market for 25 years. With a team of more than 200 highly experienced professionals, the company is looking for passionate individuals in the IT security industry to join their rapidly expanding team. Work location: Tampines Working hours: 8.30am – 6pm (Mon – Thu), 8.30am – 5.30pm (Fri) Company transport provided to &amp; from Tampines MRT daily. Benefits AWS and performance bonus Annual salary increment Medical and Dental claim $1900 per annum Team bonding budget $160 per employee per year 1 day inspirational leave per year Job Responsibilities Work in a team to build and maintain data systems or pipelines. Perform setup, installation, configuration, troubleshooting and/or upgrade for commercial software and hardware. Develop or implement methods to improve data warehouses, data lakes or equivalent platforms. Participate in creating documentations e.g., design documents, troubleshooting guides etc. Requirements 2-3 years experience in data management and installation/troubleshoot of commercial software and hardware Minimum Diploma in Computer Engineering/Computer Science/Information Technology or related technical fields Hands-on knowledge with Linux commands and shell script Hands-on knowledge in relational (i.e., SQL) or NoSQL database (i.e., documents, graphs) Familiar with any of the below is advantageous: Data / Search / Automation platforms like Hadoop, Elasticsearch, Ansible Data integration tools like Talend, DataStage, Denodo Programming languages like Python, Spark Microsoft Azure Cloud services like Azure Data Factory, Azure Synapse Analytics Analytics platforms like Databricks, Dataiku, Data Robot Follow us for more updates, interview tips! https://www.instagram.com/juliangreygroup/ https://www.linkedin.com/company/juliangreygroup/ https://www.facebook.com/juliangreygroup/ Our telegram channel for job opportunities - https://t.me/jobopportunitiessg Celine Chan Reg No. R21103433 Julian Grey Corporate Advisory Pte. Ltd. EA License No: 19C9568",https://www.jobstreet.com.sg/en/job/data-engineer-10477133?jobId=jobstreet-sg-job-10477133&sectionRank=81&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
81,Senior Data Engineer - R00010964,Nanyang Technological University,"As a member of the Analytics and AI team, the incumbent will collaborate with cross-functional teams to analyze, design, and implement analytics/data science solutions and innovations that will enhance NTU’s business operations and performance. Responsibilities Engage business stakeholders to identify, design, and implement Data Analytics (DA)/Data Science (DS) projects, including problem scoping, use case formulation, data sourcing, development, and maintenance of analytical models. Examples of DA/DS projects in NTU includes Learning analytics for the NTULearn ecosystems, Analytics for Administration, including students’ administration. Support the development of NTU’s data strategy and in-house analytics capabilities. Provide guidance to business units on the application of DA/DS (including solution) to help drive business initiatives e.g., improving the students’ journey and University operations. Conduct data-driven analysis to drive process improvements or draw out actionable insights, including designing and building data visualization to support management decision making, and aid learning outcomes, as well as enhancing the experience of students’ end-to-end journey in NTU. Apply analytical techniques such as data mining, statistical analysis, machine learning etc., and build predictive models to address business challenges, support NTU Learning ecosystems, and enhance administration. Work closely with relevant teams to productionize analytical models, including tracking and improving its performance. Familiar with setting up end-to-end processing platform to automate data processing, dashboarding and machine learning will be an added advantage. Requirements Degree in Mathematics, Statistics, Operations Research, Computer Science, Engineering or other related discipline. Poly graduates with relevant experiences are welcome to apply. Specialization in Data Analytics or Data Science will be an added advantage. Minimally 3 years of in-depth experience in implementing end-to-end analytics/data science solutions. Renumeration and appointment grades will be based on experience. Experience in data Extraction / Transformation / Load using SQL, Excel or any other applications. Experience in using data analytical and visualization tools such as Qlik Sense, Power BI, Python. Experience in using data mining tool such as Orange or any other applications. Ability to work collaboratively across teams and quickly breakdown problems and find innovative solutions. Experience with analytical modelling, predictive analytics, AI and machine learning would be an added advantage. Experience with using Microsoft Azure AI Platform to deploy automated data processing and machine learning would be an added advantage. Ability to communicate data-driven findings and ideas to technical and non-technical stakeholders. Knowledge in deploying solutions in a cloud environment, and in implementing DA/DS solutions will be an added advantage. Good communication, written and presentation skills. Good analytical, problem solving and critical thinking skills and meticulous attitude. Ability to work independently or in a team with minimal supervision. Hiring Institution: NTU",https://www.jobstreet.com.sg/en/job/senior-data-engineer-r00010964-10493625?jobId=jobstreet-sg-job-10493625&sectionRank=82&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
82,Data Engineer,LUXOLA PTE. LTD.,"Roles &amp; Responsibilities Sephora is a global leader in omnichannel beauty retailing, and a division of LVMH – Moët Hennessy Louis Vuitton. At Sephora, we stand together, and we stand for something more. For the empowerment, exploration, and opportunity to impact people’s lives through the unlimited power of beauty. Every day we reimagine beauty, discover new brands, and influence positive change. Data plays a significant role in that. We successfully operate more than three thousand points of sale across the Americas, Europe, the Middle East, and Asia. Together, we aim to animate the most loved beauty community in the world. Here in Asia, our teams run omnichannel businesses in 11 markets across the region (9 different markets in Southeast Asia), in addition to cross-border e-commerce to several more. Our success is built on innovation, a unique product portfolio, market-leading digital capability, and our unique customer experience. With ambitious growth plans, we always look for talented people who aspire to build businesses and develop themselves. Sparked by energy and excitement, our passion is contagious. We are united by a common goal – to reimagine the future of beauty. We’re a data-driven omnichannel business with a special focus on e-commerce (our platform is built in-house!). The data team builds and maintains data management and Machine Learning capabilities to power both customer-facing services and internal data products. We manage a large-scale data platform in Google Cloud, relying heavily on BigQuery, Kubernetes, and Terraform. The data team is looking to hire a proactive, commercially savvy Data Engineer to ensure all our data users - analysts, end users, or AI-driven systems, have access to the right data at the right time, and ensure its accuracy. You will get a chance to work on our core data pipelines (batch and streaming), machine learning platform, and cloud infrastructure, depending on your interests and previous experience. We believe in enabling our engineers to work across the stack to solve interesting problems and keep work exciting and enable this through weekly and monthly sharing sessions, pair coding, and architecture design sessions. To be successful in this role ● You will need to be well-versed in building scalable, reliable, test-driven data pipelines to integrate data from various systems and platforms into the data warehouse on Google BigQuery. ● You will need to design the data warehouse schema, ensure extensibility, and clarity as new data sources are continuously integrated. You will oversee data reliability to build overall company trust in data to be more data-driven and continuously identify improvements to existing data architecture and data flows. ● You will need to promote and ensure technical excellence within the team. You are passionate about the culture and quality of engineering, and strive to continuously improve the quality and delivery of the team. ● You will need to enjoy working together in a team, planning and executing sprint tasks following Agile processes. ● You will need to be able to communicate clearly with our internal stakeholders, technical or non-technical, deeply understand business priorities and formalize them into challenges that can be tackled with engineering effort. What we expect from you ● 2+ years of experience building software as a team following Agile methodologies. ● Strong production-level Python and SQL programming knowledge. Big bonus if you have also worked with BigQuery or are familiar with Golang or Javascript. ● Experience building and scaling batch ETL/ELT data pipelines, especially in Apache Airflow, Kubernetes, and DBT. Understanding of size and performance constraints. ● Experience building and scaling streaming data pipelines, especially in Apache Kafka, Spark, or Beam. ● Experience architecting and building data products with Cloud Services and Data Warehousing services in GCP or AWS (GCP is preferred). ● Knowledge of columnar databases, infrastructure automation tools like Terraform, data modeling techniques, data warehouse design patterns and google analytics is advantageous. If these are aspects you value, please apply! Your attitude, experience and passion to excel are more important than specific experience.",https://www.jobstreet.com.sg/en/job/data-engineer-10495959?jobId=jobstreet-sg-job-10495959&sectionRank=83&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
83,"[WD46247] AVP, Senior Data Engineer, Group Consumer Banking Technology, Technology &amp; Operations #JobsThatMatter",DBS Bank Limited,"Business Function Group Technology and Operations (T&amp;O) enables and empowers the bank with an efficient, nimble, and resilient infrastructure through a strategic focus on productivity, quality &amp; control, technology, people capability and innovation. In Group T&amp;O, we manage most of the Bank's operational processes and inspire to delight our business partners through our multiple banking delivery channels. As a Senior Data Engineer, you'll be a specialist defining Data design, architecture, and strategy for C2MA platform projects, ensuring effective adoption of DBS enterprise Big Data stack and help us discover the information hidden in vast amounts of data. You'll help us make smarter decisions to deliver even better products and apply data mining techniques and statistical analysis to build high quality prediction systems integrated with our products. Responsibilities Design and implement key components for highly scalable, distributed data collection and analysis system built for handling petabytes of data in the cloud. Move architecture and implementation through the development pipeline, from research to deployment Work with architects from other divisions contributing to this analytics system and mentor team members on best practices in backend infrastructure and distributed computing topics. Analyse source data and data flows, working with structured and unstructured data. Manipulate high-volume, high-dimensionality data from varying sources to highlight patterns, anomalies, relationships and trends Analyse and visualize diverse sources of data, interpret results in the business context and report results clearly and concisely. Work side-by-side with product managers, software engineers, and designers in designing experiments and minimum viable products. Enhance data collection procedures that is relevant for building analytic systems. Aid project teams to discover data sources, get access to them, import them, clean them up, and make them “model-ready”. You need to be willing and able to do your own ETL. Ability to install, analyse and evaluate different vendor products and tools catering to different areas of data work (Data exploration, Data visualization and MLOps) in the DBS Bigdata ecosystem and enable the business and Data scientists. Design and build API’s to fetch and processing(request based) of the batch curated data. Requirements 6+ years of Experience in one or more areas of big data and machine learning Able to work with loosely defined requirements and exercise your analytical skills to clarify questions, share your approach and build/test elegant solutions in weekly sprint/release cycles. Development experience in Java/Scala and pride in producing clean, maintainable code Experience creating pipelines to analyze data, extracted features and prep the ML model Independence and self-reliance while being a pro-active team player with excellent communication skills, able to lead and mentor distributed teams. Professional experience building enterprise Big Data Applications using Spark, Hadoop, Hive, Presto, &amp; Airflow. Hands-on development of Data applications using Spark Execution Framework, Spark SQL, Scala/Python(pyspark) Experience with distributed databases, such as MongoDB Aerospike, and the key issues affecting their performance and reliability. Experience using high-throughput, distributed message queueing systems such as Kafka. Familiarity with operational technologies, including Docker (required), Chef, Puppet, Zookeeper, Terraform, and Ansible (preferred). An ability to periodically deploy systems to on-prem environments. Mastery of key development tools such as GIT, and familiarity with collaboration tools such as Jira and Confluence or similar tools. Experience with Teradata SQL, Exadata SQL, T-SQL. Experience in migrating SQL from traditional RDBMS to Spark and Bigdata technologies In-depth knowledge of database internals and Spark SQL Catalyst engine Performance optimization in distributed compute environment (Spark &amp; Hadoop). Experience/Exposure to SAS programming fundamentals Exposure to Data exploration tools like DataIQ and onboarding them into enterprise environments Handling of Data visualization tools like (Tableau, QlikView) Working experience with web-services (REST, SOAP) and/or experience in Microservices will be add on. Good with Architecture and has good understanding and in-depth knowledge on distributed systems Good knowledge of OOPs, data structure, and algorithm Apply Now ​ We offer a competitive salary and benefits package and the professional advantages of a dynamic environment that supports your development and recognises your achievements.​",https://www.jobstreet.com.sg/en/job/%5Bwd46247%5D-avp-senior-data-engineer-group-consumer-banking-technology-technology-operations-jobsthatmatter-10493869?jobId=jobstreet-sg-job-10493869&sectionRank=84&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
84,"Lead, Data Engineering (AVP)",Mediacorp Pte Ltd,"Description We are looking for a high-performing data engineer with full stack experience creating web-based data applications. You will be a key contributor to the Data Engineering team, primarily by applying and building tools to aggregate data from disparate sources, processing and loading the transformed data to support internal and external constituencies. You will be required to maintain and enhance our data infrastructure and proprietary analytical solutions. This role is a hands-on engineering position. Job Responsibilities Translate business requirements to responsive functional web solutions. This includes designing and building APIs, front-end interfaces and scalable tools that ingest and transform real-time data using a variety of open-source and proprietary big data technologies. Recommend and implement ways to improve data reliability, efficiency and quality Work closely with stakeholders to ensure high standards of data governance during implementation Serve as technical subject matter expert on the latest big data technologies Requirements Hands-on proven track record in developing products from front-end interface, middle-tier, to backend infrastructure 7+ years of superior experience developing commercial web-based applications 4+ years of full-stack web development experience in Javascript (node.js and React framework) Proficiency in SQL is mandatory Excellent scripting knowledge in Python, Shell etc Those with strong production experience in Scala or Spark programming languages will be considered favourably Relevant experience in web, video, mobile or adtech domain is a definite plus Demonstrated clear and thorough analytical thinking Good eye for aesthetics and an attention to detail A proven team player and contributor who can multi-task and deliver against timelines Minimum degree in Computer Science/Engineering, or equivalent Mediacorp is committed to creating an inclusive and diverse workplace where talent thrives. Our hiring decisions are made based on merit and fit-to-role. If you have a disability or special need which requires accommodation to participate in the recruitment process, please inform us when you submit your online application. We will be happy to support as necessary. Thank you for your interest and application to this role. Please note that only short-listed candidates will be contacted.",https://www.jobstreet.com.sg/en/job/lead-data-engineering-avp-10495480?jobId=jobstreet-sg-job-10495480&sectionRank=85&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
85,"Data Engineer (Python, SQL, Azure)",Manpower Staffing Services (S) Pte Ltd - Corporate,"Company Highlight: Company transport provided at Tampines MRT Good Employee benefits and Transparent career progression Job stability for long-term career growth Roles &amp; Responsibilities: Join a team responsible for building and maintaining data systems or pipelines Set up, install, configure, troubleshoot, and upgrade commercial off-the-shelf (COTS) products Develop and implement ways to enhance data warehouses, data lakes, or similar platforms Contribute to the creation of documentation such as design documents and troubleshooting guides Requirement: Knowledge and/or experience in data management or data engineering Familiarity with Linux commands and shell scripting Knowledge and/or experience in relational databases (including SQL) or NoSQL databases (e.g., document, graph) Advantageous to have experience in DataStage, Denodo, Hadoop, Python, Spark, Microsoft Azure Cloud services, Databricks, Dataiku, Data Robot Degree/Diploma in Computer Engineering/Computer Science/Information Technology or a related technical discipline with 1-4 years of experience in related fields No Experienced candidates are encouraged to apply If you are interested in this opportunity, submit your application now to find out more about this position. We regret that only shortlisted applicants will be contacted. Thank you. Sim Wen Yih Reine Personal Reg No: R21103357 Manpower Staffing Services (S) Pte Ltd EA License No: 02C3423",https://www.jobstreet.com.sg/en/job/data-engineer-python-sql-azure-10474394?jobId=jobstreet-sg-job-10474394&sectionRank=86&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
86,Data Engineer (Oracle Database) J40116,ScienTec Personnel,"Database Administrator (Performance Tuning) Working Hours: Monday to Friday Working Location: Central Basic Salary: Up to S$ 7,500 + AWS + VB (Min 2 months) Benefits: Attractive Bonuses + Insurance Coverage + Wide range of Leave What to Expect: Develop, construct, test and maintain data architectures such as databases, data warehouses and large-scale data processing systems Design and develop data pipelines/systems for data modelling, mining and production Ensure the data architecture is in place to support routine and ad-hoc requirements of data analytics team, stakeholders and the business Leverage on variety of programming languages and data crawling/processing tools to make raw data clean and highly available for use in descriptive and predictive modelling Recommend and implement ways to improve data quality, reliability, flexibility and efficiency Ensure data assets and data catalogs are organized and stored in an efficient way so that information is easy to access and retrieve PL/SQL and SQL Tuning and optimization of newly develop and existing applications Responsibilities: Minimum of 3years of Oracle data architecture, data warehousing, data processing, data modelling and ETL/ELT Experienced in Database infrastructure and architecture design Experienced in executing and writing Oracle PL/SQL in the most efficient way Working experience in AWS cloud environment, familiar with solutions such as EC2, S3, EMR, Redshift, Athena, Kinesis Advanced programming knowledge in Java, Hadoop, HDFS, Apache Airflow, Apache Spark, Scala, Hive, Pig Hands-on experience in data crawling, data modeling, data lake formation and data warehouse constructionx If you are keen on the position, kindly submit your application to spwl(a)scientecpersonnel.com or click on the apply. Wyman Low Team Lead (IHRP - CA) Low Yong Wei (Wyman) - R1550983 ScienTec Consulting Pte Ltd - 11C5781",https://www.jobstreet.com.sg/en/job/data-engineer-oracle-database-j40116-10470164?jobId=jobstreet-sg-job-10470164&sectionRank=87&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
87,Data Engineer / Senior Data Engineer,Singapore Land Authority,"What the role is The data engineer will work with stakeholders to execute the SLA Data Strategy (3 Pillars: People, Process, Technology). Job Scope: Plan and implement technology and policies to enhance organisational integration and responsiveness in data-driven decision making. Plan and implement initiatives and processes aligned with the national strategy for Smart Nation and Digital Government relating to data, capacity development and outreach. Plan and implement robust and resilient data engineering work flows on SLA’s data platform Requirements Background in data engineering, computer engineering, data analytics or any related discipline To ensure a data-centric approach is taken in projects and issues resolution ensuring that data governance best practices are incorporated into each and every effort At least 2 years of using ETL tools to deliver data workflows (e.g. IBM Datastage, Talend, Airflow etc.) At least 2 years of experience working with a variety of on premise data warehouses (e.g. IBM DB2, Apache Hive, PostgreSQL, MS SQL Server or similar) Able to code data engineering flows in Python and SQL Able to combine ETL workflows with command line scripts in Windows Server or Redhat Linux to deliver end to end data flows Able to design resilient and robust data flows, with good application of exception handling and data load conditions Able to extend beyond data engineering into aspects of system engineering (where required) Able to conduct and elicit requirements from business users and design data flows (including all data transformations) a plus Inclination and ability to work across a wide and diverse spectrum of areas/issues Expected to exercise initiative, and demonstrate strong analytical and communication skills A good command of English, both written and spoken, as well as strong presentation skills Ability to formulate and apply data governance policies in data engineering flows a plus Knowledge and application of data engineering in using geospatial data a plus Entry level are welcome to apply What you will be working on What we are looking for",https://www.jobstreet.com.sg/en/job/data-engineer-senior-data-engineer-10487191?jobId=jobstreet-sg-job-10487191&sectionRank=88&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
88,Data Engineer,Nansen SG,"Roles &amp; Responsibilities About the Role As Data Engineer you'll join one of our mission oriented squads or platform teams. Data is key in all of our products, and your contributions will have a big impact. You can be located anywhere in the world , as our work is 100% online. The position is full-time . Responsibilities Design, develop and support data pipelines, warehouses and reporting systems to solve business operations, users and product problems Work closely with product engineers to create, test and maintain data models Collaborate and influence stakeholders and support engineers to ensure our data infrastructure meets constantly evolving requirements Work closely with analysts to create data analytics and research platform Contribute to engineering efforts from planning and organization to execution and delivery to solving complex engineering problems Take initiative and be responsible for technical solutions to data quality and workflow challenges Write and review technical documents, including design, development, and revision documents.‍ Are you the right person for this role? The ideal candidate for us has: 3+ years work experience as a Data Engineer or similar role Experience with building data pipelines using Python and SQL Experience designing data models and data warehouses Experience in computer science , data structures , algorithms and software design Experience with the following: BigQuery, Postgres, Airflow, Kubernetes, dbt The following are nice-to-haves: Experience with Data Visualization tools Experience with Ethereum and the crypto markets (either professionally or as a hobby)",https://www.jobstreet.com.sg/en/job/data-engineer-10486311?jobId=jobstreet-sg-job-10486311&sectionRank=89&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
89,Data Engineer,Singapore Land Authority,"The data engineer will work with stakeholders to execute the SLA Data Strategy (3 Pillars: People, Process, Technology). Job Scope : Plan and implement technology and policies to enhance organisational integration and responsiveness in data-driven decision making. Plan and implement initiatives and processes aligned with the national strategy for Smart Nation and Digital Government relating to data, capacity development and outreach. Plan and implement robust and resilient data engineering work flows on SLA’s data platform Requirements Background in data engineering, computer engineering, data analytics or any related discipline To ensure a data-centric approach is taken in projects and issues resolution ensuring that data governance best practices are incorporated into each and every effort At least 2 years of using ETL tools to deliver data workflows (e.g. IBM Datastage, Talend, Airflow etc.) At least 2 years of experience working with a variety of on premise data warehouses (e.g. IBM DB2, Apache Hive, PostgreSQL, MS SQL Server or similar) Able to code data engineering flows in Python and SQL Able to combine ETL workflows with command line scripts in Windows Server or Redhat Linux to deliver end to end data flows Able to design resilient and robust data flows, with good application of exception handling and data load conditions Able to extend beyond data engineering into aspects of system engineering (where required) Able to conduct and elicit requirements from business users and design data flows (including all data transformations) a plus Inclination and ability to work across a wide and diverse spectrum of areas/issues Expected to exercise initiative, and demonstrate strong analytical and communication skills A good command of English, both written and spoken, as well as strong presentation skills Ability to formulate and apply data governance policies in data engineering flows a plus Knowledge and application of data engineering in using geospatial data a plus Entry level are welcome to apply",https://www.jobstreet.com.sg/en/job/data-engineer-10486996?jobId=jobstreet-sg-job-10486996&sectionRank=90&token=0~ee69f848-c87e-4836-b942-633925101e21&fr=SRP%20Job%20Listing
90,Senior Data Engineer,Aon Hewitt,"Job Description What the day will look like.. Be part of a dynamic team focused on healthcare data and innovation initiatives Collaborate with a team of experienced actuaries, data scientists, developers and business experts to deliver on Aon’s data, analytics and reporting capabilities Lead the design, build and maintenance of a scalable data pipeline architecture from ingestion to transformation to storage to consumption across various applications Focus on an efficient approach to design, allowing for agile and robust development to meet ever-changing business needs Contribute to the design of our data lake and the development of all data assets and downstream warehouses/marts Partner with data scientists and analysts to ensure efficient and accurate flow of data into downstream analytics tools and reporting solutions Implement automation wherever possible to streamline the process, minimizing the need for manual intervention Assist in database performance tuning and data lifecycle management Develop and integrate an automated data validation and quality control mechanism throughout the pipeline Problem solve complex issues and work to create elegant, simplified solutions Maintain up-to-date technical and operational documentation Skills and experience that will lead to success.. BS or MS degree in Computer Science, Information Technology or equivalent 5+ years in-depth experience in working with a relational database system (eg. MSSQL, PostgreSQL) Highly knowledgeable in ETL/ELT processes, both design and implementation Some experience in a programming language (eg.Python ,C#) Experience building data pipelines that ingests various types of data sources into a database or data lake and populating a structured warehouse or data mart Fluent in both complex SQL query performance tuning and database performance tuning Experience in Apache Spark/Databricks, Python/Pandas, R/Tidyverse and large file processing and analytics data pipelines Knowledge of data security and privacy practices and regulations, including data access controls and de-identification and protection of sensitive data Proven ability to convey technical information successfully to a wide variety of stakeholders Quick and eager student of new technologies as and when they are needed Knowledge of Agile Scrum and Continuous Delivery practices is desirable Experience in BI tools (e.g. Tableau, Power BI) is an advantage Experience working with medical and prescription drug claims data is an advantage About ACIA Aon’s Centers for Innovation and Analytics are at the heart of delivering Aon’s Data &amp; Analytic Services team’s mission to: Accelerate the rate of innovation through digital solutions to help better respond to clients’ evolving needs Provide foundational data and analytics capabilities in one place for 50,000 Aon colleagues and our global clients who use our risk and people solutions Established in 2012, there are over 150 colleagues in Singapore’s Centre today including actuaries, software developers, data scientists, financial analysts and accountants. We are expanding rapidly and looking for dedicated individuals who can leverage emerging technologies and collaborate across Aon’s solution lines to help clients and colleagues make better, data-driven decisions today and tomorrow. How to Apply Your opportunity to empower results could start right here. Make your mark and apply online today with a brief covering letter and your resume, sharing relevant achievements for this position. Please upload your resume in PDF format. How we support our colleagues In addition to our comprehensive benefits package, we encourage a diverse workforce. Plus, our agile, inclusive environment allows you to manage your wellbeing and work/life balance, ensuring you can be your best self at Aon. Furthermore, all colleagues enjoy two “Global Wellbeing Days” each year, encouraging you to take time to focus on yourself. We offer a variety of working style solutions, but we also recognise that flexibility goes beyond just the place of work... and we are all for it. We call this Smart Working! Our continuous learning culture inspires and equips you to learn, share and grow, helping you achieve your fullest potential. As a result, at Aon, you are more connected, more relevant, and more valued. We provide individuals with disabilities reasonable accommodations to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment in accordance with applicable law. Aon values an innovative, diverse workplace where all colleagues feel empowered to be their authentic selves. Aon is proud to be an equal opportunity workplace.",https://www.jobstreet.com.sg/en/job/senior-data-engineer-10484633?jobId=jobstreet-sg-job-10484633&sectionRank=91&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
91,Data Engineer / Architect - #Urgent #Immediate,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills: Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-urgent-immediate-10465137?jobId=jobstreet-sg-job-10465137&sectionRank=92&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
92,Service Delivery Engineer (Reporting and Data Analytics) M/F #JobsThatMatter #Seekbetter #JobsThatMatter,STMicroelectronics Asia Pacific Pte Ltd (Lite ads),"Job description You will be joining the DIT organization, supporting Singapore Front-End Manufacturing operations of STMicroelectronics. In this group, you will be part of the Reporting and Data Analytics team focusing on the delivery of data, reports and dashboard-oriented solutions and liaising with manufacturing user communities in order to continuously improve their data-driven decision-making process. the role requires to have or acquire a solid understanding of the data eco system supporting our manufacturing operations in order to be able to maintain or enhance the accuracy and timeliness of the various data analytics platforms. this will provide you exposure to data management solutions such as: Applied Materials APF RTD and Reporter suite, TIBCO Spotfire, SQL DBMS (mostly Oracle), You will be involved into: Maintaining and enhancing robustness and high availability of all solutions Training to end-users for the available features or new solutions Equipping 24x7 IT ProdOps team with comprehensive materials and knowledge for 1st level of support Provide 24x7 level 2 support to ensure timely resolution of issues Profile Bachelor degree in Computer Science/Computer Engineering /Information Technology. (Data Scientist/Data engineer cursus is a plus) Experience in Unix, Linux and Windows environment Experience in web-based applications Strong in application development with MySQL/Oracle and performance optimization Strong in PL/SQL, perl/shell or Python scripting Preferable with experience in wafer fab or manufacturing Ability to adapt quickly to new technology and in-house application exposure to AMAT APF products and TIBCO Spotfire is a plus",https://www.jobstreet.com.sg/en/job/service-delivery-engineer-reporting-and-data-analytics-m-f-jobsthatmatter-seekbetter-jobsthatmatter-10520214?jobId=jobstreet-sg-job-10520214&sectionRank=93&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
93,Service Delivery Engineer (Reporting and Data Analytics) M/F #WorkNow #JobsThatMatter - | #LetsGoToWork,STMicroelectronics Asia Pacific Pte Ltd (Lite ads),"Job description You will be joining the DIT organization, supporting Singapore Front-End Manufacturing operations of STMicroelectronics. In this group, you will be part of the Reporting and Data Analytics team focusing on the delivery of data, reports and dashboard-oriented solutions and liaising with manufacturing user communities in order to continuously improve their data-driven decision-making process. the role requires to have or acquire a solid understanding of the data eco system supporting our manufacturing operations in order to be able to maintain or enhance the accuracy and timeliness of the various data analytics platforms. this will provide you exposure to data management solutions such as: Applied Materials APF RTD and Reporter suite, TIBCO Spotfire, SQL DBMS (mostly Oracle), You will be involved into: Maintaining and enhancing robustness and high availability of all solutions Training to end-users for the available features or new solutions Equipping 24x7 IT ProdOps team with comprehensive materials and knowledge for 1st level of support Provide 24x7 level 2 support to ensure timely resolution of issues Profile Bachelor degree in Computer Science/Computer Engineering /Information Technology. (Data Scientist/Data engineer cursus is a plus) Experience in Unix, Linux and Windows environment Experience in web-based applications Strong in application development with MySQL/Oracle and performance optimization Strong in PL/SQL, perl/shell or Python scripting Preferable with experience in wafer fab or manufacturing Ability to adapt quickly to new technology and in-house application exposure to AMAT APF products and TIBCO Spotfire is a plus",https://www.jobstreet.com.sg/en/job/service-delivery-engineer-reporting-and-data-analytics-m-f-worknow-jobsthatmatter-%7C-letsgotowork-10520179?jobId=jobstreet-sg-job-10520179&sectionRank=94&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
94,Data Engineer,Stellar Link Partners Pte Ltd,"Job Description Our client, a emerging hedge fund firm headquartered in Asia, The firm's investment strategy is mainly quantitative trading using high-frequency trading strategies with a focus on domestic and overseas markets. Your Key Responsibilities includes: Maintaining and overseeing of internal data production pipeline Developing of data for ETL pipelines and data management platform Perform data mining and explore other alternative for data Requirements: Minimum a Bachelor's degree in Computer Science or equivalent Experience in Data extracting and ETL pipeline in python is required Knowledge in RDBMS and big data infrastructure Alternatively, you may call +65 9004 5401 for a quick discussion. We regret to inform that only shortlisted candidates would be notified. Chan Chin How, Javier Associate Consultant Reg. No: R1989608 Stellar- Link Partners Pte Ltd (EA License: 21S0698)",https://www.jobstreet.com.sg/en/job/data-engineer-10461208?jobId=jobstreet-sg-job-10461208&sectionRank=95&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
95,"Service Delivery Engineer, (Reporting and Data Analytics) M/F - #JobsThatMatter #JobsThatMatter #UrgentHire #Worknow' -- #LetsGoToWork.",STMicroelectronics Asia Pacific Pte Ltd (Lite ads),"Job description You will be joining the DIT organization, supporting Singapore Front-End Manufacturing operations of STMicroelectronics. In this group, you will be part of the Reporting and Data Analytics team focusing on the delivery of data, reports and dashboard-oriented solutions and liaising with manufacturing user communities in order to continuously improve their data-driven decision-making process. the role requires to have or acquire a solid understanding of the data eco system supporting our manufacturing operations in order to be able to maintain or enhance the accuracy and timeliness of the various data analytics platforms. this will provide you exposure to data management solutions such as: Applied Materials APF RTD and Reporter suite, TIBCO Spotfire, SQL DBMS (mostly Oracle), You will be involved into: Maintaining and enhancing robustness and high availability of all solutions Training to end-users for the available features or new solutions Equipping 24x7 IT ProdOps team with comprehensive materials and knowledge for 1st level of support Provide 24x7 level 2 support to ensure timely resolution of issues Profile Bachelor degree in Computer Science/Computer Engineering /Information Technology. (Data Scientist/Data engineer cursus is a plus) Experience in Unix, Linux and Windows environment Experience in web-based applications Strong in application development with MySQL/Oracle and performance optimization Strong in PL/SQL, perl/shell or Python scripting Preferable with experience in wafer fab or manufacturing Ability to adapt quickly to new technology and in-house application exposure to AMAT APF products and TIBCO Spotfire is a plus",https://www.jobstreet.com.sg/en/job/service-delivery-engineer-reporting-and-data-analytics-m-f-jobsthatmatter-jobsthatmatter-urgenthire-worknow%27-letsgotowork.-10519732?jobId=jobstreet-sg-job-10519732&sectionRank=96&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
96,"Service Delivery Engineer, (Reporting and Data Analytics) M/F - #JobsThatMatter #JobsThatMatter #UrgentHire #Worknow' -- #LetsGoToWork. #JobsThatMatt",STMicroelectronics Asia Pacific Pte Ltd (Lite ads),"Job description You will be joining the DIT organization, supporting Singapore Front-End Manufacturing operations of STMicroelectronics. In this group, you will be part of the Reporting and Data Analytics team focusing on the delivery of data, reports and dashboard-oriented solutions and liaising with manufacturing user communities in order to continuously improve their data-driven decision-making process. the role requires to have or acquire a solid understanding of the data eco system supporting our manufacturing operations in order to be able to maintain or enhance the accuracy and timeliness of the various data analytics platforms. this will provide you exposure to data management solutions such as: Applied Materials APF RTD and Reporter suite, TIBCO Spotfire, SQL DBMS (mostly Oracle), You will be involved into: Maintaining and enhancing robustness and high availability of all solutions Training to end-users for the available features or new solutions Equipping 24x7 IT ProdOps team with comprehensive materials and knowledge for 1st level of support Provide 24x7 level 2 support to ensure timely resolution of issues Profile Bachelor degree in Computer Science/Computer Engineering /Information Technology. (Data Scientist/Data engineer cursus is a plus) Experience in Unix, Linux and Windows environment Experience in web-based applications Strong in application development with MySQL/Oracle and performance optimization Strong in PL/SQL, perl/shell or Python scripting Preferable with experience in wafer fab or manufacturing Ability to adapt quickly to new technology and in-house application exposure to AMAT APF products and TIBCO Spotfire is a plus",https://www.jobstreet.com.sg/en/job/service-delivery-engineer-reporting-and-data-analytics-m-f-jobsthatmatter-jobsthatmatter-urgenthire-worknow%27-letsgotowork.-jobsthatmatt-10518462?jobId=jobstreet-sg-job-10518462&sectionRank=97&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
97,Senior Data Engineer #Immediate #JobsThatMatter,Aon Hewitt,"Job Description We’re hiring! Aon's Center for Innovation &amp; Analytics (ACIA) is currently recruiting a Senior Data Engineer to join our Health Analytics team in Singapore. About ACIA Aon’s Centers for Innovation and Analytics are at the heart of delivering Aon’s Data &amp; Analytic Services team’s mission to: Accelerate the rate of innovation through digital solutions to help better respond to clients’ evolving needs Provide foundational data and analytics capabilities in one place for 50,000 Aon colleagues and our global clients who use our risk and people solutions Established in 2012, there are over 150 colleagues in Singapore’s Centre today including actuaries, software developers, data scientists, financial analysts and accountants. We are expanding rapidly and looking for dedicated individuals who can leverage emerging technologies and collaborate across Aon’s solution lines to help clients and colleagues make better, data-driven decisions today and tomorrow. What the day will look like. Be part of a dynamic team focused on healthcare data and innovation initiatives Collaborate with a team of experienced actuaries, data scientists, developers and business experts to deliver on Aon’s data, analytics and reporting capabilities Lead the design, build and maintenance of a scalable data pipeline architecture from ingestion to transformation to storage to consumption across various applications Focus on an efficient approach to design, allowing for agile and robust development to meet ever-changing business needs Contribute to the design of our data lake and the development of all data assets and downstream warehouses/marts Partner with data scientists and analysts to ensure efficient and accurate flow of data into downstream analytics tools and reporting solutions Implement automation wherever possible to streamline the process, minimizing the need for manual intervention Assist in database performance tuning and data lifecycle management Develop and integrate an automated data validation and quality control mechanism throughout the pipeline Problem solve complex issues and work to create elegant, simplified solutions Maintain up-to-date technical and operational documentation Skills and experience that will lead to success. BS or MS degree in Computer Science, Information Technology or equivalent 5+ years in-depth experience in working with a relational database system (eg. MSSQL, PostgreSQL) Highly knowledgeable in ETL/ELT processes, both design and implementation Some experience in a programming language (eg.Python ,C#) Experience building data pipelines that ingests various types of data sources into a database or data lake and populating a structured warehouse or data mart Fluent in both complex SQL query performance tuning and database performance tuning Experience in Apache Spark/Databricks, Python/Pandas, R/Tidyverse and large file processing and analytics data pipelines Knowledge of data security and privacy practices and regulations, including data access controls and de-identification and protection of sensitive data Proven ability to convey technical information successfully to a wide variety of stakeholders Quick and eager student of new technologies as and when they are needed Knowledge of Agile Scrum and Continuous Delivery practices is desirable Experience in BI tools (e.g. Tableau, Power BI) is an advantage Experience working with medical and prescription drug claims data is an advantage How to Apply Your opportunity to empower results could start right here. Make your mark and apply online today with a brief covering letter and your resume, sharing relevant achievements for this position. Please upload your resume in PDF format. How we support our colleagues In addition to our comprehensive benefits package, we encourage a diverse workforce. Plus, our agile, inclusive environment allows you to manage your wellbeing and work/life balance, ensuring you can be your best self at Aon. Furthermore, all colleagues enjoy two “Global Wellbeing Days” each year, encouraging you to take time to focus on yourself. We offer a variety of working style solutions, but we also recognise that flexibility goes beyond just the place of work... and we are all for it. We call this Smart Working! Our continuous learning culture inspires and equips you to learn, share and grow, helping you achieve your fullest potential. As a result, at Aon, you are more connected, more relevant, and more valued.",https://www.jobstreet.com.sg/en/job/senior-data-engineer-immediate-jobsthatmatter-10481092?jobId=jobstreet-sg-job-10481092&sectionRank=98&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
98,Research Associate (Computer Science/IT) - [R00007075] | #LetsGoToWork,Nanyang Technological University,"A Research Associate position is currently available in the College of Business, Nanyang Business School. We are looking for an experienced data engineer to join our team and you will use various methods to transform raw data into useful data systems. This includes developing algorithms and conducting statistical analysis. Overall, your goal is to develop data systems in alignment with business goals. To succeed in this data engineering position, you should have strong analytical skills and the ability to integrate data /data streams from different sources. Data engineer skills also include familiarity with apt programming langus and knowledge of machine learning methods. If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear from you. Job Responsibilities Co-evaluate business needs and objectives Identify opportunities for data acquisition Build data systems and pipelines Build algorithms and prototypes Analyze and organize raw data Interpret trends and patterns Conduct data analysis, working independently or with data analysts, and report on results Prepare data for prescriptive and predictive modeling Combine raw information from different sources Explore ways to enhance data quality and reliability Develop analytical tools and programs Collaborate with data scientists and architects Job Requirements Master in Computer Science, IT, or similar field Previous experience as a data engineer or in a similar role Technical expertise with data models, data mining, and segmentation techniques Knowledge of programming langus (e.g. Java and Python) Hands-on experience with SQL database design Great numerical and analytical skills We regret to inform that only shortlisted candidates will be notified.",https://www.jobstreet.com.sg/en/job/research-associate-computer-science-it-%5Br00007075%5D-%7C-letsgotowork-10470376?jobId=jobstreet-sg-job-10470376&sectionRank=99&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
99,Data Engineer,Abbott Laboratories Pte Ltd,"Full Job Description Primary Function/Primary Goals/Objectives: Identify business needs, collect, data analysis &amp; interpretation and visualization of manufacturing and business data. Report insights and help users to make decisions and find improvement opportunities. Major Responsibilities: Engaging cross-functional stakeholders to understand business requirements (voice of customer). Manage cross-functional projects from ideation, execution to change management. Extract, transform and load data from data source systems, machines and sensors using tools such as Python, SQL, SEEQ and batch scripting. Develop data cleaning and data wrangling tools (Python, SQL, Excel) for analysis and analytics modeling. Extract time series process data from PI process historian using PI Web API. Implement next generation electronic tier reporting dashboard through data automation and analysis solutions. Serve as an on-site consultant for existing data systems. Troubleshoot issues via root cause analysis and implement timely corrective actions Work with IT and subject matter experts to ensure data accuracy and availability. Upgrading existing dashboards, apps and tools based on business needs. Creating Power Platform applications for data entry and improving workflows. Skills/Experience Requirements: Major in Computer Science, Computer Engineering or related fields from a recognized university. Major in Engineering with a minor or second major in Computer Science from a recognized university. Strong knowledge and experience in Programming Languages like Java, Python, R, etc. Strong knowledge in data visualization tools like Python, PowerBI, Tableau, QlikView and SEEQ. Strong analytical/critical thinking/problem solving skills. Strong communication skills and stakeholder management skills. Knowledge in Microsoft Power Platform tools such as Power Apps, Power Automate, Power Query and Power BI. Strong knowledge and experience in SQL, batch scripting, etc. 2-3 years work experience as a Data Engineer, Data Analyst, Business Analyst or related roles in a mature manufacturing/tech/IT consultancy firm.",https://www.jobstreet.com.sg/en/job/data-engineer-10478906?jobId=jobstreet-sg-job-10478906&sectionRank=100&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
100,Senior Data Engineer (3+1 year contract),Economic Development Board,"About EDB The Singapore Economic Development Board (EDB), a government agency under the Ministry of Trade and Industry, is responsible for strategies that enhance Singapore’s position as a global centre for business, innovation, and talent. We undertake investment promotion and industry development, and work with international businesses, both foreign and local, by providing information, connection to partners and access to government incentives for their investments. Our mission is to create sustainable economic growth, with vibrant business and good job opportunities for Singapore. For more information on EDB, please visit www.edb.gov.sg We are looking for an experienced Data Engineer to grow EDB’s data warehouse. You will be responsible for designing, implementing, overseeing and maintaining of data flow channels and data processing systems. Responsibilities In this role, your responsibilities will include: Analysing information from structured and unstructured sources in a scalable, repeatable and secure manner. Supporting data scientists with the extraction of valuable insights from data sets to derive valuable and actionable insights and recommendations according to business requirements. Involvement in rollouts, upgrades, implementation and release of data system changes as required for streamlining of internal practices. Staying abreast with industry best practices and developments in analytics domain and analytics technology. Requirements Bachelor's degree in Information Systems (IS), Computer Science or related field in a reputed institution. At least 3 years relevant experience in designing, testing and maintaining a data warehouse and data marts. Proficient in creating and maintaining complex ETL pipeline end-to-end while maintaining high reliability and security. Proficient in implementing integrations to different systems, REST APIs and have good knowledge of web requests/protocols. Proficient in shell scripting, building modern APIs and reviewing codes and designs. Proficient in defining guidelines on coding and development practices. Excellent interpersonal and communication skills with the ability to engaging and managing internal and external stakeholders across all levels of seniority. Strong collaboration skills with the ability to build rapport across teams and stakeholders. Singaporean We review applications and interview on a rolling basis. Applicants can expect to receive an application outcome within 8 weeks of application date",https://www.jobstreet.com.sg/en/job/senior-data-engineer-3-1-year-contract-10476357?jobId=jobstreet-sg-job-10476357&sectionRank=101&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
101,Data Engineer (Remote possible) #Immediate | - #UrgentHire,TikTok,"Data Engineer (Remote possible) Competitive Remuneration Package Remote working available About the Client Our client is a high growth fintech firm with strong regional presence. They are seeking for an experienced Data Engineer to join their expanding team. Candidates who are not based in Singapore are welcomed as well. Main Duties &amp; Responsibilities Build scalable batch and real-time data pipelines to ingest data from various channels Set up a streamlined data lake and data warehouse Deploy production quality code and maintain data quality Establish tools for data ingesting and building data cubes Experience and Qualifications At least 4 years of experience Bachelor/Master’s degree in Computer Science, Engineering or a related field, software engineering background preferred Proficiency in Python, Java or Scala Hands-on experience implementing ETL (or ELT) best practices at scale Experience in designing data warehouse – Snowflake, Redshift or Athena Hands-on experience working with Kubernetes Experience with stream processing systems (Flink or Spark) Knowledge of big data technologies - Spark, Hadoop, Hive, Kafka, Flink etc. and machine learning is a plus Familiarity with machine learning tools from AWS or GCP preferred Knowledge of software engineering concepts will be valuable Interest &amp; Application Advance your career to the next level with this unique opportunity. To further consult on this role, please send your updated Word format resume to ""Apply Now"" Do note that only shortlisted candidates will be contacted. Personnel Registration No R22109255 EA license No. 09C5803",https://www.jobstreet.com.sg/en/job/data-engineer-remote-possible-immediate-%7C-urgenthire-10472685?jobId=jobstreet-sg-job-10472685&sectionRank=102&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
102,"Data Engineer, Video Infrastructure #UrgentHire #Immediate'",TikTok,"Responsibilities Video Infrastructure is a world-leading video platform that provides multi-media storage, delivery, transcoding, and streaming services. We are building the next generation video processing platform and the largest live streaming network, which provides excellent experiences for billions of users around the world. Popular video products of TikTok and its affiliates are all empowered by our cutting-edge cloud technologies. Working in this team, you will have the opportunity to tackle challenges of large-scale networks all over the world, while leveraging your expertise in coding, algorithms, complexity analysis, and large-scale system design. Responsibilities Craft optimal data processing architecture and systems for new data and ETL pipelines. Design, build, and maintain efficient and reliable data pipelines to move and transform data (both large and small amounts). Drive internal process improvements and automate manual processes for data quality and SLA management. Work with different cross-functional partners including CDN, Video Understanding, Video Transcoding, Live Streaming, and Real-Time Communication. Qualifications Bachelor's degree in Computer Science or a related technical background involving software/system engineering, or equivalent working experience. Good programming experience with at least one of the following languages: C, C++, Java, Python, or Go. Experience in custom ETL/data pipeline design, implementation, and maintenance. Experience with data processing software (Hadoop, Spark, Pig, Hive) and algorithms (MapReduce, Flume).",https://www.jobstreet.com.sg/en/job/data-engineer-video-infrastructure-urgenthire-immediate%27-10473307?jobId=jobstreet-sg-job-10473307&sectionRank=103&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
103,Senior Consultant (Data Engineer / ETL / BI),NTT Data Business Solutions Singapore Pte Ltd,"Job Description As the leading analytics provider in APAC and part of our Company's growth, we are looking for dynamic, motivated, and dedicated individuals to be part of our team in Singapore. If you have the right skill set, driven, willing to learn and demonstrates a can-do attitude, come join us ! We welcome candidates of all levels. Responsibilities Deliver end-to-end Business Intelligence, Analytics and Data Management solutions to customer Work with the larger team in technical design sessions to define data definition, data and analytics solution requirements and specifications Analyse business requirements, designing, developing, testing &amp; supporting application and Data warehouses from build to production (including proof-of-concept) Ability to develop test plans and lead testing cycles Provide product and application support and maintenance when needed Actively participates in defining solution options and selecting the appropriate BI, Analytics and Data Management solution Development of ETL pipelines, data management and BI platform Ensures appropriate documentation, customer involvement and sign-off Develop development framework and assign development effort to team members Actively leads and manages team members to a successful project Requirements Diploma/Degree in Computer Science / Computer Engineering / Information Technology related field or IT equivalent Have 3 - 5 years’ experience in Business Intelligence/Data Warehouse/Analytics / Big Data Projects involving in requirements gathering designing, development, deployment, conducting knowledge transfer and post deployment support Have 3 - 5 years’ experience with ETL, Business Intelligence and Visualization Tools Have experience with Data Modelling using dimensional modelling techniques and designing the metadata layer for self-service analytics Have experience actively leading and managing a team of 3 to 5 members Independent with ability to work effectively in a team and who takes initiative and engages their colleagues Excellent communication and interpersonal skills with ability to communicate with clarity and confidence with colleagues and customers Likes technology, taking initiative to learn more and share knowledge with juniors and within the team Proven abilities to take initiative, innovative and the ability to develop creative solutions for challenging client needs Additional knowledge it would be great to have: SAP related skillsets S/4 HANA, SAP Analytics Cloud, SAP BW Cloud and network concepts Databases such as MariaDB, MySQL, PostgreSQL Programming languages such as Java, Python, ASP.Net with C#.Net or VB.Net AWS, Azure or Google Cloud Platform services and products",https://www.jobstreet.com.sg/en/job/senior-consultant-data-engineer-etl-bi-10444278?jobId=jobstreet-sg-job-10444278&sectionRank=104&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
104,"Data Engineer Intern, TikTok #WorkNow #Urgent #JobsThatMatter* | #LetsGoToWork | - #UrgentHire",TikTok,"About TikTok TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul, and Tokyo. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok e-commerce business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Responsibilities Responsible for providing end to end solutions to enable business; Responsible for data warehouse modeling design &amp; implementation; Responsible for data pipeline &amp; services development for data products; Responsible for developing and optimizing ETL processes; Responsible for enriching &amp; optimizing technical documents; Qualifications 1Undergraduate, or Postgraduate who is currently pursuing a degree in Computer Science, related engineering discipline, or equivalent practical experience; Proficiency in SQL with related project experience; Software development experience in one or more general-purpose programming languages, such as Java/Go/C++/C#/Python; Good understanding of the Hadoop ecosystem, open-source big data tech stacks like Hive, MapReduce, Spark, etc; Familiar with large-scale data warehouse architecture design, data model design, and ETL; Good understanding of streaming pipeline development, open-source OLAP engines, or Machine Learning/Data Mining is a plus; .Strong analytical thinking and exceptional attention to detail; Working proficiency in verbal and written English; Able to commit at least 3 days a week.",https://www.jobstreet.com.sg/en/job/data-engineer-intern-tiktok-worknow-urgent-jobsthatmatter*-%7C-letsgotowork-%7C-urgenthire-10473461?jobId=jobstreet-sg-job-10473461&sectionRank=105&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
105,"Big Data Engineer, Recommendation Architecture #UrgentHire #WorkNow #Immediate",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-urgenthire-worknow-immediate-10473291?jobId=jobstreet-sg-job-10473291&sectionRank=106&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
106,Data Engineer - TikTok #UrgentHire #JobsThatMatter,TikTok,"Responsibilities About TikTok TikTok is the world's leading destination for short-form mobile videos. Our mission is to capture and present the world's creativity, knowledge, and moments that matter in everyday life. TikTok empowers everyone to be a creator directly from their smartphones and is committed to building a community by encouraging users to share their passion and creative expression through their videos. TikTok has offices in Beijing, Berlin, Jakarta, London, Los Angeles, Moscow, Mumbai, Sao Paulo, Seoul, Shanghai, Singapore, and Tokyo. In 2018, TikTok was one of the most downloaded apps in the world. TikTok is available worldwide for iOS and Android. Visit tiktok.com. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Translate business requirements &amp; end to end designs into technical implementations and responsible for building batch and real-time data warehouse Manage data modeling design, writing, and optimizing ETL jobs Collaborate with the business team to building data metrics based on data warehouse Responsible for building and maintaining data products Involvement in rollouts, upgrades, implementation, and release of data system changes as required for streamlining of internal practices Qualifications At least 5 years in software engineering and 2 years of relevant experience in data engineering Proficient in creating and maintaining complex ETL pipelines end-to-end while maintaining high reliability and security Familiar with data warehouse concept and have production experience in modeling design Familiar with at least 1 distributed computing engine (e.g. Hive, Spark, Flink) Familiar with at least 1 NoSQL database is a plus (e.g. HBase) Excellent interpersonal and communication skills with the ability to engage and manage internal and external stakeholders across all levels of seniority Strong collaboration skills with the ability to build rapport across teams and stakeholders",https://www.jobstreet.com.sg/en/job/data-engineer-tiktok-urgenthire-jobsthatmatter-10473271?jobId=jobstreet-sg-job-10473271&sectionRank=107&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
107,Senior Data Engineer #Immediate,Aon Hewitt,"Job Description We’re hiring! Aon's Center for Innovation &amp; Analytics (ACIA) is currently recruiting a Senior Data Engineer to join our Health Analytics team in Singapore. About ACIA Aon’s Centers for Innovation and Analytics are at the heart of delivering Aon’s Data &amp; Analytic Services team’s mission to: Accelerate the rate of innovation through digital solutions to help better respond to clients’ evolving needs Provide foundational data and analytics capabilities in one place for 50,000 Aon colleagues and our global clients who use our risk and people solutions Established in 2012, there are over 150 colleagues in Singapore’s Centre today including actuaries, software developers, data scientists, financial analysts and accountants. We are expanding rapidly and looking for dedicated individuals who can leverage emerging technologies and collaborate across Aon’s solution lines to help clients and colleagues make better, data-driven decisions today and tomorrow. What the day will look like. Be part of a dynamic team focused on healthcare data and innovation initiatives Collaborate with a team of experienced actuaries, data scientists, developers and business experts to deliver on Aon’s data, analytics and reporting capabilities Lead the design, build and maintenance of a scalable data pipeline architecture from ingestion to transformation to storage to consumption across various applications Focus on an efficient approach to design, allowing for agile and robust development to meet ever-changing business needs Contribute to the design of our data lake and the development of all data assets and downstream warehouses/marts Partner with data scientists and analysts to ensure efficient and accurate flow of data into downstream analytics tools and reporting solutions Implement automation wherever possible to streamline the process, minimizing the need for manual intervention Assist in database performance tuning and data lifecycle management Develop and integrate an automated data validation and quality control mechanism throughout the pipeline Problem solve complex issues and work to create elegant, simplified solutions Maintain up-to-date technical and operational documentation Skills and experience that will lead to success. BS or MS degree in Computer Science, Information Technology or equivalent 5+ years in-depth experience in working with a relational database system (eg. MSSQL, PostgreSQL) Highly knowledgeable in ETL/ELT processes, both design and implementation Some experience in a programming language (eg.Python ,C#) Experience building data pipelines that ingests various types of data sources into a database or data lake and populating a structured warehouse or data mart Fluent in both complex SQL query performance tuning and database performance tuning Experience in Apache Spark/Databricks, Python/Pandas, R/Tidyverse and large file processing and analytics data pipelines Knowledge of data security and privacy practices and regulations, including data access controls and de-identification and protection of sensitive data Proven ability to convey technical information successfully to a wide variety of stakeholders Quick and eager student of new technologies as and when they are needed Knowledge of Agile Scrum and Continuous Delivery practices is desirable Experience in BI tools (e.g. Tableau, Power BI) is an advantage Experience working with medical and prescription drug claims data is an advantage How to Apply Your opportunity to empower results could start right here. Make your mark and apply online today with a brief covering letter and your resume, sharing relevant achievements for this position. Please upload your resume in PDF format. How we support our colleagues In addition to our comprehensive benefits package, we encourage a diverse workforce. Plus, our agile, inclusive environment allows you to manage your wellbeing and work/life balance, ensuring you can be your best self at Aon. Furthermore, all colleagues enjoy two “Global Wellbeing Days” each year, encouraging you to take time to focus on yourself. We offer a variety of working style solutions, but we also recognise that flexibility goes beyond just the place of work... and we are all for it. We call this Smart Working! Our continuous learning culture inspires and equips you to learn, share and grow, helping you achieve your fullest potential. As a result, at Aon, you are more connected, more relevant, and more valued.",https://www.jobstreet.com.sg/en/job/senior-data-engineer-immediate-10474018?jobId=jobstreet-sg-job-10474018&sectionRank=108&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
108,Big Data Engineer (Ads Data) - 2023 Start #Worknow`,TikTok,"Responsibilities TikTok will be prioritizing applicants who have a current right to work in Singapore, and do not require TikTok's sponsorship of a visa. TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. Why Join Us At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok. We are looking for talented individuals to join us for this future position in 2023. As a graduate, you will get unparalleled opportunities for you to kickstart your career, pursue bold ideas and explore limitless growth opportunities. Co-create a future driven by your inspiration with TikTok. Candidates can apply to a maximum of two positions and will be considered for jobs in the order you apply. The application limit is applicable to all TikTok and its affiliates' jobs globally. Applications will be reviewed on a rolling basis - we encourage you to apply early. About the Team The Ads Data team provides tools and services to deliver ad data to millions of internal and external clients all around the globe. The team has end-to-end ownership of ad data's lifecycle including data ETL, data warehouse and data services. We leverage data technologies to advice local customer support teams and help global advertisers make wiser investment decisions on our Advertising Platform. Ads Data is the cornerstone of every business decision that millions of advertisers make every day on our platform. Therefore, we are tasked with innovating on daily basis to create and maintain complex systems at large scale and continue expanding the capacity to better serve advertisers growing at exponential pace. You will share in the ownership of the technical vision and direction for advanced Ads Data products. You will be a part of a team of top notch technical professionals developing scalable systems and with a focus on sustained operational excellence. Members of this team will be challenged to innovate using cutting edge technologies. We are looking for people who are highly motivated by aiming for the highest, moving fast, and changing the way customers use data to drive profitability. Responsibilities Translate business requirements into technical implementations and responsible for building batch and real-time data warehouse; Design, build and launch real-time/batch data models/pipelines in production; Build up data marts and own data quality for business areas; Support existing real-time/batch systems in production, solve on-call issues; Define and manage SLA for all data sets in business areas; Support daily project management, assist junior engineers in business and technical problems. Qualifications Final year or Entry level with a background in Software Development, Computer Science, Computer Engineering, or a related technical discipline Experience working with big data technologies such as Hadoop, Hive, Spark, etc.; Experience with schema design and dimensional data modelling; Experience in custom ETL design, implementation and maintenance; Proficient in at least one programming language such as Python, Java or C++; Good communication skills, including the ability to identify and communicate data driven insights. TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https://careers.tiktok.com/legal/privacy. If you have any questions, please reach out to us at apac-""Apply Now""",https://www.jobstreet.com.sg/en/job/big-data-engineer-ads-data-2023-start-worknow-10474598?jobId=jobstreet-sg-job-10474598&sectionRank=109&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
109,"Data Engineer, Growth #Immediate`",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. The Growth team plays a core role in acquisition, activation, and retention of billions of users, through our globally popular products such as TikTok, Resso, CapCut, Helo, etc. We are building platform foundation, leveraging data and ML models, and providing end-to-end solutions to power global growth of ByteDance products. Typical Growth projects including referral, notifications, paid ads, etc. You will: Build data pipelines to portray business status, based on a deep understanding of our fast changing business and data-driven approach; Extract information and signals from a broad range of data and build hierarchies to accomplish analytical and mining goals for “Packaged Business Capability” such as user-growth, gaming and searching; Keep improving the integrity of data pipelines to provide a comprehensive data service. Qualifications Bachelor's degree in Computer Science, Statistic, Data Science or a related field; Skilled in SQL and additional object-oriented programming language (e.g. Scala, Java, or Python); Experience in issue tracking and problem solving on data pipelines; Fast business understanding and collaborative in teamwork.",https://www.jobstreet.com.sg/en/job/data-engineer-growth-immediate-10467278?jobId=jobstreet-sg-job-10467278&sectionRank=110&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
110,Project Officer (Programmer/Data Engineer) #UrgentHire --| #LetsGotoWork.,Nanyang Technological University,"The Rehabilitation Research Institute of Singapore (RRIS) invites applications for the position of Project Officer. Key Responsibilities: The successful candidate will work on a research project to implement the core biomechanical analysis plugins on top of the measurement layers from the markerless motion capture system. To have a proper set of features, the job also includes communicating with potential users of the system to find the needs and requirements for the plugin development. Those features may include automatic event detection, normative comparison, self-comparison, and their visualizations. The job also includes the development of a flexible plugin system to allow a third-party developer to develop their own plugin for the analysis layer. The job also includes the development of software to scan through the results from the trained model to find its weakness and regularly perform training data patching or algorithmic patching. Job Requirements: Degree (MS or BS) in Computer Science, Computer Engineering, Electrical/Electronic Engineering, Mechanical Engineering, engineering, or equivalent industry experience. Python programming Experiences in machine learning for image processing with PyTorch Experiences in articulated human modelling or biomechanics Experiences in camera calibration, digital image processing and OpenCV. Experiences in 3D visualization library such as OpenGL, PyOpenGL, or Vispy will be an advantage. Experiences in at least one human motion capture system. We regret that only shortlisted candidates will be notified.",https://www.jobstreet.com.sg/en/job/project-officer-programmer-data-engineer-urgenthire-%7C-letsgotowork.-10469799?jobId=jobstreet-sg-job-10469799&sectionRank=111&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
111,Big Data Engineer (Hadoop/Spark) | Up to $6500/mth | 1 year contract (extendable),RecruitFirst Pte. Ltd,"Join one of the largest Tech Gaming MNC in the region! This is an APAC role that provides extremely great exposure for portfolio building. Responsibilities: Responsible for the development, maintenance and positioning of big data systems Responsible for the development of big data analysis tasks using Hadoop, HiveSQL, Spark Construction of Offline databases Perform SQL development Implementing real-time data warehouse using Flink Requirements: Degree in Computer Science or related technical field with at least 2 years experience in big data Proficient in Python, Java or other programming language Proficient in Databases such as MySQL/Hive/Redis Mandarin speaking candidates preferred as the role requires liaising with China HQ and business partners Singaporeans only Other Information: Raffles Place Mon - Fri, 9am - 6pm Remuneration between $6000 - $6500 per month (depending on qualification &amp; years of experience.) Comfortable with 1 year renewable contract. Cassandra Foo R22104596 RecruitFirst Pte Ltd E.A.13C6342",https://www.jobstreet.com.sg/en/job/big-data-engineer-hadoop-spark-%7C-up-to-%246500-mth-%7C-1-year-contract-extendable-10446960?jobId=jobstreet-sg-job-10446960&sectionRank=112&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
112,"Data Engineer Intern, Growth #Urgent - #UrgentHire",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. The Growth team plays a core role in acquisition, activation, and retention of billions of users, through our globally popular products such as TikTok, Resso, CapCut, Helo, etc. We are building platform foundation, leveraging data and ML models, and providing end-to-end solutions to power global growth of our products. Typical Growth projects include referral, notifications, paid ads, etc. Responsibilities Build data pipelines and reports to portray business status, based on a deep understanding of our fast changing business with data-driven approaches; Extract information and signals from a broad range of data and build hierarchies to accomplish analytical and mining goals for “Packaged Business Capability” such as growth, gaming and search; Continually improve the integrity of data pipelines to provide a comprehensive data service. Qualifications Undergraduate, or Postgraduate who is currently pursuing a degree/master in Engineering, Computer Science, Statistics, Data Science or a related technical discipline from a university; Experience in SQL and an additional object-oriented programming language (e.g., Python, Java, or Scala); Experience in issue tracking and problem-solving on data pipelines; Strong analytical thinking and exceptional attention to details.",https://www.jobstreet.com.sg/en/job/data-engineer-intern-growth-urgent-urgenthire-10467582?jobId=jobstreet-sg-job-10467582&sectionRank=113&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
113,Senior Data Engineer,Tencent International Service Pte. Ltd.,"Responsibilities: Design, build and own the core data models and systems that able to support petabyte of data pipeline across the Tencent's overseas games. Analyze large amounts of players’ data with business use cases to bridge the gaps of data-driven lifecycles. Partner with multiple internal teams and external partners to collect requirements and deliver large-scale data solutions for various analytics and business applications. Collaborate with product team to define, create, and maintain data applications and platform such as real-time platforms, data pipeline, telemetry implementation, and machine learning deployment to help achieve Tencent's publishing goals. The challenges range from building real-time and offline distributed data processing pipelines for feature engineering and automation as well as building systems and frameworks to deploy, scale, test, monitor real-time machine learning models and user acquisition algorithms. Requirements: Advanced degree in Computer Science, Engineering, Mathematics or equivalent technical field. Programming and scripting language (e.g. SQL, Python, Java/Scala, Golang). 4+ years of professional software development: experience in backend development experience with interest in work involving data pipelines, distributed systems, and large-scale data processing. Experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Flink, Kafka, Impala, HBase etc.) for building efficient and large-scale data pipelines. Experience shipping scalable data solutions in the cloud (AWS, Azure, GCP) and database technologies such as Snowflake, Redshift, SQL/NoSQL and or columnar databases. Dynamic team player with ability to handle numerous requests concurrently and strategically, prioritizing when necessary. Strong problem-solving skills with an ability to isolate, deconstruct and resolve complex data engineering challenges. Ability to communicate with worldwide business stakeholders regard data products and technical requests. Proven track record to clearly form and communicate ideas to both technical and non-technical worldwide audiences.",https://www.jobstreet.com.sg/en/job/senior-data-engineer-10469753?jobId=jobstreet-sg-job-10469753&sectionRank=114&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
114,"Data Engineer Intern, TikTok #WorkNow #JobsThatMatter`",TikTok,"About TikTok TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul, and Tokyo. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok e-commerce business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Responsibilities Responsible for providing end to end solutions to enable business; Responsible for data warehouse modeling design &amp; implementation; Responsible for data pipeline &amp; services development for data products; Responsible for developing and optimizing ETL processes; Responsible for enriching &amp; optimizing technical documents; Qualifications Undergraduate, or Postgraduate who is currently pursuing a degree in Computer Science, related engineering discipline, or equivalent practical experience; Proficiency in SQL with related project experience; Software development experience in one or more general-purpose programming languages, such as Java/Go/C++/C#/Python; Good understanding of the Hadoop ecosystem, open-source big data tech stacks like Hive, MapReduce, Spark, etc; Familiar with large-scale data warehouse architecture design, data model design, and ETL; Good understanding of streaming pipeline development, open-source OLAP engines, or Machine Learning/Data Mining is a plus; Strong analytical thinking and exceptional attention to detail; Working proficiency in verbal and written English; Able to commit at least 3 days a week.",https://www.jobstreet.com.sg/en/job/data-engineer-intern-tiktok-worknow-jobsthatmatter-10467589?jobId=jobstreet-sg-job-10467589&sectionRank=115&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
115,"Big Data Engineer, Recommendation Architecture #Seekbetter",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-seekbetter-10467092?jobId=jobstreet-sg-job-10467092&sectionRank=116&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
116,"Big Data Engineer, Recommendation Architecture #WorkNow",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-worknow-10469838?jobId=jobstreet-sg-job-10469838&sectionRank=117&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
117,Big Data Engineer - Recommendation Architecture`,TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability Willing to challenge questions that have no obvious answers, and have a strong enthusiasm for learning new technologies Experience of Peta Byte level data processing is a plus At least 3 years of relevant experience TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-10468361?jobId=jobstreet-sg-job-10468361&sectionRank=118&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
118,Data Engineer,mDR Limited,"Job description Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions. Mine and analyze data from company databases to drive optimization and improvement of product / project development, marketing techniques and business strategies. Assess the effectiveness and accuracy of new data sources and data gathering techniques. Develop custom data models and algorithms to apply to data sets. Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes. Work with Product to define product / project requirements. Strong problem solving skills with an emphasis on product / project development. Provide 2nd layer develops support. Manage &amp; develop company A/B testing framework and test model quality. Coordinate with different functional teams to implement models and monitor outcomes. Develop processes and tools to monitor and analyze model performance and data accuracy. Other ad hoc technical related assignments by senior manager. Requirements Degree in Data Science, Computer Science, Big Data, Machine Learning Entry level candidates are welcome to apply Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets. Coding knowledge with several languages: C, C++, Java, JavaScript, etc. Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc. Experience querying databases and using statistical computer languages: R, Python, SQL, etc. Experience using web services: Redshift, S3, Spark, DigitalOcean, etc. Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc. Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc. Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.",https://www.jobstreet.com.sg/en/job/data-engineer-10442936?jobId=jobstreet-sg-job-10442936&sectionRank=119&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
119,[Digital] Analytics Engineer / Data Engineer,Pfizer (Malaysia),"ROLE SUMMARY Do you want to make an impact on patient health around the world? Do you thrive in a fast-paced environment that brings together scientific, clinical and commercial domains through engineering, data science, and analytics? Then join Pfizer Digital’s Artificial Intelligence, Data, and Analytics organization (AIDA) where you can leverage cutting-edge technology to inform critical business decisions and improve customer experiences for our patients and physicians. Our collection of engineering, data science, and analytics professionals are at the forefront of Pfizer’s transformation into a digitally driven organization leveraging data science and advanced analytics to change patient’s lives. The Industrialization team within Enterprise Data Science and Advanced Analytics leads the scaling of data and insights capabilities - critical drivers and enablers of Pfizer’s digital transformation. As a senior associate analytics engineer, you will be part of the Data Science Industrialization team charged with building and automating high quality data pipelines that power advanced analytics/AI/ML and key business applications. You will be a member of a global team helping to develop and innovate on commercial go-to-market strategies. ROLE RESPONSIBILITIES Leverage data wrangling techniques to deliver data pipelines that Ingest and integrate data from various information sources and deliver high quality data products that drive analytics and data science applications Translate data needs into intro programable queries and convert Python based data wrangling code into PySpark/SQL pipelines for scalable pushdown execution Conduct basic data profiling and quality checks Fine tune performance on datasets for visualization and other applications Develop automated and self-monitoring data pipelines including automated QA/QC processes Work with stakeholders to assist with data-related technical issues and support data infrastructure needs. QUALIFICATIONS BASIC QUALIFICATIONS Bachelor’s degree in analytics engineering related area (Data Science, Computer Engineering, Computer Science, Information Systems or related discipline) 2+ years of work experience as an analyst/analytics engineer for a diverse range of projects Strong hands-on skills in analytics engineering (e.g., Python, industrialized ETL software) Experience working in a cloud based analytics ecosystem (AWS, Snowflake, etc) Experience with working with various types of data (structured / unstructured) Understanding of data ingestion, data warehousing, and data model concepts Knowledge of relational and dimensional data structures, theories, and practices Proficient in SQL, Python Highly self-motivated to deliver both independently and with strong team collaboration. Ability to creatively take on new challenges and work outside comfort zone. Strong aptitude for learning new technologies and analytics techniques. PREFERRED QUALIFICATIONS Advanced degree in Data Science, Computer Engineering, Computer Science, Information Systems or related discipline Experience with Dataiku is a plus Hands on experience working in Agile teams, processes, and practices Experience with hands-on skills in containerization (e.g. AWS EKS, Kubernetes) Experience with hands-on skills for data pipeline orchestration (e.g. Airflow) Understanding of data science development lifecycle (e.g CRISP) Pharma &amp; Life Science commercial functional knowledge is a plus Pharma &amp; Life Science commercial data literacy is a plus Work Location Assignment: Flexible Pfizer is an equal opportunity employer and complies with all applicable equal employment opportunity legislation in each jurisdiction in which it operates. Information &amp; Business Tech #LI-PFE",https://www.jobstreet.com.sg/en/job/%5Bdigital%5D-analytics-engineer-data-engineer-10469169?jobId=jobstreet-sg-job-10469169&sectionRank=120&token=0~ebc60912-65b7-445b-a642-bba1fc7e2497&fr=SRP%20Job%20Listing
120,"Data Engineer, Group Banking Technology, - #WorkNow#Seekbetter -- #LetsGoToWork",United Overseas Bank Limited (UOB),"About UOB United Overseas Bank Limited (UOB) is a leading bank in Asia with a global network of more than 500 branches and offices in 19 countries and territories in Asia Pacific, Europe and North America. In Asia, we operate through our head office in Singapore and banking subsidiaries in China, Indonesia, Malaysia and Thailand, as well as branches and offices.Our history spans more than 80 . Over this time, we have been guided by our values — Honorable, Enterprising, United and Committed. This means we always strive to do what is right, build for the future, work as one team and pursue long-term success. It is how we work, consistently, be it towards the company, our colleagues or our customers. About the Department The Technology and Operations function is comprised of five teams of specialists with distinct capabilities: business partnership, technology, operations, risk governance and planning support and services. We work closely together to harness the power of technology to support our and digital banking services and operations. This includes developing, centralising and standardising technology systems as well as banking operations in Singapore and overseas branches. Job Responsibilities Take end-to-end development ownership for one or more modules and deliver to production Understand functional requirements / user stories and come up with effective solutions by breaking down into meaningful tasks Participate as a member of agile team and deliver high quality software Man multiple projects at the same time Guide and support other members of the team, including temporary staff to perform effectively in their role Communicate with other stakehers like other project teams, infrastructure security teams as required and man dependencies Understand and follow UOB software delivery process deliverables, ensure process compliance Create a network with other departments and teams, to know about strategic issues and new developments Understand long terms strategic plans for the department and support towards the same Possess personal cour to do what is right and work as a team member to meet customer expectations Continuously prioritize technical debt for the team and ensure they are taken care in project releases Participate in int meetings (planning, review) and estimate stories, breakdown to tasks Prepare for int demos and demonstrate to Product Owner, receive feedback and implement Exhibit good attention to detail and enthusiasm to take ownership Job Requirements Degree in Computer Science or related discipline Strong knowledge and experience building Apache Kafka applications Strong working experience with Java, ing Boot and API (Microservices) Experience building data pipelines with Apache NiFi in production scale Experience building data streaming applications using Apache Spark and Kafka Streams Experience working with a variety of data sources and sinks (API, MQ, Files, Databases, Hot lakes, Big data systems etc.) Experience with both SQL and NoSQL databases (like MariaDB, Oracle, MongoDB) and Object-Relational Mapping (ORM) frameworks (e.g. Hibernate) Experience with CI/CD practices and tools (Bitbucket, Jenkins, Artifactory, Veracode etc.) to build pipelines Familiarity with Agile development methodologies Experience with software design and development in a test-driven environment Experience tuning Kafka and NiFi components for varying traffic and performance requirements Ability to learn new programming langus and technologies Excellent communication skills to interact within and outside the team Be a part of UOB Family UOB is an equal opportunity employer. UOB does not discriminate on the basis of a candidate's , race, gender, color, religion, sexual orientation, or mental disability, or other non-merit factors. All employment decisions at UOB are based on business needs, job requirements and qualifications. If you require any assistance or accommodations to be made for the recruitment process, please inform us when you submit your online application. Apply now and make a difference.",https://www.jobstreet.com.sg/en/job/data-engineer-group-banking-technology-worknow-seekbetter-letsgotowork-10470611?jobId=jobstreet-sg-job-10470611&sectionRank=121&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
121,Big Data Engineer (Ads Data) - 2023 Start #Worknow`- | #UrgentHire#Immediate,TikTok,"Responsibilities TikTok will be prioritizing applicants who have a current right to work in Singapore, and do not require TikTok's sponsorship of a visa. TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. Why Join Us At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok. We are looking for talented individuals to join us for this future position in 2023. As a graduate, you will get unparalleled opportunities for you to kickstart your career, pursue bold ideas and explore limitless growth opportunities. Co-create a future driven by your inspiration with TikTok. Candidates can apply to a maximum of two positions and will be considered for jobs in the order you apply. The application limit is applicable to all TikTok and its affiliates' jobs globally. Applications will be reviewed on a rolling basis - we encourage you to apply early. About the Team The Ads Data team provides tools and services to deliver ad data to millions of internal and external clients all around the globe. The team has end-to-end ownership of ad data's lifecycle including data ETL, data warehouse and data services. We leverage data technologies to advice local customer support teams and help global advertisers make wiser investment decisions on our Advertising Platform. Ads Data is the cornerstone of every business decision that millions of advertisers make every day on our platform. Therefore, we are tasked with innovating on daily basis to create and maintain complex systems at large scale and continue expanding the capacity to better serve advertisers growing at exponential pace. You will share in the ownership of the technical vision and direction for advanced Ads Data products. You will be a part of a team of top notch technical professionals developing scalable systems and with a focus on sustained operational excellence. Members of this team will be challenged to innovate using cutting edge technologies. We are looking for people who are highly motivated by aiming for the highest, moving fast, and changing the way customers use data to drive profitability. Responsibilities Translate business requirements into technical implementations and responsible for building batch and real-time data warehouse; Design, build and launch real-time/batch data models/pipelines in production; Build up data marts and own data quality for business areas; Support existing real-time/batch systems in production, solve on-call issues; Define and manage SLA for all data sets in business areas; Support daily project management, assist junior engineers in business and technical problems. Qualifications Final year or Entry level with a background in Software Development, Computer Science, Computer Engineering, or a related technical discipline Experience working with big data technologies such as Hadoop, Hive, Spark, etc.; Experience with schema design and dimensional data modelling; Experience in custom ETL design, implementation and maintenance; Proficient in at least one programming language such as Python, Java or C++; Good communication skills, including the ability to identify and communicate data driven insights. TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https://careers.tiktok.com/legal/privacy. If you have any questions, please reach out to us at apac-""Apply Now""",https://www.jobstreet.com.sg/en/job/big-data-engineer-ads-data-2023-start-worknow-%7C-urgenthire-immediate-10470104?jobId=jobstreet-sg-job-10470104&sectionRank=122&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
122,"VP, Data Engineer - Platform Tools #Seekbetter | - #LetsGoToWork",United Overseas Bank Limited (UOB),"About UOB United Overseas Bank Limited (UOB) is a leading bank in Asia with a global network of more than 500 branches and offices in 19 countries and territories in Asia Pacific, Europe and North America. In Asia, we operate through our head office in Singapore and banking subsidiaries in China, Indonesia, Malaysia and Thailand, as well as branches and offices. Our history spans more than 80 years. Over this time, we have been guided by our values – Honorable, Enterprising, United and Committed. This means we always strive to do what is right, build for the future, work as one team and pursue long-term success. It is how we work, consistently, be it towards the company, our colleagues or our customers. About the Department The Technology and Operations function is comprised of five teams of specialists with distinct capabilities: business partnership, technology, operations, risk governance and planning support and services. We work closely together to harness the power of technology to support our physical and digital banking services and operations. This includes developing, centralising and standardising technology systems as well as banking operations in Singapore and overseas branches. Job Responsibilities You will be responsible for the end-to-end software development and support for all work related to projects, quarterly change requests, L3 production fixes. This includes software product implementation and administration, application design, development, implementation, testing and support. You will also be responsible for quality assurance of the team’s delivery in conformance with the Bank-defined software delivery methodology and tools. You will partner with other technology functions to help deliver required technology solutions. - Create frameworks, technical features which helps in faster operationalisation of Data models, Analytical models(including AI/ML) and user generated contents (dashboards, reports etc) - Effectively partner with citizen data scientists in enabling faster adoption of AL/ML model based systems - Independently install, customise and integrate software packages and programs - Carry out POCs involving new data technologies - Design and develop application frameworks for data integration - Create technical documents such as solution design, program specifications for target solutions - Perform design and development of applications which may not be limited to: Software Applications, Data Integration, User Interfaces, Automation - Maintain and recommend software improvements to ensure a platform centric management of software applications - Performance tuning - Work with production support team members to conduct root cause analysis of issues, review new and existing code and/or perform unit testing - Perform tasks as part of a cross functional development team using agile or other methodologies and utilising project management software Job Requirements Functional skillsets TEAM &lt;&lt; Data Lake, EDW, Data marts, GDW, Data Integration &gt;&gt; Hands-on experience in implementing large scale data warehouse &amp; analytics platforms in financial services industry with good functional knowledge of products &amp; services offered in Retail bank / Wholesale / Global Markets covering some of the following analytics domains: - Data Modeling, Data mapping for Data Warehouse and Data Marts solutions - FSLM or similar industry models - Financial domain - Retail , Wholesale, Compliance , Digital - Experience in analytics - Finance Analytics , Credit Risk Analytics , Credit Scoring, Financial Crime Analytics - Experience in decision systems - Campaign Analytics, Credit Analytics - Expertise in design of role based fine grained access control - Designing cloud ready data solutions, Virtualization Technical skillsets TEAM &lt;&lt;Data Lake, EDW, Data marts, GDW, Data Integration&gt;&gt; - Expertise in implementing Teradata based EDW and Data mart solution using ETL tool such as (Informatica Power Centre, BDM), GCFR based framework, BTEQ scripts - Expertise in implementing Hadoop based Data mart using Spark based framework (Java, Scala, Pyspark) - Good knowledge and working experience in data loading into Teradata using different load pattern (TPT, MLOAD, FAST Load), data compression (MVC, BLC) - Expertise in implementing Data Governance tools; Data Lineage (eg: Informatica MM, EDC), Business Glossary and Data Quality - Expertise in implementing Reference data management (Data standardization, Hierarchy maintenance) using tools (eg: MDM,RDM) - Good knowledge and working experience in Teradata FSLM or similar industry standard data model - Expertise in Cloudera CDH / CDP components - Good knowledge in developing Spark based ingestion framework (Java, Scala, Pyspark) - Experience in building and operationalising feature pipeline to support AI/ML model execution, data pipelines for supporting large scale data warehouse/data marts Additional requirements - 2 to 3 technical certifications from enclosed list: • Cloudera Hadoop distribution – Hive, Impala, Spark, Kudo, Kafka, Flume • Teradata – Bteq, Query Grid, GCFR, MDM, Data Mover, BAR • Informatica Data Integration – PC, IDR, BDM, MM, IDQ, EDC • Data modelling tools (Erwin) • QlikSense • Microsoft – R • Data science workbenches – Cloudera Workbench, Jupyter, DataRobot, H2O.AI, IBM DSX • Data Virtualization tool (Denodo, Dremio) • AS400 • Language – SQL, Java, Python, Scala, Pyspark • Automation / scripting – CtrlM, Shell Scripting, Groovy Be a part of UOB Family UOB is an equal opportunity employer. UOB does not discriminate on the basis of a candidate's age, race, gender, color, religion, sexual orientation, physical or mental disability, or other non-merit factors. All employment decisions at UOB are based on business needs, job requirements and qualifications. If you require any assistance or accommodations to be made for the recruitment process, please inform us when you submit your online application. Apply now and make a difference.",https://www.jobstreet.com.sg/en/job/vp-data-engineer-platform-tools-seekbetter-%7C-letsgotowork-10470092?jobId=jobstreet-sg-job-10470092&sectionRank=123&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
123,"VP, - Data Engineer - #LetsGetToWork #Seekbetter| - #LetsGoToWork",United Overseas Bank Limited (UOB),"About UOB United Overseas Bank Limited (UOB) is a leading bank in Asia with a global network of more than 500 branches and offices in 19 countries and territories in Asia Pacific, Europe and North America. In Asia, we operate through our head office in Singapore and banking subsidiaries in China, Indonesia, Malaysia and Thailand, as well as branches and offices. Our history spans more than 80 years. Over this time, we have been guided by our values — Honorable, Enterprising, United and Committed. This means we always strive to do what is right, build for the future, work as one team and pursue long-term success. It is how we work, consistently, be it towards the company, our colleagues or our customers. About the Department The Technology and Operations function is comprised of five teams of specialists with distinct capabilities: business partnership, technology, operations, risk governance and planning support and services. We work closely together to harness the power of technology to support our physical and digital banking services and operations. This includes developing, centralising and standardising technology systems as well as banking operations in Singapore and overseas branches. Job Responsibilities The Data Engineer will be directly responsible for the end-to-end software development and support for all work related to projects, quarterly change requests, L3 production fixes. This includes software product implementation and administration, application design, development, implementation, testing and support. You will be expected to work on Finance &amp; Risk Analytics. You will also be responsible for quality assurance of the team's delivery in conformance with the Bank-defined software delivery methodology and tools. You will partner with other technology functions to help deliver required technology solutions: Create frameworks, technical features which helps in faster operationalisation of Data models, Analytical models (including AI/ML) and user generated contents (dashboards, reports etc) Effectively partner with citizen data scientists in enabling faster adoption of AL/ML model based systems Independently install, customise and integrate software packages and programs Carry out POCs involving new data technologies Design and develop application frameworks for data integration Create technical documents such as solution design, program specifications for target solutions Perform design and development of applications which may not be limited to: Software Applications, Data Integration, User Interfaces, Automation Maintain and recommend software improvements to ensure a platform centric management of software applications Performance tuning Work with production support team members to conduct root cause analysis of issues, review new and existing code and/or perform unit testing Perform tasks as part of a cross functional development team using agile or other methodologies and utilising project management software What will help you succeed in this role Adopt an uncompromising attitude when it comes to quality and help raise bar of products and team members Be a team player who communicates effectively and professionally with both internal and external customers Identify ideas to improve system performance and impact availability Embrace tackling and resolving complex technical design issues Possess strong problem solving and decision-making skills while exercising good judgment Strong analytical and problem-solving skills Ability to work on multiple projects at a time Be able to work under pressure and manage deadlines or unexpected changes in expectations or requirements Good communication skills - ability to convey technical information to non-technical audience Ability to understand the big picture Ability to develop long lasting relationships with all levels Deep understanding and experience in software development cycle, including Agile based rapid delivery Collaborate with business and IT to analyse, elicit and review business requirements Facilitate communication between vendor, project team, business stakeholders and internal IT team Ability to work in a team distributed across multiple locations Job Requirements Functional Skills: Data Lake, EDW, Data Mart, Data Integration &amp; Visualisation Hands-on experience in implementing large scale data warehouse &amp; analytics platforms in financial services industry; with good functional knowledge of products &amp; services offered in Retail bank/Wholesale/Global Markets covering some of the following analytics domains: Setting up and running BI tools oriented platform Design and develop QlikSense &amp; Microsoft Power BI applications Design and develop Applications in SAS, Microsoft-R, Python Integration of BI tools with data stores (EDW, data marts) Experience in Data Modeling, Data mapping for Data Warehouse and Data Marts solutions Expertise in FSLDM or similar industry models Experience in financial domain - Retail , Wholesale, Compliance, Digital Experience in analytics - Finance Analytics, Credit Risk Analytics, Credit Scoring, Financial Crime Analytics Expertise in design of role based fine grained access control Designing cloud ready data solutions, Virtualization Technical Skills: Data Lake, EDW, Data marts, Data Integration &amp; Visualisation Expertise in implementing Teradata based EDW and Data mart solution using ETL tool such as (Informatica Power Centre, BDM), GCFR based framework, BTEQ scripts) Expertise in implementing Hadoop based Data mart using Spark based framework (Java, Scala, Pyspark) Good knowledge and working experience in data loading into Teradata using different load pattern (TPT, MLOAD, FAST Load), data compression (MVC, BLC) Expertise in implementing Data Governance tools; Data Lineage (e.g. Informatica MM, EDC), Business Glossary and Data Quality Expertise in implementing Reference data management (Data standardization, Hierarchy maintenance) using tools (e.g. MDM,RDM) Good knowledge and working experience in Teradata FSLM or similar industry standard data model Expertise in Cloudera CDH / CDP components Good knowledge in developing Spark based ingestion framework (Java, Scala, Pyspark) Experience in building and operationalising feature pipeline to support AI/ML model execution, data pipelines for supporting large scale data warehouse/data marts Any TWO technical certifications Cloudera Hadoop distribution - Hive, Impala, Spark, Kudo, Kafka, Flume Teradata - Bteq, Query Grid, GCFR, MDM, Data Mover, BAR Informatica Data Integration - PC, IDR, BDM, MM, IDQ, EDC Data modelling tools - Erwin QlikSense Microsoft Power BI - SSAS, SSRS Microsoft - R Data science workbenches - Cloudera Workbench, Jupyter, DataRobot, H2O.AI, IBM DSX Data Virtualization tool - Denodo, Dremio AS400 Language - SQL, Java, Python, Scala, Pyspark Automation / scripting - CtrlM, Shell Scripting, Groovy Any ONE as added advantage CI/CD software, Testing Tools - Jenkins, SonarQube Version Control Tool - Aldon+LMe, CA Endeavor Deployment Tool kit - Jenkins Service or Incident Management (IcM) Tools - Remedy Source Code Repository Tool - Bitbucket Scheduling Tool - Control-M Defect Management Tool - JIRA Application Testing tool - QuerySurge Cloud certification Platforms provided by FICO, Experian, SAS for credit and portfolio management Be a part of UOB Family UOB is an equal opportunity employer. UOB does not discriminate on the basis of a candidate's age, race, gender, color, religion, sexual orientation, physical or mental disability, or other non-merit factors. All employment decisions at UOB are based on business needs, job requirements and qualifications. If you require any assistance or accommodations to be made for the recruitment process, please inform us when you submit your online application.Apply now and make a difference.",https://www.jobstreet.com.sg/en/job/vp-data-engineer-letsgettowork-seekbetter%7C-letsgotowork-10470070?jobId=jobstreet-sg-job-10470070&sectionRank=124&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
124,Big Data Engineer,Axheleon It Services (Pte. Ltd.),"Experience with big data tools: Hadoop, Spark, Kafka, etc. ● Experience with relational SQL and NoSQL databases, including Postgres and Cassandra. ● Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. ● Experience with AWS cloud services: EC2, EMR, RDS, Redshift and MS equivalents. ● Experience with stream-processing systems: Storm, Spark-Streaming, etc. ● Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc",https://www.jobstreet.com.sg/en/job/big-data-engineer-10461777?jobId=jobstreet-sg-job-10461777&sectionRank=125&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
125,Data Engineer / Architect #Urgent #Seekbetter,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills: Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-urgent-seekbetter-10438545?jobId=jobstreet-sg-job-10438545&sectionRank=126&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
126,Data Engineer / Architect #WorkNow#Seekbetter,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills: Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-worknow-seekbetter-10439498?jobId=jobstreet-sg-job-10439498&sectionRank=127&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
127,"Data Engineer, Group Banking Technology, #Seekbetter | - #LetsGoToWork",United Overseas Bank Limited (UOB),"About UOB United Overseas Bank Limited (UOB) is a leading bank in Asia with a global network of more than 500 branches and offices in 19 countries and territories in Asia Pacific, Europe and North America. In Asia, we operate through our head office in Singapore and banking subsidiaries in China, Indonesia, Malaysia and Thailand, as well as branches and offices. Our history spans more than 80 . Over this time, we have been guided by our values — Honorable, Enterprising, United and Committed. This means we always strive to do what is right, build for the future, work as one team and pursue long-term success. It is how we work, consistently, be it towards the company, our colleagues or our customers. About the Department The Technology and Operations function is comprised of five teams of specialists with distinct capabilities: business partnership, technology, operations, risk governance and planning support and services. We work closely together to harness the power of technology to support our and digital banking services and operations. This includes developing, centralising and standardising technology systems as well as banking operations in Singapore and overseas branches. Job Responsibilities Take end-to-end development ownership for one or more modules and deliver to production Understand functional requirements / user stories and come up with effective solutions by breaking down into meaningful tasks Participate as a member of agile team and deliver high quality software Man multiple projects at the same time Guide and support other members of the team, including temporary staff to perform effectively in their role Communicate with other stakehers like other project teams, infrastructure security teams as required and man dependencies Understand and follow UOB software delivery process deliverables, ensure process compliance Create a network with other departments and teams, to know about strategic issues and new developments Understand long terms strategic plans for the department and support towards the same Possess personal cour to do what is right and work as a team member to meet customer expectations Continuously prioritize technical debt for the team and ensure they are taken care in project releases Participate in int meetings (planning, review) and estimate stories, breakdown to tasks Prepare for int demos and demonstrate to Product Owner, receive feedback and implement Exhibit good attention to detail and enthusiasm to take ownership Job Requirements Degree in Computer Science or related discipline Strong knowledge and experience building Apache Kafka applications Strong working experience with Java, ing Boot and API (Microservices) Experience building data pipelines with Apache NiFi in production scale Experience building data streaming applications using Apache Spark and Kafka Streams Experience working with a variety of data sources and sinks (API, MQ, Files, Databases, Hot lakes, Big data systems etc.) Experience with both SQL and NoSQL databases (like MariaDB, Oracle, MongoDB) and Object-Relational Mapping (ORM) frameworks (e.g. Hibernate) Experience with CI/CD practices and tools (Bitbucket, Jenkins, Artifactory, Veracode etc.) to build pipelines Familiarity with Agile development methodologies Experience with software design and development in a test-driven environment Experience tuning Kafka and NiFi components for varying traffic and performance requirements Ability to learn new programming langus and technologies Excellent communication skills to interact within and outside the team Be a part of UOB Family UOB is an equal opportunity employer. UOB does not discriminate on the basis of a candidate's , race, gender, color, religion, sexual orientation, or mental disability, or other non-merit factors. All employment decisions at UOB are based on business needs, job requirements and qualifications. If you require any assistance or accommodations to be made for the recruitment process, please inform us when you submit your online application. Apply now and make a difference.",https://www.jobstreet.com.sg/en/job/data-engineer-group-banking-technology-seekbetter-%7C-letsgotowork-10466115?jobId=jobstreet-sg-job-10466115&sectionRank=128&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
128,Data Engineer / Architect #Immediate #Seekbetter,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills: Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-immediate-seekbetter-10439463?jobId=jobstreet-sg-job-10439463&sectionRank=129&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
129,Data Engineer / Architect #WorkNow #Urgent,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills: Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-worknow-urgent-10438749?jobId=jobstreet-sg-job-10438749&sectionRank=130&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
130,"Research Engineer II, - (Big Data &amp; IoT) [R00009221] -- #LetsGoToWork",Nanyang Technological University,"The Energy Research Institute NTU (ERIAN) invites applications for the position of Research Engineer II. Key Responsibilities: Data Engineer (Big Data &amp; IoT) for Data fusion project Job Requirements: Masters from a reputed institute Must have a minimum 4 years of hands-on experience in building the data pipeline using Python, Kafka &amp; Spark Must have solid concepts on IoT &amp; Sensors Must have experience in pulling data from Gateways / Edge Devices Must have done minimum 2 end to end Big Data Pipeline implementations, either on cloud or on-premise Experience in configuring or developing custom code components for data ingestion, data processing, and data provisioning, using Big data &amp; distributed computing platforms such as Python Spark, and Cloud platforms such as AWS or Azure. Must have hands-on knowledge of Spark RDD, DataFrame, MLLib and Streaming API Must have solid experience in advance python programming Knowledge of Python ML will be an added advantage Proficiency in data modelling, for both structured and unstructured data, for various layers of storage Must have ability to collaborate closely with business analysts, architects, and client stakeholders to create technical specifications. Must have expertise in building the CI / CD Pipeline &amp; Automatics deployment of jobs Skills and Proficiency Solid Python Programming skills Spark, Kafka, Spark RDD, Streaming API Pandas, Numpy, MatplotLib, Scikit-learn Git-lab, CI / CD Pipeline Docker Excellent Communication Skills We regret that only shortlisted candidates will be notified. Hiring Institution: NTU In line with Singapore’s nationwide Vaccination-Differentiated Safe Management Measures (VDS), employees must be fully vaccinated to return to the workplace, unless certified to be medically ineligible. For Information on VDS, please click here.",https://www.jobstreet.com.sg/en/job/research-engineer-ii-big-data-iot-%5Br00009221%5D-letsgotowork-10462596?jobId=jobstreet-sg-job-10462596&sectionRank=131&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
131,Data Engineer / Architect - #Urgent,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills: Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-urgent-10439764?jobId=jobstreet-sg-job-10439764&sectionRank=132&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
132,"Lead, Data Engineering (AVP)",Mediacorp Pte Ltd,"Description We are looking for a high-performing data engineer with full stack experience creating web-based data applications. You will be a key contributor to the Data Engineering team, primarily by applying and building tools to aggregate data from disparate sources, processing and loading the transformed data to support internal and external constituencies. You will be required to maintain and enhance our data infrastructure and proprietary analytical solutions. This role is a hands-on engineering position. Job Responsibilities Translate business requirements to responsive functional web solutions. This includes designing and building APIs, front-end interfaces and scalable tools that ingest and transform real-time data using a variety of open-source and proprietary big data technologies. Recommend and implement ways to improve data reliability, efficiency and quality Work closely with stakeholders to ensure high standards of data governance during implementation Serve as technical subject matter expert on the latest big data technologies Requirements Hands-on proven track record in developing products from front-end interface, middle-tier, to backend infrastructure 7+ years of superior experience developing commercial web-based applications 4+ years of full-stack web development experience in Javascript (node.js and React framework) Proficiency in SQL is mandatory Excellent scripting knowledge in Python, Shell etc Those with strong production experience in Scala or Spark programming languages will be considered favourably Relevant experience in web, video, mobile or adtech domain is a definite plus Demonstrated clear and thorough analytical thinking Good eye for aesthetics and an attention to detail A proven team player and contributor who can multi-task and deliver against timelines Minimum degree in Computer Science/Engineering, or equivalent Mediacorp is committed to creating an inclusive and diverse workplace where talent thrives. Our hiring decisions are made based on merit and fit-to-role. If you have a disability or special need which requires accommodation to participate in the recruitment process, please inform us when you submit your online application. We will be happy to support as necessary. Thank you for your interest and application to this role. Please note that only short-listed candidates will be contacted.",https://www.jobstreet.com.sg/en/job/lead-data-engineering-avp-10466245?jobId=jobstreet-sg-job-10466245&sectionRank=133&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
133,"APAC Big Data Engineer (Gaming MNC, Data Warehouse) #WorkNow #Seekbetter",RecruitFirst Pte. Ltd,"Hiring for one of the largest gaming MNC in the world Role: Responsible for the development, maintenance and positioning of big data systems Responsible for the development of big data analysis tasks using Hadoop, HiveSQL, Spark Construction of Offline databases Perform SQL development Implementing real-time data warehouse using Flink Requirements &amp; Skills: Degree in Computer Science or related technical field with at least 2 yers of big data experience using hadoop / Hive / Spark Highly proficient in advanced SQL Good understanding of Python Proficient in Databases such as MySQL/Hive/Redis Other Information: Hybrid Work Model (WFH / Raffles Place) Mon - Fri, 9am - 6pm up to $6,500 per month Singapore citizens only. No quota for work pass Interested candidates, kindly apply online.",https://www.jobstreet.com.sg/en/job/apac-big-data-engineer-gaming-mnc-data-warehouse-worknow-seekbetter-10439833?jobId=jobstreet-sg-job-10439833&sectionRank=134&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
134,Data Engineer / Architect #WorkNow,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills: Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-worknow-10435478?jobId=jobstreet-sg-job-10435478&sectionRank=135&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
135,Data Engineer / Architect #Immediate,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills: Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-immediate-10435883?jobId=jobstreet-sg-job-10435883&sectionRank=136&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
136,"Big Data Engineer, Recommendation Architecture #UrgentHire #JobsThatMatter",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-urgenthire-jobsthatmatter-10459174?jobId=jobstreet-sg-job-10459174&sectionRank=137&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
137,Data Engineer / Architect #JobsThatMatter,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills: Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-jobsthatmatter-10435923?jobId=jobstreet-sg-job-10435923&sectionRank=138&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
138,Technical Data Engineer - (220002B0),OCBC Bank (Singapore),"Bank of Singapore is currently looking for a qualified candidate to assist the Data Engineering Team’s operational and analytical needs. The Technical Data Enginer will work alongside Data Analytics and big data platform (Hadoop) and engineering team to provide data related support, data ingestion, data interface for unstructured/structred data, data analytics and data management. This person will also assist in building interfaces from various upstream systems and ingest the data into Micrsoft SQL server 2019 / Cloudera Hadoop data store and build the enterprise visulasation tool. This is a great opportunity for someone who is interested in innovative group with the possibility of tremendous career development in data engineering, big data management, data analytics and enterprise data visulsaisation tool. A little more about this role: As our Technical Data Enginer, you will be instrumental in big data coding and work in Hadoop-ecosystem. This is a brand-new position at Data Competency vertical. Perform extensive unstructured data ingestion into Hadoop StronG knowledge of Anaconda, Data visualisation BI tool, Python, SPARK, Java Scala, HIVE and Beeline with hands on experience Ability to organize and lead meetings with business and operational data owners Experience in integrating data processes with architecture requirements used across company Understand Hadoop-ecosystem and Data Engineering activities as well as loading data from several disparate datasets and documentation Strong ability to troubleshoot and resolve data issues Analytical skill to perform data profiling and data visulization Experience in Agile and Waterfall frameworkWork Work closely with engineering and operations to document business processes Work independently and with team members to understand database structure and business processes Help form data management and governance processes within the data engineering team Qualifications What you’ll need to have: Graduate degree in statistics, math, computer science, physics or other technical related fields; Master’s degree is preferred Minimum of 10 years working experience in technical data analysis, data science, or data warehousing with proven business analysis experience Experience in at least one or more languages: SPARK, Java Scala,Python Experience writing Java Scala, Python Experience with Hadoop Hands on expierence or knowledge of minimum one mainstream cloud infrastructures:AWS,MS Azure and GCP; ablity to implement data lake. Good to have Hands-on experienceon the Hadoop, MangoDB,SPARK, Scala, HIVE, Kafka ,Beelin…etc Excellent communication skills Passionate about data and analyzing business needs Previous experience on a data team in an agile environment preferred Hands-on experience on the Hadoop ecosystem, HDFS, Hadoop, Spark, Scala preferred Develop in-depth plans and major milestones that must be approved by top management during the planning and design phases of the project.",https://www.jobstreet.com.sg/en/job/technical-data-engineer-220002b0-10458738?jobId=jobstreet-sg-job-10458738&sectionRank=139&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
139,Data Engineer / Architect #UrgentHire #Urgent,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills: Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-urgenthire-urgent-10435725?jobId=jobstreet-sg-job-10435725&sectionRank=140&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
140,"[WD46608] AVP, Big Data Analyst, LCS Analytics &amp; Innovation, Group Compliance #JobsThatMatter",DBS Bank Limited,"Business Function This role lies within the Group Legal, Compliance &amp; Secretariat (LCS) Analytics &amp; Innovation team. LCS ensures that the bank's interests are protected by zealously guarding and enhancing its reputation and capital. We also work to maintain a good standing with all our regulators, customers, and business partners. Because we believe that at theheart of business banking is to uphold the values of trust and integrity for all our stakeholders. Responsibilities Work with domain experts from cross-functional teams to drive end-to-end design of LCS Analytics data architecture Ensure reusability and flexibility of the data schema designs across domains for data analytics, dashboards, and AI/ML models Drive requirements gathering and technical development of LCS data and feature marts on ADA common operational cluster (OC). ADA is the bank’s data platform. Maintain LCS ADA analytics cluster (AC) and pipelines. Plan the gradual migration of AC jobs to OC. Provide technical oversight for integrating new technology, new initiatives or source system changes into LCS Analytics data standards and structures Develop and implement a data quality, testing and monitoring framework to ensure integrity and consistency of LCS Analytics architecture and data marts Source for new data, and streamline data requirements and common keys across domains during data onboarding Collaborate with Technology and Platform to collectively resolve data quality related issues Continuously explore new tools and methods to improve efficiency of the function Work with Data Steward on data governance within and across functional teams Have proper and regular documentation of designs, mappings, sources and definitions concerning data management Be a well-rounded Analytics Data Expert who bridges business, financial crime or compliance to technology Requirements At least 10 years of work experience in data engineering / data analytics with relevant Bachelor's Degree (Information Systems, Computer Science, etc) At least 5 years working experience as Data Engineer, ML Engineer or equivalent Hands-on working experience in Python and SQL are mandatory Familiarity with Big Data technologies such as Hadoop and Spark. Working experience in RDBMS, NOSQL database and streaming data processing Familiarity with AWS stack and scheduling tools like airflow preferred Broad and in-depth knowledge in Banking products, services and data Experience with financial crime, core and corporate banking systems an advantage Strong interpersonal skills, professionalism and teamwork awareness Hands-on and detail-oriented with excellent organizational skills Strong analytical skills with an investigative mindset A proactive approach to tasks &amp; responsibilities",https://www.jobstreet.com.sg/en/job/%5Bwd46608%5D-avp-big-data-analyst-lcs-analytics-innovation-group-compliance-jobsthatmatter-10493628?jobId=jobstreet-sg-job-10493628&sectionRank=141&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
141,Data Engineer / Architect #UrgentHire #Seekbetter,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-urgenthire-seekbetter-10435965?jobId=jobstreet-sg-job-10435965&sectionRank=142&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
142,#Data Scientist - 22436757 #JobsThatMatter #Urgent'.,Citibank N.A.,"Job Background/context: We are looking for a data scientist with deep analytics and statistics background who can contribute on finding new insights on data. Ability to conduct high-level market and business research to identify trends and opportunities The candidate will be working closely with data engineer, application developers and TTS business units to realize data and AI based solutions for high impact business problems/projects through in-depth data discovery and exploration Key Responsibilities: Identify valuable data sources and automate collection processes. Undertake preprocessing of structured and unstructured data. Analyze large amounts of information to discover trends and patterns. Build predictive models and machine-learning algorithms. Combine models through ensemble modeling. Present information using data visualization techniques. Propose solutions and strategies to business challenges. Collaborate with engineering and product development teams. The candidate needs to be able to present back the findings to the business in a business friendly manner Knowledge/Experience: Essential Total 8 years of overall experience with minimum 5 years of experience in Dealing with Data (Analytics/Modeling/Mining/Engineering) Strong problem-solving skills. Strong mathematical and analytical skills Experience in data mining techniques Knowledge of advanced statistical methods and concepts Extensive knowledge of predictive modeling algorithms and frameworks Experience using statistical computer languages (like R and Python) to manipulate data and draw insights from large data sets. Experience working with and creating data architectures. Knowledge of a variety of machine learning techniques like but not limited to clustering, decision tree learning, artificial neural networks, and their real-world advantages/drawbacks. Desirable Have been part of an agile development team in a reciprocal environment Openness to learn new and emerging technologies Skills: (technical skills) Essential Deep understanding of architecture and system integration Experience analyzing data from third-party providers like AdWords, Facebook Insights, Google Analytics, and Hexagon Real-Time and Dynamic data analysis expertise (such as airline in-flight data, on-track engine data) is a plus Experience in both NoSQL databases and relational databases (for example, Couch, MongoDB, and Neo4J) Experience developing automated workflows (Python or R) Experience using web services like Digital Ocean, Redshift, Spark, and S3 Experience visualizing and presenting data using Business Objects, Periscope, ggplot, and D3 Experience with distributed data/computing tools like Map/Reduce, Hadoop, Hive, Spark, and Gurobi. Experience with data visualization tools like Tableau. Desirable Experience working in a cloud environment with large data sets Qualifications: (degree/certifications) Essential Master’s degree or Ph.D. in computer science, math, engineering, or a related quantitative field Demonstrated leadership and project/program management skills Certification from a recognized institution on one of data analytics, machine learning and deep learning Consistently demonstrates clear and concise written and verbal communication Competencies (soft skills you are looking for in a candidate)",https://www.jobstreet.com.sg/en/job/data-scientist-22436757-jobsthatmatter-urgent%27.-10494171?jobId=jobstreet-sg-job-10494171&sectionRank=143&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
143,"Machine Learning Engineer Senior Manager, (22481444) #UrgentHire#.",Citibank N.A.,"The Machine Learning Engineering Senior Manager accomplishes results through the management of professional team(s) and department(s). Integrates subject matter and industry expertise within a defined area. Contributes to standards around which others will operate. Requires in-depth understanding of how areas collectively integrate within the sub-function as well as coordinate and contribute to the objectives of the entire function. Requires basic commercial awareness. Developed communication and diplomacy skills are required to guide, influence, and convince others, in particular colleagues in other areas and occasional external customers. Has responsibility for volume, quality, timeliness, and delivery of end results of an area. May have responsibility for planning, budgeting, and policy formulation within area of expertise. Involved in short-term resource planning. Full management responsibility of a team, which may include management of people, budget, and planning, to include duties such as performance evaluation, compensation, hiring, disciplinary and terminations and may include budget approval. A highly capable machine learning engineer to optimize our machine learning platforms, this role will be evaluating existing machine learning development lifecycle, driving the development of the AI technology roadmap and ensure successful MLOps capabilities to support the production of AI models for key business functions. Responsibilities: Design, implement and take ownership for the AI technology roadmap for APAC - enabling the capabilities of innovative AI solutions. Hands on with data engineering and MLOps support for successful ML solution deployment. Design and develop ML products. Work with data scientists, ML engineers, business stakeholders and other technology teams to ensure that best practice MLOps is followed. Provide thought leadership by researching standard methodologies and collaborating with external partners. Contributes to data analytics standards around which others will operate. Applies in-depth understanding of how data analytics collectively integrate within the sub-function as well as coordinates and contributes to the objectives of the entire function. Employs developed communication and diplomacy skills to guide, influence and convince other colleagues in other areas and occasionally external entities. Resolves occasionally complex and highly variable issues. Produces detailed analysis of issues where the best course of action is not evident from the information available, but actions must be recommended/taken. Responsible for volume, quality, timeliness, and delivery of data science projects along with short-term planning resource planning. Oversees management of people, budget, and planning, to include duties such as performance evaluation, compensation, hiring, disciplinary action and terminations and may include budget approval. Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency, as well as effectively supervise the activity of others and create accountability with those who fail to maintain these standards. Qualifications: Advanced proficiency with Python, Java, and Spark. Extensive knowledge of ML frameworks, libraries, data structures, data modeling, and software architecture. Proven track record as a data engineer or Devops engineer - with specific focus on AI/ML solutions deployment to production. Hands on experience in development and designing of ML platforms and data pipelines. Must have experience with Kubernetes, CI/CD automation, Docker, and microservice architecture. Familiar with MLOps tools like MLflow or Kubeflow. Web application development experience with RESTful APIs. Nice to have cloud experience like Amazon SageMaker or Vertex AI. Familiar with deep learning frameworks like Tensorflow or Pytorch. Education: Bachelor's degree in computer science, data science, mathematics, or a related field. Master’s degree is a plus. This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.",https://www.jobstreet.com.sg/en/job/machine-learning-engineer-senior-manager-22481444-urgenthire-.-10494842?jobId=jobstreet-sg-job-10494842&sectionRank=144&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
144,"Manager/AVP, Data Engineer",OCBC Bank (Singapore),"Based in the Group Data Office – Data Engineering team, you will be responsible for developing and enhancing data pipelines and architecture Create and maintain the optimal data pipeline to enable ingestion from a wide variety of structured and unstructured data sources via Talend Working with business users to define and understand business requirements to develop and implement solutions Support development and deployment of applications utilising the data pipelines to provide actionable insights Involve in UAT execution with a focus on strategic testing processes and procedures to ensure that business standards and specifications are met Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery and cleansing/transformation Support various business functions by collaborating with multiple stakeholders – business, IT, and vendors independently *Li-VL Qualifications Minimum 4 to 6 years of working experience in Data Engineering, Big Data solutions, and analytics functions Solid background in traditional structured database environments such as Teradata / Oracle, SQL &amp; PL/SQL Knowledge on Hadoop ecosystem components such as HIVE, Impala, HDFS, Spark, Scala, HBase Fluent in structured and unstructured data, its management, and modern data transformation methodologies Hands-on experience working on real-time data and streaming applications using Kafka or other similar tools Experience in automation process – building procedures, ETL and automated job scheduling using data integration tool such as Talend Knowledge on data warehouse and FSLDM concepts Understanding of banking with exposure to consumer business functions is preferred Energetic personality with an innovative, self-starting spirit. Someone that likes to ask “why?”",https://www.jobstreet.com.sg/en/job/manager-avp-data-engineer-10454381?jobId=jobstreet-sg-job-10454381&sectionRank=145&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
145,"Big Data Engineer, Recommendation Architecture -- #Immediate",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-immediate-10454594?jobId=jobstreet-sg-job-10454594&sectionRank=146&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
146,"Big Data Engineer, Recommendation Architecture #Seekbetter #Immediate | #LetsGoToWork | - #UrgentHire",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-seekbetter-immediate-%7C-letsgotowork-%7C-urgenthire-10458476?jobId=jobstreet-sg-job-10458476&sectionRank=147&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
147,Data Architect,Adecco Personnel Pte Ltd.,"The Opportunity Opportunity to work in IT industry Working hours: Mon - Fri (9:00 AM-6:00 PM) Job type: Contract (12 months extendable) Adecco is currently partnering with a MNC based in Singapore. We are now looking for an energetic and highly motivated individual to work at the intersection of customer and partners in this fast growing industry. Main responsibilities of the role: As a Data Engineering Architect, you will use comprehensive modern data engineer techniques and methods with Advanced Analytics to support business decisions for client. You can collect, aggregate, and analyze structured/unstructured data from multiple internal and external sources and patterns, insights, and trends to decision-makers. Your goal is to support the use of data-driven insights to help our Clients achieve business outcomes and objectives. In this role, you will collect, aggregate, store, and reconcile data in support of Client business decisions. You will help design and build data pipelines, data streams, reporting tools, information dashboards, data service APIs, data generators and other end-user information portals and insight tools. You will be a critical part of the data supply chain, ensuring that stakeholders can access and manipulate data for routine and ad hoc analysis to drive business outcomes using Advanced Analytics. Translate business requirements to technical solutions leveraging strong business acumen. Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data &amp; Analytics PaaS Services. Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments. Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies. Design and Build Modern Data Pipelines and Data Streams. Design and Build Data Service APIs. Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics. Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience. Implement effective metrics and monitoring processes. Travel as needed Requirements: 1 - Database Architecture 2 - Microsoft SQL Server Integration Services SSIS (P3 - Advanced) 3 - Data Modeling Techniques and Methodologies (P3 - Advanced) 4 - Data &amp; AI Strategy (P3 - Advanced) 5 - Extract Transform and Load (ETL) (P3 - Advanced) 6 - Microsoft SQL Server Analysis Services (SSAS) (P3 - Advanced) * Demonstrated experience of turning business use cases and requirements to technical solutions. * Experience in business processing mapping of data and analytics solutions. * Ability to conduct data profiling, cataloging, and mapping for technical design and construction of technical data flows. * The ability to apply such methods to solve business problems using one or more Azure Data and Analytics services in combination with building data pipelines, data streams, and system integration. * Mastery of .NET C# and T-SQL with the familiarity of U-SQL is required * Knowledge of Azure Data Factory, Azure Data Lake, Azure SQL DW, and Azure SQL, Azure App Service is required. * Azure IoT, Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics is a plus. * Knowledge of Python is a plus. * Experience preparing data for Data Science and Machine Learning. * Experience preparing data for use in Azure Machine Learning and/or Azure Databricks is a plus. * Demonstrated experience preparing data and building data pipelines for AI Use Cases (text, voice, image, etc.…). * Designing and building Data Pipelines using streams of IOT data. * Knowledge of Lambda and Kappa architecture patterns. * Knowledge of Master Data Management (MDM) and Data Quality tools and processes * Strong team collaboration and experience working with remote teams. * Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals. * Working experience with Visual Studio, PowerShell Scripting, and ARM templates. * Experience with Git/TFS/VSTS is a must. Preferred Certifications: MCAD .NET, MCSD .NET, MCDBA Preferred Education Background: You likely possess MS/ Ph.D. in a quantitative field such as computer science, applied mathematics, statistics, or machine learning. An equivalent combination of education and experience will also suffice. Preferred Years of Work Experience: You likely have about 5+ years of relevant professional experience. Preferred Years of Management Experience: 3+ years managing &amp; leadership of 3 or more associates in management consulting or industry. If interested, feel free to reach me at saghana.sithara@adecco.com with the updated CV and the below details: Are you open for 1 year extendable contract under Adecco ? Current salary with benefits: expected salary: official notice period: Visa status in Singapore: Vaccination status: Valid passport (Yes/No): Next Step: Prepare your updated resume (please include your current salary package with full breakdown such as base, incentives, annual wage supplement, etc.) and expected package. Simply click on 'Apply here' to drop your resume or send to saghana.sithara@adecco.com All shortlisted candidates will be contacted. Saghana Sithara Registration Number: R1550224 Saghana Sithara Direct Line: 6697 7876 EA License No: 91C2918 Personnel Registration Number: R1550224",https://www.jobstreet.com.sg/en/job/data-architect-10481905?jobId=jobstreet-sg-job-10481905&sectionRank=148&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
148,Data Engineer / Architect,VOLT,"Data Engineer/Architect Company Overview: Our client is globally established Multinational Company with a significant footprint within the tourism and hospitality industry. You will be responsible for the management of data constraints, design of data schemas and development of ETL flows. Your Key Accountabilities: Designing data schemas Organising data into separate entities, creating relationships between entities Managing data constraints. Building and development of ETL flows with SQL, PowerShell, Batch scripting. Provide other database users logical understanding of data. Required Skills: Degree in Information Technology or any relevant discipline. 4+ Years in Data/Data Engineering, Data Architecture Experience in the following field(s): SQL Server Integration Service (SSIS) Microsoft SQL Server Data Modelling, Engineering SQL, PowerShell, Batch Scripting. This role is a 1 year contract to start. Permanent conversion and Renewals are possible subject to performance review. Please send your resume in WORD format by clicking the apply button below or contact Darren Ou on +65 6701 1520 for a confidential discussion. Please note that only short-listed candidates will be contacted. CEI Reg. Number R21103097 Darren Ou Jia Jun.",https://www.jobstreet.com.sg/en/job/data-engineer-architect-10431900?jobId=jobstreet-sg-job-10431900&sectionRank=149&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
149,IT Data Analyst | #UrgentHire#,UBS AG,"Your role Are you interested in developing regulatory reporting solutions using the latest technologies? Are you confident at iteratively refining user requirements and removing any ambiguity? Do you like to be challenged and encouraged to learn and grow professionally? We are looking for IT Data Analyst to: Design, plan and deliver sustainable solutions using modern programming languages (Apache Spark 2.x, Databricks, SCALA) Provide technical expertise and recommendations in assessing new software projects and initiatives to support and enhance our existing applications Work with key stakeholders including business change teams and wider SMEs within CTB organizations in GCRG technology to identify and delivery on functional/System design, Data model / Data Quality Performance tuning improvement opportunities Use technical knowhow (Enterprise Architecture, Database, data model) to support Capability Change teams to design data models and ensure logical and physical data models are properly reflected in data model repository of GCRG (Enterprise architecture, DGP) Your team You’ll be working in the Group Compliance, Regulatory &amp; Governance IT team based in Pune. Our role is to design and implement IT solutions for global Regulatory Reporting requirements (Major shareholding disclosures, Short Selling disclosures, 13F reporting, Conflict clearance, etc). We are a global IT team supporting internal clients throughout the world. Your expertise System Analyst / Big Data Engineer / Data Analyst focused on developing regulatory reporting solutions Strong experience with data warehousing, SQL, PL/SQL, PostgreSQL, Oracle databases Experience with Big Data technologies like Spark 2.0, SPARK SQL, Databricks using Scala or Python Well versed with working on Azure cloud platform. Good understanding of financial products and front to back trade lifecycle Experienced handling critical L3 support queries Design, plan and deliver solutions in a large-scale enterprise environment About us UBS is the world’s largest and only truly global wealth manager. We operate through four business divisions: Global Wealth Management, Personal &amp; Corporate Banking, Asset Management and the Investment Bank. Our global reach and the breadth of our expertise set us apart from our competitors. With more than 70,000 employees, we have a presence in all major financial centers in more than 50 countries. Do you want to be one of us? Join us From gaining new experiences in different roles to acquiring fresh knowledge and skills, at UBS we know that great work is never done alone. We know that it's our people, with their unique backgrounds, skills, experience levels and interests, who drive our ongoing success. Together we’re more than ourselves. Ready to be part of #teamUBS and make an impact? Disclaimer / Policy Statements UBS is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills and experiences within our workforce. Employees working from UBS Singapore offices must comply with Workforce Vaccination Measures as implemented by the Singapore government with effect from 1 January 2022, and other applicable safe management measures as may be amended from time to time.",https://www.jobstreet.com.sg/en/job/it-data-analyst-%7C-urgenthire-10491438?jobId=jobstreet-sg-job-10491438&sectionRank=150&token=0~55286dfb-660e-44c1-9c25-73d46e325174&fr=SRP%20Job%20Listing
150,IT Data Analyst - #Immediate#,UBS AG,"Your role Are you interested in developing regulatory reporting solutions using the latest technologies? Are you confident at iteratively refining user requirements and removing any ambiguity? Do you like to be challenged and encouraged to learn and grow professionally? We are looking for IT Data Analyst to: Design, plan and deliver sustainable solutions using modern programming languages (Apache Spark 2.x, Databricks, SCALA) Provide technical expertise and recommendations in assessing new software projects and initiatives to support and enhance our existing applications Work with key stakeholders including business change teams and wider SMEs within CTB organizations in GCRG technology to identify and delivery on functional/System design, Data model / Data Quality Performance tuning improvement opportunities Use technical knowhow (Enterprise Architecture, Database, data model) to support Capability Change teams to design data models and ensure logical and physical data models are properly reflected in data model repository of GCRG (Enterprise architecture, DGP) Your team You’ll be working in the Group Compliance, Regulatory &amp; Governance IT team based in Pune. Our role is to design and implement IT solutions for global Regulatory Reporting requirements (Major shareholding disclosures, Short Selling disclosures, 13F reporting, Conflict clearance, etc). We are a global IT team supporting internal clients throughout the world. Your expertise System Analyst / Big Data Engineer / Data Analyst focused on developing regulatory reporting solutions Strong experience with data warehousing, SQL, PL/SQL, PostgreSQL, Oracle databases Experience with Big Data technologies like Spark 2.0, SPARK SQL, Databricks using Scala or Python Well versed with working on Azure cloud platform. Good understanding of financial products and front to back trade lifecycle Experienced handling critical L3 support queries Design, plan and deliver solutions in a large-scale enterprise environment About us UBS is the world’s largest and only truly global wealth manager. We operate through four business divisions: Global Wealth Management, Personal &amp; Corporate Banking, Asset Management and the Investment Bank. Our global reach and the breadth of our expertise set us apart from our competitors. With more than 70,000 employees, we have a presence in all major financial centers in more than 50 countries. Do you want to be one of us? Join us From gaining new experiences in different roles to acquiring fresh knowledge and skills, at UBS we know that great work is never done alone. We know that it's our people, with their unique backgrounds, skills, experience levels and interests, who drive our ongoing success. Together we’re more than ourselves. Ready to be part of #teamUBS and make an impact? Disclaimer / Policy Statements UBS is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills and experiences within our workforce. Employees working from UBS Singapore offices must comply with Workforce Vaccination Measures as implemented by the Singapore government with effect from 1 January 2022, and other applicable safe management measures as may be amended from time to time.",https://www.jobstreet.com.sg/en/job/it-data-analyst-immediate-10491400?jobId=jobstreet-sg-job-10491400&sectionRank=151&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
151,IT Data Analyst | #UrgentHire #JobsThatMatter#,UBS AG,"Your role Are you interested in developing regulatory reporting solutions using the latest technologies? Are you confident at iteratively refining user requirements and removing any ambiguity? Do you like to be challenged and encouraged to learn and grow professionally? We are looking for IT Data Analyst to: Design, plan and deliver sustainable solutions using modern programming languages (Apache Spark 2.x, Databricks, SCALA) Provide technical expertise and recommendations in assessing new software projects and initiatives to support and enhance our existing applications Work with key stakeholders including business change teams and wider SMEs within CTB organizations in GCRG technology to identify and delivery on functional/System design, Data model / Data Quality Performance tuning improvement opportunities Use technical knowhow (Enterprise Architecture, Database, data model) to support Capability Change teams to design data models and ensure logical and physical data models are properly reflected in data model repository of GCRG (Enterprise architecture, DGP) Your team You’ll be working in the Group Compliance, Regulatory &amp; Governance IT team based in Pune. Our role is to design and implement IT solutions for global Regulatory Reporting requirements (Major shareholding disclosures, Short Selling disclosures, 13F reporting, Conflict clearance, etc). We are a global IT team supporting internal clients throughout the world. Your expertise System Analyst / Big Data Engineer / Data Analyst focused on developing regulatory reporting solutions Strong experience with data warehousing, SQL, PL/SQL, PostgreSQL, Oracle databases Experience with Big Data technologies like Spark 2.0, SPARK SQL, Databricks using Scala or Python Well versed with working on Azure cloud platform. Good understanding of financial products and front to back trade lifecycle Experienced handling critical L3 support queries Design, plan and deliver solutions in a large-scale enterprise environment About us UBS is the world’s largest and only truly global wealth manager. We operate through four business divisions: Global Wealth Management, Personal &amp; Corporate Banking, Asset Management and the Investment Bank. Our global reach and the breadth of our expertise set us apart from our competitors. With more than 70,000 employees, we have a presence in all major financial centers in more than 50 countries. Do you want to be one of us? Join us From gaining new experiences in different roles to acquiring fresh knowledge and skills, at UBS we know that great work is never done alone. We know that it's our people, with their unique backgrounds, skills, experience levels and interests, who drive our ongoing success. Together we’re more than ourselves. Ready to be part of #teamUBS and make an impact? Disclaimer / Policy Statements UBS is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills and experiences within our workforce. Employees working from UBS Singapore offices must comply with Workforce Vaccination Measures as implemented by the Singapore government with effect from 1 January 2022, and other applicable safe management measures as may be amended from time to time.",https://www.jobstreet.com.sg/en/job/it-data-analyst-%7C-urgenthire-jobsthatmatter-10492029?jobId=jobstreet-sg-job-10492029&sectionRank=152&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
152,Data Engineer - (34531-JOB),Illumina Singapore Pte Ltd,"What if the work you did every day could impact the lives of people you know? Or all of humanity? At Illumina, we are expanding access to genomic technology to realize health equity for billions of people around the world. Our efforts enable life-changing discoveries that are transforming human health through the early detection and diagnosis of diseases and new treatment options for patients. Working at Illumina means being part of something bigger than yourself. Every person, in every role, has the opportunity to make a difference. Surrounded by extraordinary people, inspiring leaders, and world changing projects, you will do more and become more than you ever thought possible. What if the work you did every day could impact the lives of people you know? Or all of humanity? At Illumina, we are expanding access to genomic technology to realize health equity for billions of people around the world. Our efforts enable life-changing discoveries that are transforming human health through the early detection and diagnosis of diseases and new treatment options for patients. Working at Illumina means being part of something bigger than yourself. Every person, in every role, has the opportunity to make a difference. Surrounded by extraordinary people, inspiring leaders, and world-changing projects, you will do more and become more than you ever thought possible. Position Summary: This position works closely with the software engineers, data scientists and manufacturing supervisors. The ideal candidate for this position will be responsible for delivering data needs of consumables manufacturing department. Requires attention to detail when making judgments and recommendations based on the analysis of information. Applies professional judgment when interpreting data and results. You will be required to constantly learn/explore new front tier technology and innovatively apply/deliver solutions to Manufacturing operation. Responsibilities: • Design, implement and maintain data pipelines in existing system • Understand business requirement and solution design to cater enterprise level data needs • Fine tuning of new and existing data pipelines • To help in building scalable and robust data infrastructure to support business continuity and operation excellence • Demonstrates attention to quality and timeliness of service to ensure the effectiveness of the team • Applies analytical thinking and knowledge of data analysis tools and methodologies. • Communicate and collaborate with product and software development teams to understand and deliver optimal data solution Listed responsibilities are an essential, but not exhaustive list, of the usual duties associated with the position. Changes to individual responsibilities may occur due to business needs. Requirements: • Bachelor's Degree in IT, Software Development, Computer Science, Computer Engineering, or a related technical discipline with 3-4 years of experience in managing data warehouse or data engineering systems. • Experience in relational databases like MS SQL server, Oracle, MySQL. • Able to code data engineering flows in C#, Python, or any programming language. • Hands-on experience with any of the cloud-based systems viz. Snowflake, GCP, AWS and Azure. • Familiarity with working on Big Data technologies like Spark, Kafka, and distributed system. • Ability to communicate clearly and effectively. • Ability to explain technical information in business terms. • Strong in User Requirement Gathering, Maintenance and Support. • High level of discipline and integrity. • Willing to undertake multiple tasks. • Possess a positive attitude and sense of urgency. • Meticulous, keen attention to details and organized. All listed requirements are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional task and responsibilities. Illumina believes that everyone has the ability to make an impact, and we are proud to be an equal opportunity employer committed to providing employment opportunity regardless of sex, race, creed, color, gender, religion, marital status, domestic partner status, age, national origin or ancestry, physical or mental disability, medical condition, sexual orientation, pregnancy, military or veteran status, citizenship status, and genetic information.",https://www.jobstreet.com.sg/en/job/data-engineer-34531-job-10430783?jobId=jobstreet-sg-job-10430783&sectionRank=153&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
153,Senior/Principal data engineer,The Great Eastern Life Assurance Co Ltd,"Job Purpose At Great Eastern, we are building a data platform to realize the full value of our data. We seek an experienced Big Data Engineer to join our growing data engineering and analytics team. The right person for the job will have strong knowledge of Big Data Engineering and proven ability to strategize the implementation of data and analytics capabilities on a data platform (on premise and cloud) — from conception through release and production. The ideal candidate will be a strong data engineer; be willing to wrangle data, optimize data systems and products, and build them from the ground up. Experience with AWS, Snowflake, and migration to public could would be an advantage. The Job The Senior / Principal Big Data Engineer will work with cross-functional teams like Data &amp; Analytics (Data Engineer, Data Visual Analyst and Data Scientist), Data Management and Governance, IT and Digital Platform to support data curation and analytics. Assess and implement robust and scalable Big Data Technologies/Architecture to enable optimal data extraction, ingestion, transformation and storage from a wide variety of data sources. Architect end-to-end solution for Business Analytics Product (Dashboards or Statistical Model) from the curation of data, contextualizing data for business analytics and integrating of Product with Business process. Build and maintain an efficient, scalable and future-proof deployment infrastructure to enable the development and deployment of production quality analytics and AI applications. Engineer, optimize, fine-tune and maintain efficient, secure and reliable data pipelines to ingest, clean and consolidate data sources into the analytics systems and solutions. Provide technical guidance to Junior Data Engineers/Analysts on complex data issues, handling of big data sets and use of advanced methodologies. Recommend and implement ways to improve data reliability, efficiency and quality through the use of programming languages and big data processing/manipulation tools. Conduct research on emerging Big Data Architecture, Technologies and Systems to ensure that they continue to support the requirements of the data scientists and the business stakeholders in the mid to long-term. Work with data scientists to operationalize and maintain analytics/ artificial intelligence solutions (e.g. applications, models) by integrating them into business processes. This includes converting proof-of-concepts developed by data scientists into production-grade products and converting machine learning models in Application Program Interfaces (APIs). Takes accountability in considering business and regulatory compliance risks and takes appropriate steps to mitigate the risks. Maintains awareness of industry trends on regulatory compliance, emerging threats and technologies in order to understand the risk and better safeguard the company. Highlights any potential concerns /risks and proactively shares best risk management practices Desired Experience Degree in Computer Engineering, Computer Science, Mathematics, Software Engineering, equivalent fields or proven experience in data engineering At least 5-7 years of experience in data engineering, which includes developing and maintaining data, data science infrastructure, and pipelines that use big data and/or cloud platforms Technical Skillset Experience in delivering and maintaining Big Data Technologies/Architecture Experience modelling data for analytics and with DevOps, ModelOps, automation, containerization is preferred Hand-on experience working on both relational and non-relational databases Minimum 3 years experiences with Cloud Platforms with AWS/Azure Minimum 3 years of experience in Hadoop Cloudera and Scala Proficiency in SQL, Spark, Python is a must Specialized experience, not limited, with Nifi, Kafka, Spark, Hbase, Spark Streaming Minimum 5 years of programming experience in preferred languages – Python, R, Java Team Player Strong verbal and written communication skills and ability to explain technical solutions to the business users and partners Good coaching skills. Able to provide effective guidance to junior team members High level of integrity, takes accountability of work and good attitude over teamwork. Takes initiative to improve current state of things and adaptable to embrace new changes. To all recruitment agencies: Great Eastern does not accept unsolicited agency resumes. Please do not forward resumes to our email or our employees. We will not be responsible for any fees related to unsolicited resumes.",https://www.jobstreet.com.sg/en/job/senior-principal-data-engineer-10450804?jobId=jobstreet-sg-job-10450804&sectionRank=154&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
154,"Data Engineer, Video Infrastructure #UrgentHire #Immediate #JobsThatMatter",TikTok,"Responsibilities Video Infrastructure is a world-leading video platform that provides multi-media storage, delivery, transcoding, and streaming services. We are building the next generation video processing platform and the largest live streaming network, which provides excellent experiences for billions of users around the world. Popular video products of TikTok and its affiliates are all empowered by our cutting-edge cloud technologies. Working in this team, you will have the opportunity to tackle challenges of large-scale networks all over the world, while leveraging your expertise in coding, algorithms, complexity analysis, and large-scale system design. Responsibilities Craft optimal data processing architecture and systems for new data and ETL pipelines. Design, build, and maintain efficient and reliable data pipelines to move and transform data (both large and small amounts). Drive internal process improvements and automate manual processes for data quality and SLA management. Work with different cross-functional partners including CDN, Video Understanding, Video Transcoding, Live Streaming, and Real-Time Communication. Qualifications Bachelor's degree in Computer Science or a related technical background involving software/system engineering, or equivalent working experience. Good programming experience with at least one of the following languages: C, C++, Java, Python, or Go. Experience in custom ETL/data pipeline design, implementation, and maintenance. Experience with data processing software (Hadoop, Spark, Pig, Hive) and algorithms (MapReduce, Flume).",https://www.jobstreet.com.sg/en/job/data-engineer-video-infrastructure-urgenthire-immediate-jobsthatmatter-10453637?jobId=jobstreet-sg-job-10453637&sectionRank=155&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
155,"Data Engineer (EDW), Group Operations &amp; Technology - (220000Z5)",OCBC Bank (Singapore),"Collaborate with End Users, Business Analysts, and translate requirements into robust, scalable, operable solutions. Build, Test, Deploy Data Pipelines for both Real time , Batch and Hybrid Frameworks Implement Best Practices and Performance Optimization on Big Data Pipelines to achieve the best data engineering outcomes Troubleshoot &amp; Resolve Issues across various toolsets and services on the Big Data Platform Work with various stakeholders within IT and Business and Support the Projects Life Cycle (Agile &amp; SDLC) Employ DevOps to deliver Codes from Development to Production using relevant technologies Qualifications Overall, 7-10 years of relevant working experience in Data Management / Integration / Modelling the data warehouse in a Banking environment 5+ Years’ Experience with Teradata FSL-DM 5+ Years as a hands-on technologist familiar with SQL, UNIX and Teradata tools and technologies 5+ Years’ experience, Designing, Architecting, Implementing, and optimizing high throughput fault tolerant data pipelines for Batch (ETL/ELT) 3+ Years’ experience with Architecting Frameworks for Self Service Platforms/Data Market Place/ data at Scale 4+ Years’ experience with collaborating and fronting business users for gathering Requirements and translating to Technical Outcomes 3+ Years’ experience with Performance Tuning on Teradata or other MPP data pipelines Demonstrable automation experience on Unix Shell Scripting Collaborate with diverse cross functional teams within IT and Business to Independently drive outcomes Possess Good Communication Skills",https://www.jobstreet.com.sg/en/job/data-engineer-edw-group-operations-technology-220000z5-10452829?jobId=jobstreet-sg-job-10452829&sectionRank=156&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
156,"Big Data Engineer, Recommendation Architecture #Immediate",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-immediate-10453804?jobId=jobstreet-sg-job-10453804&sectionRank=157&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
157,"Big Data Engineer, Recommendation Architecture #Seekbetter#.#JobsThatMatter",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-seekbetter-.-jobsthatmatter-10454120?jobId=jobstreet-sg-job-10454120&sectionRank=158&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
158,"Data Engineer, TikTok --| #LetsGoToWork",TikTok,"Responsibilities About TikTok TikTok is the world's leading destination for short-form mobile videos. Our mission is to capture and present the world's creativity, knowledge, and moments that matter in everyday life. TikTok empowers everyone to be a creator directly from their smartphones and is committed to building a community by encouraging users to share their passion and creative expression through their videos. TikTok has offices in Beijing, Berlin, Jakarta, London, Los Angeles, Moscow, Mumbai, Sao Paulo, Seoul, Shanghai, Singapore, and Tokyo. In 2018, TikTok was one of the most downloaded apps in the world. TikTok is available worldwide for iOS and Android. Visit tiktok.com. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Translate business requirements &amp; end to end designs into technical implementations and responsible for building batch and real-time data warehouse Manage data modeling design, writing, and optimizing ETL jobs Collaborate with the business team to building data metrics based on data warehouse Responsible for building and maintaining data products Involvement in rollouts, upgrades, implementation, and release of data system changes as required for streamlining of internal practices Qualifications At least 3 years in software engineering and 2 years of relevant experience in data engineering Proficient in creating and maintaining complex ETL pipeline end-to-end while maintaining high reliability and security Familiar with data warehouse concept and have production experience in modeling design Familiar with at least 1 distributed computing engine (e.g. Hive, Spark, Flink) Familiar with at least 1 NoSQL database is a plus (e.g. HBase) Excellent interpersonal and communication skills with the ability to engage and managing internal and external stakeholders across all levels of seniority Strong collaboration skills with the ability to build rapport across teams and stakeholders",https://www.jobstreet.com.sg/en/job/data-engineer-tiktok-%7C-letsgotowork-10450551?jobId=jobstreet-sg-job-10450551&sectionRank=159&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
159,Data Engineer - TikTok - #UrgentHire,TikTok,"Responsibilities About TikTok TikTok is the world's leading destination for short-form mobile videos. Our mission is to capture and present the world's creativity, knowledge, and moments that matter in everyday life. TikTok empowers everyone to be a creator directly from their smartphones and is committed to building a community by encouraging users to share their passion and creative expression through their videos. TikTok has offices in Beijing, Berlin, Jakarta, London, Los Angeles, Moscow, Mumbai, Sao Paulo, Seoul, Shanghai, Singapore, and Tokyo. In 2018, TikTok was one of the most downloaded apps in the world. TikTok is available worldwide for iOS and Android. Visit tiktok.com. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Translate business requirements &amp; end to end designs into technical implementations and responsible for building batch and real-time data warehouse Manage data modeling design, writing, and optimizing ETL jobs Collaborate with the business team to building data metrics based on data warehouse Responsible for building and maintaining data products Involvement in rollouts, upgrades, implementation, and release of data system changes as required for streamlining of internal practices Qualifications: At least 5 years in software engineering and 2 years of relevant experience in data engineering Proficient in creating and maintaining complex ETL pipelines end-to-end while maintaining high reliability and security Familiar with data warehouse concept and have production experience in modeling design Familiar with at least 1 distributed computing engine (e.g. Hive, Spark, Flink) Familiar with at least 1 NoSQL database is a plus (e.g. HBase) Excellent interpersonal and communication skills with the ability to engage and manage internal and external stakeholders across all levels of seniority Strong collaboration skills with the ability to build rapport across teams and stakeholders",https://www.jobstreet.com.sg/en/job/data-engineer-tiktok-urgenthire-10451261?jobId=jobstreet-sg-job-10451261&sectionRank=160&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
160,Big Data Engineer - Recommendation Architecture #Urgent,TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications: Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability Willing to challenge questions that have no obvious answers, and have a strong enthusiasm for learning new technologies Experience of Peta Byte level data processing is a plus At least 3 years of relevant experience TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-urgent-10453932?jobId=jobstreet-sg-job-10453932&sectionRank=161&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
161,[Digital] Analytics Engineer / Data Engineer,Pfizer Asia Pacific Pte Ltd,"ROLE SUMMARY Do you want to make an impact on patient health around the world? Do you thrive in a fast-paced environment that brings together scientific, clinical and commercial domains through engineering, data science, and analytics? Then join Pfizer Digital’s Artificial Intelligence, Data, and Analytics organization (AIDA) where you can leverage cutting-edge technology to inform critical business decisions and improve customer experiences for our patients and physicians. Our collection of engineering, data science, and analytics professionals are at the forefront of Pfizer’s transformation into a digitally driven organization leveraging data science and advanced analytics to change patient’s lives. The Industrialization team within Enterprise Data Science and Advanced Analytics leads the scaling of data and insights capabilities - critical drivers and enablers of Pfizer’s digital transformation. As a senior associate analytics engineer, you will be part of the Data Science Industrialization team charged with building and automating high quality data pipelines that power advanced analytics/AI/ML and key business applications. You will be a member of a global team helping to develop and innovate on commercial go-to-market strategies. ROLE RESPONSIBILITIES Leverage data wrangling techniques to deliver data pipelines that Ingest and integrate data from various information sources and deliver high quality data products that drive analytics and data science applications Translate data needs into intro programable queries and convert Python based data wrangling code into PySpark/SQL pipelines for scalable pushdown execution Conduct basic data profiling and quality checks Fine tune performance on datasets for visualization and other applications Develop automated and self-monitoring data pipelines including automated QA/QC processes Work with stakeholders to assist with data-related technical issues and support data infrastructure needs. QUALIFICATIONS BASIC QUALIFICATIONS Bachelor’s degree in analytics engineering related area (Data Science, Computer Engineering, Computer Science, Information Systems or related discipline) 2+ years of work experience as an analyst/analytics engineer for a diverse range of projects Strong hands-on skills in analytics engineering (e.g., Python, industrialized ETL software) Experience working in a cloud based analytics ecosystem (AWS, Snowflake, etc) Experience with working with various types of data (structured / unstructured) Understanding of data ingestion, data warehousing, and data model concepts Knowledge of relational and dimensional data structures, theories, and practices Proficient in SQL, Python Highly self-motivated to deliver both independently and with strong team collaboration. Ability to creatively take on new challenges and work outside comfort zone. Strong aptitude for learning new technologies and analytics techniques. PREFERRED QUALIFICATIONS Advanced degree in Data Science, Computer Engineering, Computer Science, Information Systems or related discipline Experience with Dataiku is a plus Hands on experience working in Agile teams, processes, and practices Experience with hands-on skills in containerization (e.g. AWS EKS, Kubernetes) Experience with hands-on skills for data pipeline orchestration (e.g. Airflow) Understanding of data science development lifecycle (e.g CRISP) Pharma &amp; Life Science commercial functional knowledge is a plus Pharma &amp; Life Science commercial data literacy is a plus Work Location Assignment: Flexible Pfizer is an equal opportunity employer and complies with all applicable equal employment opportunity legislation in each jurisdiction in which it operates. Information &amp; Business Tech #LI-PFE",https://www.jobstreet.com.sg/en/job/%5Bdigital%5D-analytics-engineer-data-engineer-10452166?jobId=jobstreet-sg-job-10452166&sectionRank=162&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
162,Big Data Engineer (Ads Data) - 2023 Start #Worknow -| #JobsThatMatter #Immediate,TikTok,"Responsibilities TikTok will be prioritizing applicants who have a current right to work in Singapore, and do not require TikTok's sponsorship of a visa. TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. Why Join Us At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok. We are looking for talented individuals to join us for this future position in 2023. As a graduate, you will get unparalleled opportunities for you to kickstart your career, pursue bold ideas and explore limitless growth opportunities. Co-create a future driven by your inspiration with TikTok. Candidates can apply to a maximum of two positions and will be considered for jobs in the order you apply. The application limit is applicable to all TikTok and its affiliates' jobs globally. Applications will be reviewed on a rolling basis - we encourage you to apply early. About the Team The Ads Data team provides tools and services to deliver ad data to millions of internal and external clients all around the globe. The team has end-to-end ownership of ad data's lifecycle including data ETL, data warehouse and data services. We leverage data technologies to advice local customer support teams and help global advertisers make wiser investment decisions on our Advertising Platform. Ads Data is the cornerstone of every business decision that millions of advertisers make every day on our platform. Therefore, we are tasked with innovating on daily basis to create and maintain complex systems at large scale and continue expanding the capacity to better serve advertisers growing at exponential pace. You will share in the ownership of the technical vision and direction for advanced Ads Data products. You will be a part of a team of top notch technical professionals developing scalable systems and with a focus on sustained operational excellence. Members of this team will be challenged to innovate using cutting edge technologies. We are looking for people who are highly motivated by aiming for the highest, moving fast, and changing the way customers use data to drive profitability. Responsibilities Translate business requirements into technical implementations and responsible for building batch and real-time data warehouse; Design, build and launch real-time/batch data models/pipelines in production; Build up data marts and own data quality for business areas; Support existing real-time/batch systems in production, solve on-call issues; Define and manage SLA for all data sets in business areas; Support daily project management, assist junior engineers in business and technical problems. Qualifications Final year or Entry level with a background in Software Development, Computer Science, Computer Engineering, or a related technical discipline Experience working with big data technologies such as Hadoop, Hive, Spark, etc.; Experience with schema design and dimensional data modelling; Experience in custom ETL design, implementation and maintenance; Proficient in at least one programming language such as Python, Java or C++; Good communication skills, including the ability to identify and communicate data driven insights. TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https://careers.tiktok.com/legal/privacy. If you have any questions, please reach out to us at apac-""Apply Now""",https://www.jobstreet.com.sg/en/job/big-data-engineer-ads-data-2023-start-worknow-%7C-jobsthatmatter-immediate-10451602?jobId=jobstreet-sg-job-10451602&sectionRank=163&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
163,IT Data Analyst | #Immediate #Urgent#,UBS AG,"Your role Are you interested in developing regulatory reporting solutions using the latest technologies? Are you confident at iteratively refining user requirements and removing any ambiguity? Do you like to be challenged and encouraged to learn and grow professionally? We are looking for IT Data Analyst to: Design, plan and deliver sustainable solutions using modern programming languages (Apache Spark 2.x, Databricks, SCALA) Provide technical expertise and recommendations in assessing new software projects and initiatives to support and enhance our existing applications Work with key stakeholders including business change teams and wider SMEs within CTB organizations in GCRG technology to identify and delivery on functional/System design, Data model / Data Quality Performance tuning improvement opportunities Use technical knowhow (Enterprise Architecture, Database, data model) to support Capability Change teams to design data models and ensure logical and physical data models are properly reflected in data model repository of GCRG (Enterprise architecture, DGP) Your team You’ll be working in the Group Compliance, Regulatory &amp; Governance IT team based in Pune. Our role is to design and implement IT solutions for global Regulatory Reporting requirements (Major shareholding disclosures, Short Selling disclosures, 13F reporting, Conflict clearance, etc). We are a global IT team supporting internal clients throughout the world. Your expertise System Analyst / Big Data Engineer / Data Analyst focused on developing regulatory reporting solutions Strong experience with data warehousing, SQL, PL/SQL, PostgreSQL, Oracle databases Experience with Big Data technologies like Spark 2.0, SPARK SQL, Databricks using Scala or Python Well versed with working on Azure cloud platform. Good understanding of financial products and front to back trade lifecycle Experienced handling critical L3 support queries Design, plan and deliver solutions in a large-scale enterprise environment About us UBS is the world’s largest and only truly global wealth manager. We operate through four business divisions: Global Wealth Management, Personal &amp; Corporate Banking, Asset Management and the Investment Bank. Our global reach and the breadth of our expertise set us apart from our competitors. With more than 70,000 employees, we have a presence in all major financial centers in more than 50 countries. Do you want to be one of us? Join us From gaining new experiences in different roles to acquiring fresh knowledge and skills, at UBS we know that great work is never done alone. We know that it's our people, with their unique backgrounds, skills, experience levels and interests, who drive our ongoing success. Together we’re more than ourselves. Ready to be part of #teamUBS and make an impact? Disclaimer / Policy Statements UBS is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills and experiences within our workforce. Employees working from UBS Singapore offices must comply with Workforce Vaccination Measures as implemented by the Singapore government with effect from 1 January 2022, and other applicable safe management measures as may be amended from time to time.",https://www.jobstreet.com.sg/en/job/it-data-analyst-%7C-immediate-urgent-10487603?jobId=jobstreet-sg-job-10487603&sectionRank=164&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
164,Senior Software Engineer (Big Data Platform Application),The Great Eastern Life Assurance Co Ltd,"We are seeking a highly motivated and talented Big Data Engineer (data application) to work on Great Eastern Life’s next-generation data platform. Working alongside team of engineers and architects, you will be playing the role of application SME to handle enhancements and implantation of new features. This is a great opportunity to be an integral part of a team building GE’s technology platform leveraging open source technologies, and work on challenging and business-impacting projects. The Job Provide support for big data applications (on-premises and private cloud) directly and via triage to 3rd party support vendors where appropriate. Write functional and technical documentation for applications. Engage in Database Administration / Maintenance tasks on big data platform for testing purposes. Respond to business user requests for change (RSA) in application functional capabilities and engage with technical leadership on business demand for feature development. Participate in Projects involving application or data components as a SME. Takes accountability in considering business and regulatory compliance risks and takes appropriate steps to mitigate the risks. Maintains awareness of industry trends on regulatory compliance, emerging threats and technologies in order to understand the risk and better safeguard the company. Highlights any potential concerns /risks and proactively shares best risk management practices. Our Requirements Create and maintain optimal data pipeline architecture. Combine raw information from different sources. Work with business and internal teams to identify business needs and opportunities. Develops a deep understanding of how data is used by the business, and to add semantic meaning to a data catalog, to accelerate high-value datasets, to blend datasets together and to create actionable insights for the stakeholders. Undertake pre-processing of structured and unstructured data. Analyze large amounts of information to discover trend and patterns. Ensure data compliance and accuracy. Present information using data visualization techniques. Setup relevant set of dashboards to provide information for the business and influence decision. Organize and consolidate various set of data internal/external, quantitative/qualitative and liaise with the different internal system to maximize the usage of all set of data. Work closely with stakeholders to identify and propose system enhancement and process improvement on the data collection. Communicate and present technical information to non-technical stakeholders. High level of integrity, takes accountability of work and good attitude over teamwork. Takes initiative to improve current state of things and adaptable to embrace new changes. About Great Eastern Established in 1908, Great Eastern places customers at the heart of everything we do. Our legacy extends beyond our products and services to our culture, which is defined by our core values and how we work. As champions of Integrity, Initiative and Involvement, our core values act as a compass, guiding and inspiring us to embrace the behaviours associated with each value, upholding our promise to our customers - to continue doing our best for them in a sustainable manner. We work collaboratively with our stakeholders to look for candidates who exhibit or have the potential to embrace our core values and associated behaviours, as these are the key traits that we expect from our employees as they develop their careers with us. We embrace inclusivity, giving all employees an equal opportunity to shine and play their role in exploring possibilities to deliver innovative insurance solutions. Since 2018, Great Eastern has been a signatory to the United Nations (UN) Principles of Sustainable Insurance. Our sustainability approach around environmental, social, and governance (ESG) considerations play a key role in every business decision we make. We are committed to being a sustainability-driven company to achieve a low-carbon economy by managing the environmental footprint of our operations and incorporating ESG considerations in our investment portfolios; improving people’s lives by actively helping customers live healthier, better and longer; and drive responsible business practices through material ESG risk management.",https://www.jobstreet.com.sg/en/job/senior-software-engineer-big-data-platform-application-10450842?jobId=jobstreet-sg-job-10450842&sectionRank=165&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
165,Data Engineer (Remote possible) #Immediate,TikTok,"Data Engineer (Remote possible) Competitive Remuneration Package Remote working available About the Client Our client is a high growth fintech firm with strong regional presence. They are seeking for an experienced Data Engineer to join their expanding team. Candidates who are not based in Singapore are welcomed as well. Main Duties &amp; Responsibilities Build scalable batch and real-time data pipelines to ingest data from various channels Set up a streamlined data lake and data warehouse Deploy production quality code and maintain data quality Establish tools for data ingesting and building data cubes Experience and Qualifications At least 4 years of experience Bachelor/Master’s degree in Computer Science, Engineering or a related field, software engineering background preferred Proficiency in Python, Java or Scala Hands-on experience implementing ETL (or ELT) best practices at scale Experience in designing data warehouse – Snowflake, Redshift or Athena Hands-on experience working with Kubernetes Experience with stream processing systems (Flink or Spark) Knowledge of big data technologies - Spark, Hadoop, Hive, Kafka, Flink etc. and machine learning is a plus Familiarity with machine learning tools from AWS or GCP preferred Knowledge of software engineering concepts will be valuable Interest &amp; Application Advance your career to the next level with this unique opportunity. To further consult on this role, please send your updated Word format resume to ""Apply Now"" Do note that only shortlisted candidates will be contacted. Personnel Registration No R22109255 EA license No. 09C5803",https://www.jobstreet.com.sg/en/job/data-engineer-remote-possible-immediate-10448180?jobId=jobstreet-sg-job-10448180&sectionRank=166&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
166,Data Analyst / Senior,Benchmark Staffing Solutions,"Our Client is a leading worldwide technology partner providing critical components for IoT intelligence, with a special focus on Telecommunication Equipment and Metal Precision, LED technologies and Interconnect solutions. Technological innovation is in the DNA of entire organization and is also the cornerstone of state-of-the-art products and quality services. Towards this, they have established the data analytics COE to fully incorporate Big Data and Artificial Intelligence into strategic roadmap and enable digital transformation and smart manufacturing initiatives. This tole as Data Analyst / Senior will enable an organization to make more informed decisions by blending various data to provide actionable insight. He/she will be part of innovation drivers to improve business process and coordinates with internal stakeholders to develop projections on implementing digital transformation strategies. Meanwhile, he/she works in a team setting and is exposed to various technologies (e.g., Big Data, advanced analytics, cybersecurity) for further career progression. They are a public listed company and operates in more than 15 countries globally with annual revenue of more than US$4 billion. Data Analyst / Senior Job Responsibilities: Identify information required for stakeholders’ decision-making and translate business requirements into analytics and reporting requirements. Recommend types of data and data sources needed to obtain the required information and insights. Identify potential business intelligence service offerings required by the business and long-term analytics strategies. Work with data engineer team to prepare the data warehouse for BI reporting and analytics consumption. Collaborate with technical and non-technical stakeholders to identify opportunities for process improvements, recommend system modifications, and develop policies for data governance. Gather data from internal and external sources as needed to build POC in timely fashion. Perform data validation, cleaning and transformation as needed to ensure data quality before data consumption. Design data reports and visualization tools to facilitate data understanding through storytelling. Plan and conduct analytics training for business adoption and data-driven culture cultivation. Perform progress check, solution review and documentation on the regular basis. Job Requirements: Degree in Computer Science, Software Engineering, Applied Math, Business, Engineering or a related discipline. At least 3 to 5 years of relevant data analyst/developer experience in analysing large dataset. Hands-on experience in using data visualization tool, e.g., Power BI, Tableau, Fanruan. Hands-on experience in various data analysis, e.g., gap analysis, root cause, regression. Strong domain knowledge and product sense to drive the analytics adoption. Good analytical and critical thinking skills – able to drive the analytics adoption. Familiar with Agile methodology to continuously review and correct the “playbook”. Experience in supply chain, operation planning and manufacturing is highly valued. Able to communicate clearly and effectively in both English and Mandarin. Software development experience (front-end or backend) is a plus. Are you ready for a challenging and exciting endeavour that will require the investment of a lot of hard work, dedication and all your experience? Are you ready to bring your skills and competencies to support the establishment and enhancement of our client’s business? If yes, you might be exactly the new team member they are looking for! Please submit your updated and comprehensive CV in MS WORD FORMAT ONLY (NOT PDF) with full career details, stating current or last drawn salary with full breakdown such as base, incentives, AWS, etc. and expected salary, contact details, educational qualifications, working experiences, reasons for leaving each past employment(s) and availability date. What our client offers Our client offers an attractive remuneration package, a fast-paced and exciting working environment and provide challenging opportunities for career advancement. They care about their employees. They are not just an employer. They are a Team. They do not just offer you a job, they offer you a career. By joining their team, you will find strong purpose and deep meaning in everything you do. You will have the chance to make a real difference for customers, working alongside a passionate team of like-minded colleagues, while building your knowledge/skills and developing your career in a fun, dynamic and fast-growing organization. Personal Data Protection Statement for Job Applicants Please be informed that the personal data you provided by way of your job application to Benchmark will be collected, used and disclosed by or on behalf of Benchmark to determine or investigate your suitability, eligibility or qualifications for employment with Benchmark and/or its clients and manage your application for employment with Benchmark and/or its clients including identifying you as potential candidate for future suitable positions and/or notifying you of any such positions, either existing or in the future. Thank You! We thank all applicants for their interest in a career with our client. Due to the high volume of incoming applications, we will not be able to respond to all applicants. Therefore, only shortlisted applicants will be notified for interviews. All applications will be treated with the strictest confidence. THOMAS CHAN | CEI No: R1766693 | Benchmark Staffing Solutions | EA Licence: 21C0679 | UEN: 53435609E",https://www.jobstreet.com.sg/en/job/data-analyst-senior-10455302?jobId=jobstreet-sg-job-10455302&sectionRank=167&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
167,"Data Engineer, Growth #Urgent --| #LetsGoToWork",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. The Growth team plays a core role in acquisition, activation, and retention of billions of users, through our globally popular products such as TikTok, Resso, CapCut, Helo, etc. We are building platform foundation, leveraging data and ML models, and providing end-to-end solutions to power global growth of ByteDance products. Typical Growth projects including referral, notifications, paid ads, etc. You will: Build data pipelines to portray business status, based on a deep understanding of our fast changing business and data-driven approach; Extract information and signals from a broad range of data and build hierarchies to accomplish analytical and mining goals for “Packaged Business Capability” such as user-growth, gaming and searching; Keep improving the integrity of data pipelines to provide a comprehensive data service. Qualifications: Bachelor's degree in Computer Science, Statistic, Data Science or a related field; Skilled in SQL and additional object-oriented programming language (e.g. Scala, Java, or Python); Experience in issue tracking and problem solving on data pipelines; Fast business understanding and collaborative in teamwork.",https://www.jobstreet.com.sg/en/job/data-engineer-growth-urgent-%7C-letsgotowork-10450137?jobId=jobstreet-sg-job-10450137&sectionRank=168&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
168,Data Engineer - Video Infrastructure #WorkNow #UrgentHire*-- #LetsGoToWork,TikTok,"Responsibilities Video Infrastructure is a world-leading video platform that provides multi-media storage, delivery, transcoding, and streaming services. We are building the next generation video processing platform and the largest live streaming network, which provides excellent experiences for billions of users around the world. Popular video products of TikTok and its affiliates are all empowered by our cutting-edge cloud technologies. Working in this team, you will have the opportunity to tackle challenges of large-scale networks all over the world, while leveraging your expertise in coding, algorithms, complexity analysis, and large-scale system design. Responsibilities Craft optimal data processing architecture and systems for new data and ETL pipelines. Design, build, and maintain efficient and reliable data pipelines to move and transform data (both large and small amounts). Drive internal process improvements and automate manual processes for data quality and SLA management. Work with different cross-functional partners including CDN, Video Understanding, Video Transcoding, Live Streaming, and Real-Time Communication. Qualifications Bachelor's degree in Computer Science or a related technical background involving software/system engineering, or equivalent working experience. Good programming experience with at least one of the following languages: C, C++, Java, Python, or Go. Experience in custom ETL/data pipeline design, implementation, and maintenance. Experience with data processing software (Hadoop, Spark, Pig, Hive) and algorithms (MapReduce, Flume). Experience in troubleshooting in large scale distributed systems.",https://www.jobstreet.com.sg/en/job/data-engineer-video-infrastructure-worknow-urgenthire*-letsgotowork-10448485?jobId=jobstreet-sg-job-10448485&sectionRank=169&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
169,"Data Engineer, - Growth#. #JobsThatMatter --| #LetsGoToWork",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. The Growth team plays a core role in acquisition, activation, and retention of billions of users, through our globally popular products such as TikTok, Resso, CapCut, Helo, etc. We are building platform foundation, leveraging data and ML models, and providing end-to-end solutions to power global growth of ByteDance products. Typical Growth projects including referral, notifications, paid ads, etc. You will: Build data pipelines to portray business status, based on a deep understanding of our fast changing business and data-driven approach; Extract information and signals from a broad range of data and build hierarchies to accomplish analytical and mining goals for “Packaged Business Capability” such as user-growth, gaming and searching; Keep improving the integrity of data pipelines to provide a comprehensive data service. Qualifications Bachelor's degree in Computer Science, Statistic, Data Science or a related field; Skilled in SQL and additional object-oriented programming language (e.g. Scala, Java, or Python); Experience in issue tracking and problem solving on data pipelines; Fast business understanding and collaborative in teamwork. Preferred Qualifications: Industry experience working with user growth.",https://www.jobstreet.com.sg/en/job/data-engineer-growth-.-jobsthatmatter-%7C-letsgotowork-10450110?jobId=jobstreet-sg-job-10450110&sectionRank=170&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
170,Data Integration Specialist,Keppel Enterprise Services,"About Group Digital Office – Data and Digital team The folks at Keppel Corporation’s Group Digital Office are digital natives whose goal is to drive digitalization and transformation across the group. Sparking innovation and thought leadership, with core competency as critical thinker, disciplined thinker that is clear, rational, open-minded, and informed by evidence. A lean organization understands the value of its wealth data and strives to derive the sharpest insights to create competitive advantages. Our goal is to deliver those insights and work with the businesses to execute those actions. We are on the hunt for a data integration specialist who is comfortable working across multiple functions and teams that can help us stich together all the data and systems needed to deliver improved holistic business insights. Your tenaciousness and passion will help to ensure we can see through our missions through from conceptualization to final delivery. The job title offered will commensurate with the years of experience, skillset and other relevant attributes. Job Scope The Data Integration specialist is a subject matter expert of data integration solutions and data architecture You will be responsible for the technical development of any new data integration solution to be plugged in to the overall enterprise data architecture You will be supporting the Data Engineer to organise data at the macro and micro levels, creating data models that enable the implementation of the intended business architecture, key data entity diagrams, and a data inventory to implement the architecture vision Responsibilities Planning and executing data migrations, providing logical data models with business logic needed for creation of data quality rules Contributing to the Data Quality Improvement Program through application of data management best practices, designing data solutions, implementing future proof fixes, identifying opportunities for driving data process efficiency and data quality Supporting the Data Engineer to scope out and recommend technologies to enhance data Extracting, transforming and integrating large and small datasets. Working alongside developers to develop data integration solutions Maintaining and developing a reliable and efficient master data for the long term Supporting the development of a reporting data warehouse Developing and maintaining documentation for each data solution to ensure it reflects current business rules and definitions Facilitating stakeholders in identifying technology challenges, supporting them in defining requirements of their projects Collaborating with technology business partners to allow the organisation to absorb and scale into business-as-usual development work Executing some routine tasks on regular basis, which can include data imports and executing SSIS packages, also to support the Data Operations Team during peak times Additional Job Description A curious data enthusiast with a passion for technology and problem solving 5 years’ experience working with any of the mainstream RDBMS Experience with end-to-end data pipeline implementation with cloud services such as Azure Data Factory/AWS Glue Data manipulation, data integration design and development including T-SQL, SSIS and APIs Datawarehouse tech: experience developing OLAP cubes and/or in memory data models Business Intelligence technology (e.g., Power BI) Good understanding of data lifecycle and architecture best practices Systems integration experience with SAP systems is a bonus. Understanding of Data Protection Legislation is a plus Good communication and excellent listening skills. Strong relationship building skills and a collaborative attitude towards everyday working. Empathetic when dealing with colleagues Ability to work with modern workplace technology (such as MS Teams) from home and in the office",https://www.jobstreet.com.sg/en/job/data-integration-specialist-10444047?jobId=jobstreet-sg-job-10444047&sectionRank=171&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
171,Data Engineer,Laureoli International Pte Ltd,"Summary AYP is seeking a goal-oriented Data Engineer to be a part of the Technology team and work closely with the Business Intelligence team to ensure data pipelines are secure and effective. This person will play a pivotal role in operationalizing the most-urgent data and analytics initiatives for AYP’s digital business initiatives. You’ll be given the autonomy to innovate, create and implement tools/applications/processes. Also, you’ll be tasked to work with key business stakeholders, IT experts and subject matter experts to plan and deliver optimal analytics solutions. What you’ll need: Passion to constantly improving existing processes with new technologies. Willing to learn new things. Experienced in setting up data pipeline, including designing, managing datas, and implementing technologies, etc. Responsibility Analyze and organize raw data. Build data systems and pipelines. Evaluate business needs and objectives. Interpret trends and patterns. Conduct complex data analysis and report on results. Prepare data for prescriptive and predictive modeling. Build algorithms and prototypes. Combine raw information from different sources. Explore ways to enhance data quality and reliability. Identify opportunities for data acquisition. Develop analytical tools and programs. Collaborate with business intelligence team and architects on several projects. Curious and knowledgeable about new data initiatives. Participate in ensuring compliance and governance during data usage. Skills and Qualifications Bachelor’s Degree in Computer Science, Data Management, Statistics, Applied Mathematics, or related field with a solid foundation. Min 3 years’ experience in Data Management disciplines, including data integration, modelling, optimisation and data quality, and/or other areas directly with relevance to data engineering responsibilities and tasks. Experience with analytics tools for Object-oriented/object function scripting using languages such as R, Python, Java, C++, Scala, and/or others. Track record in setting up, including designing, building, and managing data pipelines for data structures encompassing data transformation, data models, schemas, metadata and workload management. The ability to work with both IT and business in integrating analytics output into business processes and workflows. Experience in working with datasets in building and optimizing data pipelines, pipeline architectures and integrated datasets using data integration technologies. Experience in working with and optimizing ETL processes and data integration and data preparation flows and helping to move them into production. Ability to work in cross-functional teams and collaborate with business stakeholders in support of a departmental and/or multi-departmental data management and analytics initiative. Experience in the following is a plus: Ability to work across multiple deployment environments to the cloud, multiple operating systems and through containerization techniques such as Docker, Kubernetes, and/or AWS Elastic Container Service. Experience in working with both open-source and commercial message queuing technologies such as Kafka, and/or Amazon Simple Queuing Service. Experience working with data discovery, analytics and BI software tools like Tableau. Experience in working with data governance/data quality and specifically in moving data pipelines into production with appropriate data quality, governance and security standards and certification. **We regret to inform that only shortlisted candidates will be considered and contacted. Thank you.",https://www.jobstreet.com.sg/en/job/data-engineer-10449466?jobId=jobstreet-sg-job-10449466&sectionRank=172&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
172,Lead Software Engineer (Big Data Platform),The Great Eastern Life Assurance Co Ltd,"Job Purpose We are seeking a highly motivated and talented Lead Big Data Engineer to work on Great Eastern Life’s next-generation data platform. Working alongside team of engineers and architects, you will be responsible for running and managing our big data stack in DEV/SIT/UAT/PROD and supporting a hybrid data platform. This is a great opportunity to be an integral part of a team building GE’s technology platform leveraging open source technologies, and work on challenging and business-impacting projects. The Job As the Big Data Lead, your will provide leadership in the following: • Guiding, leading, and managing a small team of devops, big data engineers and developers on the feature design and development activities. Working with the team for Backend Performance improvement across different components of the Product (Batch jobs, Streaming Job, etc.) Setting up and introduction of new tools and tech stack to support new features and security across the Product. Guiding the development activity and branching strategies. Code Review and Best Practices implementation. Work in an AGILE team to turn innovative ideas into robust software and solve complex design and implementation problems. Work with business leads to define project scope and timeline. Gather requirements and functional specifications assessing the current software systems in place to identify areas in need of improvement, and overseeing development teams. Work with business to for adoption and ensure support model in place. Develop systems to collect usage data to monitor application performance. Takes accountability in considering business and regulatory compliance risks and takes appropriate steps to mitigate the risks. Maintains awareness of industry trends on regulatory compliance, emerging threats and technologies in order to understand the risk and better safeguard the company. Highlights any potential concerns /risks and proactively shares best risk management practices. Our Requirements • Experience in Architecture, design, implementation, and deployment of high volume, highly available, cloud-based/hybrid systems would be a plus. Hands on experience in Java/Scala/Python or any programming language software development skills. Good to have hands on experience in Impala, Hive, Kudu, Knowledge of CI/CD, SQL, ETL tools, data masking technology, Informatica. Experience and Demonstrated understanding of Object/Component Oriented Design techniques. Experience with Big Data and real-time analytics. Experience with Agile software development methodologies and Test-Driven Design. Proven ability to evaluate and adopt new technology. A proactive and eager nature for tackling new challenge. High level of integrity, takes accountability of work and good attitude over teamwork. Takes initiative to improve current state of things and adaptable to embrace new changes. About Great Eastern Established in 1908, Great Eastern places customers at the heart of everything we do. Our legacy extends beyond our products and services to our culture, which is defined by our core values and how we work. As champions of Integrity, Initiative and Involvement, our core values act as a compass, guiding and inspiring us to embrace the behaviours associated with each value, upholding our promise to our customers - to continue doing our best for them in a sustainable manner. We work collaboratively with our stakeholders to look for candidates who exhibit or have the potential to embrace our core values and associated behaviours, as these are the key traits that we expect from our employees as they develop their careers with us. We embrace inclusivity, giving all employees an equal opportunity to shine and play their role in exploring possibilities to deliver innovative insurance solutions. Since 2018, Great Eastern has been a signatory to the United Nations (UN) Principles of Sustainable Insurance. Our sustainability approach around environmental, social, and governance (ESG) considerations play a key role in every business decision we make. We are committed to being a sustainability-driven company to achieve a low-carbon economy by managing the environmental footprint of our operations and incorporating ESG considerations in our investment portfolios; improving people’s lives by actively helping customers live healthier, better and longer; and drive responsible business practices through material ESG risk management.",https://www.jobstreet.com.sg/en/job/lead-software-engineer-big-data-platform-10450334?jobId=jobstreet-sg-job-10450334&sectionRank=173&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
173,"Data Engineer, TikTok*#Worknow#Seekbetter #JobsThatMatter",TikTok,"TikTok is the world's leading destination for short-form mobile videos. Our mission is to capture and present the world's creativity, knowledge, and moments that matter in everyday life. TikTok empowers everyone to be a creator directly from their smartphones and is committed to building a community by encouraging users to share their passion and creative expression through their videos. TikTok has offices in Beijing, Berlin, Jakarta, London, Los Angeles, Moscow, Mumbai, Sao Paulo, Seoul, Shanghai, Singapore, and Tokyo. In 2018, TikTok was one of the most downloaded apps in the world. TikTok is available worldwide for iOS and Android. Visit tiktok.com. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Translate business requirements &amp; end to end designs into technical implementations and responsible for building batch and real-time data warehouse Manage data modeling design, writing, and optimizing ETL jobs Collaborate with the business team to building data metrics based on data warehouse Responsible for building and maintaining data products Involvement in rollouts, upgrades, implementation, and release of data system changes as required for streamlining of internal practices Qualifications At least 3 years in software engineering and 2 years of relevant experience in data engineering Proficient in creating and maintaining complex ETL pipeline end-to-end while maintaining high reliability and security Familiar with data warehouse concept and have production experience in modeling design Familiar with at least 1 distributed computing engine (e.g. Hive, Spark, Flink) Familiar with at least 1 NoSQL database is a plus (e.g. HBase) Excellent interpersonal and communication skills with the ability to engage and managing internal and external stakeholders across all levels of seniority Strong collaboration skills with the ability to build rapport across teams and stakeholders",https://www.jobstreet.com.sg/en/job/data-engineer-tiktok*-worknow-seekbetter-jobsthatmatter-10442005?jobId=jobstreet-sg-job-10442005&sectionRank=174&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
174,"Data Engineer, TikTok #UrgentHire* #JobsThatMatter #Worknow-- #LetsGoToWork",TikTok,"TikTok is the world's leading destination for short-form mobile videos. Our mission is to capture and present the world's creativity, knowledge, and moments that matter in everyday life. TikTok empowers everyone to be a creator directly from their smartphones and is committed to building a community by encouraging users to share their passion and creative expression through their videos. TikTok has offices in Beijing, Berlin, Jakarta, London, Los Angeles, Moscow, Mumbai, Sao Paulo, Seoul, Shanghai, Singapore, and Tokyo. In 2018, TikTok was one of the most downloaded apps in the world. TikTok is available worldwide for iOS and Android. Visit tiktok.com. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Translate business requirements &amp; end to end designs into technical implementations and responsible for building batch and real-time data warehouse Manage data modeling design, writing, and optimizing ETL jobs Collaborate with the business team to building data metrics based on data warehouse Responsible for building and maintaining data products Involvement in rollouts, upgrades, implementation, and release of data system changes as required for streamlining of internal practices Qualifications At least 3 years in software engineering and 2 years of relevant experience in data engineering Proficient in creating and maintaining complex ETL pipeline end-to-end while maintaining high reliability and security Familiar with data warehouse concept and have production experience in modeling design Familiar with at least 1 distributed computing engine (e.g. Hive, Spark, Flink) Familiar with at least 1 NoSQL database is a plus (e.g. HBase) Excellent interpersonal and communication skills with the ability to engage and managing internal and external stakeholders across all levels of seniority Strong collaboration skills with the ability to build rapport across teams and stakeholders",https://www.jobstreet.com.sg/en/job/data-engineer-tiktok-urgenthire*-jobsthatmatter-worknow-letsgotowork-10443635?jobId=jobstreet-sg-job-10443635&sectionRank=175&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
175,IT Data Analyst | #Immediate #JobsThatMatter#,UBS AG,"Your role Are you interested in developing regulatory reporting solutions using the latest technologies? Are you confident at iteratively refining user requirements and removing any ambiguity? Do you like to be challenged and encouraged to learn and grow professionally? We are looking for IT Data Analyst to: Design, plan and deliver sustainable solutions using modern programming languages (Apache Spark 2.x, Databricks, SCALA) Provide technical expertise and recommendations in assessing new software projects and initiatives to support and enhance our existing applications Work with key stakeholders including business change teams and wider SMEs within CTB organizations in GCRG technology to identify and delivery on functional/System design, Data model / Data Quality Performance tuning improvement opportunities Use technical knowhow (Enterprise Architecture, Database, data model) to support Capability Change teams to design data models and ensure logical and physical data models are properly reflected in data model repository of GCRG (Enterprise architecture, DGP) Your team You’ll be working in the Group Compliance, Regulatory &amp; Governance IT team based in Pune. Our role is to design and implement IT solutions for global Regulatory Reporting requirements (Major shareholding disclosures, Short Selling disclosures, 13F reporting, Conflict clearance, etc). We are a global IT team supporting internal clients throughout the world. Your expertise System Analyst / Big Data Engineer / Data Analyst focused on developing regulatory reporting solutions Strong experience with data warehousing, SQL, PL/SQL, PostgreSQL, Oracle databases Experience with Big Data technologies like Spark 2.0, SPARK SQL, Databricks using Scala or Python Well versed with working on Azure cloud platform. Good understanding of financial products and front to back trade lifecycle Experienced handling critical L3 support queries Design, plan and deliver solutions in a large-scale enterprise environment About us UBS is the world’s largest and only truly global wealth manager. We operate through four business divisions: Global Wealth Management, Personal &amp; Corporate Banking, Asset Management and the Investment Bank. Our global reach and the breadth of our expertise set us apart from our competitors. With more than 70,000 employees, we have a presence in all major financial centers in more than 50 countries. Do you want to be one of us? Join us From gaining new experiences in different roles to acquiring fresh knowledge and skills, at UBS we know that great work is never done alone. We know that it's our people, with their unique backgrounds, skills, experience levels and interests, who drive our ongoing success. Together we’re more than ourselves. Ready to be part of #teamUBS and make an impact? Disclaimer / Policy Statements UBS is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills and experiences within our workforce. Employees working from UBS Singapore offices must comply with Workforce Vaccination Measures as implemented by the Singapore government with effect from 1 January 2022, and other applicable safe management measures as may be amended from time to time.",https://www.jobstreet.com.sg/en/job/it-data-analyst-%7C-immediate-jobsthatmatter-10482839?jobId=jobstreet-sg-job-10482839&sectionRank=176&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
176,"Big Data Engineer, Recommendation Architecture #URGENT",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. About The Team Our Recommendation Architecture Team is responsible for building up and optimizing the architecture for our recommendation system to provide the most stable and best experience for our TikTok users. The team is responsible for system stability and high availability, online services and offline data flow performance optimization, solving system bottlenecks, reducing cost overhead, building data and service mid-platform, realizing flexible and scalable high-performance storage and computing systems. Responsibilities - What You'll Do Design and implement a reasonable offline data architecture for large-scale recommendation systems Design and implement flexible, scalable, stable and high-performance storage and computing systems Trouble-shooting of the production system, design and implement the necessary mechanisms and tools to ensure the stability of the overall operation of the production system Build industry-leading distributed systems such as storage and computing to provide reliable infrastructure for massive data and large-scale business systems Qualifications Bachelor's degree or above in computer science, software engineering, or a related field Familiar with many open source frameworks in the field of big data, e.g.Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc. Familiar with Java, C ++ and other programming languages Strong coding and trouble shooting ability TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.",https://www.jobstreet.com.sg/en/job/big-data-engineer-recommendation-architecture-urgent-10438240?jobId=jobstreet-sg-job-10438240&sectionRank=177&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
177,IT Data Analyst | #UrgentHire #Urgent#,UBS AG,"Your role Are you interested in developing regulatory reporting solutions using the latest technologies? Are you confident at iteratively refining user requirements and removing any ambiguity? Do you like to be challenged and encouraged to learn and grow professionally? We are looking for IT Data Analyst to: Design, plan and deliver sustainable solutions using modern programming languages (Apache Spark 2.x, Databricks, SCALA) Provide technical expertise and recommendations in assessing new software projects and initiatives to support and enhance our existing applications Work with key stakeholders including business change teams and wider SMEs within CTB organizations in GCRG technology to identify and delivery on functional/System design, Data model / Data Quality Performance tuning improvement opportunities Use technical knowhow (Enterprise Architecture, Database, data model) to support Capability Change teams to design data models and ensure logical and physical data models are properly reflected in data model repository of GCRG (Enterprise architecture, DGP) Your team You’ll be working in the Group Compliance, Regulatory &amp; Governance IT team based in Pune. Our role is to design and implement IT solutions for global Regulatory Reporting requirements (Major shareholding disclosures, Short Selling disclosures, 13F reporting, Conflict clearance, etc). We are a global IT team supporting internal clients throughout the world. Your expertise System Analyst / Big Data Engineer / Data Analyst focused on developing regulatory reporting solutions Strong experience with data warehousing, SQL, PL/SQL, PostgreSQL, Oracle databases Experience with Big Data technologies like Spark 2.0, SPARK SQL, Databricks using Scala or Python Well versed with working on Azure cloud platform. Good understanding of financial products and front to back trade lifecycle Experienced handling critical L3 support queries Design, plan and deliver solutions in a large-scale enterprise environment About us UBS is the world’s largest and only truly global wealth manager. We operate through four business divisions: Global Wealth Management, Personal &amp; Corporate Banking, Asset Management and the Investment Bank. Our global reach and the breadth of our expertise set us apart from our competitors. With more than 70,000 employees, we have a presence in all major financial centers in more than 50 countries. Do you want to be one of us? Join us From gaining new experiences in different roles to acquiring fresh knowledge and skills, at UBS we know that great work is never done alone. We know that it's our people, with their unique backgrounds, skills, experience levels and interests, who drive our ongoing success. Together we’re more than ourselves. Ready to be part of #teamUBS and make an impact? Disclaimer / Policy Statements UBS is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills and experiences within our workforce. Employees working from UBS Singapore offices must comply with Workforce Vaccination Measures as implemented by the Singapore government with effect from 1 January 2022, and other applicable safe management measures as may be amended from time to time.",https://www.jobstreet.com.sg/en/job/it-data-analyst-%7C-urgenthire-urgent-10482466?jobId=jobstreet-sg-job-10482466&sectionRank=178&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
178,"Aon Early Careers Graduate Programme, Singapore - Innovation &amp; Analytics #JobsThatMatter #Worknow",Aon Hewitt,"ob Description Aon Early Careers Graduate Programme, Singapore - Innovation &amp; Analytics Make a career out of better decisions Join Aon as a graduate and propel your career with us. Develop your professional skills and build strong relationships with clients and colleagues alike. Our 24-month Graduate Programme is designed to develop high performers so they can grow and potentially lead our business in the future.​ Innovation &amp; Analytics ​Track​ In this graduate programme, you will be exposed to all aspects of our business through four job rotations (6-month cycle) across different business areas, participate in Agile scrum-based projects and have the opportunity to work with key stakeholders across the Aon business, gaining knowledge and insight into our world of data and analytics. There are 3 roles in our Innovation &amp; Analytics Track: In the Application Developer role, you will collaborate with the brightest minds in our innovation center to build high-performing applications that deliver insightful analytics to our users. You should be familiar with one or more of the following languages C#, JavaScript, Python. Knowledge in SQL, CSS, ReactJS, Angular would be advantageous. In the Data Engineer role, you will be a part of a high-performing team to make data accessible for our analytics teams. You will be building systems that collect, manage, and convert raw data into usable information. You need to have the ability to code in Python / Scala and SQL to perform data operations. Good knowledge of databases, data structures is a must. Knowledge of Spark would be advantageous. In the Data Analyst role, you will act as a champion for Aon’s suite of analytical tools and help business leaders drive performance by supporting the delivery of analytics solutions around client data. Having technical knowledge of SQL, Python/R, and Microsoft Office is a must. Knowledge in visualisation software such as Tableau /PowerBI is a big plus. Your Development As an Aon Graduate, you will be enrolled onto our Launch Programme when you join. This development programme is built around 3 core elements : Business Learning – on the job learning and experiences giving you the opportunity to develop your knowledge and understanding of the team and Graduate Track you have joined Centralised Learning – Graduates complete an Aon Induction, webinars, business skills training and workshops; all designed to help you develop your knowledge of Aon, build your confidence and your network across our business Professional Qualifications – we want you to be as successful as possible, so we’ll fully support your study towards the attainment of industry qualifications/certificates. You will identify the qualification/certificate you wish to pursue together with your career mentor, and we will support you with course fees, course materials and paid study leave. Your Career beyond our Graduate Programme We believe that no individual person or piece of Aon is stronger than the whole. As a firm, Aon is committed to creating a work environment where every colleague feels safe and comfortable being their authentic self, experiences a sense of belonging, is empowered to reach their full professional potential and is valued for the unique perspectives and talents they bring. Upon successful completion of your graduate program, we’ll work together to find you a landing role within our organisation. You’ll continue to receive support at Aon as you continue your career with us. What are we looking for? Motivation and ambition – you will need to be able to articulate why you want to start your career in the track you have selected. Commercial awareness – this helps us to provide support and advice to our clients with clarity. You must be numerically confident and have the desire and ability to excel in a competitive environment where communication is key. We're looking for collaborators, critical thinkers, problem solvers, team players, effective communicators, relationship builders and future leaders. Building relationships is at the heart of what we do and you'll need to show that you can work collaboratively to develop solutions for our clients. How we support our colleagues In addition to our comprehensive benefits package, we encourage a diverse workforce. Plus, our agile, inclusive environment allows you to manage your wellbeing and work/life balance, ensuring you can be your best self at Aon. Furthermore, all colleagues enjoy two “Global Wellbeing Days” each year, encouraging you to take time to focus on yourself. We offer a variety of working style solutions, but we also recognise that flexibility goes beyond just the place of work... and we are all for it. We call this Smart Working! Our continuous learning culture inspires and equips you to learn, share and grow, helping you achieve your fullest potential. As a result, at Aon, you are more connected, more relevant, and more valued. We provide individuals with disabilities reasonable accommodations to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment in accordance with applicable law. Aon values an innovative, diverse workplace where all colleagues feel empowered to be their authentic selves. Aon is proud to be an equal opportunity workplace.",https://www.jobstreet.com.sg/en/job/aon-early-careers-graduate-programme-singapore-innovation-analytics-jobsthatmatter-worknow-10479558?jobId=jobstreet-sg-job-10479558&sectionRank=179&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
179,"Data Engineer, Growth -- #Immediate - | #LetsGoToWork",TikTok,"Responsibilities TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. The Growth team plays a core role in acquisition, activation, and retention of billions of users, through our globally popular products such as TikTok, Resso, CapCut, Helo, etc. We are building platform foundation, leveraging data and ML models, and providing end-to-end solutions to power global growth of ByteDance products. Typical Growth projects including referral, notifications, paid ads, etc. You will: Build data pipelines to portray business status, based on a deep understanding of our fast changing business and data-driven approach; Extract information and signals from a broad range of data and build hierarchies to accomplish analytical and mining goals for “Packaged Business Capability” such as user-growth, gaming and searching; Keep improving the integrity of data pipelines to provide a comprehensive data service. Qualifications Bachelor's degree in Computer Science, Statistic, Data Science or a related field; Skilled in SQL and additional object-oriented programming language (e.g. Scala, Java, or Python); Experience in issue tracking and problem solving on data pipelines; Fast business understanding and collaborative in teamwork.",https://www.jobstreet.com.sg/en/job/data-engineer-growth-immediate-%7C-letsgotowork-10430638?jobId=jobstreet-sg-job-10430638&sectionRank=180&token=0~3b2cd1f6-0f1c-471f-9d81-5307b9fae6dc&fr=SRP%20Job%20Listing
180,Data Engineer (Data Platform) - 2023 Start #Immediate,TikTok,"Responsibilities TikTok will be prioritizing applicants who have a current right to work in Singapore, and do not require TikTok's sponsorship of a visa. TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. Why Join Us At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok. We are looking for talented individuals to join us for this future position in 2023. As a graduate, you will get unparalleled opportunities for you to kickstart your career, pursue bold ideas and explore limitless growth opportunities. Co-create a future driven by your inspiration with TikTok. Candidates can apply to a maximum of two positions and will be considered for jobs in the order you apply. The application limit is applicable to all TikTok and its affiliates' jobs globally. Applications will be reviewed on a rolling basis - we encourage you to apply early. About the Team The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you. Responsibilities Translate business requirements &amp; end-to-end designs into technical implementations and responsible for building batch and real-time data warehouse; Manage data modeling design, writing and optimizing ETL jobs - collaborate with business teams to build data metrics based on data warehouse; Responsible for building and maintaining data products; Involvement in rollouts, upgrades, implementation and release of data system changes as required for streamlining of internal practices. Qualifications Final year or entry level with a background in Computer Science, Computer Engineering, Information Systems or a related technical discipline; Solid computer basic knowledge (e.g. data structure &amp; algorithms, SQL and networks); Strong coding capabilities and mastering at least one programming language (e.g. C/C++/Java/Python/Golang); Passionate about data warehouse, ETL development, data analysis and eCommerce; Good communication skills and a fast learner of new business and technology knowledge. TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. By submitting an application for this role, you accept and agree to o",https://www.jobstreet.com.sg/en/job/data-engineer-data-platform-2023-start-immediate-10432731?jobId=jobstreet-sg-job-10432731&sectionRank=181&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
181,Data Engineer Intern (TikTok Data Platform) - 2023 #UrgentHire,TikTok,"Responsibilities TikTok will be prioritizing applicants who have a current right to work in Singapore, and do not require TikTok's sponsorship of a visa. TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. Why Join Us At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok. We are looking for talented individuals to join us for an internship in 2023. Internships at TikTok aim to offer students industry exposure and hands-on experience. Watch your ambitions become reality as your inspiration brings infinite opportunities at TikTok. Successful candidates must be able to commit to one of the following internship cycles below: - Summer Internship - 08 May 2023 to 28 July 2023 (12 weeks) Off-cycle Internship - Starting 09 January 2023 or 14 August 2023 We will prioritize candidates who are able to commit in either internship period. Please state your availability clearly in your resume (Start date, End date). Candidates can apply to a maximum of two positions and will be considered for jobs in the order you apply. The application limit is firm and includes all TikTok and its affiliates' jobs globally. Applications will be reviewed on a rolling basis and we encourage you to apply early. About the team The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Responsibilities Translate business requirements &amp; end-to-end designs into technical implementations and responsible for building batch and real-time data warehouse; Manage data modeling design, writing and optimizing ETL jobs - collaborate with business teams to build data metrics based on data warehouse; Responsible for building and maintaining data products; Involvement in rollouts, upgrades, implementation and release of data system changes as required for streamlining of internal practices. Qualifications Undergraduate or Postgraduate currently pursuing a Degree/Master/PhD in Software Development, Computer Science, Computer Engineering, or a related technical discipline; Solid computer basic knowledge (e.g. data structure &amp; algorithms, SQL and networks); Strong coding capabilities and mastering at least one programming language (e.g. C/C++/Java/Python/Golang); Passionate about data warehouse, ETL development, data analysis and eCommerce; Good communication skills and a fast learner of new business and technology knowledge. TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https://careers.tiktok.com/legal/privacy.",https://www.jobstreet.com.sg/en/job/data-engineer-intern-tiktok-data-platform-2023-urgenthire-10431004?jobId=jobstreet-sg-job-10431004&sectionRank=182&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
182,Data Engineer #Urgent,Bayer (South East Asia) Pte Ltd,"Roles &amp; Responsibilities The Data Engineer (RAD Platform) is responsible to design and deliver comprehensive technical data platforms providing reliable and consistent data to Bayer internal and external radiology customers. He/She will also focus on Deliver the ‘Deep Customer Knowledge’ platform to the business stakeholders including visualization of data to enable customer insights and efficient business decisions and develop an APAC-specific data plan consistent with Global RAD data strategy and other global IT enablement projects. YOUR TASKS AND RESPONSIBILITIES: Hands-on with data preparation, data cleansing and data modelling on clouds (Azure, AWS, Google, etc.) Optimal/automate the ETL process, extraction, transformation, and loading of data from a wide variety of data sources using various state of the art and big data technologies Understand business capability needs and processes as they relate to IT solutions through partnering with Digital Lead, Product Managers and business Initiate and lead evaluation of new technologies, like Domino or Redshift, or new languages, like Go or React, including performing POCs and presenting results to others, with a goal of providing technical recommendations. Help the team establish and improve processes and methodologies, like SCRUM or Kanban, and/or lead piloting new ones. Implement data solutions according to design documentation using a variety of tools and programming languages, like Kafka, SQL and non-SQL databases, Scala, Go etc., and following team’s established processes and methodologies. Facilitate and participate in code reviews, retrospectives, functional and integration testing and other team activities focused on improving quality of delivery. Provide reliable estimates for large scale project. Lead collaboration with Product Owners, other engineers and data stewards within the team and across data, technical platforms and product teams on developing and aligning roadmaps, delivery dates and integration efforts. Manage external vendor to ensure the outcome to meet the expectation Consulting and requirements management regarding technology areas and process optimization in close collaboration with business process owner Planning, design and implementation of integration working packages in the platforms WHO YOU ARE: Bachelor’s degree in a Computer Science, Computer Engineering, or equivalent experience Hands-on experience in Big Data processing, data cleansing, data preparation, data engineering, AI, machine learning and deep learning implementation processes Demonstrated experience of Cloud computing, leading data modeling and architecture design efforts, including designing both logical and physical models for datasets Experience integrating data sources into a data platform, building data pipelines, and modeling large data sets in distributed databases such as Snowflake, Presto/Trino, Apache Spark/PySpark Strong problem solving, project management, collaboration &amp; leadership skills Strong communication skills with a high standard in written and spoken English",https://www.jobstreet.com.sg/en/job/data-engineer-urgent-10425778?jobId=jobstreet-sg-job-10425778&sectionRank=183&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
183,Data Engineer - TikTok - #Urgent,TikTok,"Responsibilities About TikTok TikTok is the world's leading destination for short-form mobile videos. Our mission is to capture and present the world's creativity, knowledge, and moments that matter in everyday life. TikTok empowers everyone to be a creator directly from their smartphones and is committed to building a community by encouraging users to share their passion and creative expression through their videos. TikTok has offices in Beijing, Berlin, Jakarta, London, Los Angeles, Moscow, Mumbai, Sao Paulo, Seoul, Shanghai, Singapore, and Tokyo. In 2018, TikTok was one of the most downloaded apps in the world. TikTok is available worldwide for iOS and Android. Visit tiktok.com. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Translate business requirements &amp; end to end designs into technical implementations and responsible for building batch and real-time data warehouse Manage data modeling design, writing, and optimizing ETL jobs Collaborate with the business team to building data metrics based on data warehouse Responsible for building and maintaining data products Involvement in rollouts, upgrades, implementation, and release of data system changes as required for streamlining of internal practices Qualifications: At least 5 years in software engineering and 2 years of relevant experience in data engineering Proficient in creating and maintaining complex ETL pipelines end-to-end while maintaining high reliability and security Familiar with data warehouse concept and have production experience in modeling design Familiar with at least 1 distributed computing engine (e.g. Hive, Spark, Flink) Familiar with at least 1 NoSQL database is a plus (e.g. HBase) Excellent interpersonal and communication skills with the ability to engage and manage internal and external stakeholders across all levels of seniority Strong collaboration skills with the ability to build rapport across teams and stakeholders",https://www.jobstreet.com.sg/en/job/data-engineer-tiktok-urgent-10425930?jobId=jobstreet-sg-job-10425930&sectionRank=184&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
184,Data Engineer - TikTok - #Seekbetter #Immediate,TikTok,"Responsibilities About TikTok TikTok is the world's leading destination for short-form mobile videos. Our mission is to capture and present the world's creativity, knowledge, and moments that matter in everyday life. TikTok empowers everyone to be a creator directly from their smartphones and is committed to building a community by encouraging users to share their passion and creative expression through their videos. TikTok has offices in Beijing, Berlin, Jakarta, London, Los Angeles, Moscow, Mumbai, Sao Paulo, Seoul, Shanghai, Singapore, and Tokyo. In 2018, TikTok was one of the most downloaded apps in the world. TikTok is available worldwide for iOS and Android. Visit tiktok.com. Team Introduction The mission of the Data Platform Singapore Business Partnering (DPSG BP) team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics &amp; dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you! Translate business requirements &amp; end to end designs into technical implementations and responsible for building batch and real-time data warehouse Manage data modeling design, writing, and optimizing ETL jobs Collaborate with the business team to building data metrics based on data warehouse Responsible for building and maintaining data products Involvement in rollouts, upgrades, implementation, and release of data system changes as required for streamlining of internal practices Qualifications At least 5 years in software engineering and 2 years of relevant experience in data engineering Proficient in creating and maintaining complex ETL pipelines end-to-end while maintaining high reliability and security Familiar with data warehouse concept and have production experience in modeling design Familiar with at least 1 distributed computing engine (e.g. Hive, Spark, Flink) Familiar with at least 1 NoSQL database is a plus (e.g. HBase) Excellent interpersonal and communication skills with the ability to engage and manage internal and external stakeholders across all levels of seniority Strong collaboration skills with the ability to build rapport across teams and stakeholders",https://www.jobstreet.com.sg/en/job/data-engineer-tiktok-seekbetter-immediate-10427411?jobId=jobstreet-sg-job-10427411&sectionRank=185&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
185,"Service Delivery Engineer, - (Reporting and Data Analytics) M/F - #JobsThatMatter #UrgentHire",STMicroelectronics Asia Pacific Pte Ltd (Lite ads),"Job description You will be joining the DIT organization, supporting Singapore Front-End Manufacturing operations of STMicroelectronics. In this group, you will be part of the Reporting and Data Analytics team focusing on the delivery of data, reports and dashboard-oriented solutions and liaising with manufacturing user communities in order to continuously improve their data-driven decision-making process. the role requires to have or acquire a solid understanding of the data eco system supporting our manufacturing operations in order to be able to maintain or enhance the accuracy and timeliness of the various data analytics platforms. this will provide you exposure to data management solutions such as: Applied Materials APF RTD and Reporter suite, TIBCO Spotfire, SQL DBMS (mostly Oracle), You will be involved into: Maintaining and enhancing robustness and high availability of all solutions Training to end-users for the available features or new solutions Equipping 24x7 IT ProdOps team with comprehensive materials and knowledge for 1st level of support Provide 24x7 level 2 support to ensure timely resolution of issues Profile Bachelor degree in Computer Science/Computer Engineering /Information Technology. (Data Scientist/Data engineer cursus is a plus) Experience in Unix, Linux and Windows environment Experience in web-based applications Strong in application development with MySQL/Oracle and performance optimization Strong in PL/SQL, perl/shell or Python scripting Preferable with experience in wafer fab or manufacturing Ability to adapt quickly to new technology and in-house application exposure to AMAT APF products and TIBCO Spotfire is a plus",https://www.jobstreet.com.sg/en/job/service-delivery-engineer-reporting-and-data-analytics-m-f-jobsthatmatter-urgenthire-10465830?jobId=jobstreet-sg-job-10465830&sectionRank=186&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
186,Service Delivery Engineer | (Reporting and Data Analytics) M/F #JobsThatMatter #UrgentHire #JobsThatMatter #JobsThatMatter #UrgentHire,STMicroelectronics Asia Pacific Pte Ltd (Lite ads),"Job description You will be joining the DIT organization, supporting Singapore Front-End Manufacturing operations of STMicroelectronics. In this group, you will be part of the Reporting and Data Analytics team focusing on the delivery of data, reports and dashboard-oriented solutions and liaising with manufacturing user communities in order to continuously improve their data-driven decision-making process. the role requires to have or acquire a solid understanding of the data eco system supporting our manufacturing operations in order to be able to maintain or enhance the accuracy and timeliness of the various data analytics platforms. this will provide you exposure to data management solutions such as: Applied Materials APF RTD and Reporter suite, TIBCO Spotfire, SQL DBMS (mostly Oracle), You will be involved into: Maintaining and enhancing robustness and high availability of all solutions Training to end-users for the available features or new solutions Equipping 24x7 IT ProdOps team with comprehensive materials and knowledge for 1st level of support Provide 24x7 level 2 support to ensure timely resolution of issues Profile Bachelor degree in Computer Science/Computer Engineering /Information Technology. (Data Scientist/Data engineer cursus is a plus) Experience in Unix, Linux and Windows environment Experience in web-based applications Strong in application development with MySQL/Oracle and performance optimization Strong in PL/SQL, perl/shell or Python scripting Preferable with experience in wafer fab or manufacturing Ability to adapt quickly to new technology and in-house application exposure to AMAT APF products and TIBCO Spotfire is a plus",https://www.jobstreet.com.sg/en/job/service-delivery-engineer-%7C-reporting-and-data-analytics-m-f-jobsthatmatter-urgenthire-jobsthatmatter-jobsthatmatter-urgenthire-10463213?jobId=jobstreet-sg-job-10463213&sectionRank=187&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
187,Service Delivery Engineer (Reporting and Data Analytics) M/F #Worknow #Urgent #JobsThatMatter #Seekbetter #JobsThatMatter,STMicroelectronics Asia Pacific Pte Ltd (Lite ads),"Job description You will be joining the DIT organization, supporting Singapore Front-End Manufacturing operations of STMicroelectronics. In this group, you will be part of the Reporting and Data Analytics team focusing on the delivery of data, reports and dashboard-oriented solutions and liaising with manufacturing user communities in order to continuously improve their data-driven decision-making process. the role requires to have or acquire a solid understanding of the data eco system supporting our manufacturing operations in order to be able to maintain or enhance the accuracy and timeliness of the various data analytics platforms. this will provide you exposure to data management solutions such as: Applied Materials APF RTD and Reporter suite, TIBCO Spotfire, SQL DBMS (mostly Oracle), You will be involved into: Maintaining and enhancing robustness and high availability of all solutions Training to end-users for the available features or new solutions Equipping 24x7 IT ProdOps team with comprehensive materials and knowledge for 1st level of support Provide 24x7 level 2 support to ensure timely resolution of issues Profile Bachelor degree in Computer Science/Computer Engineering /Information Technology. (Data Scientist/Data engineer cursus is a plus) Experience in Unix, Linux and Windows environment Experience in web-based applications Strong in application development with MySQL/Oracle and performance optimization Strong in PL/SQL, perl/shell or Python scripting Preferable with experience in wafer fab or manufacturing Ability to adapt quickly to new technology and in-house application exposure to AMAT APF products and TIBCO Spotfire is a plus",https://www.jobstreet.com.sg/en/job/service-delivery-engineer-reporting-and-data-analytics-m-f-worknow-urgent-jobsthatmatter-seekbetter-jobsthatmatter-10463822?jobId=jobstreet-sg-job-10463822&sectionRank=188&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
188,Service Delivery Engineer | (Reporting and Data Analytics) M/F - #Immediate #UrgentHire #Seekbetter #JobsThatMatter #Worknow,STMicroelectronics Asia Pacific Pte Ltd (Lite ads),"Job description You will be joining the DIT organization, supporting Singapore Front-End Manufacturing operations of STMicroelectronics. In this group, you will be part of the Reporting and Data Analytics team focusing on the delivery of data, reports and dashboard-oriented solutions and liaising with manufacturing user communities in order to continuously improve their data-driven decision-making process. the role requires to have or acquire a solid understanding of the data eco system supporting our manufacturing operations in order to be able to maintain or enhance the accuracy and timeliness of the various data analytics platforms. this will provide you exposure to data management solutions such as: Applied Materials APF RTD and Reporter suite, TIBCO Spotfire, SQL DBMS (mostly Oracle), You will be involved into: Maintaining and enhancing robustness and high availability of all solutions Training to end-users for the available features or new solutions Equipping 24x7 IT ProdOps team with comprehensive materials and knowledge for 1st level of support Provide 24x7 level 2 support to ensure timely resolution of issues Profile Bachelor degree in Computer Science/Computer Engineering /Information Technology. (Data Scientist/Data engineer cursus is a plus) Experience in Unix, Linux and Windows environment Experience in web-based applications Strong in application development with MySQL/Oracle and performance optimization Strong in PL/SQL, perl/shell or Python scripting Preferable with experience in wafer fab or manufacturing Ability to adapt quickly to new technology and in-house application exposure to AMAT APF products and TIBCO Spotfire is a plus",https://www.jobstreet.com.sg/en/job/service-delivery-engineer-%7C-reporting-and-data-analytics-m-f-immediate-urgenthire-seekbetter-jobsthatmatter-worknow-10466258?jobId=jobstreet-sg-job-10466258&sectionRank=189&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
189,Service Delivery Engineer (Reporting and Data Analytics) M/F #JobsThatMatter #WorkNow #JobsThatMatter - | #LetsGoToWork,STMicroelectronics Asia Pacific Pte Ltd (Lite ads),"Job description You will be joining the DIT organization, supporting Singapore Front-End Manufacturing operations of STMicroelectronics. In this group, you will be part of the Reporting and Data Analytics team focusing on the delivery of data, reports and dashboard-oriented solutions and liaising with manufacturing user communities in order to continuously improve their data-driven decision-making process. the role requires to have or acquire a solid understanding of the data eco system supporting our manufacturing operations in order to be able to maintain or enhance the accuracy and timeliness of the various data analytics platforms. this will provide you exposure to data management solutions such as: Applied Materials APF RTD and Reporter suite, TIBCO Spotfire, SQL DBMS (mostly Oracle), You will be involved into: Maintaining and enhancing robustness and high availability of all solutions Training to end-users for the available features or new solutions Equipping 24x7 IT ProdOps team with comprehensive materials and knowledge for 1st level of support Provide 24x7 level 2 support to ensure timely resolution of issues Profile Bachelor degree in Computer Science/Computer Engineering /Information Technology. (Data Scientist/Data engineer cursus is a plus) Experience in Unix, Linux and Windows environment Experience in web-based applications Strong in application development with MySQL/Oracle and performance optimization Strong in PL/SQL, perl/shell or Python scripting Preferable with experience in wafer fab or manufacturing Ability to adapt quickly to new technology and in-house application exposure to AMAT APF products and TIBCO Spotfire is a plus",https://www.jobstreet.com.sg/en/job/service-delivery-engineer-reporting-and-data-analytics-m-f-jobsthatmatter-worknow-jobsthatmatter-%7C-letsgotowork-10461532?jobId=jobstreet-sg-job-10461532&sectionRank=190&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
190,Service Delivery Engineer | (Reporting and Data Analytics) [M/F],STMicroelectronics Asia Pacific Pte Ltd (Lite ads),"Job description You will be joining the DIT organization, supporting Singapore Front-End Manufacturing operations of STMicroelectronics. In this group, you will be part of the Reporting and Data Analytics team focusing on the delivery of data, reports and dashboard-oriented solutions and liaising with manufacturing user communities in order to continuously improve their data-driven decision-making process. the role requires to have or acquire a solid understanding of the data eco system supporting our manufacturing operations in order to be able to maintain or enhance the accuracy and timeliness of the various data analytics platforms. this will provide you exposure to data management solutions such as: Applied Materials APF RTD and Reporter suite, TIBCO Spotfire, SQL DBMS (mostly Oracle), You will be involved into: Maintaining and enhancing robustness and high availability of all solutions Training to end-users for the available features or new solutions Equipping 24x7 IT ProdOps team with comprehensive materials and knowledge for 1st level of support Provide 24x7 level 2 support to ensure timely resolution of issues Profile Bachelor degree in Computer Science/Computer Engineering /Information Technology. (Data Scientist/Data engineer cursus is a plus) Experience in Unix, Linux and Windows environment Experience in web-based applications Strong in application development with MySQL/Oracle and performance optimization Strong in PL/SQL, perl/shell or Python scripting Preferable with experience in wafer fab or manufacturing Ability to adapt quickly to new technology and in-house application exposure to AMAT APF products and TIBCO Spotfire is a plus",https://www.jobstreet.com.sg/en/job/service-delivery-engineer-%7C-reporting-and-data-analytics-%5Bm-f%5D-10455133?jobId=jobstreet-sg-job-10455133&sectionRank=191&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
191,Service Delivery Engineer - (Reporting and Data Analytics) M/F #JobsThatMatter #WorkNow #UrgentHire #JobsThatMatter,STMicroelectronics Asia Pacific Pte Ltd (Lite ads),"Job description You will be joining the DIT organization, supporting Singapore Front-End Manufacturing operations of STMicroelectronics. In this group, you will be part of the Reporting and Data Analytics team focusing on the delivery of data, reports and dashboard-oriented solutions and liaising with manufacturing user communities in order to continuously improve their data-driven decision-making process. the role requires to have or acquire a solid understanding of the data eco system supporting our manufacturing operations in order to be able to maintain or enhance the accuracy and timeliness of the various data analytics platforms. this will provide you exposure to data management solutions such as: Applied Materials APF RTD and Reporter suite, TIBCO Spotfire, SQL DBMS (mostly Oracle), You will be involved into: Maintaining and enhancing robustness and high availability of all solutions Training to end-users for the available features or new solutions Equipping 24x7 IT ProdOps team with comprehensive materials and knowledge for 1st level of support Provide 24x7 level 2 support to ensure timely resolution of issues Profile Bachelor degree in Computer Science/Computer Engineering /Information Technology. (Data Scientist/Data engineer cursus is a plus) Experience in Unix, Linux and Windows environment Experience in web-based applications Strong in application development with MySQL/Oracle and performance optimization Strong in PL/SQL, perl/shell or Python scripting Preferable with experience in wafer fab or manufacturing Ability to adapt quickly to new technology and in-house application exposure to AMAT APF products and TIBCO Spotfire is a plus",https://www.jobstreet.com.sg/en/job/service-delivery-engineer-reporting-and-data-analytics-m-f-jobsthatmatter-worknow-urgenthire-jobsthatmatter-10447738?jobId=jobstreet-sg-job-10447738&sectionRank=192&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
192,"Aon Early Careers Graduate Programme, Singapore - Innovation &amp; Analytics",Aon Hewitt,"ob Description Aon Early Careers Graduate Programme, Singapore - Innovation &amp; Analytics Make a career out of better decisions Join Aon as a graduate and propel your career with us. Develop your professional skills and build strong relationships with clients and colleagues alike. Our 24-month Graduate Programme is designed to develop high performers so they can grow and potentially lead our business in the future.​ Innovation &amp; Analytics ​Track​ In this graduate programme, you will be exposed to all aspects of our business through four job rotations (6-month cycle) across different business areas, participate in Agile scrum-based projects and have the opportunity to work with key stakeholders across the Aon business, gaining knowledge and insight into our world of data and analytics. There are 3 roles in our Innovation &amp; Analytics Track: In the Application Developer role, you will collaborate with the brightest minds in our innovation center to build high-performing applications that deliver insightful analytics to our users. You should be familiar with one or more of the following languages C#, JavaScript, Python. Knowledge in SQL, CSS, ReactJS, Angular would be advantageous. In the Data Engineer role, you will be a part of a high-performing team to make data accessible for our analytics teams. You will be building systems that collect, manage, and convert raw data into usable information. You need to have the ability to code in Python / Scala and SQL to perform data operations. Good knowledge of databases, data structures is a must. Knowledge of Spark would be advantageous. In the Data Analyst role, you will act as a champion for Aon’s suite of analytical tools and help business leaders drive performance by supporting the delivery of analytics solutions around client data. Having technical knowledge of SQL, Python/R, and Microsoft Office is a must. Knowledge in visualisation software such as Tableau /PowerBI is a big plus. Your Development As an Aon Graduate, you will be enrolled onto our Launch Programme when you join. This development programme is built around 3 core elements : Business Learning – on the job learning and experiences giving you the opportunity to develop your knowledge and understanding of the team and Graduate Track you have joined Centralised Learning – Graduates complete an Aon Induction, webinars, business skills training and workshops; all designed to help you develop your knowledge of Aon, build your confidence and your network across our business Professional Qualifications – we want you to be as successful as possible, so we’ll fully support your study towards the attainment of industry qualifications/certificates. You will identify the qualification/certificate you wish to pursue together with your career mentor, and we will support you with course fees, course materials and paid study leave. Your Career beyond our Graduate Programme We believe that no individual person or piece of Aon is stronger than the whole. As a firm, Aon is committed to creating a work environment where every colleague feels safe and comfortable being their authentic self, experiences a sense of belonging, is empowered to reach their full professional potential and is valued for the unique perspectives and talents they bring. Upon successful completion of your graduate program, we’ll work together to find you a landing role within our organisation. You’ll continue to receive support at Aon as you continue your career with us. What are we looking for? Motivation and ambition – you will need to be able to articulate why you want to start your career in the track you have selected. Commercial awareness – this helps us to provide support and advice to our clients with clarity. You must be numerically confident and have the desire and ability to excel in a competitive environment where communication is key. We're looking for collaborators, critical thinkers, problem solvers, team players, effective communicators, relationship builders and future leaders. Building relationships is at the heart of what we do and you'll need to show that you can work collaboratively to develop solutions for our clients. How we support our colleagues In addition to our comprehensive benefits package, we encourage a diverse workforce. Plus, our agile, inclusive environment allows you to manage your wellbeing and work/life balance, ensuring you can be your best self at Aon. Furthermore, all colleagues enjoy two “Global Wellbeing Days” each year, encouraging you to take time to focus on yourself. We offer a variety of working style solutions, but we also recognise that flexibility goes beyond just the place of work... and we are all for it. We call this Smart Working! Our continuous learning culture inspires and equips you to learn, share and grow, helping you achieve your fullest potential. As a result, at Aon, you are more connected, more relevant, and more valued. We provide individuals with disabilities reasonable accommodations to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment in accordance with applicable law. Aon values an innovative, diverse workplace where all colleagues feel empowered to be their authentic selves. Aon is proud to be an equal opportunity workplace.",https://www.jobstreet.com.sg/en/job/aon-early-careers-graduate-programme-singapore-innovation-analytics-10457820?jobId=jobstreet-sg-job-10457820&sectionRank=193&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
193,"Head, Aspire Digital COE, - (2200018249)*'#JobsThatMatter",ALLEGIS GLOBAL SOLUTIONS (SINGAPORE) PTE. LTD,"The Role Responsibilities The Head of Aspire Digital COE has been created to transform Finance into a digital forward-looking organisation. The role will take full end-to-end ownership (i.e. both onshore and offshore) of the Finance Digital delivery The role will be responsible for global teams including Singapore, Global Finance Service (Poland &amp; India). They will interface extensively with Aspire MT, Global Process Owners &amp; Senior Finance Management at Group level, with Country, Segment, Function, and Regional CFOs, and the heads of the GFS centres and work closely with the Aspire MT Team to deliver the data science &amp; analytic capability. There is an ongoing operating model and technology programme underway within Finance (the Aspire Programme). This role will work closely with this programme, shaping the future design of the Digital &amp; Business Science landscape Strategy Together with the Global Head, Aspire Analytics &amp; P2P Change assist the evolution of the digital &amp; business science strategy for the function, incorporating business, economic and regulatory change with clear alignment to the Bank’s strategy Work with the Aspire MT to highlight and resolve trade-offs between competing business priorities and drive standardisation in the approach Leadership &amp; Governance Lead the Aspire Digital agenda Take the lead in identifying and driving initiatives designed to become digital Partner with globally accountable process owners driving global standards for analytics Standardised, centralised digital &amp; business science capability Execution, Process and Alignment Improve business insights, productivity and efficiency by driving the digital &amp; business science agenda for the function to deliver scorecard. Lead in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance. Analyse source data systems and drive best practices in source teams Implement data ingestion routines using best practices in data modelling, ETL/ELT processes Sign off on gathered business and functional requirements and ensuring they are translated into requirements that are robust, scalable and operable solutions that work well within the data architecture pan Finance Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers. Evaluate and make decisions around the use of new or existing software products and tools Lead and drive the building of large database models for Balance Sheet, PNL, Cost analytics and ratios To design data reflection optimization using partitions, sorting and virtualized views accelerate query times by reducing query planning and reading times Lead both the visualisation and data teams from multiple locations to ensure they are working in harmony and towards the same common goal Partner with Workstream Leads and GPOs to deliver and determine appropriate ways to navigate complex issues in the digital &amp; business science domain Drive the ideation, design and complex implementation of the frameworks for digitalizing SCB’s finance processes. This includes Working with and across functions to define process end to end, outline digital workflow solutions and linkage to Finance legacy systems and ability to navigate a complex business &amp; highly matrixed organization Build and manage relationships with key stakeholders locally, regionally and globally Foster strong internal and external relationships to ensure strong teaming, develop team skills and improve the overall success of the project. Act as advisor to the transformation initiatives in Finance by sharing experience and ideas on what the art of possible is to transform SCB’s Finance function Work collaboratively with other teams within and outside the Finance Functions to connect dots and integrate initiatives as needed Be a change ambassador across the Global Finance network, infusing learning, creating forum to share best practices and develop skills and capabilities in process transformations Maintain intellectual curiosity to understand advancements in technology and innovations which are happening across digital, analytics, robotics and artificial intelligence to influence SCB Finance Function direction Become a trusted advisor to the Journeys. Aspire MT, GPOs, FinOps MT and Global Finance partners and be able to support issues, communication and influence outcomes. Risk Management Reinforce an effective and exemplary risk and control culture and further strengthen the control environment, ensure that specialist knowledge and skills are assigned to relevant needs. Act to minimize operational loss and audit failures and take proactive measures to respond to matters arising and identify and manage forward looking risks. Work with relevant teams to identify and mitigate identified operational risks in their areas. Through assignment of direct and indirect reports, establish and maintain an appropriate framework and procedures for monitoring, identifying, measuring, assessing, reporting and managing compliance, regulatory, financial crime, operational and reputational risks. People and Talent Ensure the Finance organisation has appropriate capabilities and capacity to deliver scorecard priorities with potential to grow with needs of the Bank over time. Lead on the drive for up-tiering and up-skilling GFS and applicable countries in order to develop high performing teams for the future; inspire and engage people Business leadership / defining and agreeing solutions to drive effectiveness and efficiency with Finance and Business / Front Office management Support cross-Bank and finance talent development through thoughtful job design, selection of people managers and providing stretch opportunities for individuals to learn in role. Employ, engage and retain high quality people, with succession planning for critical roles. Responsibility to review team structure/capacity plans. Set and monitor job descriptions and objectives for direct reports and provide feedback and rewards in line with their performance against those responsibilities and objectives. Regulatory &amp; Business conduct Display exemplary conduct and live by the Group’s Values and Code of Conduct. Take personal responsibility for embedding the highest standards of ethics, including regulatory and business conduct, across Standard Chartered Bank. This includes understanding and ensuring compliance with, in letter and spirit, all applicable laws, regulations, guidelines and the Group Code of Conduct. Support the Finance &amp; Transformation team to achieve the outcomes set out in the Bank’s Conduct Principles: Fair Outcomes for Clients; Effective Operation of Financial Markets; Financial Crime Prevention; The Right Environment. Effectively and collaboratively identify, escalate, mitigate and resolve risk, conduct and compliance matters. Key Stakeholders Aspire Programme Director &amp; GCFO Strategic Initiatives Aspire MT Global Head of Finance Operations Finance Operations Management Team Deputy Group CFO Regional CFOs Country and Product CFOs Support function and business COOs Regional Finance Heads Group &amp; Country Finance Aspire Design Authority’ T&amp;I Business / Front Office Our Ideal Candidate 15+ years Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, and extracting value from large datasets. Experience in the full data project life cycles around large-scale, high-volume, and high-performance data structures for analytics and in software and data architecture in financial institution Experience with Big Data Platforms / Ecosystem (Hadoop, MongoDB, Kafka) and integration strategies for automated data consumption Experience across the full analytics stack from data storage, processing, 3rd party data enhancements, analytical techniques, and presentation layer Strong leadership and interpersonal skills in networking and influencing decisions taken in the business and in T&amp;I teams. Excellent business judgment, operational control management and risk assessment. Expert with data platforms, reporting products, hands-on, obsessed with using data to drive business decisions and passionate about building compelling and engaging visualizations Role Specific Technical Competencies Data Engineer Business Intelligence &amp; Big Data Platforms Data Analytics",https://www.jobstreet.com.sg/en/job/head-aspire-digital-coe-2200018249-*%27-jobsthatmatter-10448137?jobId=jobstreet-sg-job-10448137&sectionRank=194&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
194,Service Delivery Engineer | (Reporting and Data Analytics) [M/F]#UrgentHire -- #LetsGoToWork.,STMicroelectronics Asia Pacific Pte Ltd (Lite ads),"Job description You will be joining the DIT organization, supporting Singapore Front-End Manufacturing operations of STMicroelectronics. In this group, you will be part of the Reporting and Data Analytics team focusing on the delivery of data, reports and dashboard-oriented solutions and liaising with manufacturing user communities in order to continuously improve their data-driven decision-making process. the role requires to have or acquire a solid understanding of the data eco system supporting our manufacturing operations in order to be able to maintain or enhance the accuracy and timeliness of the various data analytics platforms. this will provide you exposure to data management solutions such as: Applied Materials APF RTD and Reporter suite, TIBCO Spotfire, SQL DBMS (mostly Oracle), You will be involved into: Maintaining and enhancing robustness and high availability of all solutions Training to end-users for the available features or new solutions Equipping 24x7 IT ProdOps team with comprehensive materials and knowledge for 1st level of support Provide 24x7 level 2 support to ensure timely resolution of issues Profile Bachelor degree in Computer Science/Computer Engineering /Information Technology. (Data Scientist/Data engineer cursus is a plus) Experience in Unix, Linux and Windows environment Experience in web-based applications Strong in application development with MySQL/Oracle and performance optimization Strong in PL/SQL, perl/shell or Python scripting Preferable with experience in wafer fab or manufacturing Ability to adapt quickly to new technology and in-house application exposure to AMAT APF products and TIBCO Spotfire is a plus",https://www.jobstreet.com.sg/en/job/service-delivery-engineer-%7C-reporting-and-data-analytics-%5Bm-f%5D-urgenthire-letsgotowork.-10447554?jobId=jobstreet-sg-job-10447554&sectionRank=195&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
195,"Head, Aspire Digital COE - (2200018249).' *.`#JobsThatMatter",ALLEGIS GLOBAL SOLUTIONS (SINGAPORE) PTE. LTD,"The Role Responsibilities The Head of Aspire Digital COE has been created to transform Finance into a digital forward-looking organisation. The role will take full end-to-end ownership (i.e. both onshore and offshore) of the Finance Digital delivery The role will be responsible for global teams including Singapore, Global Finance Service (Poland &amp; India). They will interface extensively with Aspire MT, Global Process Owners &amp; Senior Finance Management at Group level, with Country, Segment, Function, and Regional CFOs, and the heads of the GFS centres and work closely with the Aspire MT Team to deliver the data science &amp; analytic capability. There is an ongoing operating model and technology programme underway within Finance (the Aspire Programme). This role will work closely with this programme, shaping the future design of the Digital &amp; Business Science landscape Strategy Together with the Global Head, Aspire Analytics &amp; P2P Change assist the evolution of the digital &amp; business science strategy for the function, incorporating business, economic and regulatory change with clear alignment to the Bank’s strategy Work with the Aspire MT to highlight and resolve trade-offs between competing business priorities and drive standardisation in the approach Leadership &amp; Governance Lead the Aspire Digital agenda Take the lead in identifying and driving initiatives designed to become digital Partner with globally accountable process owners driving global standards for analytics Standardised, centralised digital &amp; business science capability Execution, Process and Alignment Improve business insights, productivity and efficiency by driving the digital &amp; business science agenda for the function to deliver scorecard. Lead in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance. Analyse source data systems and drive best practices in source teams Implement data ingestion routines using best practices in data modelling, ETL/ELT processes Sign off on gathered business and functional requirements and ensuring they are translated into requirements that are robust, scalable and operable solutions that work well within the data architecture pan Finance Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers. Evaluate and make decisions around the use of new or existing software products and tools Lead and drive the building of large database models for Balance Sheet, PNL, Cost analytics and ratios To design data reflection optimization using partitions, sorting and virtualized views accelerate query times by reducing query planning and reading times Lead both the visualisation and data teams from multiple locations to ensure they are working in harmony and towards the same common goal Partner with Workstream Leads and GPOs to deliver and determine appropriate ways to navigate complex issues in the digital &amp; business science domain Drive the ideation, design and complex implementation of the frameworks for digitalizing SCB’s finance processes. This includes Working with and across functions to define process end to end, outline digital workflow solutions and linkage to Finance legacy systems and ability to navigate a complex business &amp; highly matrixed organization Build and manage relationships with key stakeholders locally, regionally and globally Foster strong internal and external relationships to ensure strong teaming, develop team skills and improve the overall success of the project. Act as advisor to the transformation initiatives in Finance by sharing experience and ideas on what the art of possible is to transform SCB’s Finance function Work collaboratively with other teams within and outside the Finance Functions to connect dots and integrate initiatives as needed Be a change ambassador across the Global Finance network, infusing learning, creating forum to share best practices and develop skills and capabilities in process transformations Maintain intellectual curiosity to understand advancements in technology and innovations which are happening across digital, analytics, robotics and artificial intelligence to influence SCB Finance Function direction Become a trusted advisor to the Journeys. Aspire MT, GPOs, FinOps MT and Global Finance partners and be able to support issues, communication and influence outcomes. Risk Management Reinforce an effective and exemplary risk and control culture and further strengthen the control environment, ensure that specialist knowledge and skills are assigned to relevant needs. Act to minimize operational loss and audit failures and take proactive measures to respond to matters arising and identify and manage forward looking risks. Work with relevant teams to identify and mitigate identified operational risks in their areas. Through assignment of direct and indirect reports, establish and maintain an appropriate framework and procedures for monitoring, identifying, measuring, assessing, reporting and managing compliance, regulatory, financial crime, operational and reputational risks. People and Talent Ensure the Finance organisation has appropriate capabilities and capacity to deliver scorecard priorities with potential to grow with needs of the Bank over time. Lead on the drive for up-tiering and up-skilling GFS and applicable countries in order to develop high performing teams for the future; inspire and engage people Business leadership / defining and agreeing solutions to drive effectiveness and efficiency with Finance and Business / Front Office management Support cross-Bank and finance talent development through thoughtful job design, selection of people managers and providing stretch opportunities for individuals to learn in role. Employ, engage and retain high quality people, with succession planning for critical roles. Responsibility to review team structure/capacity plans. Set and monitor job descriptions and objectives for direct reports and provide feedback and rewards in line with their performance against those responsibilities and objectives. Regulatory &amp; Business conduct Display exemplary conduct and live by the Group’s Values and Code of Conduct. Take personal responsibility for embedding the highest standards of ethics, including regulatory and business conduct, across Standard Chartered Bank. This includes understanding and ensuring compliance with, in letter and spirit, all applicable laws, regulations, guidelines and the Group Code of Conduct. Support the Finance &amp; Transformation team to achieve the outcomes set out in the Bank’s Conduct Principles: Fair Outcomes for Clients; Effective Operation of Financial Markets; Financial Crime Prevention; The Right Environment. Effectively and collaboratively identify, escalate, mitigate and resolve risk, conduct and compliance matters. Key Stakeholders Aspire Programme Director &amp; GCFO Strategic Initiatives Aspire MT Global Head of Finance Operations Finance Operations Management Team Deputy Group CFO Regional CFOs Country and Product CFOs Support function and business COOs Regional Finance Heads Group &amp; Country Finance Aspire Design Authority’ T&amp;I Business / Front Office Our Ideal Candidate 15+ years Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, and extracting value from large datasets. Experience in the full data project life cycles around large-scale, high-volume, and high-performance data structures for analytics and in software and data architecture in financial institution Experience with Big Data Platforms / Ecosystem (Hadoop, MongoDB, Kafka) and integration strategies for automated data consumption Experience across the full analytics stack from data storage, processing, 3rd party data enhancements, analytical techniques, and presentation layer Strong leadership and interpersonal skills in networking and influencing decisions taken in the business and in T&amp;I teams. Excellent business judgment, operational control management and risk assessment. Expert with data platforms, reporting products, hands-on, obsessed with using data to drive business decisions and passionate about building compelling and engaging visualizations Role Specific Technical Competencies Data Engineer Business Intelligence &amp; Big Data Platforms Data Analytics",https://www.jobstreet.com.sg/en/job/head-aspire-digital-coe-2200018249-.%27-*.-jobsthatmatter-10434635?jobId=jobstreet-sg-job-10434635&sectionRank=196&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
196,"Head, Aspire Digital COE - (2200018249).' *.#Worknow",ALLEGIS GLOBAL SOLUTIONS (SINGAPORE) PTE. LTD,"The Role Responsibilities The Head of Aspire Digital COE has been created to transform Finance into a digital forward-looking organisation. The role will take full end-to-end ownership (i.e. both onshore and offshore) of the Finance Digital delivery The role will be responsible for global teams including Singapore, Global Finance Service (Poland &amp; India). They will interface extensively with Aspire MT, Global Process Owners &amp; Senior Finance Management at Group level, with Country, Segment, Function, and Regional CFOs, and the heads of the GFS centres and work closely with the Aspire MT Team to deliver the data science &amp; analytic capability. There is an ongoing operating model and technology programme underway within Finance (the Aspire Programme). This role will work closely with this programme, shaping the future design of the Digital &amp; Business Science landscape Strategy Together with the Global Head, Aspire Analytics &amp; P2P Change assist the evolution of the digital &amp; business science strategy for the function, incorporating business, economic and regulatory change with clear alignment to the Bank’s strategy Work with the Aspire MT to highlight and resolve trade-offs between competing business priorities and drive standardisation in the approach Leadership &amp; Governance Lead the Aspire Digital agenda Take the lead in identifying and driving initiatives designed to become digital Partner with globally accountable process owners driving global standards for analytics Standardised, centralised digital &amp; business science capability Execution, Process and Alignment Improve business insights, productivity and efficiency by driving the digital &amp; business science agenda for the function to deliver scorecard. Lead in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance. Analyse source data systems and drive best practices in source teams Implement data ingestion routines using best practices in data modelling, ETL/ELT processes Sign off on gathered business and functional requirements and ensuring they are translated into requirements that are robust, scalable and operable solutions that work well within the data architecture pan Finance Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers. Evaluate and make decisions around the use of new or existing software products and tools Lead and drive the building of large database models for Balance Sheet, PNL, Cost analytics and ratios To design data reflection optimization using partitions, sorting and virtualized views accelerate query times by reducing query planning and reading times Lead both the visualisation and data teams from multiple locations to ensure they are working in harmony and towards the same common goal Partner with Workstream Leads and GPOs to deliver and determine appropriate ways to navigate complex issues in the digital &amp; business science domain Drive the ideation, design and complex implementation of the frameworks for digitalizing SCB’s finance processes. This includes Working with and across functions to define process end to end, outline digital workflow solutions and linkage to Finance legacy systems and ability to navigate a complex business &amp; highly matrixed organization Build and manage relationships with key stakeholders locally, regionally and globally Foster strong internal and external relationships to ensure strong teaming, develop team skills and improve the overall success of the project. Act as advisor to the transformation initiatives in Finance by sharing experience and ideas on what the art of possible is to transform SCB’s Finance function Work collaboratively with other teams within and outside the Finance Functions to connect dots and integrate initiatives as needed Be a change ambassador across the Global Finance network, infusing learning, creating forum to share best practices and develop skills and capabilities in process transformations Maintain intellectual curiosity to understand advancements in technology and innovations which are happening across digital, analytics, robotics and artificial intelligence to influence SCB Finance Function direction Become a trusted advisor to the Journeys. Aspire MT, GPOs, FinOps MT and Global Finance partners and be able to support issues, communication and influence outcomes. Risk Management Reinforce an effective and exemplary risk and control culture and further strengthen the control environment, ensure that specialist knowledge and skills are assigned to relevant needs. Act to minimize operational loss and audit failures and take proactive measures to respond to matters arising and identify and manage forward looking risks. Work with relevant teams to identify and mitigate identified operational risks in their areas. Through assignment of direct and indirect reports, establish and maintain an appropriate framework and procedures for monitoring, identifying, measuring, assessing, reporting and managing compliance, regulatory, financial crime, operational and reputational risks. People and Talent Ensure the Finance organisation has appropriate capabilities and capacity to deliver scorecard priorities with potential to grow with needs of the Bank over time. Lead on the drive for up-tiering and up-skilling GFS and applicable countries in order to develop high performing teams for the future; inspire and engage people Business leadership / defining and agreeing solutions to drive effectiveness and efficiency with Finance and Business / Front Office management Support cross-Bank and finance talent development through thoughtful job design, selection of people managers and providing stretch opportunities for individuals to learn in role. Employ, engage and retain high quality people, with succession planning for critical roles. Responsibility to review team structure/capacity plans. Set and monitor job descriptions and objectives for direct reports and provide feedback and rewards in line with their performance against those responsibilities and objectives. Regulatory &amp; Business conduct Display exemplary conduct and live by the Group’s Values and Code of Conduct. Take personal responsibility for embedding the highest standards of ethics, including regulatory and business conduct, across Standard Chartered Bank. This includes understanding and ensuring compliance with, in letter and spirit, all applicable laws, regulations, guidelines and the Group Code of Conduct. Support the Finance &amp; Transformation team to achieve the outcomes set out in the Bank’s Conduct Principles: Fair Outcomes for Clients; Effective Operation of Financial Markets; Financial Crime Prevention; The Right Environment. Effectively and collaboratively identify, escalate, mitigate and resolve risk, conduct and compliance matters. Key Stakeholders Aspire Programme Director &amp; GCFO Strategic Initiatives Aspire MT Global Head of Finance Operations Finance Operations Management Team Deputy Group CFO Regional CFOs Country and Product CFOs Support function and business COOs Regional Finance Heads Group &amp; Country Finance Aspire Design Authority’ T&amp;I Business / Front Office Our Ideal Candidate 15+ years Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, and extracting value from large datasets. Experience in the full data project life cycles around large-scale, high-volume, and high-performance data structures for analytics and in software and data architecture in financial institution Experience with Big Data Platforms / Ecosystem (Hadoop, MongoDB, Kafka) and integration strategies for automated data consumption Experience across the full analytics stack from data storage, processing, 3rd party data enhancements, analytical techniques, and presentation layer Strong leadership and interpersonal skills in networking and influencing decisions taken in the business and in T&amp;I teams. Excellent business judgment, operational control management and risk assessment. Expert with data platforms, reporting products, hands-on, obsessed with using data to drive business decisions and passionate about building compelling and engaging visualizations Role Specific Technical Competencies Data Engineer Business Intelligence &amp; Big Data Platforms Data Analytics",https://www.jobstreet.com.sg/en/job/head-aspire-digital-coe-2200018249-.%27-*.-worknow-10434643?jobId=jobstreet-sg-job-10434643&sectionRank=197&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
197,"Head, Aspire Digital COE, - (2200018249)' #Worknow #UrgentHire #Worknow",ALLEGIS GLOBAL SOLUTIONS (SINGAPORE) PTE. LTD,"The Role Responsibilities The Head of Aspire Digital COE has been created to transform Finance into a digital forward-looking organisation. The role will take full end-to-end ownership (i.e. both onshore and offshore) of the Finance Digital delivery The role will be responsible for global teams including Singapore, Global Finance Service (Poland &amp; India). They will interface extensively with Aspire MT, Global Process Owners &amp; Senior Finance Management at Group level, with Country, Segment, Function, and Regional CFOs, and the heads of the GFS centres and work closely with the Aspire MT Team to deliver the data science &amp; analytic capability. There is an ongoing operating model and technology programme underway within Finance (the Aspire Programme). This role will work closely with this programme, shaping the future design of the Digital &amp; Business Science landscape Strategy Together with the Global Head, Aspire Analytics &amp; P2P Change assist the evolution of the digital &amp; business science strategy for the function, incorporating business, economic and regulatory change with clear alignment to the Bank’s strategy Work with the Aspire MT to highlight and resolve trade-offs between competing business priorities and drive standardisation in the approach Leadership &amp; Governance Lead the Aspire Digital agenda Take the lead in identifying and driving initiatives designed to become digital Partner with globally accountable process owners driving global standards for analytics Standardised, centralised digital &amp; business science capability Execution, Process and Alignment Improve business insights, productivity and efficiency by driving the digital &amp; business science agenda for the function to deliver scorecard. Lead in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance. Analyse source data systems and drive best practices in source teams Implement data ingestion routines using best practices in data modelling, ETL/ELT processes Sign off on gathered business and functional requirements and ensuring they are translated into requirements that are robust, scalable and operable solutions that work well within the data architecture pan Finance Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers. Evaluate and make decisions around the use of new or existing software products and tools Lead and drive the building of large database models for Balance Sheet, PNL, Cost analytics and ratios To design data reflection optimization using partitions, sorting and virtualized views accelerate query times by reducing query planning and reading times Lead both the visualisation and data teams from multiple locations to ensure they are working in harmony and towards the same common goal Partner with Workstream Leads and GPOs to deliver and determine appropriate ways to navigate complex issues in the digital &amp; business science domain Drive the ideation, design and complex implementation of the frameworks for digitalizing SCB’s finance processes. This includes Working with and across functions to define process end to end, outline digital workflow solutions and linkage to Finance legacy systems and ability to navigate a complex business &amp; highly matrixed organization Build and manage relationships with key stakeholders locally, regionally and globally Foster strong internal and external relationships to ensure strong teaming, develop team skills and improve the overall success of the project. Act as advisor to the transformation initiatives in Finance by sharing experience and ideas on what the art of possible is to transform SCB’s Finance function Work collaboratively with other teams within and outside the Finance Functions to connect dots and integrate initiatives as needed Be a change ambassador across the Global Finance network, infusing learning, creating forum to share best practices and develop skills and capabilities in process transformations Maintain intellectual curiosity to understand advancements in technology and innovations which are happening across digital, analytics, robotics and artificial intelligence to influence SCB Finance Function direction Become a trusted advisor to the Journeys. Aspire MT, GPOs, FinOps MT and Global Finance partners and be able to support issues, communication and influence outcomes. Risk Management Reinforce an effective and exemplary risk and control culture and further strengthen the control environment, ensure that specialist knowledge and skills are assigned to relevant needs. Act to minimize operational loss and audit failures and take proactive measures to respond to matters arising and identify and manage forward looking risks. Work with relevant teams to identify and mitigate identified operational risks in their areas. Through assignment of direct and indirect reports, establish and maintain an appropriate framework and procedures for monitoring, identifying, measuring, assessing, reporting and managing compliance, regulatory, financial crime, operational and reputational risks. People and Talent Ensure the Finance organisation has appropriate capabilities and capacity to deliver scorecard priorities with potential to grow with needs of the Bank over time. Lead on the drive for up-tiering and up-skilling GFS and applicable countries in order to develop high performing teams for the future; inspire and engage people Business leadership / defining and agreeing solutions to drive effectiveness and efficiency with Finance and Business / Front Office management Support cross-Bank and finance talent development through thoughtful job design, selection of people managers and providing stretch opportunities for individuals to learn in role. Employ, engage and retain high quality people, with succession planning for critical roles. Responsibility to review team structure/capacity plans. Set and monitor job descriptions and objectives for direct reports and provide feedback and rewards in line with their performance against those responsibilities and objectives. Regulatory &amp; Business conduct Display exemplary conduct and live by the Group’s Values and Code of Conduct. Take personal responsibility for embedding the highest standards of ethics, including regulatory and business conduct, across Standard Chartered Bank. This includes understanding and ensuring compliance with, in letter and spirit, all applicable laws, regulations, guidelines and the Group Code of Conduct. Support the Finance &amp; Transformation team to achieve the outcomes set out in the Bank’s Conduct Principles: Fair Outcomes for Clients; Effective Operation of Financial Markets; Financial Crime Prevention; The Right Environment. Effectively and collaboratively identify, escalate, mitigate and resolve risk, conduct and compliance matters. Key Stakeholders Aspire Programme Director &amp; GCFO Strategic Initiatives Aspire MT Global Head of Finance Operations Finance Operations Management Team Deputy Group CFO Regional CFOs Country and Product CFOs Support function and business COOs Regional Finance Heads Group &amp; Country Finance Aspire Design Authority’ T&amp;I Business / Front Office Our Ideal Candidate 15+ years Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, and extracting value from large datasets. Experience in the full data project life cycles around large-scale, high-volume, and high-performance data structures for analytics and in software and data architecture in financial institution Experience with Big Data Platforms / Ecosystem (Hadoop, MongoDB, Kafka) and integration strategies for automated data consumption Experience across the full analytics stack from data storage, processing, 3rd party data enhancements, analytical techniques, and presentation layer Strong leadership and interpersonal skills in networking and influencing decisions taken in the business and in T&amp;I teams. Excellent business judgment, operational control management and risk assessment. Expert with data platforms, reporting products, hands-on, obsessed with using data to drive business decisions and passionate about building compelling and engaging visualizations Role Specific Technical Competencies Data Engineer Business Intelligence &amp; Big Data Platforms Data Analytics",https://www.jobstreet.com.sg/en/job/head-aspire-digital-coe-2200018249-%27-worknow-urgenthire-worknow-10432302?jobId=jobstreet-sg-job-10432302&sectionRank=198&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
198,Data Engineer - ref: CBL,ST Engineering Advanced Networks &amp; Sensors Pte Ltd,"Job Overview The Data Engineer supports the design, build, implementation and maintenance of Big Data processing systems to collect, parse and process large datasets and transform them into useful information and insights. The Data Engineer focuses on sourcing of open source technologies, data cleaning and data transformation. Job Responsibilities Identify suitable data structures based on business needs to ensure availability and accessibility of data. Determine technical system requirements based on data needs. Keep abreast of latest technologies and products in open source technologies, database and data processing software. Develop codes and scripts to process structured and unstructured data in real-time from a variety of data sources. Consolidate and create data storage solutions for storage and retrieval of information. Assist in the integration of data systems with existing infrastructure. Requirements Master / Degree in Computer Science, Computer Engineering, Information Systems, Information Engineering, or equivalent At least 2 years of data engineering experience, fresh graduates are welcome to apply Experience in open source technologies, data cleaning Experience in programming languages such as Java, Python, C++ Experience in building and optimizing architectures and data sets Experience working with stakeholders to identify business needs and analytics opportunities Singaporean only Location: Jurong East -",https://www.jobstreet.com.sg/en/job/data-engineer-ref%3A-cbl-1034913978?jobId=jobstreet-sg-job-1034913978&sectionRank=199&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
199,Senior data engineer,Evolution Singapore Pte. Ltd.,"We are seeking a talented Senior Data Engineer to join a leading AI-powered company that helps businesses automate their operations and gain valuable insights through advanced data analytics. As a Senior Data Engineer, you will be responsible for designing, building, and maintaining the company's data infrastructure. You will work closely with the data science team to develop and deploy machine learning models, as well as with the software engineering team to integrate data into our client's products and services. You will also be responsible for ensuring the quality and integrity of their data. Responsibilities: Design and build data pipelines to support machine learning models and data-driven products Develop and maintain data storage systems, including data warehouses and data lakes Ensure data quality and integrity by implementing data validation and cleansing procedures Oversee the AI technology roadmap Optimize data pipelines for scalability and efficiency Work with stakeholders to understand business requirements and translate them into data engineering solutions Mentor junior data engineers and collaborate with internal technology partners Requirements: Bachelor's or Master's degree in Computer Science, Engineering, or a related field 5+ years of experience in data engineering/ML Ops Proficiency in Python or Java, and experience with big data technologies such as Hadoop, Spark, or Kafka Experience with cloud-based data storage and computing platforms such as AWS, Google Cloud, or Azure Knowledge of database technologies such as SQL, NoSQL, and graph databases Experience with ETL tools and techniques Strong problem-solving skills and ability to work independently Excellent communication and collaboration skills Interested in applying? Please click on the ‘Easy Apply’ button Alternatively, send your resume to ******@evolutionjobs.sg for more info or to have a confidential conversation. -",https://www.jobstreet.com.sg/en/job/senior-data-engineer-1034997082?jobId=jobstreet-sg-job-1034997082&sectionRank=200&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
200,Data Engineer,Cognizant Technology Solutions Asia Pacific Pte Ltd,"Cognizant is on the fast track to growth and expansion. As we strive to provide the best services to our clients, we need more talented individuals to join our team. We are looking for Data Engineer who has a passion to engineers modern businesses in our journey to help our clients modernize technology, reimagine processes and transform experiences so they can stay ahead in our fast-changing world. Together, we’re improving everyday life. Join us as we continue to push boundaries and make a lasting impact in our industry. Apply now and be a part of our growth story. Job Responsibilities • Create and optimize end-to-end data pipelines to populate the data marts from multiple data sources • Perform data profiling to understand data quality of source data, and address data quality issues through data transformation and data loading • Provide support for UAT and PROD implementation Skill Set Requirements • Proficiency in MySQL scripting and unix shell script writing • Experience in using ETL tools such as Talend and Informatica Power Centre #LI-JL1 -",https://www.jobstreet.com.sg/en/job/data-engineer-1035011095?jobId=jobstreet-sg-job-1035011095&sectionRank=201&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
201,Data Engineer,KPLER PTE. LTD.,Own different data pipelines and ensure data is flowing consistently and efficiently Work closely with the Product Manager and other business stakeholders to understand their challenges from both a product and technical perspective Participate in the evolution of the platform (infrastructure and services) to address any challenges identified or implement new features Follow the highest software design standards and Kpler’s best practices -,https://www.jobstreet.com.sg/en/job/data-engineer-1034777469?jobId=jobstreet-sg-job-1034777469&sectionRank=202&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
202,Data Engineer - ETL,sagl consulting pte. ltd.,"Key Requirements: Experience in banking applications using ETL, Oracle, and Teradata. Expertise in Oracle PL/SQL and Teradata BTEQ scripting Expertise in Informatica tools like Power Center, Data Quality, Metadata manager, BG, and BDM Working experience in scripting using Shell script and awk programming. Worked with CI/CD automated deployment using Bitbucket and Github. -",https://www.jobstreet.com.sg/en/job/data-engineer-etl-1034802201?jobId=jobstreet-sg-job-1034802201&sectionRank=203&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
203,Data Engineer,Castlery Private Limited,"Castlery is looking for a Data Engineer to join our Supply Chain Strategy and Business Intelligence team. As part of our Supply Chain Strategy and Business Intelligence team, your role as a Data Engineer will be to ensure that our team has the right infrastructure to perform analysis that helps in making better-informed business decisions. You'll be building systems and that collect, manage and convert data into usable information for our team, and the details are as per below. What you'll be doing Define, collect, and model data from business processes or third parties to generate insights and drive strategic or continuous improvement initiatives for the whole company. Work with technology teams to design and implement reliable and scalable data pipelines. Work with functional stakeholders to build modern data infrastructure (e.g. data warehouse, data lake) and solve any data-related technical issues. Be the ‘Go-To’ expert and constantly improve data infrastructure in Castlery. What you'll need Bachelor’s or Master’s degree in Computer Science, Computing Engineering or other equivalent degrees with outstanding academic achievements. Proven track records working as Data Engineer, Data Scientist, Data Analyst or equivalent. Good command of database structures and query languages. Strong in Python programming and familiar with popular libraries such as Pandas, Scrapy. Familiar with AWS Data Analytics service and setting up data pipelines, e.g. Airflow, Jenkins. Knowledge of big data framework and tech stack is a plus, e.g. Spark, Hadoop. Passion and curiosity for solving challenging problems by leveraging on the right technology. Ability to work collaboratively in a multi-cultural team environment and lead changes. Ability to work effectively with people at all levels in an organization. Ability to deliver sophisticated ideas effectively, both verbally and in writing, in English. What we promise Our first promise - the ride of a lifetime You’ll be joining a company in its most exciting phase; we’ve proven our product market fit, and with the growing online penetration of furniture, we’re now focused on hypergrowth. You’ll have a front-row seat in witnessing the growth of our customer-base and organisation at a global-level. Our second promise – a place to thrive We’re building a company that has people as one of the company’s core pillars for success. It’s our mandate to help every employee perform to their highest potential so that they can do the very best work of their lives here, at Castlery. We’re committed to our employees’ growth, and continuously strive to ensure our employees are set up for success through their journey, starting with an excellent onboarding experience, and carrying over into emphasis on personal and professional development Castlery strives to maintain a psychologically safe, transparent, and flexible work environment to enable our people can perform at their best level and believes in partnering our employees to raise that level as they grow with us. -",https://www.jobstreet.com.sg/en/job/data-engineer-1034940455?jobId=jobstreet-sg-job-1034940455&sectionRank=204&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
204,Data Engineer,NANSEN PTE. LTD.,"About the role As Data Engineer you'll join one of our mission oriented squads or platform teams. Data is key in all of our products, and your contributions will have a big impact. You can be located anywhere in the world , as our work is 100% online. The position is full-time . Responsibilities Design, develop and support data pipelines, warehouses and reporting systems to solve business operations, users and product problems Work closely with product engineers to create, test and maintain data models Collaborate and influence stakeholders and support engineers to ensure our data infrastructure meets constantly evolving requirements Work closely with analysts to create data analytics and research platform Contribute to engineering efforts from planning and organization to execution and delivery to solving complex engineering problems Take initiative and be responsible for technical solutions to data quality and workflow challenges Write and review technical documents, including design, development, and revision documents.‍ Are you the right person for this role? The ideal candidate for us has: 3+ years work experience as a Data Engineer or similar role Experience with building data pipelines using Python and SQL Experience designing data models and data warehouses Experience in computer science , data structures , algorithms and software design Experience with the following: BigQuery, Postgres, Airflow, Kubernetes, dbt The following are nice-to-haves: Experience with Data Visualization tools Experience with Ethereum and the crypto markets (either professionally or as a hobby) -",https://www.jobstreet.com.sg/en/job/data-engineer-1034856668?jobId=jobstreet-sg-job-1034856668&sectionRank=205&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
205,Data Engineer/Modeller - Learning Mgmt Syst [ITE Headquarters] (1 Year Contract),Singapore Public Service,"[What the role is] As Data Engineer/Modeller, you will partner subject matter experts from the colleges to perform learning analytics based on structured data that are generated in the system as a result of students’ participation in their learning activities. You are expected to extract, prepare, transform and load data into an analytics software; build AI models with clustering and predictive capabilities. You will work closely with our team to gather user requirement; design, create, test, and implement visual dashboards that are relevant to different groups of college stakeholders. These dataset and dashboards reside in our Learning Management System (LMS), a D2L Brightspace SaaS LMS platform, using DOMO as the visualization tool which is also rendered within our LMS. [What you will be working on] - Support analysis of learning data to help lecturers and stakeholders gain insights into students’ learning behavior during term time - Provide training and consultancy to lecturers on how to use the dashboards - Conduct knowledge transfer on data analytics and modelling to staff [What we are looking for] -Skills and knowledge in business intelligence tools, data modelling software and programming or scripting languages that support model development, manipulation, aggregation and visualization. -Suitable credentials in Computer Science, Information Technology or equivalent -Practical experiences in data analytics and visualization projects using business intelligence tools would be an advantage. -Excellent interpersonal and communication skills, both verbal and written Applicants may check their application status at the end of 8 weeks from the closing date of this job posting. -",https://www.jobstreet.com.sg/en/job/data-engineer-modeller-learning-mgmt-syst-%5Bite-headquarters%5D-1-year-contract-1034762233?jobId=jobstreet-sg-job-1034762233&sectionRank=206&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
206,Data Engineer,Trinity Consulting Services Pte. Ltd.,"· Bachelor’s degree/Diploma in Computer Science, Computer Studies, Information Technology, or related disciplines · 5+ years of experience in software development · Minimum 2 years of experience with Snowflake · Minimum 3 years of designing, building and operationalizing data solutions and applications (with batch or streaming data) · Excellent understanding on SQL data storage structures and storage/query optimizations · Mastered SQL querying to build any data presentations using joins, reference tables, groupings, statistics etc. · Proficient in at least one core language: Python, Scala, Java · Exposure to concepts like Serverless computing, CI/CD, Containerization, Infrastructure as Code, code version control and automated testing · Exposure to one of more of cloud services like AWS, Azure or GCP · Excellent communication and presentation skills -",https://www.jobstreet.com.sg/en/job/data-engineer-1034976914?jobId=jobstreet-sg-job-1034976914&sectionRank=207&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
207,Data Engineer - Big Data,sagl consulting pte. ltd.,"Requirement • Experience in developing banking applications using ETL, Hadoop, and Teradata • Experience in Teradata (SQL, BTEQ scripting) and Hadoop (Hive, Impala, Kudu). • It is desirable to have working experience in No SQL and virtualized Database Environment. • Experience in Teradata FSLDM in Finance industry, • How BI tools integrate with Data Mart and Data Lake (Qlik Sense, Power BI) • Scripting using Shell script and awk programming • Good understanding of CI/CD automation, bitbucket, and Github. • Data Modeling using industry-standard data model (FSLDM) • Good understanding of Hadoop, In memory, No SQL -",https://www.jobstreet.com.sg/en/job/data-engineer-big-data-1034802530?jobId=jobstreet-sg-job-1034802530&sectionRank=208&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
208,Data Engineer/Modeller - Text Analytics [ITE Headquarters] (1 Year Contract),Singapore Public Service,"[What the role is] As Data Engineer/Modeller, you will partner subject matter experts from the colleges to perform advanced analytics based on data that are generated in the system as a result of students’ participation in their internship programmes with companies in different industries. These data can be structured or unstructured data from different sources. You will work closely with our team to gather user requirement; design and develop use cases; customize, test and implement dashboards that are relevant to different industry sectors. You are expected to extract, prepare, transform and load data into an analytics software; build AI models with clustering and predictive capabilities; and create visual dashboards to present data that are relevant to different groups of stakeholders. [What you will be working on] - Support analysis of internship data to help lecturers gain insights into students’ learning behavior, performance gaps and learning needs during their internships - Provide training and consultancy to lecturers on how to use the dashboards - Conduct knowledge transfer on data analytics and AI modelling to staff [What we are looking for] - Skills and knowledge in software engineering, programming languages used for statistical modeling and analysis, data warehousing solutions, and building data pipelines. - A strong foundation in mathematics and statistics. Skills &amp; knowledge in statistical modelling software and programming languages that support model development, data mining, manipulation, aggregation and visualization is a bonus. - Suitable credentials in Computer Science, Information Technology or equivalent - Practical experiences in data analytics projects (including text analytics) or AI projects for at least two years would be an advantage. - Excellent interpersonal and communication skills, both verbal and written Applicants may check their application status at the end of 8 weeks from the closing date of this job posting. -",https://www.jobstreet.com.sg/en/job/data-engineer-modeller-text-analytics-%5Bite-headquarters%5D-1-year-contract-1034759704?jobId=jobstreet-sg-job-1034759704&sectionRank=209&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
209,Data Engineer,Green Link Digital Bank Pte. Ltd.,"About Us Green Link Digital Bank is Singapore's inaugural wholesale digital bank focusing on supply chain finance, mainly serving MSMEs and aiming to help MSMEs grow and improve digitization. We are looking for a Data Engineer joining our Data Management Office (DMO). The DMO provides comprehensive data services to all business units, and manages data governance policies and procedures. We apply best practices in managing our data assets and making it our competitive advantages to serve our customers better. We are embarking on a greenfield project to build our big data platform with the latest technologies. We invite the best talent to join us on this exciting journey. Responsibilities Design, develop and test a custom distributed big data platform using the latest technologies Design, create and maintain physical data models optimised for performance, security, privacy, and maintenance Design and develop real-time and batch ETL/ELT processes that ingest and transform a variety of data sources into data warehouse and data lake Design and build data reconciliation processes to ensure data completeness and accuracy Diagnose and remediate production issues Provide training to users and other team members on technical aspects of data flow, procedures, and use of tools to consume the data effectively Create and maintain documentations of technical solutions such as solution design, system architecture, technical specifications, and user manuals Requirements In-depth knowledge of concepts and practices building big data platforms, including data warehouse, data mart, and data lake Practical experience in big data technologies, such as Hive, Spark, Kafka, Sqoop, Greenplum and any other RDBMS Proficient with SQL, Stored Procedures, Shell, Python, and Java Familiar with Elasticsearch or other NoSQL databases Experiences in CI/CD and containerization are added advantages Passionate for technical excellence and eager to learn new technologies Committed to rigorous quality standards -",https://www.jobstreet.com.sg/en/job/data-engineer-1034839988?jobId=jobstreet-sg-job-1034839988&sectionRank=210&token=0~19a10e4f-763a-4b02-86fc-a815617cb40c&fr=SRP%20Job%20Listing
210,Big Data Engineer,BASIL TECHNOLOGIES PTE. LTD.,"· Develop data processing pipelines for ingestion, modelling, analysis, mining and reporting with Enterprise Big Data Lake · Responsible for the code writing of the core module of the system · Develop POC and build data pipeline architecture using of the overall technical framework of the software · Work closely with teams ensure timely delivery of assignments What do you need to succeed? · Possess good communications skills to understand our customers' core business objectives and build end-to-end data centric solutions to address them · Good critical thinking and problem-solving abilities Must-have: · Experience building large scale enterprise data pipelines using commercial and/or open source Big Data platforms from vendors such as Hortonworks/Cloudera, MapR, for Hadoop based platforms or NoSQL platforms such as Cassandra, HBase, DataStax, Couchbase, Elastic Search, Neo4j etc · Hands on experience in Spark, Scala, Impala, Hive SQL, Apache Nifi necessary to build and maintain complex queries, streaming and real-time data pipelines · Data modelling and architecting skills including strong foundation in data warehousing concepts, data normalisation, and dimensional data modelling such as OLAP · Undergraduate or graduate degree in Computer science or equivalent -",https://www.jobstreet.com.sg/en/job/big-data-engineer-1034941386?jobId=jobstreet-sg-job-1034941386&sectionRank=211&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
211,Data Engineer,Total eBiz Solutions,"Experience : 2 – 8 Years No of openings : 02 JOB DESCRIPTION: Roles and Responsibilities Senior developer and Assistant Project Manager for dataware housing and BI projects Assist project manager in management work and guide junior developers. Responsible for technical design and systems impact analysis Provide on-going application support and be involved in various stages of the SDLC. Conduct user requirement analysis for the development / implementation of new systems and enhancements to existing systems. Requirements / Qualifications Degree in Computer Science, Computer Engineering or equivalent Has at least 3 – 4 years’ experience in Business Intelligence/Analytics projects. Has technical skills and knowledge on Business Intelligence data model design; Databases – Oracle or SQL Server; Business Intelligence software – Oracle Business Intelligence (OBIEE); Tableau; ETL software – Informatica; Oracle PL/SQL scripting or SQL scripting or UNIX scripting. Preferably with experience in Informatica Power center and\or OBIEE/Tableau. You may send us your resume to ***********@totalebizsolutions.com -",https://www.jobstreet.com.sg/en/job/data-engineer-1034978997?jobId=jobstreet-sg-job-1034978997&sectionRank=212&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
212,Data Engineer,People Profilers (services) Pte. Ltd.,"Responsibilities 5+ years experiences of data lake and data warehouse design and development experience. Deeply understanding of data warehouse modeling and data governance. Solid knowledge of data warehouse development methodology, including dimensional modeling, information factory, and one data, etc. Proficient in Java / Scala / Python (at least one language) and Hive &amp; Spark SQL programming languages. Familiar with OLAP technology (such as: kylin, impala, presto, druid, etc.). Proficient in Big Data batch pipeline development. Familiar with Big Data components including but not limited to Hadoop, Hive, Spark, Delta lake, Hudi, Presto, Hbase, Kafka, Zookeeper, Airflow, Elasticsearch, Redis, etc. Experiences with AWS Big Data services are a plus. Clear mind, with good business requirement understanding, analysis, abstraction, and system design capabilities. Have a strong team collaboration attitude and develop partnerships with other teams and businesses. Be optimistic, able to adapt quickly to meet new challenges, and quick to respond to incidents. We regret that only shortlisted candidates will be notified Noga Lim Wei Loong Registration Number: R1329872 EA License Number: 10C3804 People Profilers Pte Ltd, 20 Cecil St, #08-09, PLUS Building, Singapore 049705 *************** -",https://www.jobstreet.com.sg/en/job/data-engineer-1034928287?jobId=jobstreet-sg-job-1034928287&sectionRank=213&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
213,Data Engineer,BlueSG Pte Ltd,"We are looking for talented Data Engineers, who will join our Data Science Team and help us build the state-of-the-art data analytics capabilities powering the future of our platform. Roles and Responsibilities Work closely with data scientists to support the analysis of data, and the development, validation, and deployment of ML models. Collaborate with DevOps and Business Intelligence teams establish a common data platform and best practices. Participate in technical discussions across the team through code reviews, RFC or architecture review sessions. Requirements At least 2 years of experience working as an ML engineer or similar. Good understanding of Agile and DevOps practices: version control, CI/CD, Infrastructure-as-Code, containerization, observability/monitoring. Experience working with data scientists in end-to-end production use cases: from feature engineering through to real-time inference. Deep familarity with data engineering systems such as Airflow, Dagster, Flyte, Spark, or similar. Familiarity with data platforms such as Sagemaker, Dataiku, Databricks, Datarobot, or similar. Familiarity with SQL (PostgreSQL preferred) and NoSQL databases (Redis, Elasticsearch preferred). Familiarity with AWS data analytics services and databases. Preferred qualifications Hands-on experience supporting high-traffic consumer apps. Data science or related education or work experience. Experience with business intelligence and data warehousing processes and tools: star schema, Hadoop, Redshift, etc. -",https://www.jobstreet.com.sg/en/job/data-engineer-1034710920?jobId=jobstreet-sg-job-1034710920&sectionRank=214&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
214,AI Data Engineer,Ifun Singapore Pte. Ltd.,"Responsibilities Analyze business requirements from cross functional teams and translate to technical data science problems Optimize machine learning models for performance and scalability and deploys them into production to ensure repeatable and dependable operation Automate the machine learning pipeline, from data ingestion to prediction generation Collaborate with business, product and engineering teams to build end-to-end data science pipelines Gather data from various sources and assess business utility Perform exploratory data analysis, feature-engineering/selection Apply data science techniques to get insights out of data Build, deploy, and tune Machine Learning models Develop prototypes and visuals to illustrate insights Requirements Minimum Bachelor’s or above degree in Applied Mathematics, Statistics, Computer Science, or Artificial Intelligent At least 2 years or more of experience building AI/ML based products or features in Tree Based machine learning model Evaluating machine learning models and hyperparameter tuning Expert in Python, SQL etc strong understanding of AI/ML frameworks or cloud services Preferred Qualification Basic knowledge of Machine Learning algorithm Experiences on automotive Experience with deploying and scaling Machine Learning models Experience with first line or second line system operation and maintenance -",https://www.jobstreet.com.sg/en/job/ai-data-engineer-1035040835?jobId=jobstreet-sg-job-1035040835&sectionRank=215&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
215,Python Data Engineer,Zenika Pte. Ltd.,"In Zenika, we are looking for a Python Data Engineer with at least 5 years of experience You may be a fit if: You are able to develop, maintain and enhance Python applications processing high volumes of data. You have experience in Python pandas and Python API/web frameworks such as FastAPI, Flask or Django You have experience in writing SQL statements and optimizing Python applications performance You are well versed in business analysis - you are able to converse with business users to understand requirements, to analyse the existing data, to identify the required data transformation and to design the data processing workflow Who are we? Are you passionate about complex problem solving through futuristic technology? Zenika is a global premium IT services consultancy intending to link the organic and the digital worlds. We are a cohesive team of technology enthusiasts and experts who thrive in a collaborative and inclusive environment. Firm believers in 'Open Source' philosophy, our developers share more than 47K contributions on over 7K projects across several communities. Curious and pragmatic, we have multiple publications in our name. We share our knowledge by speaking at conferences and supporting companies in their digital transformation journeys through consulting, training, &amp; IT delivery. As fervent team members, you could join us as we adapt, test and develop innovative new applications for a fintech startup, influence the digital strategy of a banking giant, or create progressive solutions to resolve challenging problems every day for our clients. Zenika has been recognized as the ""Great Place to Work"" in France for four years in a row (2015 -2018). We take pride in our employee-first approach and diversity. Know about our values (Gender Equity, Equal Opportunities, Work life Balance, Handicap Mission) and perks - *************** While joining Zenika Singapore you will get: Attractive salary package with bonuses Attractive benefits (Eg: High health insurance coverage, transport allowances, work from home, 20 days annual leave) Career progression and upskilling opportunities Internal learning session and events Monthly and yearly internal social events Integration in our international developers community (Singapore - France - Canada) When you join Zenika you join: A highly qualified team of international professionals In an outstanding people-first culture Based on sharing, transparency and fun Do you like challenges? Do you like freedom? So, join our passionate team and actively contribute to ""Coding the World"". Explore open-source technologies &amp; the most innovative methods in the IT world with Zenika today! -",https://www.jobstreet.com.sg/en/job/python-data-engineer-1034841200?jobId=jobstreet-sg-job-1034841200&sectionRank=216&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
216,[LTA-ITCD] DATA ENGINEER / SCIENTIST,Singapore Public Service,"[What the role is] DATA ENGINEER / SCIENTIST [What you will be working on] You will work in a team of land transport specialists, data scientists, solution architects as well as infrastructure and cybersecurity engineers to build, expand and maintain an island-wide network of engineering and commuter-centric IoT sensors and big data platform. You will work on ingesting and analysing real-time and batch data to sense make commuting patterns and operations anomalies for improving overall journey experience. You will play a significant role as part of the Smart Nation initiatives and Land Transport Masterplan to shape Singapore’s land transport system to 2040. You will need to understand business requirements, support project implementation and perform ETL on large amounts of data. The ability to analyse data quickly and provide decision support to stakeholders is a key part of this job function. You will develop statistical or probabilistic models to derive actionable insights which also includes performing daily, weekly and monthly reporting tasks, e.g. for monitoring the quality and consistency of the analytical outcomes as part of the overall operations and maintenance of a big data ecosystem. You will also work on designing dashboards and compelling visualizations for decision-making and management reporting. [What we are looking for] • Tertiary qualifications in Computer Science/Engineering, Mathematics, Statistics or other related technical fields • At least 2 years of industry experience using common scripting languages (e.g. R, Python, SQL) and visualization tools (e.g. Tableau, Qliksense) • Strong knowledge in data structures and mining algorithms including those in statistical learning, machine learning, probabilistic models and neural networks • Good understanding and experience in the set up and maintenance of real-time big data infrastructures including ETL pipelines and hybrid cloud services involving on-premise system, network, storage and security solutions will be an advantage • Proven ability in digital storytelling to effectively communicate key insights to stakeholders by harnessing data science tools, high impact visuals and convincing narratives • Good problem-solving ability to ensure that application issues are being responded to and resolved proactively • Able to handle multiple tasks simultaneously -",https://www.jobstreet.com.sg/en/job/%5Blta-itcd%5D-data-engineer-scientist-1034955800?jobId=jobstreet-sg-job-1034955800&sectionRank=217&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
217,Data Engineer,BIOFOURMIS SINGAPORE PTE. LTD.,"Responsibilities: Creation and maintenance of optimal Data lake pipeline architectures. Stay abreast of industry trends and enable successful data solutions by leveraging best practices. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability. Partnering effectively with inhouse Products, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources and AWS ‘big data’ technologies. Assemble large, complex data sets that meet functional / non-functional business requirements. Keep our data separated and secure within national boundaries through multiple AWS regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader Experience / Training: 7+ years of experience in software engineering and Big Data Analytics. Prior experience on AWS cloud services EC2, Glue, Athena, S3, EKS, RDS, Redshift, Data pipeline, EMR, DynamoDB, cloud watch. Experience in creating and maintain Data lake on AWS cloud. Experience in Big Data analytics tools like Hadoop, Spark, Kafka etc... Strong experience in collecting data from different source systems and create ETL pipelines to handle complex data sets &amp; uncertain schema changes in data. Strong experience in Python programming and analytics libraries like Pandas, NumPy etc... Strong experience on Analytics skills and complex SQL based queries implementation. Data engineer also need to very passionate about efficient/accurate code development, optimizing performance of organization Data lake. Good experience in UNIX based shell scripting. Support to Data scientist team for data availability, extract &amp; provide required data sets. Coordinating with various teams and clients to provide data based on specific requirements. Education: Bachelor/Master/Engineering in IT/Computer science/software engineering or relevant experience. -",https://www.jobstreet.com.sg/en/job/data-engineer-1034955604?jobId=jobstreet-sg-job-1034955604&sectionRank=218&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
218,Data Engineer Intern,powerhouseai,"Company PowerhouseAI *************** Designation Data Engineer Intern Date Listed 08 Mar 2023 Job Type Entry Level / Junior Executive Intern/TS Job Period Immediate Start, For At Least 2 Months Profession Engineering Industry Computer and IT Location Name Singapore Work from Home Allowance / Remuneration $750 - 1,000 monthly Company Profile Powerhouse AI empowers warehouse employees to maximize their productivity and accuracy. Truly transforming warehouses into powerhouses. Job Description As a Data Engineer Intern at Powerhouseai, you will be working closely with our data team to help us build out our data infrastructure and improve our data quality. You will be responsible for conducting offline and online experiments, analyzing customer data for root cause analysis and inaccuracies, and visualizing data on the usage of the application. In addition, you will also be responsible for account management, as well as understanding the requirements of the customer. Represent the voice of the customer and influence product development roadmapPartner Product team on cross-sell opportunities and serve as the main point of contact and liaison between clients and the rest of the internal team. Analyzing and visualizing data on the usage of the application. Qualifications: Undergraduate or Postgraduate who is currently pursuing a degree/master in Engineering, Computer Science, or a related technical discipline from a university; The ideal candidate for this position should have expertise in statistical software (e.g., Python, pandas) and database languages (e.g., SQL). Familiar with Firebase and GCP - For this role, it would be beneficial if the applicant has prior coding experience using general-purpose programming language so they can hit the ground running! Furthermore, knowledge of various statistical data analysis approaches including linear models, multivariate analysis or sampling methods will be considered an advantage. Additional Information: Paid Internship3-6 Months internship Working closely with our CTO Application Instructions Please apply for this position by submitting your text CV using InternSG. Kindly note that only shortlisted candidates will be notified. Apply for this position -",https://www.jobstreet.com.sg/en/job/data-engineer-intern-1035041987?jobId=jobstreet-sg-job-1035041987&sectionRank=219&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
219,Data Engineer,Abbott,"Primary Function/Primary Goals/Objectives: Identify business needs, collect, data analysis &amp; interpretation and visualization of manufacturing and business data. Report insights and help users to make decisions and find improvement opportunities. Major Responsibilities: Engaging cross-functional stakeholders to understand business requirements (voice of customer). Manage cross-functional projects from ideation, execution to change management. Extract, transform and load data from data source systems, machines and sensors using tools such as Python, SQL, SEEQ and batch scripting. Develop data cleaning and data wrangling tools (Python, SQL, Excel) for analysis and analytics modeling. Extract time series process data from PI process historian using PI Web API. Implement next generation electronic tier reporting dashboard through data automation and analysis solutions. Serve as an on-site consultant for existing data systems. Troubleshoot issues via root cause analysis and implement timely corrective actions Work with IT and subject matter experts to ensure data accuracy and availability. Upgrading existing dashboards, apps and tools based on business needs. Creating Power Platform applications for data entry and improving workflows. Skills/Experience Requirements: Major in Computer Science, Computer Engineering or related fields from a recognized university. Major in Engineering with a minor or second major in Computer Science from a recognized university. Strong knowledge and experience in Programming Languages like Java, Python, R, etc. Strong knowledge in data visualization tools like Python, PowerBI, Tableau, QlikView and SEEQ. Strong analytical/critical thinking/problem solving skills. Strong communication skills and stakeholder management skills. Knowledge in Microsoft Power Platform tools such as Power Apps, Power Automate, Power Query and Power BI. Strong knowledge and experience in SQL, batch scripting, etc. 2-3 years work experience as a Data Engineer, Data Analyst, Business Analyst or related roles in a mature manufacturing/tech/IT consultancy firm. -",https://www.jobstreet.com.sg/en/job/data-engineer-1034803720?jobId=jobstreet-sg-job-1034803720&sectionRank=220&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
220,"Data Engineer, Technology &amp; Operations",DBS Bank Limited,"Business Function Group Technology and Operations (T&amp;O) enables and empowers the bank with an efficient, nimble and resilient infrastructure through a strategic focus on productivity, quality &amp; control, technology, people capability and innovation. In Group T&amp;O, we manage the majority of the Bank's operational processes and inspire to delight our business partners through our multiple banking delivery channels. The role: We are looking for an experienced Data Engineer to join our growing team of analytics. The candidate will be responsible for expanding and optimizing our data and data pipeline, as well as optimizing data flow. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. Candidate must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. Job Responsibilities Create and maintain optimal data pipeline. Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing Jobs/code for greater scalability, etc. Work with stakeholders including the Product owner, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Work with data and analytics experts to strive for greater functionality in our data systems. Job Requirements Advanced working SQL knowledge and experience working with RDBMS, Hadoop and NoSQL DB. Experience building and optimizing ‘big data’ data pipelines, Jobs and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with structured and unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Experience supporting and working with cross-functional teams in a dynamic environment. We are looking for a candidate with 10 years of experience in a Data Engineer role, who has a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools: Experience with:Big data tools: Hadoop, Spark, Kafka, etc. Relational SQL and NoSQL databases, including Postgres and Cassandra. Data pipeline and workflow management tools: Airflow, etc. AWS cloud services or GCP. Stream-processing systems: Spark-Streaming, Flink etc. Apply Now We offer a competitive salary and benefits package and the professional advantages of a dynamic environment that supports your development and recognises your achievements. -",https://www.jobstreet.com.sg/en/job/data-engineer-technology-operations-1035041655?jobId=jobstreet-sg-job-1035041655&sectionRank=221&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
221,Data Engineer Project Manager,EXPERIS SINGAPORE,"Job Description: Understand project requirements and manage the scope and plan of the project to make sure it adheres to the timeline, budget and scope Translate business requirements to technical specifications, provide high level solution design Drive engineering teams in building to the roadmap, managing project delivery, dependencies and risks, track deliverables, and overcome roadblocks Handle regular stakeholder communication and project updates Requirements: 5+ years of experience inmanaging engineering or data related projects Work with the business users to understand business requirements and translate that to high level technical specifications Manage and coordinate test plan, user sign off and go-live plan Work on defining high level architecture and appreciate technical complexities required Strong communication skills to coordinate with project team, stakeholders and management Comfortable working with both waterfall and agile methodologies Knowledge of one or more database technologies (Snowflake, Oracle, Hadoop) and experienced in Cloud Technologies Proficiency in writing Advanced SQLs, experience with business analytics products like Tableau Nice to have: Experience with data science and machine learning tools and technologies is a plus Knowledge of any programming language (Java, Python) and cloud deployments (CloudFoundry, AWS etc.) will be a plus. Claudia Kueh Kee Jinq EA License No.: 02C3423 Personnel Registration No.:R1880247 Please note that your response to this advertisement and communications with us pursuant to this advertisement will constitute informed consent to the collection, use and/or disclosure of personal data by ManpowerGroup Singapore for the purpose of carrying out its business, in compliance with the relevant provisions of the Personal Data Protection Act 2012. To learn more about ManpowerGroup's Global Privacy Policy, please visit *************** -",https://www.jobstreet.com.sg/en/job/data-engineer-project-manager-1034802339?jobId=jobstreet-sg-job-1034802339&sectionRank=222&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
222,Data Engineer,ST Engineering Aerospace Supplies Pte Ltd,"Job Description Engage in and improve lifecycle of infrastructure services from inception and design through development, deployment and refinement. Develop web applications using ******* MVC, C# and ******* Web API, following the development standards and technical design provided Understanding of best practices in software development process (SDLC) including coding standards, code reviews, design patterns, source control and object-oriented programming. Tap knowledge from domain experts and write SQL scripts to manage &amp; query databases to extract &amp; generate required data for analysis. Ability to develop web-based dashboards to show the results for internal &amp; external customers is preferred. Supports and develops software engineers by providing advice, coaching, and educational opportunities. Develop software solutions by studying information needs conferring with users studying systems flow, data usage and work processes Document and demonstrate solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code Design and architect new software product for data analytics 2nd level user support for application interface issues across systems Analyse issues and work with other team members to identify root cause to prevent future occurrences Requirements and Skills 5 to 7 years of relevant experience in core software development using Microsoft technologies. Working knowledge of C#, *******, MS SQL, JavaScript ******* Web API and Windows Services, SOAP, JSON Experience with WPF framework will be an added advantage Working knowledge in MSDN, TFS and SVN. Degree in Engineering or Computer Science or IT Hands on experience in technical design patterns, development and documentation. Strong in SQL server complex SQL query and Stored procedure development (4+ years) Experience in Software product development -",https://www.jobstreet.com.sg/en/job/data-engineer-1034793799?jobId=jobstreet-sg-job-1034793799&sectionRank=223&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
223,Data Engineer,CDG ZIG PTE. LTD.,"Responsibilities: Expanding data collection as well as optimizing data pipelines for cross-functional teams Work closely with data analysts and business end-users to implement and support data platforms Tuning, troubleshooting and scaling identified big data technologies. Analyse, tackle and resolve day-to-day operational incidents related to data provision Build suitable tools to provide data through acquiring, monitoring and analyzing root cause of data issues Identify, design, and implement process improvements and tools to automate data processing with data integrity Work with data scientist and business analytics to assist in data ingestion and data-related technical issues Design, build and maintain the batch or real time data pipeline in production using big data technology Design, build and manage data warehouse such as designing data model Create data views from big data platform to feed into analysis engines or visualization engines Requirements: Bachelor degree in Computer Science, Computer Engineering, Software Engineering or equivalent At least 2 years of relevant working experience in ETL/data integration and data modelling Experience with Data Engineering and Data Quality Cloud experience, ideally with Azure and AWS Understanding of Big data technologies like HDFS, Hive, Spark Experience of relational or NoSQL database (e.g. Oracle) and using database technologies (PL/SQL, SQL) Experience in data warehousing / distributed system Experience in data ingestion, cleaning and processing tools Experience in data acquiring, data processing using Scala/Python/Java Highly organized, self-motivated, pro-active, and desire to learn new technology Excellent communication and collaborative skills -",https://www.jobstreet.com.sg/en/job/data-engineer-1034708158?jobId=jobstreet-sg-job-1034708158&sectionRank=224&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
224,Principal Data Engineer,St Engineering Ihq Pte. Ltd.,"Participate in the design, development, and testing of an open architecture, open source based, and cloud native data analytics platform product Explore and evaluate modern data management and MLOps components for continuous improvement of data analytics platform product Contribute to the design and integration of data management &amp; data governance capabilities for the product Establish best practices and guidelines to be followed by engineers working on data pipelines Assist in the setup and maintenance of big data, machine learning and Kubernetes clusters Work with Data Scientists, Data Analysts, and other internal stakeholders to assist with datarelated technical issues and support their data pipeline infrastructure and data preparation needs Job Requirements: Bachelor or Master’s degree computer science, software engineering, information systems or related field. The candidate should have at least 8 years of technical experience in Information Technology with at least 4 years, preferably 6 years in Big Data, Data Warehousing or Business Intelligence technology with knowledge of analytics and AI technologies Broad knowledge of various aspects of Big Data with good understanding and hands-on experience in Hadoop based technologies such as HDFS, Hive, Spark, Kafka etc. Deep understanding of relational, NoSQL, NewSQL database technologies such as PostgreSQL, Oracle DB, CitusDB, SingleStore, Cassandra, MongoDB, Neo4J etc. Good knowledge in programming languages such as Java, Python or Scala on Linux/Windows platforms. Experience in Kubernetes and Kubeflow is a plus point Experience in Big Data visualization and reporting software. Experience in designing ETL/BI solutions. Experience in DevOps and DataOps Familiar with Linux/UNIX system administration Experience in operational support in delivering Big Data solutions. Effective oral and written communication with strong analytical, problem solving, multitasking and project management skills are essential on the job. -",https://www.jobstreet.com.sg/en/job/principal-data-engineer-1034823622?jobId=jobstreet-sg-job-1034823622&sectionRank=225&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
225,Big Data Engineer,PERSOLKELLY Singapore Pte Ltd,"Job Responsibilities Be responsible for big data governance, data access, data assets, and data quality maintenance, bigdata platforms and applicationg data , and be able to handle the routine maintenance, fault locating, and issue handling of various big data-related systems and data products. Ensure that the system and services are running properly and stably. Analyze the performance of the big data system and optimize the system, including developing O&amp;M automation scripts and periodically clearing junk data and tasks. Be able to process routine maintenance, fault locating, and troubleshooting of various big data-related systems and data products to ensure the normal and stable running of systems and services. Job Requirements: Be familiar with basic big data components, including (but not limited to) related technical principles such as Hadoop/Spark/Spark Streaming/Hive/Hbase/Zookeeper/Flume/Flink/Kafka/Redis/Es. Have a basic command of basic Linux operations and basic Linux principles. Have a basic command of SQL syntax and have used database programming languages such as HiveSQL, SparkSQL, Oracle, MySQL, and PostgreSQL. Be able to formulate O&amp;M deployment plans and solutions and prepare O&amp;M reports based on the actual situation. Be able to detect platform problems through data analysis. Interested candidate who wish to apply for this position, please click on APPLY NOW EA License No.: 01C4394 | PERSOLKELLY Singapore Pte Ltd EA Registration No.: R22107871 | Peng Ming Hui By sending us your personal data and curriculum vitae (CV), you are deemed to consent to PERSOLKELLY Singapore Pte Ltd and its local and overseas subsidiaries and affiliates collecting, using and disclosing your personal data to prospective employers/companies based in any country for purposes of evaluating suitability for employment, conducting reference checks, administering employment related services, complying with Government’s COVID-19 health advisories and such other purposes stated in our privacy policy. Our full privacy policy is available at *************** If you wish to withdraw your consent, please drop us an email to let us know. Please feel free to contact us if you have any queries -",https://www.jobstreet.com.sg/en/job/big-data-engineer-1034777899?jobId=jobstreet-sg-job-1034777899&sectionRank=226&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
226,Cloud data engineer,Sciente International PL,"Job Summary Look for opportunity of a different kind? This is an excellent role for Cloud Engineers to dabble into a hybrid role of Cloud and Data to run an Enterprise data lake used by many users and hosted across cloud and on-premises servers. Mandatory Skill-set Degree holder majoring in Business, Finance, Computer Science or equivalent; Experience and hands on skills in Terraform, Jenkins, AWS CodePipeline, AWS CodeBuild, SQL and Python; Experience in cloud application architecture and administration in AWS/GCP; At least 5 years of work experience in large scale infrastructure, ETL deployment, managing pipelines; Team player, self­ motivated and resourceful; Numerically inclined with a strong analytical mind; Basic experience in ETL design, implementation and maintenance. Desired Skill-set Prior experience in Insurance domain; Certified in AWS. Responsibilities Collaborating with data engineering and machine learning teams to optimize the data infrastructure for better reliability, maintainability, and scalability; Using various tools such as AWS, Glue Spark, Airflow, Tableau, and PowerBI to design, build, maintain, and improve data infrastructure on the cloud; Developing solutions to enhance data delivery capabilities, data quality monitoring, and the data pipeline lifecycle; Administering cloud applications such as AWS Glue, Sagemaker, LakeFormation, and Iceberg Lakehouse; Managing the regression testing suite and continuous integration and deployment pipelines. Should you be interested in this career opportunity, please send in your updated resume to *****@sciente.com at the earliest. When you apply, you voluntarily consent to the disclosure, collection and use of your personal data for employment/recruitment and related purposes in accordance with the SCIENTE Group Privacy Policy, a copy of which is published at SCIENTE’s website (***************). Confidentiality is assured, and only shortlisted candidates will be notified for interviews. EA Licence No. 07C5639 -",https://www.jobstreet.com.sg/en/job/cloud-data-engineer-1034985198?jobId=jobstreet-sg-job-1034985198&sectionRank=227&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
227,Data Engineer,IDC Technologies (Singapore) Pte. Ltd.,"Responsibilities · Implementing Data Architecture/ Data modelling for data platform and Analytics. · Responsible for the technical design and development of Analytics and big data systems including ETL, data transformations. · Define and govern banking logical model and data platform best practices and standards to include software development practices, design styles and software deployment. · Facilitate the discovery of entities, attributes, relationships, and business rules from the functional experts and the user community. · Metadata management. · Working with cross-functional teams to discover and develop actionable, high-impact data analytics requirements and opportunity statements in a variety of core business areas. · Assessing tool implementations and architectures in the Analytics &amp; Big data space, reviewing for gaps against business needs and industry best practices. · Contributing to business process design and re-engineering impacted areas Requirements · At least 6 to 8 years of working experience, preferably in banking environments · Familiarity with key technologies and concepts, e.g. Hadoop, Hive, Spark, Scala, Java and Impala are necessary · Familiarity with Cloudera echo systems. · Candidate with experience in Analytics and big data architecture. · Familiarity with key technologies and concepts, SQL &amp; Big Data. · Knowledge of products in Banking and Financial Services. · Ability to write clear documentation of procedures, and ability to write specifications for data models to be developed. · Detail-oriented and able to follow clear methodologies for troubleshooting and development. · Expert knowledge of data Architecture in financial service data models. · Expert knowledge of Erwin data modeler tool. Certifications would be a plus. · Expert in Data Analysis and Data Profiling. · Efficient in prioritising work and multi-tasking Mandatory Skills : Java, Scala, Impala, Hive -",https://www.jobstreet.com.sg/en/job/data-engineer-1034715050?jobId=jobstreet-sg-job-1034715050&sectionRank=228&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
228,Data Engineer,maxeon solar pte. ltd.,"Maxeon is seeking a Data Engineer to design and build databases, Big Data Platforms, Datawarehouse, ELT, ETL pipelines for the Industry 4.0 data program . The position will be based in Singapore. The Data Engineer will report to the Senior for industry 4.0 data program. This person will closely work with Project Lead, Data Analytics Lead, implementation partner and other key project stakeholders. The candidate for this role will need to have a meticulous eye for data and appreciates the process of manipulating, storing and understanding data. This person will closely work with a team of experienced data experts, analyst and business resources to build databases, data warehouses and ETL/ELT pipelines as part of Industry 4.0 data program. · Work with Industry 4.0 data program team which includes project implementation vendor resources, data experts from manufacturing engineering team, data analysts &amp; business stakeholders. · Support end to end set up of data platform which is scalable and future proof for Maxeon based on the functional/non-functional &amp; technical requirements. · Integrate data platform with Maxeon Applications and 3rd party system as required from both On-Premise and Multi Cloud. · Expand and optimize our data and data pipeline architecture, as well as optimize data flow systems in a secured and scalable manner. · Assemble large, complex data sets that meet functional / non-functional business requirements, transforming data into formats that are easy to consume and analyze. · Translate complex business requirements into scalable technical solutions meeting data warehousing design standards. · Solid understanding of analytics needs and proactiveness to build generic solutions to improve overall efficiency. · Data Profiling &amp; Cleansing of data by applying data quality checks before ingesting the data. · Ingest, transform, process and store data efficiently into a database, data lake or Datawarehouse platform hosted on premise or cloud based environment. · Design &amp; Build database, Enterprise Datawarehouse design and data modelling. To be able to organize data at both macro and micro level and provide logical data models for the consumers. · Build data foundation to provide an enterprise view of data across the organization which can be seamlessly accessed by Business users through Self-Service reporting. · Build a centralized data repository (Sand Box environment) with a robust data foundation to enable data discovery, data mining for advanced analytics usecases. · Work with stakeholders including the Product owner, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. · Work with data and analytics experts to strive for greater functionality in our data systems. · Able to communicate effectively, both written and verbal, with technical and non-technical multi-functional teams. Knowledge and Technical Skills: · Bachelors degree in Science or Information Technology · Certified in Data &amp; Analytics Cloud based solution · Proven track record in designing and implementing large-scale data solutions, performing architectural assessments, optimizing data models, establish and enforce engineering guidelines and standards on Cloud based environments · 4+ years of experience in technical architecture, design &amp; build of Data &amp; Analytics projects in a multinational organization on On-Premise &amp; Cloud based solutions. · In-depth experience in working with a data warehouse and knowledgeable on data warehouse modelling techniques · Highly knowledgeable in ETL/ELT processes, both design and implementation using various leading tools like for example Informatica, Ab-Initio, Talend etc · Experienced in implementing data pipelines for stream and batch ingestion/processing using Open-Source tools (Kafka, Apache Spark) as well as Cloud Native solutions. · Good experience in building data pipelines that ingests various types of data sources (structured, semi-structured and unstructured) into a database or data lake and populating a structured warehouse or data mart · Experienced in building data lake (distributed storage, Object store), databases &amp; Datawarehouse in cloud (AWS, Azure, GCP), moving data applications to the cloud, and developing cloud native data applications. · Experienced in implementing SQL, NoSQL databases &amp; MPP databases · Experience in Data archiving &amp; Life Cycle Management. · Data Warehouse design, BI reporting and Dashboard development. · Prior experience in leading a team of technical developers will be a plus · Advanced SQL and Python skills are mandatory · Prior data modeling (dimensional, relational) and data engineering experience is mandatory · Prior experience in leading a team of technical developers will be mandatory · Strong understanding of development processes and agile methodologies is necessary Complexity: · Works on problems and projects of diverse complexity. · Engages in analyses requiring evaluation of identifiable factors. · Exercises independent judgment within generally defined boundaries. · Networks with senior individuals, internally and externally, within own area of expertise. Safety Compliance Your safety is our number one priority at Maxeon. All our employees must complete regular workplace safety training and comply with our mandatory safety standards. Equal Employment Opportunity It is Maxeon’s policy to provide equal employment opportunity to all applicants and employees. Maxeon will not tolerate unlawful discrimination against any applicant or employee because of race, color, national origin or ancestry, gender (including pregnancy, childbirth, or related medical conditions), gender identity, ages, religion, disability, family care status, veteran status, marital status, sexual orientation, or any other basis protected by national, local, state or federal laws or regulations. -",https://www.jobstreet.com.sg/en/job/data-engineer-1034977950?jobId=jobstreet-sg-job-1034977950&sectionRank=229&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
229,Data Engineer,Fong's Engineering &amp; Manufacturing Pte Ltd,"Job Description Recommend and build require infrastructure for optimal extraction, transformation and loading of data from various sources such as ERP. MES and other systems using SQL technologies. Create, manage and maintain optimal data pipeline architecture. API and integration for ERP, MES and other systems used in the company. Monitor and manage database and related systems to ensure optimized performance. Assemble large, complex data sets that meet functional and non-functional business requirements. Working with stakeholders such as sales, finance, operations, design, and executive teams to support their data infrastructure needs while assisting with data-related technical issues. Build business intelligence and analytical tools using Power BI to utilize the data pipeline, and provide actionable insight into key business performance metrics. Participate in external and internal audit to ensure company data and related system is effective and validated. Create and maintain documentations and compliance for data and systems with reference to industry best practices. Perform other tasks as assigned by the supervisor. Requirements Bachelor’s degree (or equivalent) in Computer Science, Information and Communications Technology, or related discipline 3 or more years with RDBMS and NoSQL databases 3 or more years of experience with Python, SQL, data visualization and exploration tools Working experience in MedTech / Manufacturing Industry Experienced in building and maintaining ETL processes. Experienced with Microsoft-based stack (M365, Power Platform, Azure, Dataverse,Microsoft SQL Server) Knowledge of best practices in ICT operations and data management Excellent problem solving and troubleshooting skills. Process orientated with great documentation practices. Communication skills, especially for translating technical concepts to non-technical business leaders. Ability to work on a dynamic, action-focused team that has concurrent projects -",https://www.jobstreet.com.sg/en/job/data-engineer-1034802503?jobId=jobstreet-sg-job-1034802503&sectionRank=230&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
230,Senior Big Data Engineer,One North Consulting Pte. Ltd.,"One North Consulting is currently hiring Senior Big Data Engineers with about 5 - 8 years of experience as per details given below. Interested Singapore Citizens / Singapore Permanent Residents can connect on email id - ***@OneNorthConsulting.com or +65 96414*** Skills &amp; Responsibilities As Senior Big Data Engineer, you will focus on managing the Hadoop cluster, implementing data ingestion framework designing data models. Your primary role will be to implement data lake &amp; transform the data for business use. Experience with at least one Cloud Infra provider (Azure/AWS) Experience in building data pipelines using batch processing with Apache Spark (Spark SQL, DataSet / Dataframe API) or Hive query language (HQL) Knowledge of Big data ETL processing tools Experience with Hive and Hadoop file formats (Avro / Parquet / ORC) Basic knowledge of scripting (shell / bash) Experience with CI CD tools such as Jenkins, JIRA, Bitbucket, Artifactory, Bamboo and Azure Dev-ops. understanding of DevOps practices using Git version control Debug, fine tune and optimize large scale data processing jobs Deliver big data solutions based on premise Hadoop or cloud-based systems like AWS. Manage Hadoop cluster, participate in scale out planning &amp; implementation. Design ingestion layer for structured &amp; unstructured data (text, voice, xml etc) Implement specific data model for business &amp; analytics use. Deliver ELT solution including data extraction, transformation, cleansing, data integration and data management. Augment with new sources of data including internal/external untapped data. Contribute to the establishment and maintenance of cloud computing platform and big data services. Provide support for analytics tools &amp; environment like RServer etc &amp; debug performance issues. COMPETENCIES Databases: RDBMS, SQL programming ETL and Data Integration Tools: Azure Data Factory (ADF), Microsoft SQL Server Integration Service(SSIS), SAS Data Integration Big Data: Hadoop (Hortonworks), Hive, Spark, Sqoop, etc Programming and Scripting: Linux/Unix Shell Scripting, Java, Scala, Hive QL BI/Dashboarding: SAS Visual Analytics, Qliksense Working Experience: 5~8 years in data engineering and modelling. Hands-on in managing data mapping, data quality and integrity, performance in data processing. Experience in Agile software development. If Interested, please email us your CV to *************** -",https://www.jobstreet.com.sg/en/job/senior-big-data-engineer-1034839431?jobId=jobstreet-sg-job-1034839431&sectionRank=231&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
231,"Associate/AVP, Data Engineer, Investment Insights Group",GIC Private Limited,"Investment Insights Group (IIG) The Investment Insights Group (IIG) uses advanced quantitative techniques and cutting-edge technological tools to generate insights that drive outstanding investment outcomes for GIC. We are a multi-disciplinary team of Quantitative Researchers and Software Developers that work closely with each of our investment departments – from Public Markets like Equities and Fixed Income, to Private Markets like Private Equity and Real Estate – to drive superior returns. Our team of software developers, whom we call “Alpha Technologists”, develop platforms for investment teams and quantitative researchers, allowing GIC to harness our differentiated quantitative methods at scale. They also drive synergy across departments to enhance cross-asset investment capabilities at GIC. We are hiring a Data Engineer/Analyst to join a multi-disciplinary application team supporting the research, development, and integration of sustainable analytics into our investment processes, strategies and platforms. You will be responsible for the analysis, design, development, testing and maintenance of our data architecture and pipelines to ensure a stable, robust and resilient data environment, and also contribute to generating data-driven insights. We’re looking for a proven problem-solver and team player who enjoys learning about investment management and research with a passion in applying technology to investments and portfolio analytics, and driving continuous improvement. Responsibilities Leverage large-scale enterprise data platforms to meet the analytical and operational needs of sustainability research and investment capabilities Drive consistent methodology and framework in developing cross-asset and top-down/bottom-up integration of sustainability data and analytics across various investment management platforms Review and assess data frameworks and technology platforms with the goal of suggesting and implementing improvements Understand the quality of data used to suggest process improvements and data quality routines Conduct detailed analysis on business requirements and develop solutions to enhance or add new analytical capabilities Take an agile and pragmatic approach, ensure quick time-to-market and code reusability Collaborate with stakeholders from various departments Requirements 1 to 4 years of relevant experience in data engineering or backend development, and hands on experience in solution designing, software testing and production support Experience or knowledge in the following technologies is advantageous:Data Virtualization – Denodo Database &amp; Big Data Platforms – Oracle, MS SQL, Snowflake, JDBC/ODBC Programming and Scripting – Python, Java, REST API AWS services – S3, RDS, Athena, Airflow ******** and other JavaScript framework/libraries Experience with Agile software development methodologies and practices such as Scrum, Kanban and Test-Driven Development Good knowledge in financial and risk modelling Familiarity with ESG data and analytics is desirable Keen learner, independent problem solver with strong communication and interpersonal skills To be considered for the role, please submit a formal application through the GIC Careers site at *************** -",https://www.jobstreet.com.sg/en/job/associate-avp-data-engineer-investment-insights-group-1034940273?jobId=jobstreet-sg-job-1034940273&sectionRank=232&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
232,Data Engineer,Tata Consultancy Services Asia Pacific Pte Ltd,"Job Description Are you a multitasker and good at managing stakeholders? Would you like to manage the day-to-day activities of the APAC Business Solutions team, leading experienced change staff through Team by Team or Value Stream Optimization projects, support APAC BoW and other initiatives covering Asia Pacific? We're looking for someone who can: – lead Cloud Transaformation or Migration initiatives pertaining Wealth Management under Finance Domain – ensure a consistent way in leveraging the Process Excellence Way – identify transformational levers across the 5 lenses – coach key stakeholders on their role as lean managers within the lean management system – coach project teams on tools and methods deployment, and help line managers with the consistent implementation of the PEW – collaborate with Investment Bank engagement leads and solution design specialists in identifying automation solutions Job Requirements 1)Work on GCP Migration Task to align with bank initiatives 2) Technical expertise regarding requirements specification, analysis, reviews, track &amp; respond to stakeholder feedback and support end to end change management 2) Front-to-back business process design 3) Use-case definition, documentation and target design of new solutions (mainly from a business point of view) 4) Close interaction with Data team 5) Establish impact assessment and gap analysis related to Google Cloud and Wealth management process and 6) an excellent communicator and highly organized 7) customer orientated and focused on service quality 8) fluent in English both oral and written Must Have Skills 1) Google Cloud Platform and components like App Engine, Compute Engine, GKE, Data pipelines, Terraform, and Containerization tools, Git/GitHub 2) Oracle 12c/19c, Unix, Python 3) Java, Agile ways of working Experience Good To Have Skills 1) Knowledg of Wealth Management Domain 2) Dev Ops Skills 3) Datawarehousing concepts -",https://www.jobstreet.com.sg/en/job/data-engineer-1034980001?jobId=jobstreet-sg-job-1034980001&sectionRank=233&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
233,Data Engineer | Up to SGD$7k/month – J.T.,BGC Group Pte Ltd,"What you’ll be doing: Work closely as part of the agile product team to design, develop, test and deploy data integration products under the guidance of the DSTA Product Manager Provide monthly progress reporting and status updates to Authority. Deliver all required documentations (in compliance to Authority’s QMS processes and standards) including but not limited to design specifications, data specifications, user requirements, mapping documents and unit test plan. Responsible for complying with data integration development processes and standards defined by Authority. Develop and manage the data integration programs with Authority’s furnished software that include Informatica PowerCenter and Talend. Maintain and perform continuous enhancements of data pipeline to ensure smooth data ingestion and good performance. This scope requires personnel to work with Oracle Database, Big Data Platform and tools such as Informatica PowerCenter and Talend. Conduct and support requirement gathering with the Authority’s project team for new data integration program development. Perform all required testing to ensure quality of deliverables i.e. User Acceptance Test (UAT), System Integration Test (SIT), Operational System Acceptance Test (OSAT). Review system, application activities and database logs to detect abnormalities based on provided criteria. Develop extractors for data in source systems including but not limited to SAP BW OpenHub, Oracle database, SQL Server database and flat file. What you’ll need: Degree/Diploma in Computer Science, Computing, Electrical Engineering, or IT equivalent Experience in building and optimising data pipelines, architecture and datasets using DI/ETL technology (e.g. Informatica, Talend). Shall have experience in supporting data transformation, data structures, metadata, dependency and workload management . Experience in multiple data source support (e.g. flat files, SQL database, SAP database, PostgreSQL database, unstructured data not limited to text, documents, images, digitalised video, digitalised audio, sensor data ) would be advantageous. Benefits: AL: 18 days ML: 14 days Medical benefit Bonuses Interested applicants: kindly submit your resume to **********@bgc-group.com -",https://www.jobstreet.com.sg/en/job/data-engineer-%7C-up-to-sgd%247k-month-j.t.-1034856017?jobId=jobstreet-sg-job-1034856017&sectionRank=234&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
234,Senior Data Engineer,Adnovum Singapore Pte Ltd,"What you’re going to do Design, construct, install, test, and maintain data management systems Build high-performance algorithms, predictive models, and prototypes Ensure that all systems meet the business/company requirements as well as industry practices Integrate up-and-coming data management and software engineering technologies into existing data structures Develop set processes for data mining, data modeling, and data production Create custom software components and analytics applications Research new uses for existing data Employ an array of technological languages and tools to connect systems together Install/update disaster recovery procedures Recommend different ways to constantly improve data reliability and quality What we’re looking for Bachelor’s degree in computer science or similar Min. 5 years’ proven experience as a Data Engineer or similar Proficient in Data Modelling, Data Architecture , ETL, Data warehousing, Data Lake. Proficient in Linux/Unix and shell scripting as well as in functional programming languages. Proficient in one or more scripting language (e.g Python, R) Experience in Apache Hadoop based analytics coving data processing, access, storage, governance, security, and operations. Experience in Cloud based Big Data technologies. Experience with AWS cloud services: EC2, EMR, RDS, Redshift Prior data streaming experience with Spark/Python,... Knowledge in deploying microservices Creative thinking backed by strong analytical and problem-solving skills Sharp minds, good vibes We are the sharp-minded IT experts who tackle the trickiest software and security challenges. With more than 630 employees in our locations in Zurich (HQ), Bern, Lausanne, Budapest, Lisbon, Singapore, and Ho Chi Minh City, we make the digital business of our clients work. As a great team, we empower each other to share, grow and succeed. The unique Adnovum spirit across locations stands for helping each other at any time, having an open door and contributing to an appreciating and trustful atmosphere. We always enjoy having a laugh, a coffee or a drink together! Apart from our unique «one Adnovum» spirit, we offer a solution-oriented engineering culture with flat hierarchies, which gives you the opportunity to contribute with your opinions and ideas. We embrace flexible working, like the possibility to work part-time and a hybrid work model. Your continuous education and development are key to us. Therefore, we actively encourage and support individual training opportunities. For data privacy reasons, we only accept applications submitted via our online portal. Applications received by e-mail cannot be processed. Thank you for your understanding. Adnovum accepts only direct applications. Any applications submitted by recruitment agencies without contractual agreement will be treated as direct applications. -",https://www.jobstreet.com.sg/en/job/senior-data-engineer-1034804050?jobId=jobstreet-sg-job-1034804050&sectionRank=235&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
235,Data Engineer,ALUMNI SERVICES PTE. LTD.,"Alumni Services is a global digital transformation management consultancy with offices in Singapore, Hong Kong, Australia, UAE and the UK providing high-end expertise to industry leading clients to drive real business improvement through disruptive technologies. We offer advice, provide technology, transformation, and people change expertise to deliver real impact. Our global team are hand-picked experts located all over the globe, with executive-level experience in tech-focused MNCs, consultancies, and start-ups. Alumni Services are looking for a Singapore based Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. Responsibilities will include: Create and maintain optimal data pipeline architecture. Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and AWS regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. What We Offer A vibrant and entrepreneurial culture where we fuel and realise your ambition The chance to work with and learn from a group of global experts in their field Career progression, training, and professional development Access to global clients and well-known brands across a broad range of industries including Telecoms, Financial Services, Government, Hospitality, and Logistics Competitive salary and benefits Experience Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Experience supporting and working with cross-functional teams in a dynamic environment. Qualifications We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. They should also have experience using the following software/tools: Experience with big data tools: Hadoop, Spark, Kafka, etc. Experience with relational SQL and NoSQL databases, including Postgres and Cassandra. Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. Experience with AWS cloud services: EC2, EMR, RDS, Redshift Experience with stream-processing systems: Storm, Spark-Streaming, etc. Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Strong project management and organizational skills. Characteristics Self-directed and comfortable supporting the data needs of multiple teams, systems and products. Excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives. Excellent communicator with Leadership skills and ability to influence the executive team and their direct reports cross-functionally. Demonstrates a hunger for technology and continuous learning mindset. Self-Starter with pro-active approach and solution focused working style. -",https://www.jobstreet.com.sg/en/job/data-engineer-1035025556?jobId=jobstreet-sg-job-1035025556&sectionRank=236&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
236,Data Engineer,Homage Malaysia,"ROLE DESCRIPTION Engineers at Homage build things that matter – Homage is redefining long term wellness for our parents, grandparents, friends and loved ones. At the heart of Homage are the families and care professionals we work with and the technology we build transforms their lives and care delivery experience. Here, every engineer works on exciting, meaningful projects. We move fast, have fun and help each other out. Homage’s platform is a critical component within Homage that empower our users’ care delivery journey. We’re looking for product-aware engineers who are thoughtful, responsible and passionate individuals who appreciate the value of data driven decision making. We’re looking for someone who is passionate about data, and enjoys building and owning data systems end to end. We’re proudly backed by a group of top local investors, including Golden Gate Ventures, 500 Startups, EV Growth and SeedPlus. Homage data engineers have a penchant for solving data problems. If you love and thrive on keeping up to date with and gaining a deep understanding of the latest data technologies and tools, you will love working with us. At Homage, it is about employing diverse areas of Computer Science, including machine learning, information retrieval, distributed computing and natural language processing to transform the home healthcare industry in Asia. RESPONSIBILITIES Build and maintain data pipelines Assemble variety of large complex data set to meet business analytics requirements Work with stakeholders to understand and resolve data-related technical issues, and support their data infrastructure needs. Ensure data availability, consistency, and integrity by using the right tools, architecture, design, and implementation choices SKILLS &amp; EXPERIENCE Bachelor’s or Master's Degree in Computer Science or ICT-related field, with 2-6 years of experience. Hands-on experience as a data engineer, building ETL (data extraction, transformation, and loading), storages, and analytical tools Working experience with at least 1 or more cloud services: AWS, Google Cloud, or Azure. AWS experience is a plus. Good knowledge of at least one of these programming languages e.g. Python, *******, or Java. Good knowledge of RDBMS (MySQL), NoSQL databases like AWS DocumentDB(MongoDB) and AWS Redshift. Good knowledge and experience with AWS Glue and Airflow. AWS Sagemaker experience is a plus. ​​Experience of working in Agile environment, in a close collaboration with developers Problem-solving attitude and team spirit. BONUS Experience with real time data processing. Experience with Big Data tools: Hadoop, Spark, Kafka. Working experience with Unix/Linux/Unix-like systems. ABOUT HOMAGE Homage is a care platform that combines qualified and trained caregivers, nurses, doctors and health care organisations and funders with technology, enabling care, wellness and recovery wherever you are. The work that we do and technology we build transforms lives every hour, every day. We’re looking for people who are talented, driven and motivated by our social mission. -",https://www.jobstreet.com.sg/en/job/data-engineer-1034838729?jobId=jobstreet-sg-job-1034838729&sectionRank=237&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
237,Data Engineer,Quantexa,"Founded in 2016 with only a handful of individuals, Quantexa was built with a purpose that through a greater understanding of context, better decisions can be made. 6 years, 10 locations and 600+ employees later we still believe that today. We connect the dots within our customers data using dynamic entity resolution and advanced network analytics to create context, empowering businesses to see the bigger picture and drive real value from their data. Due to the continuous success and high demand from our customers, we are looking for Data Engineers with a proven track record and who are looking for an opportunity to learn new skills and progress their careers in a dynamic and exciting start-up environment. What does a Data Engineer role at Quantexa look like? In order to be a successful Data Engineer at Quantexa, you’ll need to be comfortable dealing with both internal and external stakeholders. You will be managing, transforming and cleansing high volume data, helping our Tier 1 clients solve business problems in the area of fraud, compliance and financial crime. Being Agile is an integral part to the success we have at Quantexa and having regular team sprints and Scrum meetings with your Projects team is essential. You’ll be working closely with Data Scientists, Business Analysts, Technical Leads, Project Managers and Solutions Architects, with everyone following the same goal of meeting our clients expectations and delivering a first-class service. We want our employees to use the latest and leading open source big-data technology possible. You will be using tools such as Spark, Hadoop, Scala, Data Fusion, Entity Resolution and Elasticsearch, with our platform being hosted on both private and public virtual clouds, such as Google cloud, Microsoft Azure and Amazon. Our primary language is written in Scala, but don’t worry If that’s not currently your strongest language, we make sure that every Quantexan goes through our training academy so they’re comfortable and confident with using our platform. Typical responsibilities include: · Write defensive, fault tolerant and efficient code for data processing. · Automate data processing to enable on-going alerts on high-risk activity. · Participate in customer workshops and refinement sessions, presenting project results to clients both face to face and virtually. · Work very closely with data scientists to ensure efficient and effective delivery of solutions. · Use leading open source big-data tools, such as Spark, Hadoop, Scala and Elasticsearch. You should be comfortable with working with high profile clients, including on their sites. · Work with our expert software development team to produce reusable applications. · Use emerging and open-source technologies such as Spark, Hadoop, and Scala. · Collaborate on scalability issues involving access to massive amounts of data and information. · Take on ad-hoc tasks as required for the running of a small, yet rapidly expanding business. What do I need to have? · Proven big data experience, either from an implementation or a data science prospective. · Several years of hands-on experience working as part of an engineering development team, ideally in SCRUM. · Arrive with experience at working with a variety of modern development tooling (e.g. Git, Gradle, Jenkins, Nexus) as well as technologies supporting automation and DevOps (e.g. Ansible, Chef, Puppet, Docker and a little bit of good old Bash scripting). · Excellent technical skills including hands-on knowledge of at least one big data technology such as Spark, Hadoop, or Elasticsearch. · Experience with MVC frameworks such as AngularJS · Experience of building data processing pipelines for use in production “hands off” batch systems, including either (or preferably both) traditional ETL pipelines and/or analytics pipelines. · Strong coding experience in the likes of Scala, Java, or Python. · Enthusiasm to learn and develop emerging technologies and techniques. · Exhibit strong technical communication skills with demonstrable experience of working in rapidly changing client environments. · Demonstrate strong analytical and problem-solving skills and the ability to debug and solve technical challenges with sometimes unfamiliar technologies. · Strong academic qualifications and come from a software engineering background or other scientific degree incorporating IT modules (e.g. Maths/Physics). -",https://www.jobstreet.com.sg/en/job/data-engineer-1034796047?jobId=jobstreet-sg-job-1034796047&sectionRank=238&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
238,Senior Data Engineer / Scientist,AIDA TECHNOLOGIES PTE. LTD.,"AiDA Technologies (AIDA) is a specialist AI/Machine Learning company focused on providing products and solutions to the banking and insurance industry. The company was started by leaders from Singapore’s top Research Institutes and they have over 100 years of working experience among ************** solutions assist our customers to increase Revenue, automate processes and manage Risks and Compliance using AI/­ML. The team has delivered over 35 predictive analytics solutions and have established a name for ourselves in the FSI sector as a leading provider of advanced AI/ML solutions for the industry. We are looking for a Data Scientist as part of our Machine Learning Team. The ideal candidate will leverage strong collaboration skills and ability to extract valuable insights from highly complex medical &amp; insurance data sets to ask the right questions and find the right answers. You will have great opportunity to work with Data Scientist to understand and learn about how we can leverage AI/ML in the health insurance &amp; medical field to detect fraud &amp; waste, improve automation efficiency &amp; promote vitality. Duties and Responsibilities Analyze raw data: assessing quality, cleansing, structuring for downstream processing Be heavily involved to bring analytical prototypes to production with the data engineering &amp; dev-ops teams Become a subject-matter expert in the health &amp; insurance domain Generate actionable insights for business improvements Help to develop customizable reports / production-ready dashboards for clients Requirements · Bachelor's degree or equivalent experience in quantitative field (Statistics, Mathematics, Computer Science, Engineering, etc.) · At least 3 years' of experience in quantitative analytics or data modeling · Ability to write robust code in Python · Good understanding of Database Systems and SQL · Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms · A strong self-starter and able to work with minimal supervision · Ability to work in a dynamic, fast moving and growing environment · Critical thinker with problem-solving skills Good to have: · Experience in troubleshooting, debugging, analysing logs and tracing of logs. Familiarization with CI/CD systems such as GitLab Experience with cloud infrastructure and services, and resources administration (i.e. AWS, Azure) Experience in Plotly / Dash, Evidently or any other open-sourced dashboarding &amp; performance monitoring tools deployable in production -",https://www.jobstreet.com.sg/en/job/senior-data-engineer-scientist-1034940666?jobId=jobstreet-sg-job-1034940666&sectionRank=239&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
239,Data Engineer,OKBL PTE. LTD.,"About OKX OKX is a leading crypto trading app, and a Web3 ecosystem. Trusted by more than 20 million global customers in over 180 international markets, OKX is known for being the fastest and most reliable crypto trading app of choice for investors and professional traders globally. Since 2017, OKX has served a global community of people who share a common interest in participating in a new financial system that is designed to be a level playing field for everyone. We strive to educate people on the potential of crypto markets and how to invest Beyond the OKX trading app, our Web3 wallet, known as MetaX, is our latest offering for people looking to explore the world of NFTs and the metaverse while trading GameFi and DeFi tokens. About the team: OKX data team is responsible for the whole data scope of OKG, from techincal selection, architecture design, data ingestion, data storage, ETL, data visualization to business intelligence and data science. We are data engineers, data analysts and data scientists. The team has end-to-end ownership of most of the data at OKx throughout the whole data lifecycle including data ingestion, data ETL, data warehouse and data services. As a data engineer of the team, you will work with the team to leverage data technologies to empower evidence-based decision-making and improve the quality of the company's products and services. Responsibilities: Design and build resilient and efficient data pipelines for both batch and real-time streaming data Architect and design data infrastructure on cloud using industry standard tools Execute projects with an Agile mindset Build software frameworks to solve data problems at scale Collaborate with product managers, software engineers, data analysts and data scientists to build scalable and data-driven platforms and tools Ensure data integrity and scalability through enforcement of data standards. Improve data validation and monitoring processes to proactively prevent issues and quickly identify issues. Drive resolution on the issues. Define, understand, and test external/internal opportunities to improve our products and services. Requirements: Bachelor’s Degree in Computer Science or have equivalent professional experience Solid Experience with data processing tools such as Spark, Flink Solid Experience implementing batch and streaming data pipelines Solid experiences in Python/Go/Scala/Java. In-depth knowledge of both SQL and NoSQL databases, including performance tuning and troubleshooting Familiar with DevOps tools such as Git, Docker, k8s Experience with the cloud (e.g. AWS, Ali Cloud, GCP, Azure) Be proficient in SQL, familiar with advanced SQL features such as window functions, aggregate functions and creating scalar functions/user-defined functions. Proven successful and trackable experience in full end-to-end data solutions involving data ingestion, data persistence, data extraction and data analysis. Self-driven, innovative, collaborative, with good communication and presentation skills Fluent in English, both written and spoken. Preferred Qualifications: Experience in FinTech, eCommerce, SaaS, AdTech, or Digital Wallet business industries. Experience in working with teams across offices and timezones is a plus. Experience in big data tools such as Amplitude/Tableau/QlikView, Ali Cloud DataWorks, MaxCompute, Hadoop, Hive, Spark and HBase is a big plus. -",https://www.jobstreet.com.sg/en/job/data-engineer-1034913799?jobId=jobstreet-sg-job-1034913799&sectionRank=240&token=0~5fbdff54-2723-4448-ad48-8f635d265d31&fr=SRP%20Job%20Listing
240,Data Engineer,Keysight Technologies Singapore (International) Pte. Ltd.,"Keysight is on the forefront of technology innovation, delivering breakthroughs and trusted insights to the world’s visionaries and innovators in electronic design, simulation, prototyping, test, manufacturing, and optimization. Our ~15,000 employees create world-class solutions in communications, 5G, automotive, energy, quantum, aerospace, defense, and semiconductor markets for customers in over 100 countries. Our technical solutions – and our methods for creating them – help connect and secure the world. Learn more about what we do and how we do it. Our powerful culture has led to us being independently recognized on Fortune 100’s Best Companies List and we are “Great Place to Work” Certified. We’re driven, collaborative, ethical, and curious, and we value all ideas, especially bold ones. And our culture extends far beyond our own walls. Our corporate social responsibility efforts support our communities, nurture the next generation of engineers, and promote environmental sustainability. At Keysight, Inclusion, Equity &amp; Diversity is an integral part of our core values. We believe that when people feel a sense of belonging, they can be more creative, innovative, and thrive at all points in their careers. We believe everyone should be respected in the workplace and in their communities regardless of race, color, age, gender, sexual orientation, gender identity and expression, ethnicity, religion, disability, veteran status, national origin, or any protected class. We continuously challenge ourselves to grow in our understanding of inclusion by engaging in a wide variety of diversity programs, initiatives, employee network groups and mentoring/development. This is Keysight – People and Culture - YouTube Job Description The job is to design, define, maintain, and support the architecture of existing product. As a data engineer the person would be required to work with Big Data tools and frameworks, ETL processes, web services, collaborate with development teams, build platforms, and maintain the production system. You will work in an AGILE team to solve complex dev-ops challenges. design and implementation problems also to investigate new technologies and applications and apply modern software engineering practices such as unit testing and usability testing. About the Team: We are part of the Product Development team that is responsible for the growth of the Keysight businesses. The team consists of Manager, Architect, Data Engg, Data Scientist, UI/UX. We ensure the feature rich and highly performant product with well-designed architecture. Responsibilities: The candidate is responsible for developing sustainable and well-defined components that can enhance or introduce new innovative features to existing product. As the data engineer, you will do the following: Work in a team with other big data engineers and team leads on the feature design and development activities to achieve the sprint goals. Do the peer code review. Work in an AGILE team to turn innovative ideas into robust software and solve complex design and implementation problems. Work with the team leads to understand the problem statement and implement the solution. Job Qualifications Bachelor’s degree in Computer Science, Computer Engineering, or a software-related discipline, from an accredited college or university 3 to 5 years’ experience in Data Engineer related roles. Must have hands-on experience in Big Data (Hadoop, HBase, Hive, Scala) Must have hands-on experience in Spark development, Sqoop, Flume, Kafka and NIFI. Must have hands-on experience in relational and non-relational databases. Must have hands-on experience in built tool like Maven or SBT. Must have hands-on experience in version control tools like Gitlab or bit-bucket. Must have hands-on experience in CI/CD tools such as Jenkins and JIRA. Proven success working in a team-oriented environment and demonstrated problem-solving skills. Must have an ability to identify, formulate, and solve engineering problems. Desired Qualifications: Experience in design, implementation, and deployment of high volume, highly available, cloud-based systems would be a plus. Experience with real-time analytics will be an add-on. Experience with microservices and REST API will be an add-on. Experience with container platforms like OpenShift, Kubernetes or docker would be an add-on. Experience with configuration management tools like Ansible, Chef or Puppet would be an add-on. Experience on KX and KDB would be an add-on. Experience in bringing up Hadoop clusters and installing various packages would be an add-on. Experience with Agile software development methodologies and Test-Driven Design. A proactive and eager nature for tackling new challenges. Job Function R&amp;D Shift: Day Job Schedule: Full Time (F) Travel Required: &lt; 25% Employment Program: Internal Temporary Worker Duration (Temp Positions Only): &gt; 24 months __________________________________________________________________________________ Careers Privacy Statement ***Keysight is an Equal Opportunity Employer.*** Candidates can be considered to work from the following locations: APAC : Singapore : Singapore : Singapore Job ID: 49957 -",https://www.jobstreet.com.sg/en/job/data-engineer-1034776474?jobId=jobstreet-sg-job-1034776474&sectionRank=241&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
241,Senior Data Engineer (Digital),SPACE PTE. LTD.,"Why Work for Us We Power the Nation. Make the most of your talents and develop products that can create impact on a national scale. We are an in-house software team, assembled to move with speed and deliver with quality. We Build Reliable Solutions. For Customers, Company and Country. You will be part of the Digital Technology Team and together, you will innovate, create, and deploy digital products that will empower more than 3,800 employees within SP Group and improve the quality of life for the 1.6 million commercial, industrial and residential customers that SP Group serves. We build solutions that enable sustainable high quality lifestyles and help consumers save energy and cost, as well as supporting national goals for a sustainable livable city. Now, imagine the impact you can create. What You’ll Do: Create and maintain multiple robust and high-performance data processing pipeline within Cloud, Private Data Centre and Hybrid data ecosystem Assemble large, complex data sets from a wide variety of data sources Collaborate with Data Scientist, Machine Learning Engineer, Business Analyst and Business users to derive actionable insights and reliable foresights into customer acquisition, operational efficiency and other key business performance metrics Develop, deploy and maintain multiple microservices, rest API and reporting services Design and implement internal processes to automate manual workflow, optimize data delivery and re-designing infrastructure for greater scalability, etc Establish expertise in designing, analyzing and troubleshooting large-scale distributed systems What You’ll Need: Experience building and operating large scale data lake and data warehouse Experience with Hadoop ecosystem and big data tools, including Spark and Kafka Experience with stream-processing systems including Spark-Streaming Advance working experience with relational SQL and NoSQL databases, including Hive, Hbase and Postgres Deep understanding in SQL and able to optimize data queries Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc A successful history of manipulating, processing and extracting value from large disconnected datasets Experience applying modern development principles (Scrum, TDD, continuous integration, and code reviews) Bonus: Experience with ETL tools such as Talend Big Data, Apache Nifi, etc Experience working with Hortonworks Data Platform or Cloudera Data Platform Experience with Metadata Management tools Exposure to Data Governance processes and tools Proven ability in supporting and working with cross-functional teams in a dynamic environment Thank you for your interest in SP Group. You will be contacted if you are shortlisted for an interview. #LI-DNI -",https://www.jobstreet.com.sg/en/job/senior-data-engineer-digital-1035057621?jobId=jobstreet-sg-job-1035057621&sectionRank=242&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
242,Snr Consultant (Data Engineer / ETL / BI),NTT Data Business Solutions Singapore Pte Ltd,"Job Highlights Work Life Balance, Hybrid Work From Home Fun Working Environment &amp; Attractive Benefits Package Career Development Within a MNC Company Job Description As the leading analytics provider in APAC and part of our Company's growth, we are looking for dynamic, motivated, and dedicated individuals to be part of our team in Singapore. If you have the right skill set, driven, willing to learn and demonstrates a can-do attitude, come join us ! We welcome candidates of all levels. Responsibilities · Deliver end-to-end Business Intelligence, Analytics and Data Management solutions to customer · Work with the larger team in technical design sessions to define data definition, data and analytics solution requirements and specifications · Analyse business requirements, designing, developing, testing &amp; supporting application and Data warehouses from build to production (including proof-of-concept) · Ability to develop test plans and lead testing cycles · Provide product and application support and maintenance when needed · Actively participates in defining solution options and selecting the appropriate BI, Analytics and Data Management solution · Development of ETL pipelines, data management and BI platform · Ensures appropriate documentation, customer involvement and sign-off · Develop development framework and assign development effort to team members · Actively leads and manages team members to a successful project Requirements · Diploma/Degree in Computer Science / Computer Engineering / Information Technology related field or IT equivalent · Have 3 - 5 years’ experience in Business Intelligence/Data Warehouse/Analytics / Big Data Projects involving in requirements gathering designing, development, deployment, conducting knowledge transfer and post deployment support · Have 3 - 5 years’ experience with ETL, Business Intelligence and Visualization Tools · Have experience with Data Modelling using dimensional modelling techniques and designing the metadata layer for self-service analytics · Have experience actively leading and managing a team of 3 to 5 members · Independent with ability to work effectively in a team and who takes initiative and engages their colleagues · Excellent communication and interpersonal skills with ability to communicate with clarity and confidence with colleagues and customers · Likes technology, taking initiative to learn more and share knowledge with juniors and within the team · Proven abilities to take initiative, innovative and the ability to develop creative solutions for challenging client needs Additional knowledge it would be great to have: · SAP related skillsets S/4 HANA, SAP Analytics Cloud, SAP BW · Cloud and network concepts · Databases such as MariaDB, MySQL, PostgreSQL · Programming languages such as Java, Python, ******* with ****** or ****** · AWS, Azure or Google Cloud Platform services and products -",https://www.jobstreet.com.sg/en/job/snr-consultant-data-engineer-etl-bi-1034761361?jobId=jobstreet-sg-job-1034761361&sectionRank=243&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
243,Data Engineer,Encora,"If you decide that you wish to apply for a job with us, you may submit your contact information and your resume through Encore Sites. We will collect the information you choose to provide on your resume, such as your education and employment experience. We may use information provided by you in connection with your application for employment to assess your qualifications and we may share this information with clients and affiliates of Encora solely in connection with our efforts to evaluate you for a position at Encora or for assignment to one or more Encora Clients. **Encora has my consent to collect, store, and process my data for the purpose of considering me for employment, and for up to 1500 days thereafter. Please keep my application on file for consideration in connection with other positions at Encora and its affiliates\"",\""required\"":false}],\""legitimateInterestLegalBasis\"":\""LEGITIMATE_INTEREST_PQL\"",\""processingConsentType\"":\""REQUIRED_CHECKBOX\"",\""processingConsentCheckboxLabel\"":\"" I have read and agree to the Encora Terms of Use and Privacy Policy. \"",\""processingConsentFooterText\"":\"" If you decide that you wish to apply for a job with us, you may submit your contact information and your resume through Encore Sites. We will collect the information you choose to provide on your resume, such as your education and employment experience. We may use information provided by you in connection with your application for employment to assess your qualifications and we may share this information with clients and affiliates of Encora solely in connection with our efforts to evaluate you for a position at Encora or for assignment to one or more Encora Clients. \"",\""privacyPolicyText\"":\"" **Encora has my consent to collect, store, and process my data for the purpose of considering me for employment, and for up to 1500 days thereafter. \"",\""isLegitimateInterest\"":false}"",""embed Type"":""REGULAR"",""disableCookieSubmission"":""true"",""renderRawHtml"":""true"",""user Agent"":""Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36 JobBot/2.0 (+***************)"",""page Title"":""Encora Jobs"",""page Url"":""***************"",""page Id"":""54643943513"",""url Params"":{""4805733004?gh_jid"":""4805733004""},""isHubSpotCmsGeneratedPage"":true,""canonical Url"":""***************"",""content Type"":""standard-page"",""hutk"":""1f96a6f911c06a4a135b7a396fd158af"",""__hsfp"":2104123436,""__hssc"":""119895511.2.1676862961290"",""__hstc"":""119895511.1f96a6f911c06a4a135b7a396fd158af.1676862961290.1676862961290.1676862961290.1"",""form Target"":""#internal-form"",""boolCheckBoxFields"":""LEGAL_CONSENT.subscription_type_70802668,LEGAL_CONSENT.processing"",""locale"":""en"",""timestamp"":1676862974123,""originalEmbedContext"":{""portal Id"":""7958737"",""form Id"":""d278aac2-6b59-4e39-8856-8fc90c066bc6"",""region"":""na1"",""target"":""#internal-form"",""is Builder"":false,""isTestPage"":false},""correlation Id"":""372f8693-c84c-4bd4-8a39-160db1b3a350"",""renderedFieldsIds"":[""firstname"",""lastname"",""email"",""country_selector"",""linkedin"",""document"",""availability_to_start_working"",""candidate_gh_job_id"",""candidate_source_id"",""LEGAL_CONSENT.subscription_type_70802668"",""LEGAL_CONSENT.processing""],""captcha Status"":""LOADED"",""emailResubscribeStatus"":""NOT_APPLICABLE"",""isInsideCrossOriginFrame"":false,""source"":""forms-embed-1.2715"",""source Name"":""forms-embed"",""source Version"":""1.2715"",""sourceVersionMajor"":""1"",""sourceVersionMinor"":""2715"",""_debug_allPageIds"":{""analyticsPageId"":""54643943513"",""pageContextPageId"":""54643943513""},""_debug_embedLogLines"":[{""client Timestamp"":1676862973002,""level"":""INFO"",""message"":""Retrieved customer callbacks used on embed context: [\""onFormReady\""]""},{""client Timestamp"":1676862973006,""level"":""INFO"",""message"":""Retrieved country Code property from normalized embed definition response: \""US\""""},{""client Timestamp"":1676862973959,""level"":""INFO"",""message"":""Retrieved analytics values from API response which may be overriden by the embed context: {\""hutk\"":\""1f96a6f911c06a4a135b7a396fd158af\"",\""canonical Url\"":\""***************\"",\""content Type\"":\""standard-page\"",\""page Id\"":\""54643943513\""}""}]}""&gt; -",https://www.jobstreet.com.sg/en/job/data-engineer-1034839463?jobId=jobstreet-sg-job-1034839463&sectionRank=244&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
244,Systems Analyst (Data Engineer) – Technical Role,Urban Redevelopment Authority,"What the role is The Urban Redevelopment Authority (URA) is Singapore’s planning authority. Our mission is to make Singapore a great city to live, work and play. We plan and facilitate the physical development of Singapore, in partnership with agencies and the community, to create a vibrant, sustainable and cosmopolitan city of distinction. URA has undergone a digitalisation journey to harness geospatial and data analytics for more data-informed planning. URA was recognized as a leading organization in Digital Transformation with the awarded Asia Pacific 2017 regional DX Leader for Information Visionary and Talent Acceleration by IDC and 2019 Business Transformation Award by PSD. URA has since embarked on a Digitalization 2.0 effort to deepen our capabilities, from planning analytics to the use of artificial intelligence (AI) to support our planning processes. URA has recently been designated as the Urban Planning &amp; Design Technology Centre of Excellence (URBEX), where we aim to build up strategic and critical science, technology and engineering capabilities in an efficient and sustainable manner. We will play the role to digitalise and cohere the Whole-of-Government urban planning &amp; design ecosystem in its use of data, tools and models. We also aim to drive innovation, encourage experimentation and sharing of lessons learnt and further strengthen synergies across agencies, and streamline processes. Be part of the URA Design &amp; Planning Lab (DPLab), which spearheads development and experimentation of smart planning technologies through ops-tech inter-disciplinary collaborations. As part of URBEX, our teams with capabilities in software development, geospatial analytics, urban design modelling &amp; simulation, data science, data governance and management, work closely with planners, architects, policy makers across various agencies, as well as external partners, to generate insights and develop solutions to tackle interesting and unique challenges of Singapore’s urban planning needs. What you will be working on Join the DPLab team and be part of the expansion and optimisation of our data warehouse and pipelines across systems and agencies. You will be involved in developing the strategy, designing the architecture and managing various data pipelines into URA’s data warehouse, exploring different data-sharing platform architecture, integrating data interfaces across backend systems and ensuring seamless data and model-sharing across domains. The data engineering work will directly support data science and analytics, geospatial processing, and the development of digital tools and platforms. The work is exciting, enriching and dynamic, and will require you to interact with a wide spectrum of business users, data scientists and analysts, software developers and other technology expertise within URA and across the public sector. What we are looking for Requirements: ● Degree in Computer Science, Engineering, or related disciplines ● Experienced in data engineering works including implementation of data pipelines, sharing of data interfaces and the maintenance of data platform ● Familiarity in use of SQL and relational database like PostgreSQL for data storage and replication, PostGIS for geospatial queries ● Familiarity in supporting simulation and modelling tools and scripting ● Ability to work well in a team, and be willing to learn Preferences: ● Experienced in working with urban planning, transport planning, environmental modelling or related fields ● Familiarity with CI tools and technologies such as Git, Phabricator, Jenkins and JupyterHub ● Familiarity in cloud-based deployment solutions like Microsoft Azure, Amazon Web Services or Google Cloud Platform -",https://www.jobstreet.com.sg/en/job/systems-analyst-data-engineer-technical-role-1034979614?jobId=jobstreet-sg-job-1034979614&sectionRank=245&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
245,Senior Data Engineer,AMPLIFY HEALTH ASIA PTE. LIMITED,"Instructions for interested applicants Please apply for this position via the following link *************** What you will do? The role entails building a reusable sustainable framework to ensure collection, processing and availability of high-quality health care data to enable us to achieve the core purpose. The Data Engineer will work collaboratively with the Program Managers, Data Scientists, Systems Architects to define data sources and to build a custom data framework that facilitates Machine Learning, AI and productionising AI models based on the principles of ETL/ELT. Together these teams will enable data driven actionable insights. The role is based in Singapore. Core responsibilities include: Develop and implement a reusable architecture of data pipelines to make data available for various purposes including Machine Learning (ML), Analytics and Reporting Work collaboratively as part of team engaging with system architects, data scientists and business in a healthcare context Work comfortably with structured and unstructured data in a variety of different programming languages such as SQL, R, python, Java etc Understanding of distributing programming and advising data scientists on how to optimally structure program code for maximum efficiency Build data solutions that leverage controls to ensure privacy, security, compliance and data quality Understand meta-data management systems Orchestration architecture in the designing of ML/AI pipelines Deep understanding of cutting-edge cloud technology and frameworks to enable Data Science System integration skills between Business Intelligence and source transactional Improving overall production landscape as required Write unit tests and participate in code reviews Define strategies with Data Scientists to monitor models postproduction What skills do you need? Behavioural skills A passion for programming and working with data Self-starter Experience of leading a team to deliver solutions Willingness to learn and grow exponentially A restless curiosity in learning new technology Ability to work cohesively in a team environment and balance multiple priorities A team player who can work alone when required and without supervision High level of attention to detail, resilience, enthusiasm, energy and drive Positive, can-do attitude Ethical and able to maintain confidentiality and manage boundaries Technical understanding Essential: Advanced database knowledge in SQL Advanced MS Azure tools such as Azure Data Factory Synapse Analytics Azure Data Lake Gen2 Azure Databricks Modern Azure datawarehouse skills Experience working on large and complex datasets Advantageous: Programming languages such as R Python Scala Java Unix/Linux admin experience including shell script development Exposure to AI or model development Knowledge of: Azure stream analytics PowerBI Azure ML Services ML Flow Understanding and application of Big Data and distributed computing principles (Hadoop and MapReduce) ML model optimization skills in a production environment Production environment machine learning and AI DevOps/DataOps and CI/CD experience Kubernetes and container setup and configuration Feature store design and development Master data management Qualifications The following requirements are preferred: Honours or Master’s degree in BSc Computer Science Honours or Master’s degree in Engineering or Software Engineering with solid experience in data mining and machine learning Other qualifications will also be considered if accompanied by the relevant experience 10 to 15 years of experience is preferred -",https://www.jobstreet.com.sg/en/job/senior-data-engineer-1034743954?jobId=jobstreet-sg-job-1034743954&sectionRank=246&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
246,Data Engineer,maxeon solar pte. ltd.,"Work with Industry 4.0 data program team which includes project implementation vendor resources, data experts from manufacturing engineering team, data analysts &amp; business stakeholders. Support end to end set up of data platform which is scalable and future proof for Maxeon based on the functional/non-functional &amp; technical requirements. Integrate data platform with Maxeon Applications and 3rd party system as required from both On-Premise and Multi Cloud. Expand and optimize our data and data pipeline architecture, as well as optimize data flow systems in a secured and scalable manner. Assemble large, complex data sets that meet functional / non-functional business requirements, transforming data into formats that are easy to consume and analyze. Translate complex business requirements into scalable technical solutions meeting data warehousing design standards. Solid understanding of analytics needs and proactiveness to build generic solutions to improve overall efficiency. Data Profiling &amp; Cleansing of data by applying data quality checks before ingesting the data. Ingest, transform, process and store data efficiently into a database, data lake or Datawarehouse platform hosted on premise or cloud based environment. Design &amp; Build database, Enterprise Datawarehouse design and data modelling. To be able to organize data at both macro and micro level and provide logical data models for the consumers. Build data foundation to provide an enterprise view of data across the organization which can be seamlessly accessed by Business users through Self-Service reporting. Build a centralized data repository (Sand Box environment) with a robust data foundation to enable data discovery, data mining for advanced analytics usecases. Work with stakeholders including the Product owner, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Work with data and analytics experts to strive for greater functionality in our data systems. Able to communicate effectively, both written and verbal, with technical and non-technical multi-functional team Knowledge and Technical Skills: Bachelors degree in Science or Information Technology Certified in Data &amp; Analytics Cloud based solution Proven track record in designing and implementing large-scale data solutions, performing architectural assessments, optimizing data models, establish and enforce engineering guidelines and standards on Cloud based environments 4+ years of experience in technical architecture, design &amp; build of Data &amp; Analytics projects in a multinational organization on On-Premise &amp; Cloud based solutions. In-depth experience in working with a data warehouse and knowledgeable on data warehouse modelling techniques Highly knowledgeable in ETL/ELT processes, both design and implementation using various leading tools like for example Informatica, Ab-Initio, Talend etc Experienced in implementing data pipelines for stream and batch ingestion/processing using Open-Source tools (Kafka, Apache Spark) as well as Cloud Native solutions. Good experience in building data pipelines that ingests various types of data sources (structured, semi-structured and unstructured) into a database or data lake and populating a structured warehouse or data mart Experienced in building data lake (distributed storage, Object store), databases &amp; Datawarehouse in cloud (AWS, Azure, GCP), moving data applications to the cloud, and developing cloud native data applications. Experienced in implementing SQL, NoSQL databases &amp; MPP databases Experience in Data archiving &amp; Life Cycle Management. Data Warehouse design, BI reporting and Dashboard development. Prior experience in leading a team of technical developers will be a plus Advanced SQL and Python skills are mandatory Prior data modeling (dimensional, relational) and data engineering experience is mandatory Prior experience in leading a team of technical developers will be mandatory Strong understanding of development processes and agile methodologies is necessary Complexity: Works on problems and projects of diverse complexity. Engages in analyses requiring evaluation of identifiable factors. Exercises independent judgment within generally defined boundaries. Networks with senior individuals, internally and externally, within own area of expertise. -",https://www.jobstreet.com.sg/en/job/data-engineer-1034775531?jobId=jobstreet-sg-job-1034775531&sectionRank=247&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
247,Senior Data Engineer,Visa,"Company Description Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive. When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement. Join Visa: A Network Working for Everyone. Job Description This position is ideal for an engineer who is passionate about solving challenging business problems and building applications that provide an excellent user experience. You will be an integral part of the Payment Products Development team focusing on design and development of software solutions that leverage data to solve business problems. The candidate will be extensively involved in hands-on activities including POCs, design, documentation, development, and testing of new functionality. Candidate must be flexible and willing to switch tasks based on team's needs. Responsible for the design, development, and implementation. Work on development of new products iteratively by building quick POCs and converting ideas into real products. Design and develop mission-critical systems, delivering high-availability and performance. Interact with both business and technical stakeholders to deliver high quality products and services that meet business requirements and expectations while applying the latest available tools and technology. Develop code to ensure deliverables are on time, within budget, and with good code quality. Have a passion for delivering zero defect code and be responsible for ensuring the team's deliverables meet or exceed the prescribed defect SLA. Coordinate Continuous Integration activities, testing automation frameworks, and other related items in addition to contributing core product code. Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner. Perform other tasks on R&amp;D, data governance, system infrastructure, and other cross team functions, on an as-needed basis This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs. Qualifications We are seeking team members that are passionate, visionary and insatiably inquisitive. Successful candidates frequently have a mix of the following qualifications: 2 or more years of work experience in building large-scale applications using open source technologies Bachelor’s Degree or an Advanced Degree (e.g. Masters) in Computer Science/ Engineering, Information Science or a related discipline Extensive experience with SQL and Big Data technologies (Hadoop, Java, Spark, Kafka, Hive etc.) tools for large scale data processing and data transformation Experience with data visualization and business intelligence tools like Tableau, or other programs highly desired Familiar with software design patterns Experience working in an Agile and Test-Driven Development environment Strong knowledge of API development is highly desired Strategic thinker and good business acumen to orient data engineering to the business needs of internal and external clients Demonstrated intellectual and analytical rigor, strong attention to detail, team oriented, energetic, collaborative, diplomatic, and flexible style Previous exposure to financial services is a plus, but not required Please Note: Due to the COVID-19 pandemic and the evolving visa/travel restrictions in place, we are currently only able to extend offers to candidates with the right to work in Singapore. We are keeping the situation under close review and will adjust accordingly should the restrictive measures be lifted. Additional Information Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law. -",https://www.jobstreet.com.sg/en/job/senior-data-engineer-1034743392?jobId=jobstreet-sg-job-1034743392&sectionRank=248&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
248,Data Production Engineer,Roc Tech Pte. Ltd.,"Overview As a data engineer, you need to have a deep insight into data usage across the entire company and support trading, risk management, and product operations. The job requires the candidate to take on the challenge of keeping curious about cutting-edge technologies in the fields of quantitative trading and data mining, as we are continually looking for new potentially valuable data and leverage them to benefit our trading. What you’ll do •Maintain and oversee internal data production pipelines; •Develop data ETL pipelines, data management platform, and other relevant data systems; •Explore alternative data and perform preliminary data mining We expect you to have •A bachelor’s degree in computer science, financial engineering, or related field; •Experience in developing data extraction, transformation, and load (ETL) pipelines in Python; •Experience with big data or data modeling is preferred; •Comprehensive knowledge of relational databases (MySQL/SqlServer/Oracle) and experience with big data infrastructure; -",https://www.jobstreet.com.sg/en/job/data-production-engineer-1034856089?jobId=jobstreet-sg-job-1034856089&sectionRank=249&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
249,Senior Data Science,VGroup Holdings Pte Ltd,"We are looking for an amazing Senior Data Engineer to support our growth! The Senior Data Engineer will oversee the company’s data ingestion / integration work, including developing a data model, maintaining a data warehouse and analytics environment, and writing scripts for data ingestion / integration and analysis. This role will work closely and collaboratively with members of the Data &amp; Analytics and Development teams to define requirements, mine and analyze data, integrate data from a variety of sources, and deploy high quality data pipelines in support of the analytics needs. He will also be responsible for creating automated reporting / data visualization system based on the request of internal stakeholders. In short, what you will do Maintain and build on our data warehouse and analytics environment, the home for various source data generated in the company. Design, implement, test, deploy, and maintain stable, secure, and scalable data engineering solutions and pipelines in support of data and analytics projects, including integrating new sources of data into our central data warehouse, and moving data out to applications. Build reports and data visualizations, using data from the data warehouse and other sources. Produce scalable, replicable code and engineering solutions that help automate repetitive data management tasks. Perform one-off data manipulation and analysis on a wide variety of source data. Implement and monitor best in class security measures in our data warehouse and analytics environment. Help other data team staff troubleshoot their SQL, Python, or R code. Train other data team staff on these skills. Other duties as assigned. What you need to bring along Bachelor’s Degree with related field or equivalent work experience with strong command of relational databases and SQL. Extract, Transform, and Load (ETL) data into a relational database. Proficiency with Python or R, especially for data manipulation and analysis, and ability to build, maintain and deploy sequences of automated processes with these tools. General data manipulation skills: read in data, process and clean it, transform and recode it, merge different data sets together, reformat data between wide and long, etc. Demonstrated ability to learn new techniques and troubleshoot code without support and ability to write clear code that is well-documented and stored in a version control system (Gitlab). Experience in working with cloud infrastructure services like Amazon Web Services, Data Visualization (Power BI, Tableau) is an added advantage. Exercise good judgement and ability to prioritize multiple tasks in a timely manner Must be proficient in MS Word and MS Excel An ability to perform well in a fast-paced environment Excellent analytical and multitasking skills with the ability to solve problems creatively and effectively Ability to work independently while collaborating in a fast-paced agile team Ability to speak Mandarin and English fluently in order to communicate with global colleagues and stakeholders Why Join Us? Be at the forefront in an exciting sector. For over a decade strong year, Vantage has been an award-winning global financial services firm providing market opportunities to all clients globally. With millions of active traders ranging from retail traders to high-net-worth and institutional traders, you will have the opportunity to get your foot in the door working for a global powerhouse that has a local focus. a household name – Vantage is now looking to accelerate our growth in the Asia Headquarter that based in Singapore that known as Vgroup. We are seeking someone that is willing to learn and apply their knowledge and stretch their creative thinking to support us during this momentous journey. Generous Benefits and Perks. We understand benefits and perks matter to the individual. With that, we have irresistible benefits and perks that you cannot resist. Amazing growth and learning opportunities. We are a tight-knit team where everyone grows together. We’ll continuously work with you to refine your strengths and strengthen your weakness to further your personal and career development. For a confidential discussion, click here to apply. Due to the high volume of applicants, we regret that only shortlisted candidates will be notified. -",https://www.jobstreet.com.sg/en/job/senior-data-science-1035057016?jobId=jobstreet-sg-job-1035057016&sectionRank=250&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
250,Data Engineers,adecco personnel pte ltd,"Job Requirements - As a Data Engineering Architect, you will use comprehensive modern data engineer techniques and methods with Advanced Analytics to support business decisions for client. - You can collect, aggregate, and analyze structured/unstructured data from multiple internal and external sources and patterns, insights, and trends to decision-makers. - Your goal is to support the use of data-driven insights to help our Clients achieve business outcomes and objectives. - In this role, you will collect, aggregate, store, and reconcile data in support of Client business decisions. - You will help design and build data pipelines, data streams, reporting tools, information dashboards, data service APIs, data generators and other end-user information portals and insight tools. - You will be a critical part of the data supply chain, ensuring that stakeholders can access and manipulate data for routine and ad hoc analysis to drive business outcomes using Advanced Analytics. • Translate business requirements to technical solutions leveraging strong business acumen. • Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data &amp; Analytics PaaS Services. • Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments. • Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies. Design and Build Modern Data Pipelines and Data Streams. Design and Build Data Service APIs. • Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics. • Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience. • Implement effective metrics and monitoring processes. Saghana Sithara | Registration Number: R1550224 -",https://www.jobstreet.com.sg/en/job/data-engineers-1034777861?jobId=jobstreet-sg-job-1034777861&sectionRank=251&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
251,Data Architect,adecco personnel pte ltd,"Job Requirements - As a Data Engineering Architect, you will use comprehensive modern data engineer techniques and methods with Advanced Analytics to support business decisions for client. - You can collect, aggregate, and analyze structured/unstructured data from multiple internal and external sources and patterns, insights, and trends to decision-makers. - Your goal is to support the use of data-driven insights to help our Clients achieve business outcomes and objectives. - In this role, you will collect, aggregate, store, and reconcile data in support of Client business decisions. - You will help design and build data pipelines, data streams, reporting tools, information dashboards, data service APIs, data generators and other end-user information portals and insight tools. - You will be a critical part of the data supply chain, ensuring that stakeholders can access and manipulate data for routine and ad hoc analysis to drive business outcomes using Advanced Analytics. • Translate business requirements to technical solutions leveraging strong business acumen. • Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data &amp; Analytics PaaS Services. • Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments. • Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies. • Design and Build Modern Data Pipelines and Data Streams. • Design and Build Data Service APIs. • Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics. • Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience. • Implement effective metrics and monitoring processes. • Travel as needed Saghana Sithara | Registration Number: R1550224 -",https://www.jobstreet.com.sg/en/job/data-architect-1034793815?jobId=jobstreet-sg-job-1034793815&sectionRank=252&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
252,"Lead, Data Foundation",Great Eastern SG,"Job Purpose At Great Eastern, we are building a data platform to realize the full value of our data. We seek an experienced Big Data Engineer to join our growing data engineering and analytics team. The right person for the job will have strong knowledge of Big Data Engineering and proven ability to strategize the implementation of data and analytics capabilities on a data platform (on premise and cloud) — from conception through release and production. The ideal candidate will be a strong data engineer; be willing to wrangle data, optimize data systems and products, and build them from the ground up. Experience with AWS, Snowflake, and migration to public could would be an advantage. The Job Own the technical strategic roadmap planning and execution for the Great Eastern Group Data Foundation (data lake, DWH) and Enterprise data stores. Collaborate with engineering teams, product managers, and data scientists to inform this roadmap. Establish data generation, collection, transformation best practices Design and develop enterprise data stores, unified data schemas and tables Scale our data pipelines, tools and data stores Own data engineering practices, raising the bar for the quality and speed of software delivery and operations. Set clear measurable goals for your data engineers. Foster a culture of continuous growth improvement through coaching, mentoring, feedback and clear measurable outcomes. Attract, develop and retain great engineers who are passionate about data engineering and serving internal and external users. Support their career growth and development. As part of the leadership team, work with key stakeholders to proactively shape the organisation’s culture and conduct environment that is aligned to the organization’s Core Values Champion culture and conduct behavioral expectations within the Department/Division Takes accountability in considering business and regulatory compliance risks and takes appropriate steps to mitigate the risks. Maintains awareness of industry trends on regulatory compliance, emerging threats and technologies in order to understand the risk and better safeguard the company. Highlights any potential concerns /risks and proactively shares best risk management practices. Our Requirements 10+ years experience as a hands-on senior data engineering leader A track record of developing and leading data teams via mentorship and coaching diverse, multi-cultural engineers and engineering managers. Experience in query optimization, resource management, and data lake/warehouse performance Experience with data workflow/orchestration platforms (ex. Airflow, KubeFlow, Argo, Luigi) Experience with data streaming platforms (ex. Beam, Dataflow) Understanding of distributed compute engines (ex. Presto, Spark, Flink) and modern Big-Data storage technologies (ex. Delta Lake, Iceberg, Hudi) Experience with cloud infrastructure (ex. Google Cloud, Kubernetes, Terraform) Business understanding and ability to manage a budget. Ability to identify, evaluate and convey the engineering and technology choices and trade offs. Bachelor’s degree, with a strong academic record, in Computer Science or Engineering, Masters preferred. Demonstrates alignment with the organisation’s core values through expected behaviours High level of integrity, takes accountability of work and good attitude over teamwork. Takes initiative to improve current state of things and adaptable to embrace new changes. About Great Eastern Established in 1908, Great Eastern places customers at the heart of everything we do. Our legacy extends beyond our products and services to our culture, which is defined by our core values and how we work. As champions of Integrity, Initiative and Involvement, our core values act as a compass, guiding and inspiring us to embrace the behaviours associated with each value, upholding our promise to our customers - to continue doing our best for them in a sustainable manner. We work collaboratively with our stakeholders to look for candidates who exhibit or have the potential to embrace our core values and associated behaviours, as these are the key traits that we expect from our employees as they develop their careers with us. We embrace inclusivity, giving all employees an equal opportunity to shine and play their role in exploring possibilities to deliver innovative insurance solutions. Since 2018, Great Eastern has been a signatory to the United Nations (UN) Principles of Sustainable Insurance. Our sustainability approach around environmental, social, and governance (ESG) considerations play a key role in every business decision we make. We are committed to being a sustainability-driven company to achieve a low-carbon economy by managing the environmental footprint of our operations and incorporating ESG considerations in our investment portfolios; improving people’s lives by actively helping customers live healthier, better and longer; and drive responsible business practices through material ESG risk management. To all recruitment agencies: Great Eastern does not accept unsolicited agency resumes. Please do not forward resumes to our email or our employees. We will not be responsible for any fees related to unsolicited resumes. -",https://www.jobstreet.com.sg/en/job/lead-data-foundation-1035026249?jobId=jobstreet-sg-job-1035026249&sectionRank=253&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
253,Data Engineer,Simulation Software &amp; Technology (S2T) Pte Ltd,"We are on the lookout for a highly competent, self-motivated Data Engineer to join our team. The ideal candidate will have experience in scaping data from social media platforms and the ability to reverse engineer undocumented APIs. The Role: Develop and maintain efficient scripts to scrape data from social media platforms. Clean and organize data sets for analysis. Work with the data science team to implement data models and algorithms. Continuously monitor the performance of the scraping process and make improvements as necessary. Reverse engineer undocumented APIs and navigate complex web structures to extract data. Requirement: A degree in Computer Science from a recognized foreign or local university; a relevant master’s degree will be an added qualification. 2 to 4 years of relevant working experience with data scraping and Web scraping techniques Strong technical and analytical skill sets. Familiarity with Python and its libraries for data scraping such as beautiful soup, selenium and scrapy. Experience with data cleaning and preprocessing Good presentation skills, both oral and written. Passionate about innovating, learning new skills and technology. Interested parties, please send your resume with current &amp; expected salary &amp; date available to ********@s2t.ai. We regret only shortlisted applicants will be notified. -",https://www.jobstreet.com.sg/en/job/data-engineer-1035041685?jobId=jobstreet-sg-job-1035041685&sectionRank=254&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
254,Senior / Data Engineer,Liberty Insurance Pte Ltd,"We are looking for a Senior / Data Engineer that under limited direction, prototypes/develops data solutions of high complexity to meet the needs of the organization and business customers. This person needs to have a good communication skill to be able to manage project across East markets. You will use various methods to transform raw data into useful data systems. For example, you’ll create data for pricing modeling and conduct data quality checks. Overall, you’ll strive for efficiency by aligning data systems with E&amp;W modeling teams’ goals. To succeed in this data engineering position, you should have strong analytical skills and the ability to combine data from different sources. Data Engineer skills also include communication, familiarity with several programming languages and knowledge of learning machine methods. Responsibilities: With a comprehensive understanding of Agile techniques, set expectations for deliverables of high complexity. Maintains proof-of-concepts and prototype data solutions, and handles any assessment of their viability and scalability, with own team or in partnership with IT. Ensures data solutions include deliverables required to achieve high quality data. Displays a working understanding of complex multi-tier, IT | Data teams’ systems, and applies principles of metadata, lineage, business definitions, compliance, and data security to project work. Experience: 5+ years previous experience as a data engineer or in a similar role. Technical expertise with data models and data pipeline automation. Experience with big data tools: Spark, Kafka is a plus. Experience with as developer with SAS and SQL databases, including Postgres, Oracle and SQL Server. Hands-on experience with AWS cloud services: S3, Glue, Crawlers, EC2, EMR, RDS, Redshift. Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc. Degree in Computer Science, IT, or similar field; a master’s is a plus. Data engineering certification (AWS) is a plus. -",https://www.jobstreet.com.sg/en/job/senior-data-engineer-1035027394?jobId=jobstreet-sg-job-1035027394&sectionRank=255&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
255,Data Engineer (Power BI / SQL),Optimum Solutions (S) Pte Ltd,"Roles and Responsibilities: · Collaborate with business and Technology users to analyse user requirements and contribute to defining data models. Deliver Visualization programs · Deliver world class dashboard and analytics solutions using company standard datalake in snowflake and appropriate tools – to start with MS PowerBI and progressively to either python based or Java based UI · Contribute and Use best practices in PowerBI and other tools · Work with SQL to extract, transform and load data in snowflake and use powerbi visualization tools · Create functional and technical specifications · Provide thought leadership Requirements: Progressive work experience in the field of Business Intelligence, information management, data engineering Demonstrable experience and proficiency in PowerBI Data modelling skills Proficiency in SQL – for ETL tools Strong data storytelling experience Graduate in STEM. Post graduation preferred -",https://www.jobstreet.com.sg/en/job/data-engineer-power-bi-sql-1034872999?jobId=jobstreet-sg-job-1034872999&sectionRank=256&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
256,Associate data engineer / data engineer - artificial intelligence sap,CONCUR TECHNOLOGIES (SINGAPORE) PTE. LTD.,"We help the world run better Our company culture is focused on helping our employees enable innovation by building breakthroughs together. How? We focus every day on building the foundation for tomorrow and creating a workplace that embraces differences, values flexibility, and is aligned to our purpose-driven and future-focused work. We offer a highly collaborative, caring team environment with a strong focus on learning and development, recognition for your individual contributions, and a variety of benefit options for you to choose ********** now!*SAP will be prioritizing candidates with full working rights in Singapore. Candidates who require work passes need not apply. * About SAP A market leader in end-to-end business application software, SAP helps more than 425,000 customers worldwide work together more efficiently. We know that a diverse and inclusive workforce keeps us competitive and provides opportunities for all. We believe that together we can transform industries, grow economics, lift societies, and sustain our environment. Because it’s the best-run businesses that make the world run better and improve people’s lives. At SAP, we build breakthroughs, together. About SAP Labs Singapore SAP Labs Singapore is the 20th engineering hub in the SAP Labs Network and is the newest innovation hub at SAP that drives product leadership, fosters the best talent, and aims to boost ecosystem and community engagement with a variety of *************** Labs Singapore has the ambition to expand significantly and become the Embedded Artificial Intelligence Hub for SAP, leveraging on core competencies in the current teams. Your future team SAP Labs Singapore has experienced professionals taking on challenges posed by the SAP customers. Based in Singapore, you will have the opportunity to work on breakthrough projects addressing real-world problems, challenging norms with some of the SAP’s key customers. As part of the global product engineering team, you will participate in rich and engaging conversations with experts around the ********* Labs Singapore provides an open, modern working environment and the opportunity to become part of the global SAP engineering community. Purpose and objectives As an Associate AI Data Engineer / AI Data Engineer, you will work together with a team of dedicated experts including AI scientists, AI Developers, dev-ops engineers, and architects with a single goal of building the best-in-class AI products. You will work against fixed timelines and your success will be measured by the ability to deliver solutions matching the performance of top-notch artificial intelligence systems.Applicants with relevant experience may be considered for AI Developer role. Expectations and tasks Your Tasks Include Push the frontiers of what is possible in the area of artificial intelligence and machine learning so as to create new solutions Explore, understand, and implement most recent technologies and approaches for data pipelines for data pre and post processing Comfortably handle multi-terabyte data sets in scale-up and scale-out environments Supports machine learning research/project teams with all aspects around data Builds scalable and re-usable data processing pipelines Works on data generators in order to enrich our datasets Sets up and manages annotation projects with our annotation partner companies Works with domain experts and AI Scientists to define annotation guidelines and drive the annotation efforts towards high-quality data Coordinates &amp; supports data auditing efforts Coordinates &amp; supports data acquisition activities Integrates, validates, organizes, improves and curates datasets including metadata (e.g. data versioning, cleaning, storing, etc.) Work closely with the team, customers and partners to holistically understand business and user requirements and derive adequate application development concepts Ability to work in global teams with different time zones Immerse yourself quickly into new topics, terminology, and development tasks Required Educational and experience requirements Degree in Computer Science or related field 0 to 3 years of working experience as software developer or data engineer in AI focused application development A solid foundation in computer science, with strong competencies in algorithms, data structures, objects-oriented programming, design patterns, multi-threaded programming, and software design principles Hands-on knowledge in at least one of the server-side programming languages such as Java, Scala, Go, Python, C#, C++ Exposure to Big Data technologies such as Hadoop, Spark and Kafka Fundamental knowledge of container technologies like docker, Kubernetes etc. Experience with cloud-based application development using platforms such as SAP’s business technology platform, AWS, Azure &amp; Google Cloud Platform is a plus. Familiar with Agile/Scrum methodologies Strong desire to overcome obstacles and make your work benefit SAP's customers Excellent written and communication skills in English language Optional Hands-on knowledge of the frameworks such as Spring, Play, AngularJS, Flask etc. Hands-on experience in Shell Scripting, PowerShell Operational knowledge of Linux distributions such as Redhat, Ubuntu, CentOS, CoreOS Exposure to deployment and container orchestration technologies such as Docker, Kubernetes, Puppet, Chef, Ansible Knowledge of Machine Learning fundamentals Job Segment: Developer, Cloud Applications, Cloud Operations, Machine Learning, Artificial Intelligence, Data science development We build breakthroughs together SAP innovations help more than 400,000 customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with 200 million users and more than 100,000 employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, we build breakthroughs, together. We win with inclusion SAP’s culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone – regardless of background – feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable ********* is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: *******@sap.comFor SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy. Specific conditions may apply for roles in Vocational Training. EOE AA M/F/Vet/Disability Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, ethnicity, age, gender (including pregnancy, childbirth, et al), sexual orientation, gender identity or expression, protected veteran status, or disability.Successful candidates might be required to undergo a background verification with an external vendor.Requisition ID: 367470 | Work Area: Software-Design and Development | Expected Travel: 0 - 10% | Career Status: Graduate | Employment Type: Regular Full Time | Additional Locations: . -",https://www.jobstreet.com.sg/en/job/associate-data-engineer-data-engineer-artificial-intelligence-sap-1034940965?jobId=jobstreet-sg-job-1034940965&sectionRank=257&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
257,Technical Data Engineer,Oversea-Chinese Banking Corporation Ltd,"Bank of Singapore is currently looking for a qualified candidate to assist the Data Engineering Team’s operational and analytical needs. The Technical Data Enginer will work alongside Data Analytics and big data platform (Hadoop) and engineering team to provide data related support, data ingestion, data interface for unstructured/structred data, data analytics and data management. This person will also assist in building interfaces from various upstream systems and ingest the data into Micrsoft SQL server 2019 / Cloudera Hadoop data store and build the enterprise visulasation tool. This is a great opportunity for someone who is interested in innovative group with the possibility of tremendous career development in data engineering, big data management, data analytics and enterprise data visulsaisation tool. A little more about this role: As our Technical Data Enginer, you will be instrumental in big data coding and work in Hadoop-ecosystem. This is a brand-new position at Data Competency vertical. · Perform extensive unstructured data ingestion into Hadoop · StronG knowledge of Anaconda, Data visualisation BI tool, Python, SPARK, Java Scala, HIVE and Beeline with hands on experience · Ability to organize and lead meetings with business and operational data owners · Experience in integrating data processes with architecture requirements used across company · Understand Hadoop-ecosystem and Data Engineering activities as well as loading data from several disparate datasets and documentation · Strong ability to troubleshoot and resolve data issues · Analytical skill to perform data profiling and data visulization · Experience in Agile and Waterfall frameworkWork · Work closely with engineering and operations to document business processes · Work independently and with team members to understand database structure and business processes · Help form data management and governance processes within the data engineering team What you’ll need to have: · Graduate degree in statistics, math, computer science, physics or other technical related fields; Master’s degree is preferred · Minimum of 10 years working experience in technical data analysis, data science, or data warehousing with proven business analysis experience · Experience in at least one or more languages: SPARK, Java Scala,Python · Experience writing Java Scala, Python · Experience with Hadoop · Hands on expierence or knowledge of minimum one mainstream cloud infrastructures:AWS,MS Azure and GCP; ablity to implement data lake. · Good to have Hands-on experienceon the Hadoop, MangoDB,SPARK, Scala, HIVE, Kafka ,Beelin…etc · Excellent communication skills · Passionate about data and analyzing business needs · Previous experience on a data team in an agile environment preferred · Hands-on experience on the Hadoop ecosystem, HDFS, Hadoop, Spark, Scala preferred · Develop in-depth plans and major milestones that must be approved by top management during the planning and design phases of the project. -",https://www.jobstreet.com.sg/en/job/technical-data-engineer-1035025979?jobId=jobstreet-sg-job-1035025979&sectionRank=258&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
258,Data Engineer,Morgan McKinley Pte Ltd,"We are looking for Data Engineer on a 12-month Contract role with high possibility of extension. There is a high chance of extension as its for long term Project. Job Summary: Lead a small team of 2-5 full-stack software engineers, data engineers, and data scientists Work closely with customers and the product team to gather software requirements Lead the maintenance of data warehouses on analytics platforms such as Snowflake or Databricks Lead the architecture, design, and deployment of analytics apps to cloud platforms such as Azure or AWS Perform build vs buy analysis for each customer-facing service Drive the choice of software stack for each application Employ Agile, CI/CD, and TDD methodologies to enable rapid software development with high quality Follow best practices for data governance to ensure high-quality, secure customer data Work with the IT and InfoSec teams to ensure highly available, performant, and secure applications Participate in new product introduction (NPI) and process improvement activities with the product team Job Qualifications: Candidate must have good understanding of full-stack software applications, data engineering, data science, and Agile methodologies Experience with common frontend and backend web frameworks such as React, Angular, Express, Flutter, Flask, and Django preferred Experience with data warehouse solutions such as Snowflake and Databricks preferred Experience with cloud infrastructure such as AWS, Azure, or GCP preferred B.S. (or equivalent) in science, engineering, or mathematics required 10+ years of software engineering, data engineering, or data science experience required 2+ years leading a team of software / data engineers required Excellent verbal and written communication skills. Only shortlisted candidates will be responded to, therefore if you do not receive a response within 14 days please accept this as notification that you have not been shortlisted. Thanks, Morgan McKinley EA License No: 11C5502 EAP Registration No: R22108361 -",https://www.jobstreet.com.sg/en/job/data-engineer-1034711381?jobId=jobstreet-sg-job-1034711381&sectionRank=259&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
259,"Data Engineer, Enterprise Data Hub",Changi Airport Group (Singapore) Pte. Ltd.,"Data Engineer, Enterprise Data Hub The candidate will be responsible to support business owners, data scientists &amp; technical manager for data engineering related services, enabling them to develop quick prototypes with specific data sets, test hypothesis and build data models across various internal &amp; external data sources. He/she will be required to collaborate with the various divisions of CAG to provide data engineering services such as extract, transform, load data; identify, analyse, and interpret trends or patterns in complex data sets, address data issues and gaps and guide business owners to achieve their business objectives The candidate should process wide breadth of data engineering, management, analysis &amp; protection related knowledge &amp; working experience. He/she should have the relevant expertise in data profiling and cleaning, master data management, meta data management, data definition &amp; access control, data architecture design and data scanning. He/she should also be proficient in performing data analytics, report writing and presenting findings. He/she should process strong analytical skills to collect, organize, analyse, and disseminate significant amounts of information with attention to detail and accuracy. Scope of Work: Perform program management of the flights, passengers, baggage &amp; cargo data management and reporting &amp; business intelligence program. Support business owners, data scientists and technical manager in data driven experiments, testing hypothesis and use cases using various data sources. Acquire data from primary or secondary data sources and maintain databases/data systems in required SLA using industry standard modes of data transfer (FTP, S3, API) Develop and implement databases (efficient design of tables and Data Marts), data collection systems, data analytics and other strategies that optimize statistical efficiency and quality. Filter and “clean” data by reviewing integrity of data sources, enhancing current processes and workflow for data collection, and identifying performance indicators for measure of success. Iteratively able to perform data protection, encryption, hashing &amp; scanning functions &amp; provide respective analytical reports to meet business needs. Requirements: An accredited BS in Mathematics, Economics, Computer Science, Information Management, Statistics AI/ML or related discipline with minimum 5 years working experience in the IT industry. Strong knowledge and vast experience in SQL scripting mainly focused on Data Engineering such as data processing, generate insights and identify patterns from various source of data domains. Understanding of system network architecture and components. Familiar with Amazon Web Services (AWS) cloud environment and basic components is a must. Strong knowledge and experience using enterprise ETL tools &amp; Master Data Management (i.e. Pentaho) Familiar with business intelligence visualization tools (i.e. MicroStrategy, Tableau…etc.), databases (Oracle, SQL Server, Redshift etc.) Strong analytical, project management and communications skills, and self-motivated Good communication, verbal, written and presentation skills to effectively describe and demonstrate proposed solutions to internal and external parties. -",https://www.jobstreet.com.sg/en/job/data-engineer-enterprise-data-hub-1035010823?jobId=jobstreet-sg-job-1035010823&sectionRank=260&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
260,"Data Engineer (Python, SQL, Azure)",Manpower Staffing Services (S) Pte Ltd,"Company Highlight: Company transport provided at Tampines MRT Good Employee benefits and Transparent career progression Job stability for long-term career growth Roles &amp; Responsibilities: Join a team responsible for building and maintaining data systems or pipelines Set up, install, configure, troubleshoot, and upgrade commercial off-the-shelf (COTS) products Develop and implement ways to enhance data warehouses, data lakes, or similar platforms Contribute to the creation of documentation such as design documents and troubleshooting guides Requirement: Knowledge and/or experience in data management or data engineering Familiarity with Linux commands and shell scripting Knowledge and/or experience in relational databases (including SQL) or NoSQL databases (e.g., document, graph) Advantageous to have experience in DataStage, Denodo, Hadoop, Python, Spark, Microsoft Azure Cloud services, Databricks, Dataiku, Data Robot Degree/Diploma in Computer Engineering/Computer Science/Information Technology or a related technical discipline with 1-4 years of experience in related fields No Experienced candidates are encouraged to apply If you are interested in this opportunity, submit your application now to find out more about this position. We regret that only shortlisted applicants will be contacted. Thank you. Sim Wen Yih Reine Personal Reg No: R21103357 Manpower Staffing Services (S) Pte Ltd EA License No: 02C3423 -",https://www.jobstreet.com.sg/en/job/data-engineer-python-sql-azure-1034872498?jobId=jobstreet-sg-job-1034872498&sectionRank=261&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
261,Data Engineer Architect #SgUnitedJobs,G2 Comtech Asia Pte Ltd,"• Translate business requirements to technical solutions leveraging strong business acumen. • Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data &amp; Analytics PaaS Services. • Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments. • Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies. Design and Build Modern Data Pipelines and Data Streams. Design and Build Data Service APIs. • Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics. • Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience. • Implement effective metrics and monitoring processes. • Travel as needed Skills: 1 - Microsoft SQL Server Integration Services SSIS 2 - Microsoft SQL Server Analysis Services (SSAS) (P3 - Advanced) 3 - Data Modeling Techniques and Methodologies (P3 - Advanced) 4 - Data Warehouse Tools (P3 - Advanced) 5 - Microsoft SQL Server Mobile Reports (P3 - Advanced) • Demonstrated experience of turning business use cases and requirements to technical solutions. • Experience in business processing mapping of data and analytics solutions. • Ability to conduct data profiling, cataloging, and mapping for technical design and construction of technical data flows. • The ability to apply such methods to solve business problems using one or more Azure Data and Analytics services in combination with building data pipelines, data streams, and system integration. • Mastery of .NET C# and T-SQL with the familiarity of U-SQL is required • Knowledge of Azure Data Factory, Azure Data Lake, Azure SQL DW, and Azure SQL, Azure App Service is required. • Azure IoT, Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics is a plus. • Knowledge of Python is a plus. • Experience preparing data for Data Science and Machine Learning. • Experience preparing data for use in Azure Machine Learning and/or Azure Databricks is a plus. • Demonstrated experience preparing data and building data pipelines for AI Use Cases (text, voice, image, etc.…). • Designing and building Data Pipelines using streams of IOT data. • Knowledge of Lambda and Kappa architecture patterns. • Knowledge of Master Data Management (MDM) and Data Quality tools and processes • Strong team collaboration and experience working with remote teams. • Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals. • Working experience with Visual Studio, PowerShell Scripting, and ARM templates. • Experience with Git/TFS/VSTS is a must. - Preferred Certifications: MCAD .NET, MCSD .NET, MCDBA -",https://www.jobstreet.com.sg/en/job/data-engineer-architect-sgunitedjobs-1034793196?jobId=jobstreet-sg-job-1034793196&sectionRank=262&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
262,Senior/Data Engineer,Income Insurance Limited,"The Senior Data Engineer will be responsible for the design, develop, and maintain: Best Practices for Data Architecture and Design Patterns for Data Engineering Use-Cases. Real-time data feeds from database sources like MySQL, Oracle, and MS SQLServer using the “Change Data Capture Engine” aka “CDC”. Sub-Second Real-Time Data Pipelines using AWS Kinesis, Glue, Spark, Kinesis, Lambda . Batch Pipeline Orchestration using on Apache Airflow and Jenkins. Auto Scalable platform using Kubernetes on EKS. Org Wide Master Data Management, Data Catalog Engine, and Data Quality Engine. Code Repo Pipeline to automate Continuous Integration and Continuous Deployment (CI / CD). Structure Tables with Partitioning and Clustering to increase Cost &amp; Performance Benefits. Guide Data Analysts and Data Scientists to write efficient queries and workloads. Data Sharing with On-Demand Encryption/Decryption which can operate at Scale. Running Containerized ETL workflow at scale. Qualifications: Bachelor Degree of Computer Science, IT or equivalent at least 3 - 4 years of data engineering experience Have strong fundamentals in Computer Science concepts like Cloud Computing Architecture, Distributed Computing, High-Velocity Data Processing, Lambda Architecture, etc… Strong Data modeling and managing Distributed Computing Platforms for Data Processing. Advance knowledge of SQL and writing resource-efficient queries. Have at least 2+ years of professional programming experience in Python. Have at least 2+ years of experience in running a data processing pipelines on either of these: Google BigQuery, Redshift, Hadoop, Presto, Spark, or KSQL. Have at least 2+ years of experience in writing Sub-Second Real-Time pipelines using Google DataFlow(Apache Beam), PubSub, Kinesis Stream, Lambda, etc... Have a good understanding of how Kubernetes clusters work and scale on-demand. Have adequate experience using Containers for Data Engineering workload. Implemented manual or automated tools for Data Quality, Catalog, and Lineage. Uphold the sense of Frugality across Data Engineering teams. Have Good Interpersonal and Presentation Skills to explain and promote Best Practices across the organization with both technical as well as non-technical stakeholders. -",https://www.jobstreet.com.sg/en/job/senior-data-engineer-1034978745?jobId=jobstreet-sg-job-1034978745&sectionRank=263&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
263,Data Engineer,INFINEUM SINGAPORE LLP,"Position Summary The Digital &amp; Analytics Centre of Excellence (D&amp;A CoE) is an independent team that helps fast track and spearhead our digital &amp; analytics capabilities across the organisation. The D&amp;A CoE is designed around key pillars, with Delivery and Execution being the one responsible for Infineum’s effective use of data to provide high value solutions to the business. The Data Engineer is responsible for collaborating across the business and working with heterogenous data sources to build, manage and optimise data pipelines on Infineum’s Data and Analytics Platform to maximise the business value from our data. The Data Engineer will also ensure compliance with data governance and data security requirements. The Data Engineer will play a pivotal role in operationalizing prioritised data and analytics initiatives within Infineum’s digital portfolio. This role will require both creative and collaborative working with Data Architects, Data Scientists, Analytics Developers, IT experts as well as directly with key business stakeholders. This role will involve evangelizing effective data management practices and promoting better understanding of data and analytics. The Data Engineer position is an emerging role in Infineum’s Digital and Analytics CoE and as such the successful candidate will have the opportunity to drive the development of data engineering tools, processes, and procedures by collaborating with D&amp;A CoE and broader IT teams. This Data Engineer role is accountable to the Delivery and Execution Leader within the Digital and Analytics Centre of Excellence. Key Outputs: What we can expect from you Collaborate closely with business users, domain experts, architects, analytics developers, and data scientists to rapidly design, build and embed data pipelines Design and maintain data models to support business analytics Drive automation using modern data and analytical tools to develop repeatable data integration and data preparation flows from multiple source systems into our data lake and enterprise data warehouse systems Maintain data pipelines ensuring on-going adoption of automation and incorporation of best practice Work side by side with Data Scientists to understand business problems and support the integration of diverse data sets to support data science and advanced analytics activities Collaborate with business, D&amp;A CoE, and broader IT colleagues to evangelise data management. Act as a ‘data guru’ and work across business silos to promote better understanding of data and analytics. What will you gain from this role? Opportunity to influence the build of a new data and analytics platform Work closely with the Architecture Working Group to define data engineering and data architecture strategies Skills in defining and developing data engineering processes and best practices for use internally and with our technical partners Exposure to a wide variety of technologies and data engineering challenges as we continue to further develop our digital capability Work in a global environment interacting with all regions and functions at Infineum A successful candidate is likely to have: Bachelor’s Degree in Computer Science, Engineering, Business or equivalent discipline 5 or more years of experience in a Data Management discipline including experience in data warehousing concepts and data modelling. Strong experience working with heterogeneous datasets in building and optimizing data pipelines, pipeline architectures and integrated datasets using Talend and Azure Data Lake Experience of working with Snowflake to build data warehouses / data marts, and experience of working with data from SAP, manufacturing, or research systems is strong plus but not required/compulsory Basic understanding of popular open-source and commercial data science tools and platforms such as Python and Azure ML is an advantage Experience working in a virtual team setting and self-driven with desire to take the lead and drive tasks to completion in a remote environment Detail-oriented and strict attention to details and the ability to quickly spot and fix problems Able to stay abreast of Data Engineering industry trends -",https://www.jobstreet.com.sg/en/job/data-engineer-1034979354?jobId=jobstreet-sg-job-1034979354&sectionRank=264&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
264,Data Engineer,Abbott Manufacturing Singapore Private Limited,"Job Description Primary Function/Primary Goals/Objectives: Identify business needs, collect, data analysis &amp; interpretation and visualization of manufacturing and business data. Report insights and help users to make decisions and find improvement opportunities. Major Responsibilities: Engaging cross-functional stakeholders to understand business requirements (voice of customer). Manage cross-functional projects from ideation, execution to change management. Extract, transform and load data from data source systems, machines and sensors using tools such as Python, SQL, SEEQ and batch scripting. Develop data cleaning and data wrangling tools (Python, SQL, Excel) for analysis and analytics modeling. Extract time series process data from PI process historian using PI Web API. Implement next generation electronic tier reporting dashboard through data automation and analysis solutions. Serve as an on-site consultant for existing data systems. Troubleshoot issues via root cause analysis and implement timely corrective actions Work with IT and subject matter experts to ensure data accuracy and availability. Upgrading existing dashboards, apps and tools based on business needs. Creating Power Platform applications for data entry and improving workflows. Skills/Experience Requirements: Strong knowledge and experience in Programming Languages like Java, Python, R, etc. Strong knowledge in data visualization tools like Python, PowerBI, Tableau, QlikView and SEEQ. Strong analytical/critical thinking/problem solving skills. Strong communication skills and stakeholder management skills. Knowledge in Microsoft Power Platform tools such as Power Apps, Power Automate, Power Query and Power BI. Strong knowledge and experience in SQL, batch scripting, etc. 2-3 years work experience as a Data Engineer, Data Analyst, Business Analyst or related roles in a mature manufacturing/tech/IT consultancy firm. Education: Major in Computer Science, Computer Engineering or related fields from a recognized university. Major in Engineering with a minor or second major in Computer Science from a recognized university. -",https://www.jobstreet.com.sg/en/job/data-engineer-1034985172?jobId=jobstreet-sg-job-1034985172&sectionRank=265&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
265,Data Engineer,ASM Technology Singapore Pte Ltd,"ASM Data Engineer As ASMPT is rapidly growing, we embark to become a data-driven organization and are expanding our data platform. We seek an individual with strong passion in Data Engineering who will be comfortable to work in both on-premise and Cloud environments to build the data platform to support structured &amp; unstructured datasets. You will be able to use different tools or create customized tools to transform and load data, administrate databases such as SQL and Hadoop, as well as implementing machine learning models for AIoT (Artificial Intelligence of Things). Your Responsibilities Manage and support on-premise and Cloud-based data lake and warehouse systems Design, build, support and optimize new and existing data structure and ETL processes Build scalable and efficient data pipelines &amp; services to help analytics teams to process the data Design useful dashboards and visualisation tools to display data insights and prediction/forecasting results Liaise with third party tool providers to understand and improve data workflow Work closely with data scientists and data analysts to deliver analytical solutions with robust underlying data platforms Work with business team and data analysts to understand business requirements and build efficient and scalable data solutions Minimum Qualification Bachelor Degree in Computer Science, Software Engineering, Information Technology or any related disciplines At least 2 years’ experience in data engineering, automation and integration is preferred Strong programming and scripting skills in Python and other modern programming languages Strong data management, schema design and SQL development skills Deep understanding of databases and best engineering practices – which include logging, scaling up computation, continuous integration and continuous development (CI/CD) Self-motivated and proactive, willing to learn new things Good communication skills and strong team player What our preferred candidates have? Passionate in dealing with data, learning new data technologies, and discovering innovative and interesting solutions Understand and experienced with Cloud platform, eg. Microsoft Azure, AWS, GCP Business intelligence and reporting tools, eg. Power BI, Tableau, Qlik, etc Experienced in development using Big Data platform (Hadoop/Hive/Hbase/Spark, etc.) REST/Web API development and management Knowledge in Statistical software is an advantage Experience In building machine learning models is a plus -",https://www.jobstreet.com.sg/en/job/data-engineer-1034759907?jobId=jobstreet-sg-job-1034759907&sectionRank=266&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
266,Data Engineer (Azure Data Factory &amp; Azure Databricks),Avanade Asia Pte Ltd,"As a Data Engineer, you will support the implementation of projects focused on collecting, aggregating, storing, reconciling, and making data accessible from disparate sources to enable analysis and decision making. This role will also play a critical part in the data supply chain, by ensuring stakeholders can access and manipulate data for routine and ad hoc analysis. Additionally, you will support the full lifecycle of data from ingesting through analytics to action. Key Role Responsibilities: Day-to-day you will: Translate business requirements to technical solutions leveraging strong business acumen Analyze current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data &amp; Analytics PaaS Services Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments. Deliver of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies. Design and Build Modern Data Pipelines and Data Streams. Design and Build Data Service APIs. Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics. Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience Implement effective metrics and monitoring processes. Skill &amp; Capability Requirements: Around 5 years of working experience as a Data Engineer Demonstrated experience in turning business use cases and requirements into technical solutions Experience in business processing mapping of data and analytics solutions. Ability to conduct data profiling, cataloging and mapping for technical design and construction of technical data flows The ability to apply such methods to solve business problems using one or more Azure Data and Analytics services in combination with building data pipelines, data streams, and system integration. Ability to leverage a variety of programming languages &amp; data crawling/processing tools to ensure data reliability, quality &amp; efficiency Experienced in Cloud Data Transformation using ETL/ELT tools such as Azure Data Factory, Databricks Experienced in Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals. Experienced in Data Governance tools like Unity Catalog / Purview, Master Data Management (MDM) and Data Quality tools and processes Knowledge of business intelligence tools such as Power BI, Tableau, Qlik, Cognos TM1 Knowledge of Azure Data Lake, Azure SQL DW, and Azure SQL, Azure App Service is required. Azure IoT, Azure HDInsight + Spark, Azure Cosmos DB &amp; Azure Stream Analytics are a plus. Knowledge in data modeling and database management, such as performance tuning of the Enterprise Data Warehouse, Data Mart, and Business Intelligence Reporting environments, and support the integration of those systems with other applications Knowledge of Python is a plus. Experience preparing data for Data Science and Machine Learning. Experience preparing data for use in Azure Machine Learning / Azure Databricks is a plus. Experience preparing data and building data pipelines for AI Use Cases (text, voice, image, etc). Designing and building Data Pipelines using streams of IoT data. Knowledge of Lambda and Kappa architecture patterns. Strong team collaboration and experience working with remote teams. Working experience in Visual Studio, PowerShell Scripting, and ARM templates. Azure certifications (AZ-900, AZ-200, and 201), Databricks certification, DevOps certifications What we offer you Come for the distinctive experiences you have helping forward-thinking corporations, non-profits, and governments push the boundaries of digital innovation. Stay for the limitless learning opportunities that encourage you to master Microsoft and pursue big ideas. Enjoy ambitious growth for yourself as part of Avanade’s people-first culture with benefits like employee share purchasing, flexible work arrangements, a commitment to diversity and inclusion, and competitive pay. Apply now Share this job: Share About Avanade Avanade is the leading provider of innovative digital, cloud and advisory services, industry solutions and design-led experiences across the Microsoft ecosystem. Every day, our 59,000 professionals in 26 countries make a genuine human impact for our clients, their employees and their customers. We have been recognized as Microsoft’s Global SI Partner of the Year more than any other company. With the most Microsoft certifications (60,000+) and 18 (out of 18) Gold-level Microsoft competencies, we are uniquely positioned to help businesses grow and solve their toughest challenges. We are a people first company, committed to providing an inclusive workplace where employees feel comfortable being their authentic selves. As a responsible business, we are building a sustainable world and helping young people from underrepresented communities fulfil their potential. Majority owned by Accenture, Avanade was founded in 2000 by Accenture LLP and Microsoft Corporation. Learn more at *************** -",https://www.jobstreet.com.sg/en/job/data-engineer-azure-data-factory-azure-databricks-1034985353?jobId=jobstreet-sg-job-1034985353&sectionRank=267&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
267,AWS ETL Cloud Data Engineer (IFRS 17),Income Insurance Limited,"We are looking to hire a AWS ETL Data Engineer. This is an exciting opportunity to use and further expand your AWS cloud skill set, and join Income Data Team to build Hybrid Datalake as part of key IFRS project Responsibilities: Design, build and operationalize large scale enterprise data solutions and applications using one or more of AWS data and analytics services in combination with 3rd parties – Spark/Python on Glue, DMS, S3, Athena, RDS-PostgreSQL, Airflow, Lambda, Code Commit, Code Pipeline, Code build, etc. Design and build production ETL data pipelines from ingestion to consumption within a big data architecture, using DMS, DataSync &amp; Glue. Understand the existing applications(including on-premise Cloudera Datalake) and infrastructure architecture. Analyze, re-architect and re-platform on-premise data warehouses to data platforms on AWS cloud using AWS or 3rd party services. Design and implement data engineering, ingestion and curation functions on AWS cloud using AWS native or custom programming. Perform detail assessments of current state data platforms and create an appropriate transition path to AWS cloud. Collaborate with development, infrastructure and data center teams to define Continuous Integration and Continuous Delivery processes in accordance with industry standards. Work on hybrid Datalake. Work closely with multiple stakeholders to ensure high standards are maintained. Mandatory Skill-set Bachelors Degree in Computer Science, Information Technology or other relevant fields 5+ years of work experience with ETL, Data Modelling, Data Architecture to build Datalake. Proficient in ETL optimization, designing, coding, and tuning big data processes using Pyspark. 3+ yrs of extensive experience in working on AWS platform using core services like S3, Athena, Glue (ETL), DataSync, Airflow, RDS (PostGres), CodeCommit, CodePipeline, CodeBuild, SQL &amp; Spark/Python Good to have Skill-set Fundamental of Insurance domain Functional knowledge on IFRS17 -",https://www.jobstreet.com.sg/en/job/aws-etl-cloud-data-engineer-ifrs-17-1034977537?jobId=jobstreet-sg-job-1034977537&sectionRank=268&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
268,Lead AWS ETL Cloud Data Engineer (IFRS 17),Income Insurance Limited,"We are looking to hire a Lead AWS ETL Data Engineer. This is an exciting opportunity to use and further expand your AWS cloud skill set, and join Income Data Team to build Hybrid Datalake as part of key IFRS project. Responsibilities: Design, build and operationalize large scale enterprise data solutions and applications using one or more of AWS data and analytics services in combination with 3rd parties – Spark/Python on Glue, DMS, S3, Athena, RDS-PostgreSQL, Airflow, Lambda, Code Commit, Code Pipeline, Code build, etc. Design and build production ETL data pipelines from ingestion to consumption within a big data architecture, using DMS, DataSync &amp; Glue. Understand the existing applications(including on-premise Cloudera Datalake) and infrastructure architecture. Analyze, re-architect and re-platform on-premise data warehouses to data platforms on AWS cloud using AWS or 3rd party services. Design and implement data engineering, ingestion and curation functions on AWS cloud using AWS native or custom programming. Perform detail assessments of current state data platforms and create an appropriate transition path to AWS cloud. Collaborate with development, infrastructure and data center teams to define Continuous Integration and Continuous Delivery processes in accordance with industry standards. Work on hybrid Datalake. Work closely with multiple stakeholders to ensure high standards are maintained. Mandatory Skill-set Bachelors Degree in Computer Science, Information Technology or other relevant fields 8+ years of work experience with ETL, Data Modelling, Data Architecture to build Datalake. Proficient in ETL optimization, designing, coding, and tuning big data processes using Pyspark. 5+ yrs of extensive experience in working on AWS platform using core services like S3, Athena, Glue (ETL), DataSync, Airflow, RDS (PostGres), CodeCommit, CodePipeline, CodeBuild, SQL &amp; Spark/Python Good to have Skill-set Fundamental of Insurance domain Functional knowledge on IFRS17 -",https://www.jobstreet.com.sg/en/job/lead-aws-etl-cloud-data-engineer-ifrs-17-1034976938?jobId=jobstreet-sg-job-1034976938&sectionRank=269&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
269,Data Engineer,United Overseas Bank Limited (UOB),"Take end-to-end development ownership for one or more modules and deliver to production Understand functional requirements / user stories and come up with effective solutions by breaking down into meaningful tasks Participate as a member of agile team and deliver high quality software Manage multiple projects at the same time Guide and support other members of the team, including temporary staff to perform effectively in their role Communicate with other stakeholders like other project teams, infrastructure &amp; security teams as required and manage dependencies Understand and follow UOB software delivery process &amp; deliverables, ensure process compliance Create a network with other departments and teams, to know about strategic issues and new developments Understand long terms strategic plans for the department and support towards the same Possess personal courage to do what is right and work as a team member to meet customer expectations Continuously prioritize technical debt for the team and ensure they are taken care in project releases Participate in sprint meetings (planning, review) and estimate stories, breakdown to tasks Prepare for sprint demos and demonstrate to Product Owner, receive feedback and implement Exhibit good attention to detail and enthusiasm to take ownership Requirements: Degree in Computer Science or related discipline 0 to 2 years of working experience. Strong knowledge and experience building Apache Kafka applications Strong working experience with Java, Spring Boot and API (Microservices) Experience building data pipelines with Apache NiFi in production scale Experience building data streaming applications using Apache Spark and Kafka Streams Experience working with a variety of data sources and sinks (API, MQ, Files, Databases, Hot lakes, Big data systems etc.) Experience with both SQL and NoSQL databases (like MariaDB, Oracle, MongoDB) and Object-Relational Mapping (ORM) frameworks (e.g. Hibernate) Experience with CI/CD practices and tools (Bitbucket, Jenkins, Artifactory, Veracode etc.) to build pipelines Familiarity with Agile development methodologies Experience with software design and development in a test-driven environment Experience tuning Kafka and NiFi components for varying traffic and performance requirements Ability to learn new programming languages and technologies Excellent communication skills to interact within and outside the team -",https://www.jobstreet.com.sg/en/job/data-engineer-1034980139?jobId=jobstreet-sg-job-1034980139&sectionRank=270&token=0~26b20b8c-fdb6-4479-ba54-bd48a525f6e1&fr=SRP%20Job%20Listing
270,Data Engineer,Saksoft Pte Limited,"KEY REQUIREMENTS · Minimum 8 years of extensive experience in dealing with Data-Warehousing projects on Teradata, Hadoop and Informatica . · Working with Hive, Sqoop &amp; spark framewrok. Having good understanding of Partitions, Bucketing concepts in Hive . · Extensively Worked on Teradata Utilities - BTEQ, FLoad, MLoad, TPump, FExport and TPT · Solid experience in Teradata MDM, SQL, ETL nformatica, Hadoop, Hive, Unix · Worked with 10+ different Source Systems which has structured and semi structured data. · Developed Teradata TPT scripts for continuous loading and implemented real time and near real time data warehouse system for all mobile app services. · Developed Teradata M-Load and Hadoop-Hive scripts for stage loads. · Involved and developed data mappings between Staging and Presentation/Reporting layers. · Data validation of Datamart/Reports · Wrote many UNIX shell scripts to pre - process and parse the source files · Must have banking domain experience (digital bank etc) -",https://www.jobstreet.com.sg/en/job/data-engineer-1034927659?jobId=jobstreet-sg-job-1034927659&sectionRank=271&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
271,DevOps Data Engineer,Saksoft Pte Limited,"Expereince: 5+yrs The DevOps Tools Administrator is responsible for installing, administrating and configuring the CI/CD tools in the project teams. This role will be responsible and accountable to deliver all technical implementations in-line with DevOps objectives. Additional qualities of infra administration including WAS administration, Aix / Linux commands knowledge, IBM toold administration (Datacap / Filenet / BAW) are handy. We’re looking for a hands engineer who will be: • Supporting and maintaining the entire DevOps platform and toolset. • Maintain the DevOps platform and toolset matching the enterprise standard. • Coordinate with the stakeholders from requirements gathering until successful implementation DevOps pipeline on boarding. Work with the vendors to setup centralized DevOps solutions considering market best practice, Industry standard and ease of support. • Work with the vendors to upgrade the DevOps tools farm and Integrating with tools. • Configuring SSO, SSL, Load Balancer, Auto Scaling and DNS setup for the DevOps Toolset with naming convention. • Lead analysis and resolution of root cause for Test Orchestration / Environment related issues • Ability to multitask and work in a fast-paced, collaborative team environment Excellent written and oral communication skills; writing, publishing and conference-level presentation skills Stays current with industry trends and leads development of key DevOps, Runtime, and Operational innovation platforms -",https://www.jobstreet.com.sg/en/job/devops-data-engineer-1034927061?jobId=jobstreet-sg-job-1034927061&sectionRank=272&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
272,Senior Data Engineer,Liberty Insurance Pte Ltd,"Location: Singapore Type: Full Time Min. Experience: Experienced We are looking for a Senior Data Engineer that under limited direction, prototypes/develops data solutionsof high complexity to meet the needs of the organization and business customers. This person needs to havea good communication skill to be able to manage project across East markets. You will use various methods to transform raw data into useful data systems. For example, you’ll create datafor pricing modeling and conduct data quality checks. Overall, you’ll strive for efficiency by aligning datasystems with E&amp;W modeling teams’ ******** succeed in this data engineering position, you should have strong analytical skills and the ability tocombine data from different sources. Data Engineer skills also include communication, familiarity withseveral programming languages and knowledge of learning machine methods. Responsibilities: With a comprehensive understanding of Agile techniques, set expectations for deliverables of high complexity. Maintains proof-of-concepts and prototype data solutions, and handles any assessment of their viability and scalability, with own team or in partnership with IT. Ensures data solutions include deliverables required to achieve high quality data. Displays a working understanding of complex multi-tier, IT | Data teams’ systems, and applies principles of metadata, lineage, business definitions, compliance, and data security to project work. Experience: 5+ years previous experience as a data engineer or in a similar role. Technical expertise with data models and data pipeline automation. Experience with big data tools: Spark, Kafka is a plus. Experience with as developer with SAS and SQL databases, including Postgres, Oracle and SQL Server. Hands-on experience with AWS cloud services: S3, Glue, Crawlers, EC2, EMR, RDS, Redshift. Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc. Degree in Computer Science, IT, or similar field; a master’s is a plus. Data engineering certification (AWS) is a plus. -",https://www.jobstreet.com.sg/en/job/senior-data-engineer-1034897309?jobId=jobstreet-sg-job-1034897309&sectionRank=273&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
273,Data Engineer,Income Insurance Limited,"Responsibilities: Collaborate with data scientists, coders, programmers and other stakeholders Creating and managing the AI development process and general infrastructure of a product Doing statistical analysis and interpreting findings Automating critical tasks and procedures for a data science team Creating data transformation infrastructure Developing AI models communicating the utility of the AI models they generate to a diverse range of employees inside the organisation, including product managers and management executives Converting machine learning models into APIs with which other apps may interact Qualifications: Master / Bachelor’s degree in computer science, computer engineering, or relevant field. A minimum of 5 - 7 years’ experience in a similar role. Strong knowledge of Datawarehouse / database / Cloud systems and data mining. Excellent organizational and analytical abilities. Outstanding problem solver. -",https://www.jobstreet.com.sg/en/job/data-engineer-1034710563?jobId=jobstreet-sg-job-1034710563&sectionRank=274&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
274,Data Engineer - SQL - Contract = 12 months,Zenith Infotech (S) Pte Ltd,"This is a 12 months contract assigned to our client Work Location: To be confirmed Salary Range : $3,500-$5,500 Primary Skills 1. Microsoft SQL Server Integration Services SSIS Job Description 1. Knowledge on MySQL 2. Leverage your understanding of complex data analysis and modeling to ensure project teams and clients can successfully extract value from their data. 3. Support hypothesis generation and testing, exploratory analysis, data preparation for statistical modelling/machine learning/deep learning, building machine learning or deep learning models and model interpretations. -",https://www.jobstreet.com.sg/en/job/data-engineer-sql-contract-%3D-12-months-1034795254?jobId=jobstreet-sg-job-1034795254&sectionRank=275&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
275,Data Engineer / Associate Data Engineer,Singapore Tourism Board - (1),"What the role is: Support the Data Science team in: Helping to project manage, coordinate and implement Data Science &amp; Analytics's (DS&amp;A) data ingestion and data processing pipelines across different platforms Ensuring that all data systems meet our business requirements and enable scalability of business processes Main Responsibilities: Project manage and deliver on data related implementations ensuring that deliverables are met within agreed scope and timelines Work closely with vendors and internal stakeholders to project manage and coordinate DS&amp;A’s data ingestion and data processing pipelines across platforms which can include mobile apps, SaaS platforms, on-premise databases and partner systems Help architect DS&amp;A’s data integrations and data processing flows between external / 3rd party data sources, AWS cloud datawarehouses (e.g. Redshift) and internal on-premise database instances for workloads at scale Help to gather and translate business requirements into relevant database schemas, data integrations and data processing flows to meet business objectives Develop data integrations (through API, SFTP etc) between AWS S3, Redshift instances and on-premise database instances (e.g. HANA) Assemble large, complex datasets that meet functional and non-functional business requirements Analyse and assess the effectiveness and accuracy of new data sources (e.g. datasets received from stakeholders) and annotation/ labelling of new training inputs. Identify, design and implement internal process improvements: automating manual processes, data validation tools, optimising data delivery, re-designing infrastructure for greater scalability, etc. Recommend different ways to constantly improve data reliability and quality, including helping review and enhance the existing data collection procedures to include data for building analytics models relevant for industry transformation Develop monitoring toolkits to ensure that integration is executed successfully and alerts where integrations have failed Provide guidance to internal teams on best practices for cloud to on-premise data integrations Develop set processes for data mining, data modelling and data production Support the integration and deployment of developed algorithms, machine learning and analytical models into current analytics system/production Help setup, configure, deploy and validate machine learning models and analytics scripts on Amazon Sagemaker Help in the implementation of CI/CD and deployment of ML models in production Job requirements: At least 2-3 years of Software Project Management experience successfully managing both internal stakeholders and external vendors. Successfully delivered at least 2 medium to large scale software systems in either a Project Management role, Data Architect role or Data Integration role Ability to understand the different business domains and to make connections between the data and the business needs. Good and strong communication skills and able to explain the issues, design tradeoffs between performance, maintenance and business requirements. Able to clearly articulate and justify the design decisions taken Good attention to details with regards to data workflow, data quality, data integrity and how the data will be stored and accessed. Strong analytics skills related to working with structured and unstructured datasets. Experience in performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Experience in designing database schemas to support OLTP and OLAP systems Experience with data pipeline tools (e.g. Talend, SSIS, BODS, Airflow, Kafka) Experience in using Qliksense will be advantageous. Experience with big data tools: Hadoop, Spark, Hive, Sqoop, etc. Experience with stream-processing systems: Storm, Spark-Streaming, Kalfka etc. Experience in software development and developing enterprise applications with integrations to SQL / no-SQL databases Experience with object-oriented / object function scripting languages: Python, R, Java, etc. Intellectual curiosity to find new and unusual ways of how to solve data management issues. A successful history of manipulating, processing and extracting value from large disconnected datasets. Strong working knowledge of SQL Strong project management, stakeholder management and organisational skills. Experience supporting and working with cross-functional teams in a dynamic environment. At least 3 years of working experience in a related field with real-world skills and testimonials from formal employers. Working experience with structured and unstructured datasets is essential Preferred certifications: Certified Scrum Master/ Agile Developer Certified AWS Cloud Architect Application Status: Shortlisted candidates will be contacted within 2 weeks from the closing date of this job posting. We regret to inform that only shortlisted candidates will be notified. -",https://www.jobstreet.com.sg/en/job/data-engineer-associate-data-engineer-1034857751?jobId=jobstreet-sg-job-1034857751&sectionRank=276&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
276,Senior/Data Engineer (IFRS 17),Income Insurance Limited,"We are looking to hire Data Engineers (AWS). This is an exciting opportunity to use and further expand your AWS cloud skill set, and join Income Data Team to build Hybrid Datalake as part of key IFRS project Responsibilities: Design, build and operationalize large scale enterprise data solutions and applications using one or more of AWS data and analytics services in combination with 3rd parties – Spark/Python on Glue, DMS, S3, Athena, RDS-PostgreSQL, Airflow, Lambda, Code Commit, Code Pipeline, Code build, etc. Design and build production ETL data pipelines from ingestion to consumption within a big data architecture, using DMS, DataSync &amp; Glue. Understand the existing applications(including on-premise Cloudera Datalake) and infrastructure architecture. Analyze, re-architect and re-platform on-premise data warehouses to data platforms on AWS cloud using AWS or 3rd party services. Design and implement data engineering, ingestion and curation functions on AWS cloud using AWS native or custom programming. Perform detail assessments of current state data platforms and create an appropriate transition path to AWS cloud. Collaborate with development, infrastructure and data center teams to define Continuous Integration and Continuous Delivery processes in accordance with industry standards. Work on hybrid Datalake. Work closely with multiple stakeholders to ensure high standards are maintained. Mandatory Skill-set Bachelors Degree in Computer Science, Information Technology or other relevant fields 5 years of work experience with ETL, Data Modelling, Data Architecture to build Datalake. Proficient in ETL optimization, designing, coding, and tuning big data processes using Pyspark. 3 yrs of extensive experience in working on AWS platform using core services like S3, Athena, Glue (ETL), DataSync, Airflow, RDS (PostGres), CodeCommit, CodePipeline, CodeBuild, SQL &amp; Spark/Python. Good to have Skill-set Fundamental of Insurance domain Functional knowledge on IFRS17 -",https://www.jobstreet.com.sg/en/job/senior-data-engineer-ifrs-17-1034823975?jobId=jobstreet-sg-job-1034823975&sectionRank=277&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
277,Internship - Data Engineer,Infineon Technologies Asia Pacific Pte Ltd,"At a glance Student will be supporting IT FSC in areas of data analytics, modelling, machine learning and improving databases. Job description In your new role you will: Active participation in data analytics process , including business understanding, data understanding, modelling and visualization. Identify data sources and automate ETL Process. Feature engineering and analyzing large, complex and multi-dimension database . Improve existing machine learning model and databases. Implement, document and present the solution. Your Profile You are best equipped for this task if you have: On track to attain Bachelors / Masters in Computer Science / Data Analytics in the field of AI / ML /Data Science . Good understanding of computational complexity, data structures, programming languages, design patterns and software architectures. Ability to code in Python and SQL . Keenness to learn and to collaborate effectively within a team Why Us Part of your life. Part of tomorrow. Infineon is a world leader in semiconductor solutions that make life easier, safer, and greener. Our solutions for efficient energy management, smart mobility, and secure, seamless communications link the real and the digital world. In accordance with the requirements set by the Singaporean Government, Infineon Technologies Asia Pacific Pte Ltd (“Infineon”) can only allow individuals who are (a) fully vaccinated, (b) certified to be medically ineligible for a vaccine or (c) have recovered from COVID-19 within a prescribed period, onto company premises. Therefore, Infineon requires all new employees, as well as contractors and business partners, to be fully vaccinated against COVID-19. “Fully vaccinated” means individuals have completed the full regime of an approved COVID-19 Vaccine as listed under the World Health Organization (WHO) Emergency Use Listing (EUL) including the respective post-vaccination period to ensure the vaccine has become full effective. Anyone who is unable to be vaccinated due to an approved and/or recognised exemption condition may apply for special consideration. -",https://www.jobstreet.com.sg/en/job/internship-data-engineer-1034927670?jobId=jobstreet-sg-job-1034927670&sectionRank=278&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
278,"Associate AI Data Engineer / AI Data Engineer - Artificial Intelligence, SAP Labs Singapore",CONCUR TECHNOLOGIES (SINGAPORE) PTE. LTD.,"We help the world run better Our company culture is focused on helping our employees enable innovation by building breakthroughs together. How? We focus every day on building the foundation for tomorrow and creating a workplace that embraces differences, values flexibility, and is aligned to our purpose-driven and future-focused work. We offer a highly collaborative, caring team environment with a strong focus on learning and development, recognition for your individual contributions, and a variety of benefit options for you to choose ********** now! *SAP will be prioritizing candidates with full working rights in Singapore. Candidates who require work passes need not apply. * About SAP A market leader in end-to-end business application software, SAP helps more than 425,000 customers worldwide work together more efficiently. We know that a diverse and inclusive workforce keeps us competitive and provides opportunities for all. We believe that together we can transform industries, grow economics, lift societies, and sustain our environment. Because it’s the best-run businesses that make the world run better and improve people’s lives. At SAP, we build breakthroughs, together. About SAP Labs Singapore SAP Labs Singapore is the 20th engineering hub in the SAP Labs Network and is the newest innovation hub at SAP that drives product leadership, fosters the best talent, and aims to boost ecosystem and community engagement with a variety of initiatives. SAP Labs Singapore has the ambition to expand significantly and become the Embedded Artificial Intelligence Hub for SAP, leveraging on core competencies in the current teams. Your future team SAP Labs Singapore has experienced professionals taking on challenges posed by the SAP customers. Based in Singapore, you will have the opportunity to work on breakthrough projects addressing real-world problems, challenging norms with some of the SAP’s key customers. As part of the global product engineering team, you will participate in rich and engaging conversations with experts around the globe. SAP Labs Singapore provides an open, modern working environment and the opportunity to become part of the global SAP engineering community. Purpose and objectives As an Associate AI Data Engineer / AI Data Engineer, you will work together with a team of dedicated experts including AI scientists, AI Developers, dev-ops engineers, and architects with a single goal of building the best-in-class AI products. You will work against fixed timelines and your success will be measured by the ability to deliver solutions matching the performance of top-notch artificial intelligence systems. Applicants with relevant experience may be considered for AI Developer role. Expectations and tasks Your tasks include: Push the frontiers of what is possible in the area of artificial intelligence and machine learning so as to create new solutions Explore, understand, and implement most recent technologies and approaches for data pipelines for data pre and post processing Comfortably handle multi-terabyte data sets in scale-up and scale-out environments Supports machine learning research/project teams with all aspects around data Builds scalable and re-usable data processing pipelines Works on data generators in order to enrich our datasets Sets up and manages annotation projects with our annotation partner companies Works with domain experts and AI Scientists to define annotation guidelines and drive the annotation efforts towards high-quality data Coordinates &amp; supports data auditing efforts Coordinates &amp; supports data acquisition activities Integrates, validates, organizes, improves and curates datasets including metadata (e.g. data versioning, cleaning, storing, etc.) Work closely with the team, customers and partners to holistically understand business and user requirements and derive adequate application development concepts Ability to work in global teams with different time zones Immerse yourself quickly into new topics, terminology, and development tasks Educational and experience requirements Required Degree in Computer Science or related field 0 to 3 years of working experience as software developer or data engineer in AI focused application development A solid foundation in computer science, with strong competencies in algorithms, data structures, objects-oriented programming, design patterns, multi-threaded programming, and software design principles Hands-on knowledge in at least one of the server-side programming languages such as Java, Scala, Go, Python, C#, C++ Exposure to Big Data technologies such as Hadoop, Spark and Kafka Fundamental knowledge of container technologies like docker, Kubernetes etc. Experience with cloud-based application development using platforms such as SAP’s business technology platform, AWS, Azure &amp; Google Cloud Platform is a plus. Familiar with Agile/Scrum methodologies Strong desire to overcome obstacles and make your work benefit SAP's customers Excellent written and communication skills in English language Optional Hands-on knowledge of the frameworks such as Spring, Play, AngularJS, Flask etc. Hands-on experience in Shell Scripting, PowerShell Operational knowledge of Linux distributions such as Redhat, Ubuntu, CentOS, CoreOS Exposure to deployment and container orchestration technologies such as Docker, Kubernetes, Puppet, Chef, Ansible Knowledge of Machine Learning fundamentals Job Segment: Developer, Cloud Applications, Cloud Operations, Machine Learning, Artificial Intelligence, Data science development We build breakthroughs together SAP innovations help more than 400,000 customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with 200 million users and more than 100,000 employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, we build breakthroughs, together. We win with inclusion SAP’s culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone – regardless of background – feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable world. SAP is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: *******@sap.com For SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy. Specific conditions may apply for roles in Vocational Training. EOE AA M/F/Vet/Disability: Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, ethnicity, age, gender (including pregnancy, childbirth, et al), sexual orientation, gender identity or expression, protected veteran status, or disability. Successful candidates might be required to undergo a background verification with an external vendor. Requisition ID: 367470 | Work Area: Software-Design and Development | Expected Travel: 0 - 10% | Career Status: Graduate | Employment Type: Regular Full Time | Additional Locations: #LI-Hybrid. Job Segment: Cloud, Embedded, ERP, SAP, Application Developer, Technology -",https://www.jobstreet.com.sg/en/job/associate-ai-data-engineer-ai-data-engineer-artificial-intelligence-sap-labs-singapore-1034927864?jobId=jobstreet-sg-job-1034927864&sectionRank=279&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
279,Data Engineer,Keppel Corporation. Limited.,"JOB DESCRIPTION The Data Engineer supports the design, implementation and maintenance of data flow channels and data processing systems that support the collection, storage, batch and real-time processing, and analysis of information in a scalable, repeatable and secure manner. The key responsibilities are: Define optimal solutions for data collection, processing and warehousing Design, code and test data systems and works on implementing those into the internal infrastructure or cloud platform to support software developers and data scientists on data activities such as data analytics, ML and AI Focus on collecting, parsing, managing, analyzing and visualizing large sets of data to get information ready for insight discovery The key tasks are: Identify business needs Identify suitable data structures based on business needs to ensure availability and accessibility of data Determine technical system requirements based on data needs Keep abreast of latest technologies and products in data stores and data processing software, and technologies Build and maintain data pipeline Assist in building scalable data pipelines to extract, transform, load and integrate data Develop codes and scripts to process structured and unstructured data in real-time from a variety of data sources Test data pipelines for scalability and reliability to process high data volume, variety and velocity Consolidate and create data storage solutions for storage and retrieval of information Develop prototypes and proof-of-concepts for data solutions Monitor data system performance Support the handling and logging of errors Develop backup data archiving systems to ensure system continuity Implement and monitor data security and privacy measures on existing data solutions Optimize solution performance Assist in the integration of data systems with existing infrastructure Develop tools to improve data flows between internal and/or external systems and the data warehouse Automate the data collection and analysis processes, data releasing and reporting tools Test data system configurations to increase efficiency JOB REQUIREMENTS Familiar with the popular cloud platforms such Azure, AWS, Google, etc Passionate about numbers and works with large data sets Advanced working SQL knowledge and experience working with relational databases Strong analytic skills related to working with unstructured datasets Experience with (2 or more) programming and/or scripting languages: Python, Java, Javascript, C++, etc Experience building and optimizing data pipelines, architectures and data sets Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Experience in building processes supporting data transformation, data structures, metadata, dependency and workload management Experience in manipulating, processing and extracting value from large-disconnected datasets Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores Experienced in supporting and working with cross-functional teams in a dynamic environment Experience with data pipeline and workflow management tools such as Google Dataflow, AWS Data Pipeline, Azure Data Pipeline, etc Experience with stream-processing systems/services such as Kafka, etc. will have added advantages. Domain knowledge on plant operation and asset maintenance will have added advantages ADDITIONAL QUALIFICATIONS Bachelor’s Degree in computer science, Statistics, Informatics, Information Systems, Engineering, or relevant field Completed Data Engineering training with certification will have an added advantage At least 5 years working experience in Data Engineering area BUSINESS UNIT Keppel Infrastructure-",https://www.jobstreet.com.sg/en/job/data-engineer-1034902330?jobId=jobstreet-sg-job-1034902330&sectionRank=280&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
280,Lead Data Engineer (Cloud),Income Insurance Limited,"Description: Best Practices for Data Architecture and Design Patterns for Data Engineering Use-Cases. Real-time data feeds from database sources like MySQL, Oracle, and MS SQLServer using the “Change Data Capture Engine” aka “CDC”. Sub-Second Real-Time Data Pipelines using AWS Kinesis, Glue, Spark, Kinesis, Lambda. Batch Pipeline Orchestration using on Apache Airflow and Jenkins. Auto Scalable platform using Kubernetes on EKS. Org Wide Master Data Management, Data Catalog Engine, and Data Quality Engine. Code Repo Pipeline to automate Continuous Integration and Continuous Deployment (CI / CD). Structure Tables with Partitioning and Clustering to increase Cost &amp; Performance Benefits. Guide Data Analysts and Data Scientists to write efficient queries and workloads. Data Sharing with On-Demand Encryption/Decryption which can operate at Scale. Running Containerized ETL workflow at scale. Qualifications: Bachelor Degree of Computer Science, IT or equivalent. At least 6-7 years of data engineering experience with team leading/guiding/mentoring experience. Have strong fundamentals in Computer Science concepts like Cloud Computing Architecture, Distributed Computing, High-Velocity Data Processing, Lambda Architecture, etc. Strong Data modeling and managing Distributed Computing Platforms for Data Processing. Advance knowledge of SQL and writing resource-efficient queries. Have at least 2+ years of professional programming experience in Python. Have at least 2+ years of experience in running a data processing pipelines on either of these: Google BigQuery, Redshift, Hadoop, Presto, Spark, or KSQL. Have at least 2+ years of experience in writing Sub-Second Real-Time pipelines using Google DataFlow(Apache Beam), PubSub, Kinesis Stream, Lamda, etc. Have a good understanding of how Kubernetes clusters work and scale on-demand. Have adequate experience using Containers for Data Engineering workload. Implemented manual or automated tools for Data Quality, Catalog, and Lineage. Uphold the sense of Frugality across Data Engineering teams. Have Good Interpersonal and Presentation Skills to explain and promote Best Practices across the organization with both technical as well as non-technical stakeholders. -",https://www.jobstreet.com.sg/en/job/lead-data-engineer-cloud-1034913876?jobId=jobstreet-sg-job-1034913876&sectionRank=281&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
281,Data Engineer,Autodesk Asia Pte Ltd,"Job Requisition ID # 23WD68046 Position Overview Autodesk is looking for a Data Engineer to join the Data Ingestion team within the Analytics Data organization. The Data Ingestion team processes around 100 billion events and 250TB of data per day from all Autodesk products. The team is responsible for building and maintaining streaming real-time enterprise level data pipelines and developing simple, repeatable ingestion patterns for Autodesk’s internal data platform. As a Data Engineer, you will be contributing to rapidly improve critical data processing &amp; analytics pipelines. You will be involved in delivering innovative solutions to sophisticated and modern engineering problems. As part of the team, you will learn, grow, and help bring data closer to our users. You will make critical choices, tackle hard problems and improve the platform’s reliability, resiliency, and scalability. We are looking for someone who is enthusiastic about working in a team, can own and deliver long-term projects to completion. You are detail and quality oriented, and excited about the prospects of having a big impact with data at Autodesk. Responsibilities Contribute to the team’s deliverables and innovate on scalability and latency challenges You will need a product-focused mindset. It is essential for you to understand business requirements and deliver systems that will scale and extend to accommodate those needs Diagnose and solve complex problems in distributed systems, develop and document technical solutions and sequence work to make fast, iterative deliveries and improvements Build and maintain high-performance, fault-tolerant and scalable distributed systems that can handle our massive scale Ideate and deliver innovative projects that will improve user experience Efficiently deliver thorough data-driven approach, robust systems designs, and effective software implementation Participate in, or spearhead design reviews with peers and stakeholders to adopt what’s best suited amongst available technologies Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency) Automate cloud infrastructure, services, and observability Develop CI/CD pipelines and testing automation Establish and uphold best engineering practices through thorough code and design reviews and improved processes and tools Drive a culture of trust, respect and inclusion within your team Minimum Qualifications 3+ years of relevant industry experience in streaming data systems Solid experience with streaming technologies (i.e. Kafka, Spark Streaming, Flink) and streaming tables (i.e. Hudi, Iceberg) Solid Proficiency with Amazon Web Services Proficient overall programming skills, able to write modular, maintainable code, preferably Python &amp; SQL Understanding of SQL, dimensional modeling, and at least one relational database Experience with automation frameworks/tools like Git, Jenkins, Ansible, and Cloudformation (or Terraform) Familiarity with containers and infrastructure-as-code fundamentals Problem solver with excellent written and interpersonal skills; ability to make sound, complex recommendations in a fast-paced, technical environment Humble, collaborative, team player, willing to step up and support your colleagues Effective communication, problem solving and interpersonal skills Commit to grow deeper in the knowledge and understanding of how to improve our existing applications Enthusiasm for cutting edge technologies, complex problems, and building things Familiar with non-functional testing such as load, performance and resiliency testing Good command of English (Speaking, Writing and Reading) Working in an agile environment using test driven methodologies Bachelor’s degree in Computer Science, Engineering or related field, or equivalent training, fellowship or work experience Preferred Qualifications Experience with Spark Experience with Hive and/or Snowflake Strong knowledge and experience in Hadoop 2.0 and its ecosystem. Experience with Airflow Experience with Looker #LI-POST At Autodesk, we're building a diverse workplace and an inclusive culture to give more people the chance to imagine, design, and make a better world. Autodesk is proud to be an equal opportunity employer and considers all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender, gender identity, national origin, disability, veteran status or any other legally protected characteristic. We also consider for employment all qualified applicants regardless of criminal histories, consistent with applicable law. Are you an existing contractor or consultant with Autodesk? Please search for open jobs and apply internally (not on this external site). If you have any questions or require support, contact Autodesk Careers. Salary is one part of Autodesk’s competitive package. Offers are based on the candidate’s experience and geographic location. In addition to base salaries, we also have a significant emphasis on discretionary annual cash bonuses, commissions for sales roles, stock or long-term incentive cash grants, and a comprehensive benefits package. -",https://www.jobstreet.com.sg/en/job/data-engineer-1034955922?jobId=jobstreet-sg-job-1034955922&sectionRank=282&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
282,Data Engineer (ETL),IHIS - Integrated Health Information Systems Pte Ltd,"Role and Responsibilities Manage multiple projects and is responsible for the execution from initiation to completion Determine project goals to ensure the project supports business objectives and strategies. Develop project plans which include requirements, scope, deliverables, budget and schedules. Projects tasks and resource requirements and to achieve optimal resource utilisation. Manage the vendor selection process (calling, evaluation and awarding of tenders). Evaluate potential solutions and make recommendations to resolve business problems. Liaise closely with business users and build good rapport. Liaise closely with vendors in project implementation, application testing, supporting application patches and upgrades in accordance with project methodologies and policies. Manage the risks that affect the delivery of the project outcome. Track project deliverables and ensure projects are completed within budget, schedules and quality standards. Implement process improvements to reduce development time. Present reports and project updates to stakeholders on a regular basis. Provide on-going application support and be involved in various stages of the SDLC. Conduct user requirement analysis for the development / implementation of new systems and for enhancements to existing systems, including involvement in the system integration testing phase. Perform project implementation and application testing according to project and quality assurance procedures and methodologies. Conduct end user training for system implementations or enhancements. Manage a team by monitoring the work progress to meet project requirements for medium to large projects. Provide 24/7 primary application maintenance standby support. Provide guidance and coaching to junior team members. Requirements / Qualifications · At least 7 years experience in IT Project Management · At least 3 years experience in vendor management · Has implemented at least 2 medium to large scale projects · Solid understanding in Business Processes · Solid understanding and hands on experience in all phases of project lifecycle · Experience in budgeting (costing, cost evaluation analysis etc.) · Experience in various procurement methodology e.g. RFQ, RFP etc. · Experience in writing approval papers · Having good communication skills (written and spoken) · Be a team player · Being a creative problem-solver, make choices and take responsibility for their own actions · Ability to interact with all levels of stakeholders · Ability to perform root cause analysis · Degree in Computer Science, Computer Engineering or equivalent -",https://www.jobstreet.com.sg/en/job/data-engineer-etl-1034928262?jobId=jobstreet-sg-job-1034928262&sectionRank=283&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
283,Data Engineer,Frasers Property Limited,"ABOUT FRASERS PROPERTY We are a multinational developer-owner-operator of real estate products and services across the property value chain. Listed on the Main Board of the Singapore Exchange Securities Trading Limited (“SGX-ST”) and headquartered in Singapore, Frasers Property's multinational businesses operate across five asset classes, namely, residential, retail, commercial &amp; business parks, industrial &amp; logistics as well as hospitality. The Group has businesses in Southeast Asia, Australia, Europe and China, and its well-established hospitality business owns and/or operates serviced apartments and hotels in over 70 cities and 20 countries across Asia, Australia, Europe, the Middle East and Africa. The Group is committed to inspiring experiences and creating places for good for its stakeholders. By acting progressively, producing and consuming responsibly, and focusing on its people, Frasers Property aspires to raise sustainability ideals across its value chain and commits to net-zero carbon by 2050. WHAT YOU WILL BE DOING Able to understand business requirements and translate to design document from data ingestion to data modelling. Develop data pipelines and ingest data from various sources to data warehouse for consumption from 3rd party applications. Develop and manage data schema in data warehouses Manage data lake API calls from 3rd party application and access controls. Participate in designing the architecture of the data lake platform for new use cases. Responsible for verifying changes implemented by vendor and deploy it into the data lake production environment. Identify, design, and implement continuous improvements on good data governance practices. Monitor the health of data lake and investigate on issues that occur. WHAT WE ARE LOOKING FOR A minimum 2 years’ experience in data engineering (e.g. data modelling, data pipeline, data architecture, ETL). Experience in utilising Microsoft Azure and any related tooling for data engineering (such as Azure Data Factory, Azure Data Lake Storage, Databricks, Synapse). Knowledge of data modelling and understanding of different data structures and their benefits and limitations. Proficiency in writing SQL including stored procedures in languages such as T-SQL and PL/SQL. Experience in designing, architecting, and building scalable pipelines. Capability in programming languages (such as Python and Java). Be a natural problem solver. Self-motivated and proactive, willing to learn new things. Good communication skills and strong team player. Diversity brings us closer to the communities we serve Guided by our Purpose, we are creating, inspiring, and nurturing an inclusive culture that unlocks the power of diverse teams to drive Frasers Property forward. Our values drive everything we do, which are core to creating safe places where everyone belongs, is mutually respected and feels empowered to be authentic at work. Working collaboratively makes us progressively stronger and better as an organization, which helps our people to thrive each day. -",https://www.jobstreet.com.sg/en/job/data-engineer-1034897577?jobId=jobstreet-sg-job-1034897577&sectionRank=284&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
284,Senior Data Engineer (Digital),Singapore Power Limited,"Why Work for Us We Power the Nation. Make the most of your talents and develop products that can create impact on a national scale. We are an in-house software team, assembled to move with speed and deliver with quality. We Build Reliable Solutions. For Customers, Company and Country. You will be part of the Digital Technology Team and together, you will innovate, create, and deploy digital products that will empower more than 3,800 employees within SP Group and improve the quality of life for the 1.6 million commercial, industrial and residential customers that SP Group serves. We build solutions that enable sustainable high quality lifestyles and help consumers save energy and cost, as well as supporting national goals for a sustainable livable city. Now, imagine the impact you can create. What You’ll Do: Create and maintain multiple robust and high-performance data processing pipeline within Cloud, Private Data Centre and Hybrid data ecosystem Assemble large, complex data sets from a wide variety of data sources Collaborate with Data Scientist, Machine Learning Engineer, Business Analyst and Business users to derive actionable insights and reliable foresights into customer acquisition, operational efficiency and other key business performance metrics Develop, deploy and maintain multiple microservices, rest API and reporting services Design and implement internal processes to automate manual workflow, optimize data delivery and re-designing infrastructure for greater scalability, etc Establish expertise in designing, analyzing and troubleshooting large-scale distributed systems What You’ll Need: Experience building and operating large scale data lake and data warehouse Experience with Hadoop ecosystem and big data tools, including Spark and Kafka Experience with stream-processing systems including Spark-Streaming Advance working experience with relational SQL and NoSQL databases, including Hive, Hbase and Postgres Deep understanding in SQL and able to optimize data queries Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc A successful history of manipulating, processing and extracting value from large disconnected datasets Experience applying modern development principles (Scrum, TDD, continuous integration, and code reviews) Bonus: Experience with ETL tools such as Talend Big Data, Apache Nifi, etc Experience working with Hortonworks Data Platform or Cloudera Data Platform Experience with Metadata Management tools Exposure to Data Governance processes and tools Proven ability in supporting and working with cross-functional teams in a dynamic environment #LI-DNI Please click on the blue 'Apply' button at the top right hand side corner of this screen, if you are keen to apply for this job. Thank you for your interest in SP Group. You will be contacted if you are shortlisted for an interview. -",https://www.jobstreet.com.sg/en/job/senior-data-engineer-digital-1034804654?jobId=jobstreet-sg-job-1034804654&sectionRank=285&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
285,"Associate - Technology Consulting (Financial Services), Big Data Engineer",Ernst &amp; Young Solutions LLP,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. We are the only professional services organization who has a separate business dedicated exclusively to the financial services marketplace. Join Financial Services (FSO) and you will work with multi-disciplinary teams from around the world to deliver a global perspective. Aligned to key industry groups including asset management, banking and capital markets, insurance and private equity, we provide integrated advisory, assurance, tax, and transaction services. The Opportunity As part of our Data and Analytics team of Financial Services Consulting practice you will work with multi-disciplinary teams to support clients in a wide range of big data initiatives aiming to generate and present new, useful and actionable insights. You will have the opportunity to work and take responsibilities in challenging engagements, gaining exposure to clients in various sectors both in Singapore and in the APAC region. Your Key Responsibilities Participation in large-scale client engagements. Contribution towards, or even leading, the delivery of innovative and engaging big data solutions. Understanding of business and technical requirements, provision of subject matter expertise, and implementation of big data engineering techniques. Conducting of data discovery activities, performing root cause analysis, and making recommendations for the remediation of data quality issues. Putting into practice good organizational and time management skills, with the ability to prioritize and complete multiple complex projects under tight deadlines. Skills and Attributes for Success Leverage technology to continually learn, improve service delivery and maintain our leading-edge best practices Strong presentation skills and proficiency in the use of PowerPoint, Word and Excel Good understanding of financial services industry To Qualify for the role, you must have Bachelor or Master’s degree in Computer Science, Engineering, or other related fields. Understanding or even practical experience of handling and manipulating semi-structured and unstructured data. Understanding of big data technology, concepts, tools, features, functions and benefits of different approaches available. Ability to deploy, manage, and administer Hadoop-based components. Ability to design, build, install, configure and support Hadoop-based applications. Experience with one of Java, C# or C++ Understanding of data modeling (ER models) techniques. Ideally, you’ll also have Design and implementation experience of data models in physical form in one (or more) of the leading RDBMS platforms such as SQL Server, Oracle, IBM DB2/Netezza, Teradata, etc. Experience with Business Intelligence or statistical analysis tools and techniques. Strong communication and business relationship skills to effectively explain analysis, both verbally and in writing, to others and translate analysis into a clear business plan. Strong time management and organizational skills to gather and make use of data (both internal and external). What we look for Highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry. An effective communicator, you’ll be a confident team player that collaborates with people from various teams while looking to develop your career in a dynamic organization. What we offer Continuous learning: You’ll develop the mindset and skills to navigate whatever comes next. Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way. Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs. Diverse and inclusive culture: You’ll be embraced for who you are and empowered to use your voice to help others find theirs. If you can demonstrate that you meet the criteria above, please contact us as soon as possible. The exceptional EY experience. It’s yours to build. Apply now. -",https://www.jobstreet.com.sg/en/job/associate-technology-consulting-financial-services-big-data-engineer-1034841250?jobId=jobstreet-sg-job-1034841250&sectionRank=286&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
286,"Big Data Engineer (Financial Services) Senior Consultant, Technology Consulting",Ernst &amp; Young Solutions LLP,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. We are the only professional services organization who has a separate business dedicated exclusively to the financial services marketplace. Join Financial Services (FSO) and you will work with multi-disciplinary teams from around the world to deliver a global perspective. Aligned to key industry groups including asset management, banking and capital markets, insurance and private equity, we provide integrated advisory, assurance, tax, and transaction services. The Opportunity As part of our Data and Analytics team of Financial Services Consulting practice you will work with multi-disciplinary teams to support clients in a wide range of big data initiatives aiming to generate and present new, useful and actionable insights. You will have the opportunity to work and take responsibilities in challenging engagements, gaining exposure to clients in various sectors both in Singapore and in the APAC region. Your Key Responsibilities Participation in large-scale client engagements. Contribution towards, or even leading, the delivery of innovative and engaging big data solutions. Understanding of business and technical requirements, provision of subject matter expertise, and implementation of big data engineering techniques. Conducting of data discovery activities, performing root cause analysis, and making recommendations for the remediation of data quality issues. Putting into practice good organizational and time management skills, with the ability to prioritize and complete multiple complex projects under tight deadlines. Skills and Attributes for Success Leverage technology to continually learn, improve service delivery and maintain our leading-edge best practices Strong presentation skills and proficiency in the use of PowerPoint, Word and Excel Good understanding of financial services industry To Qualify for the role, you must have Bachelor or Master’s degree in computer science, Engineering, or other related fields. Minimally 3 years of relevant experience Understanding or even practical experience of handling and manipulating semi-structured and unstructured data. Deep understanding of big data technology, concepts, tools, features, functions and benefits of different approaches available. Ability to deploy, manage, and administer Hadoop-based components. Ability to design, build, install, configure and support Hadoop-based applications. Experience with one of Java, C# or C++. Hands-on experience with HiveQL. Familiarity with data ingestion tools such as Kafka, Flume and Sqoop. Knowledge of hadoop related workflow/scheduling tools such as Oozie. Understanding of data modeling (ER models) techniques. Experience with investigating and handling data quality issues. Minimum 1-3 years hands-on experience in two (2) or more of the above areas. Ideally, you’ll also have Design and implementation experience of data models in physical form in one (or more) of the leading RDBMS platforms such as SQL Server, Oracle, IBM DB2/Netezza, Teradata, etc. Experience with Business Intelligence or statistical analysis tools and techniques. Strong communication and business relationship skills to effectively explain analysis, both verbally and in writing, to others and translate analysis into a clear business plan. Strong time management and organizational skills to gather and make use of data (both internal and external). What we look for Highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry. An effective communicator, you’ll be a confident team player that collaborates with people from various teams while looking to develop your career in a dynamic organization. What we offer Continuous learning: You’ll develop the mindset and skills to navigate whatever comes next. Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way. Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs. Diverse and inclusive culture: You’ll be embraced for who you are and empowered to use your voice to help others find theirs. If you can demonstrate that you meet the criteria above, please contact us as soon as possible. The exceptional EY experience. It’s yours to build. Apply now. -",https://www.jobstreet.com.sg/en/job/big-data-engineer-financial-services-senior-consultant-technology-consulting-1034840643?jobId=jobstreet-sg-job-1034840643&sectionRank=287&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
287,Technical Lead,Tata Consultancy Services Asia Pacific Pte Ltd,"Job Descriptions • Proficient data engineer with 9 years of experience in the banking domain involving automating manual processes, optimizing data delivery through process improvements, handling migration projects(legacy to AWS Cloud). • Strong hands-on experience in object-oriented language Python and scripting languages like PowerShell, Batch, Shell. • Good understanding of installing, building, performance tuning and monitoring of Airflow DAGs to on-board data from multiple sources through Airflow cluster. • Experience in developing and implementing dashboards/visualizations using Kibana through KQL and painless scripting. • Good hands-on experience in Data Modelling, ETL development, and Data warehousing using Erwin, Snowflake and Talend. • Conversant in Agile methodology of project execution and DevOps Framework using CI/CD Jfrog, Jenkins, Cucumber, GitLab, Checkmarx. • Good understanding of Oracle/MySQL and PLSQL programming features (parallel processing, With clause). • Experience with data ingest, Extract, Transform, and Load (ETL) techniques using Logstash and Beats (Filebeat, Metricbeat shippers). • Good hands-on exposure in the development and maintenance of ServiceNow API integrations using REST. • Clear fundamental and applied knowledge of machine learning algorithms (clustering, decision tree learning, regression, text analytics / Natural Language Processing) with appropriate use to business problem. • Hands-on experience with AWS services - CloudWatch, Lambda, S3, API Gateway Services, EC2, Quicksight. Job Responsibilities - 6 to 8 yrs of IT exp with extensive experience as Data engineer - Must have hands-on experience in Python, R and API development - Must have worked in Data Modelling, Data Warehousing - Must have worked in cloud computing using AWP,GCP,Azure(either of these) - Must have good communication skill to handle Client and PMO for successful delivery. Must Have Skills - Strong Technical Background with hands on experience in High Level languages R, Python and OOPS concepts. - Strong knowledge in data visualization tools like Elastic Search, Tableau, Power BI. -Strong knowledge and experience in SQL, Batch Scripting - Experience of Agile/Scrum development methodologies Good To Have Skills - Experience with ETL tools to deliver data workflows using Talend, Airflow - Hands-on experience with stream processing systems like Kafka, Flink or Storm -Knowledge of DevOps tools like GIT, CICD, Docker and Kubernetes -Develop data cleaning and data wrangling tools(Python, SQL, Excel) for analysis and analytics modelling Domain Competency Banking and Payments domain -",https://www.jobstreet.com.sg/en/job/technical-lead-1034871799?jobId=jobstreet-sg-job-1034871799&sectionRank=288&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
288,Lead Data Enigneer (AWS and Spark),Income Insurance Limited,"We are looking to hire a Lead Data Engineer. This is an exciting opportunity join Income and lead the data engineering ETL team to build/maintain hybrid Datalake for BAU projects. Responsibilities · Lead the team in maintaining ETL data pipelines from ingestion to consumption within a big data architecture. · Work on Change data capture from Source DBs to Datalake. · Work on ETL jobs development through Informatica BDM/SPARK on “ On-Prem Cloudera Hadoop &amp; AWS Cloud data lakes”. · Implementing data lineage and other data governance related artefacts within Datalake. · Maintain ETL data pipelines from ingestion to consumption within a big data architecture. · Establish, maintain, and enforce ETL architecture design principles, techniques, standards and best practices · Drive the technical design of ETL reference architecture to ensure high data quality, data integration performance and error recovery/handling · Review and assess existing ETL applications to support new features, performance improvements, upgrades, and ongoing sustainability · Conduct design reviews, code reviews, performance tuning and perform an active, leading role in shaping and enhancing overall Informatica architecture, including standards, patterns and best practices Experience / Skills · Good verbal and written communication skills. · At least 8+ years of experience on Informatica BigData ETL, On-Prem Cloudera(Hive, Spark &amp; kafka) &amp; Cloud(preferably AWS). · Experience in Data Engineering Technologies – MySQL, Oracle, MS SQL Server, JSON, Hadoop platform (HDFS/Hive/Impala/Kudu), AWS (Glue, DMS, S3, Athena, RDS-PostgreSQL, Lambda, Code Commit, Code Pipeline, Code build, etc), Airflow · Able to do scripting – SQL, bash and Python/PySpark. · Insurance domain knowledge is added advantage. Qualification • Minimum Degree in computer science related areas. -",https://www.jobstreet.com.sg/en/job/lead-data-enigneer-aws-and-spark-1034714996?jobId=jobstreet-sg-job-1034714996&sectionRank=289&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
289,"Data Engineer (SQL, Azure)",Adept Manpower (APAC) Ptd. Ltd.,"Company highlight Company transport provided at Tampines MRT Good Employee benefits and Transparent career progression Job stability for long-term career growth Job Description Join a team responsible for building and maintaining data systems or pipelines Set up, install, configure, troubleshoot, and upgrade commercial off-the-shelf (COTS) products Develop and implement ways to enhance data warehouses, data lakes, or similar platforms Contribute to the creation of documentation such as design documents and troubleshooting guides Requirement Knowledge and/or experience in data management or data engineering Familiarity with Linux commands and shell scripting Knowledge and/or experience in relational databases (including SQL) or NoSQL databases (e.g., document, graph) Advantageous to have experience in DataStage, Denodo, Hadoop, Python, Spark, Microsoft Azure Cloud services, Databricks, Dataiku, Data Robot Degree/Diploma in Computer Engineering/Computer Science/Information Technology or a related technical discipline with 1-4 years of experience in related fields No Experienced candidates are encouraged to apply Reine Sim Wen Yih EA License No.: 02C3423 Personnel Registration No.: R21103357 Please note that your response to this advertisement and communications with us pursuant to this advertisement will constitute informed consent to the collection, use and/or disclosure of personal data by ManpowerGroup Singapore for the purpose of carrying out its business, in compliance with the relevant provisions of the Personal Data Protection Act 2012. To learn more about ManpowerGroup's Global Privacy Policy, please visit *************** -",https://www.jobstreet.com.sg/en/job/data-engineer-sql-azure-1034871358?jobId=jobstreet-sg-job-1034871358&sectionRank=290&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
290,Data Engineer,Hewlett Packard Enterprise (SG),"Hewlett Packard Enterprise is an industry leading Technology Company that enables customers to go further, faster. With the industry’s most comprehensive portfolio, spanning the cloud to the data center to workplace applications, our technology and services help customers around the world make IT more efficient, more productive and more secure. We have an open position for Data Engineer to join the Global Digital Technology and Innovation team. This team drives the adoption of new Big Data technologies and advanced analytics for a $26B worldwide business. The team leads key initiatives across the world sponsored by senior leadership and is responsible for data analytics led innovations and business process improvement. Key Responsibilities: Understand business requirement to build reliable data infrastructure using big data technologies Work with the data engineering team to develop &amp; maintain data pipelines for batch &amp; stream processing. Build tools suitable to provide data 24x7 for a global team, thru acquiring, monitoring and root cause analysis of data issues Identify, design, and implement internal process improvements and tools to automate data processing and ensure data integrity while meeting data security standards Build tools for better discovery and consumption of data for various consumption models in the organization – DataMarts, Warehouses, APIs, Adhoc Data explorations Architect and create data views from big data store to feed into analysis engines, visualization engines etc. Work with data scientist and business analytics team to assist in data ingestion and data-related technical issues Qualifications, Experience &amp; Knowledge Required : Bachelor’s degree in IT, Computer Science, Software Engineering, Business Analytics or equivalent Advanced university degree would be additional advantage Possess 6 years of experience in data warehousing / distributed system (e.g. Hadoop) Experience with relational SQL and NoSQL DB Expert in building and optimizing ‘big data’ data pipelines, architectures, and data sets Experience in data ingestion, cleaning and processing tools. Excellent experience in data processing using Scala/Python/Java Proficient in Big data tools and ecosystem (e.g. HIVE, HBase, Kafka, Spark, ...) Knowledge &amp; practices of SDLC process and agile methodologies Strong in user requirements gathering, maintenance, and support Highly organized, self-motivated, pro-active, and able to plan Experience managing users and vendors is a plus -",https://www.jobstreet.com.sg/en/job/data-engineer-1034871792?jobId=jobstreet-sg-job-1034871792&sectionRank=291&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
291,Big Data Engineer / Data Analyst (Azure Data / Informatica),Randstad - Corporate,"To apply, It will be great if you could share your CV to ************@randstad.com.sg. Alternatively, you can apply at *************** Strong support from business stakeholders to invest in data Newly created role due to business expansion Concrete project timeline on a regional role About the company Our client is an end user with multiple offices across Asia. With the ongoing Data Azure project, they are looking to recruit a new Data Engineer to join their team. About the job Reporting to the Head of Data, you will be responsible for: Building data ingestion pipeline. This includes maintaining optimal data pipeline architecture Assembling large, complex data sets to be ready for data analytics to support analytics initiatives Implementing the delivery of data solution for business stakeholders across different departments (Manufacturing, Operations and etc) Implementing Data governance Framework (Policies, Standards and Roles). This includes driving Data governance initiative over the design and implementation of data analytics projects Analyse current business processes, identifying and translating data requirements into business improvement through data analytics. This includes developing technical solutions in areas of big data platform to fulfil various business use cases. Skills and experience required As a successful applicant, you will have at least 4 years of big data experience. Exposure to Microsoft Azure Data Services will be of added advantage. Whats on offer This is an excellent opportunity to join a leading company with the opportunity to participate in high value Data projects with exposure to latest technology. To apply online please use the 'apply' function, alternatively you may contact Hoon Teck TAN at 6510 3***. (EA: 94C3609/ R1219669) Applicants must be fully vaccinated or have a valid exemption in accordance with MOM’s regulations to allow them to enter the workplace. Applicants may be required to share verifiable COVID-19 vaccination documents or proof of a valid exemption at the point of offer. Randstad Pte. Limited and/or the Client reserves the right to withdraw an offer if the applicant fails to provide verifiable COVID-19 vaccination and/or proof of exemption documents. To apply, It will be great if you could share your CV to ************@randstad.com.sg. Alternatively, you can apply at *************** (EA: 94C3609/ R1219669) -",https://www.jobstreet.com.sg/en/job/big-data-engineer-data-analyst-azure-data-informatica-1034744115?jobId=jobstreet-sg-job-1034744115&sectionRank=292&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
292,Data Engineer (Data Engineering),Government Technology Agency of Singapore (GovTech),"What the role is The Government Technology Agency (GovTech) aims to transform the delivery of Government digital services by taking an ""outside-in"" view, putting citizens and businesses at the heart of everything we do. We also develop the Smart Nation infrastructure and applications, and facilitate collaboration with citizens and businesses to co-develop technologies. Join us as we support Singapore’s vision of building a Smart Nation - a nation of possibilities empowered through info-communications technology and related engineering. As a Data Engineer in the Data Engineering team of GovTech’s Data Science and Artificial Intelligence Division, you will be building Whole-of-Government data infrastructure to power the insights needed for evidence-based decision-making and enhancing agencies’ service-delivery. You will be architecting, designing and building next-generation data infrastructure to galvanise digitalisation in the public sector. We are looking for enthusiastic and passionate engineers to join us in this journey to make a difference. What you will be working on: Design and build resilient and efficient data pipelines for both batch and real-time streaming data Architect and design data infrastructure on cloud using industry standard Infrastructure-as-Code tools Execute projects with an Agile mindset Build software frameworks to solve data problems at scale Collaborate with product managers, software engineers, data analysts and data scientists to build scalable and data-driven platforms and tools What we are looking for: Bachelor’s Degree in Computer Science or have equivalent professional experience Experience with data processing tools such as Spark, Beam, Flink Experience with the cloud (e.g. AWS, GCP, Azure) Experience implementing batch and streaming data pipelines Experience writing efficient SQL In-depth knowledge of both SQL and NoSQL databases, including performance tuning and troubleshooting Familiar with DevOps tools such as Git, Docker, Terraform Experience in the public sector is a bonus We are an equal opportunity employer and value diversity at our company as we believe that diversity is meaningful to innovation. Our employee benefits are based on a total rewards approach, offering a holistic and market-competitive suite of perks. This includes generous leave benefits to meet your work-life needs. We trust that you will get the job done wherever you are, and whatever works best for you – so work from home or take a break to exercise if you need to*. We also believe it’s important for you to keep honing your craft in the constantly-evolving tech landscape, so we provide and support a plethora of in-house and external learning and development opportunities all year round. *Subject to the nature of your job role that might require you to be onsite during fixed hours What you will be working on What we are looking for -",https://www.jobstreet.com.sg/en/job/data-engineer-data-engineering-1034941323?jobId=jobstreet-sg-job-1034941323&sectionRank=293&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
293,Senior Data Engineer (Data Engineering),Government Technology Agency of Singapore (GovTech),"What the role is The Government Technology Agency (GovTech) aims to transform the delivery of Government digital services by taking an ""outside-in"" view, putting citizens and businesses at the heart of everything we do. We also develop the Smart Nation infrastructure and applications, and facilitate collaboration with citizens and businesses to co-develop technologies. Join us as we support Singapore’s vision of building a Smart Nation - a nation of possibilities empowered through info-communications technology and related engineering. As a Senior Data Engineer in the Data Engineering team of GovTech’s Data Science and Artificial Intelligence Division, you will be building Whole-of-Government data infrastructure to power the insights needed for evidence-based decision-making and enhancing agencies’ service-delivery. You will be architecting, designing and building next-generation data infrastructure to galvanise digitalisation in the public sector. You will be given opportunities to lead other engineers to drive impact at scale. We are looking for enthusiastic and passionate engineers to join us in this journey to make a difference. What you will be working on: Design and build resilient and efficient data pipelines for both batch and real-time streaming data Architect and design data infrastructure on cloud using industry standard Infrastructure-as-Code tools Execute projects with an Agile mindset Build software frameworks to solve data problems at scale Collaborate with product managers, software engineers, data analysts and data scientists to build scalable and data-driven platforms and tools Be put in the driving seat as an engineering leader What we are looking for: Bachelor’s Degree in Computer Science or have equivalent professional experience Have more than 4 years of experience in a technical role Experience with data processing tools such as Spark, Beam, Flink Experience with the cloud (e.g. AWS, GCP, Azure) Experience implementing batch and streaming data pipelines Experience writing efficient SQL In-depth knowledge of both SQL and NoSQL databases, including performance tuning and troubleshooting Familiar with DevOps tools such as Git, Docker, Terraform Experience in the public sector is a bonus Previous technical leadership experience is a bonus We are an equal opportunity employer and value diversity at our company as we believe that diversity is meaningful to innovation. Our employee benefits are based on a total rewards approach, offering a holistic and market-competitive suite of perks. This includes generous leave benefits to meet your work-life needs. We trust that you will get the job done wherever you are, and whatever works best for you – so work from home or take a break to exercise if you need to*. We also believe it’s important for you to keep honing your craft in the constantly-evolving tech landscape, so we provide and support a plethora of in-house and external learning and development opportunities all year round. *Subject to the nature of your job role that might require you to be onsite during fixed hours What you will be working on What we are looking for -",https://www.jobstreet.com.sg/en/job/senior-data-engineer-data-engineering-1034941159?jobId=jobstreet-sg-job-1034941159&sectionRank=294&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
294,"Principal Data Engineer, Data Engineering",Government Technology Agency of Singapore (GovTech),"What the role is The Government Technology Agency (GovTech) aims to transform the delivery of Government digital services by taking an ""outside-in"" view, putting citizens and businesses at the heart of everything we do. We also develop the Smart Nation infrastructure and applications, and facilitate collaboration with citizens and businesses to co-develop technologies. Join us as we support Singapore’s vision of building a Smart Nation - a nation of possibilities empowered through info-communications technology and related engineering. As a Principal Data Engineer in the Data Engineering team of GovTech’s Data Science and Artificial Intelligence Division, you are responsible for helping to shape the direction of the data engineering domain in GovTech; working with other domain experts, the delivery teams, vendors, and partners to influence technology roadmaps and the adoption of suitable data solutions across government. In addition, you will teach, mentor, and proactively grow fellow data engineers within the organization. You will be leading multiple teams of data engineers to drive impact at scale, by building whole-of-government data infrastructure to power the insights needed for evidence-based decision-making and enhancing agencies’ service-delivery. You will architect, design and build next-generation central data infrastructure to galvanise digitalisation in the public sector. Taking a more integrated approach to lay the foundation infrastructure and driving pervasive adoption of advanced data technologies throughout the economy and society, you will architect solutions that enable public agencies and sectoral partners to better integrate, exploit and understand their data to improve operations and decision-making, and deliver high-quality digital services to citizens and businesses in Singapore. Join us on this journey to make a difference for the nation and our future generations, if you are: Experienced leading data pipeline building and data wrangling and enjoys optimizing data systems and building them from the ground up as part of multiple cross-functional teams, Have strong project management and organizational skills, self-directed and comfortable supporting the data needs across multiple teams, systems and products, Excited by the prospect of optimizing or even re-designing central and agencies’ data architecture to support next generation of government products and data initiatives, and Recognized expert with proven technical leadership, experienced working in a agile team to build systems from architecture to deployment for cloud and on-prem infrastructure, and Have the desire to serve the public good through the use of technology. What you will be working on : Take the driving seat and lead our data engineers in complex technical projects to: Expand and optimize our data and data pipeline architecture, as well as optimize data flow systems for cross functional teams in a secured and scalable manner. Assemble large, complex data sets that meet functional / non-functional business requirements, transforming data into formats that are easy to consume and analyse. Identify, design, and implement internal process improvements, e.g., automating manual processes, optimizing data delivery, re-designing infra for greater scalability. Build the infra required for optimal extraction, transformation, and loading of data from a variety of data sources using SQL and industry standard Infra-as-Code tools. Build analytics tools that utilize the data pipeline to provide actionable insights into key performance metrics and support our next gen of products and data initiatives. Work with stakeholders including the Executive, Product, Data and Design teams to support their data and data pipelining use cases, and ensure optimal and secured data delivery architecture is consistent across projects, products and platforms. Drive innovative initiatives that uplift data capability across the government sector: Develop a strategic sense of key organisations, software and hardware tools, methodologies, and best practices in the data engineering landscape. Be the bridge between engineering and product line management and translate market requirements into product definitions and architecture designs. Analyse and solve complex data engineering problems, and translate architecture designs into implementations that satisfy the market requirements. Educate the team on new technological advances and work alongside them in proof-of-concept research projects and subsequent agile product delivery. Provide expert perspective to help shape data-related strategy and initiatives, and be our technical ambassador by writing internal blogs or publishing white papers. What we are looking for : Candidate with 8+ years of experience in a Lead Data Engineer role, who has attained a Bachelor’s degree in Computer Science or other relevant engineering degree. In-depth working knowledge across a variety of relational SQL and NoSQL databases, including efficient query authoring, performance optimisation and troubleshooting. Experience building and optimizing data, data pipelines, and architectures, with processes to support transformation, data structures, metadata, dependency and workload management. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for further improvement. Working knowledge of message queuing, stream processing, and scalable data stores. A successful history of processing and extracting value from large datasets from different sources and systems, with strong analytics skills related to working with unstructured data. You should also have experience using the following software/tools: Big data and stream-processing tools: Hadoop, Spark, Beam, Flink, Kafka, etc. Data pipelining and workflow management tools: Luigi, Airflow, etc Cloud computing environments and services: AWS, GCP, Azure DevSecOps tools: Git, Kubernetes, Docker, Terraform etc Programming languages: Python, Java, C++, Scala, etc We are an equal opportunity employer and value diversity at our company as we believe that diversity is meaningful to innovation. Our employee benefits are based on a total rewards approach, offering a holistic and market-competitive suite of perks. This includes generous leave benefits to meet your work-life needs. We trust that you will get the job done wherever you are, and whatever works best for you – so work from home or take a break to exercise if you need to*. We also believe it’s important for you to keep honing your craft in the constantly-evolving tech landscape, so we provide and support a plethora of in-house and external learning and development opportunities all year round *Subject to the nature of your job role that might require you to be onsite during fixed hours” What you will be working on What we are looking for -",https://www.jobstreet.com.sg/en/job/principal-data-engineer-data-engineering-1034940562?jobId=jobstreet-sg-job-1034940562&sectionRank=295&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
295,"Data Engineer, Quantitative Strategy",Government Technology Agency of Singapore (GovTech),"What the role is The Government Technology Agency (GovTech) seeks to transform the delivery of Government Digital Services by taking an ""outside-in"" view, putting citizens and businesses at the heart of everything we do. We also develop the Smart Nation infrastructure and applications, and facilitate collaboration with the public to co-develop technologies. Join us as we support Singapore’s vision of building a Smart Nation - a nation of possibilities empowered through info-communications technology and related engineering. Outcome Driven Our projects are not academic exercises. We are driven by the “so what” and make sure that our findings and models can be translated into tangible impact. We build things quickly. If it works, good — how can we scale this up further? If not, what went wrong and what can we do better next time? You are not just here to write code, but also to figure out what we should be building and how we should build it. Working on new ideas often means not fully understanding what you are working on. Taking time to learn new architectures, frameworks, technologies, and even languages are not just encouraged but essential. We draw from the deep domain knowledge of our partners and best practices from our community of experts. *************** Job Overview: We are seeking a Data Engineer to join our Quantitative Strategy team, to be sited with one of our Agency Data Science Teams. team deployed at a government agency identified as a strategic partner for DSAID, with the mandate to drive the growth of agency’s data analytics capabilities while operating in close alignment to DSAID's approach and philosophy. Your main role is to build Whole-of-Government data infrastructure at the partner agency, to power insights needed for evidence-based decision-making and enhancing the agency’s service delivery. to elicit useful business information that enables you to perform your job. What you will be working on: Translate data requirements from business users and data scientists into technical data modelling specifications. Interview business users and system owners to elicit information relating to their data infrastructure, data assets, data policies, and use cases. Collaborate with partner agency’s IT teams on the following tasks: Propose and build ingestion pipelines to collect, clean, harmonise, merge, and consolidate data sources, whether on-prem or in cloud; Integrate and collate data sources with data systems; Day-to-day monitoring of databases and ETL systems, e.g., database capacity planning and maintenance, monitoring, and performance tuning; diagnose issues and deploy measures to prevent recurrence; ensure maximum database uptime; Construct, test, and update useful and reusable data models, with reference to consolidated business insights obtained from users, to serve the data science team and partner agency's needs; Propose and implement appropriate cloud data infrastructure in support of the end-to-end analytics deployment lifecycle, taking into account networking between cloud data infrastructure and any on-prem data centres; Design and build API gateways to expose data to systems via secure means. Research and develop new technologies and approaches for building highly available data persistence systems. Advice and support your team on data engineering matters. Own and participate in AWS data cloud migration projects (if applicable). What we are looking for: A Bachelor’s Degree, preferably in Computer Science, Software Engineering, Information Technology, or related disciplines. Deep understanding of system design, data structure and algorithms, data modelling, data access, and data storage. Proficiency in writing SQL for databases such as Postgres, MSSQL, MongoDB, neo4j. Demonstrated ability in using cloud technologies such as AWS, Azure, and Google Cloud. Experience with data engineering tools and frameworks such as Airflow, Kafka, Hadoop, Spark, Kubernetes. Experience in benchmarking, clustering, and tuning the databases for performance, reliability. Experience in designing, building, and maintaining batch and real-time data pipelines. Experience in automation development, batch, shell, python. Familiarity with regular expressions and scripting languages such as bash, korn, awk. Familiarity with building and using CI/CD pipelines for platform development. Familiarity with DevOps tools such as Docker, Git, Terraform. Familiarity with LDAP, OAuth, API gateways. Preferred requirements: Knowledge of IT infrastructure Experience with AWS RDS / Spark / other AWS Data Services Experience with installation, management, upgrades, backup and restore MSSQL DB Working knowledge of SSIS or comparable ETL tools Familiarity with government systems and government's policies relating to data governance, data management, data infrastructure, and data security *Subject to the nature of your job role that might require you to be onsite during fixed hours What you will be working on What we are looking for -",https://www.jobstreet.com.sg/en/job/data-engineer-quantitative-strategy-1034941601?jobId=jobstreet-sg-job-1034941601&sectionRank=296&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
296,"Senior Data Engineer, Quantitative Strategy (FDT)",Government Technology Agency of Singapore (GovTech),"What the role is The Government Technology Agency (GovTech) aims to transform the delivery of Government digital services by taking an ""outside-in"" view, putting citizens and businesses at the heart of everything we do. We also develop the Smart Nation infrastructure and applications, and facilitate collaboration with citizens and businesses to co-develop technologies. Join us as we support Singapore’s vision of building a Smart Nation - a nation of possibilities empowered through info-communications technology and related engineering. Team Introduction: The Data Science &amp; Artificial Intelligence Division (DSAID) works with public sector agencies in using data science and AI to improve policy outcomes, service delivery and operational efficiency. We extract data-driven insights and build intelligent platforms to add value to the work of our partner agencies. We also help public sector agencies transform by partnering them in building data science expertise, formulating data strategies and setting up the necessary data infrastructure. How do we work: Outcome Driven - Our projects are not academic exercises. We are driven by the “so what” and make sure that our findings and models can be translated into tangible impact. Start Small and Move Fast - We build things quickly. If it works, good — how can we scale this up further? If not, what went wrong and what can we do better next time? Ownership - You are not just here to write code, but also to figure out what we should be building and how we should build it. Continuous Learning - Working on new ideas often means not fully understanding what you are working on. Taking time to learn new architectures, frameworks, technologies, and even languages are not just encouraged but essential. We are in this Together - We draw from the deep domain knowledge of our partners and best practices from our community of experts. Read more about us from the team's blog Job Overview: Team Lead (FDT - Forward Deployed Team) Team Lead, you will set up and lead a data science team in a government agency identified as a strategic partner for DSAID, to drive the growth of data science capabilities at the partner agency while operating in close alignment to DSAID’s approach and philosophy. architect, design, and build data infrastructure to power insights needed for data-driven decision making and service delivery at the partner agency. Where necessary, you will also help your team overcome project blockers, by working with the partner agency’s IT teams on the setup of relevant tools, systems, and infrastructures needed for project development and deployment. in order to drive impact at scale. You will also be reporting to multiple stakeholders, both at GovTech and the partner agency. To ensure that the team operates in close alignment with DSAID’s approach and philosophy, you and your team will meet up regularly with the central DSAID team and other agency data science teams, to exchange learning points and best practices across agencies. What you will be working on: Manage a team of 2-3 data scientists and/or data engineers deployed to the partner agency, to build next-generation data infrastructure and galvanise digitalisation at said partner agency. Organise and guide your team to execute the pipeline of projects. This will involve overseeing your team's work in the following areas: Design and build resilient and efficient data pipelines for both batch and real-time streaming data; Architect and design data infrastructure on cloud, using industry standard Infrastructure-as-Code tools; Build software frameworks to solve data problems at scale; Collaborate with product managers, software engineers, data analysts, and data scientists to build scalable and data-driven platforms and tools. Work with partner agency's Chief Data Officer (CDO)’s and Chief Information Officer (CIO)’s Offices to improve the agency’s data management and analytics infrastructure, and to grow data science capabilities within the agency’s workforce. Support the professional growth and development of data scientists and data engineers in your team and forge a positive team culture to ensure staff retention. What we are looking for: A Bachelor’s Degree or higher in Computer Science, Software Engineering, Information Technology, or related disciplines. Advanced degrees are preferred. Relevant training and certifications (e.g., Coursera) may also be considered. At least 5 years of relevant experience, in data engineering and/or the public sector, preferably with experience managing a data science team. Well-versed in government systems and government's policies relating to data governance, data management, data infrastructure, and data security. Have strong analytical, conceptualisation, and problem-solving skills. Able to take broad, strategic perspectives, and when necessary, drill deep to understand business needs and challenges. Understand key concepts, broad methodologies, and common use cases in data science. Deep understanding of key concepts in data engineering, e.g., system design, data structure and algorithms, data modelling, data access, and data storage. Training and relevant experience in four or more of the following areas: Both SQL and NoSQL databases, including performance tuning and troubleshooting; Write efficient SQL; Implement batch and streaming data pipelines; Cloud technologies such as AWS, Azure, and Google Cloud; Data engineering tools and frameworks such as Airflow, Kafka, Hadoop, Spark, Beam, Flink, Kubernetes; DevOps tools such as Docker, Git, Terraform; LDAP, OAuth, API gateways. Demonstrable experience in project management of technical initiatives. Have excellent oral and written communication skills, along with the ability to pitch ideas and influence stakeholders at all levels on the adoption of analytics. Able to present technical concepts and results of technical analyses to non-technical audience effectively. Adaptable to dynamic operating contexts and able to work with multiple stakeholders across different teams. Strong people manager who can inspire, motivate, and grow the team and has strong organisation skills. Effective in setting and managing individual and team KPIs. Have passion for improving public service using analytics and data. Preferred Requirements: Experience in agile project management Understand processes in digital transformation We are an equal opportunity employer and value diversity at our company as we believe that diversity is meaningful to innovation. Our employee benefits are based on a total rewards approach, offering a holistic and market-competitive suite of perks. This includes generous leave benefits to meet your work-life needs. We trust that you will get the job done wherever you are, and whatever works best for you – so work from home or take a break to exercise if you need to*. We also believe it’s important for you to keep honing your craft in the constantly-evolving tech landscape, so we provide and support a plethora of in-house and external learning and development opportunities all year round. *Subject to the nature of your job role that might require you to be onsite during fixed hours What you will be working on What we are looking for -",https://www.jobstreet.com.sg/en/job/senior-data-engineer-quantitative-strategy-fdt-1034940845?jobId=jobstreet-sg-job-1034940845&sectionRank=297&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
297,Data Architect - Contract = 12 months,Zenith Infotech (S) Pte Ltd,"This is a 12 months contract assigned to our client Work Location: To be confirmed Salary Range : $8,000-$12,000 Job Description: As a Data Engineering Architect 1. Comprehensive modern data engineer techniques and methods with Advanced Analytics to support business decisions for client. 2. Collect, aggregate, and analyze structured/unstructured data from multiple internal and external sources and patterns, insights, and trends to decision-makers. 3. Support the use of data-driven insights to help our Clients achieve business outcomes and objectives. 4. Collect, aggregate, store, and reconcile data in support of Client business decisions. 5. Design and build data pipelines, data streams, reporting tools, information dashboards, data service APIs, data generators and other end-user information portals and insight tools. 6. Critical part of the data supply chain, ensuring that stakeholders can access and manipulate data for routine and ad hoc analysis to drive business outcomes using Advanced Analytics. Job Scope 1. Translate business requirements to technical solutions leveraging strong business acumen. 2. Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging Microsoft Azure Data &amp; Analytics PaaS Services. 3. Support the planning and implementation of data design services, providing sizing and configuration assistance and performing needs assessments. 4. Delivery of architectures for transformations and modernizations of enterprise data solutions using Azure cloud data technologies. 5. Design and Build Modern Data Pipelines and Data Streams. 6. Design and Build Data Service APIs. 7. Develop and maintain data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics. 8. Expose data to end users using PowerBI, Azure API Apps or any other modern visualization platform or experience. 9. Implement effective metrics and monitoring processes. 10. Travel as needed Skills Requirement 1. Database Architecture 2. Microsoft SQL Server Integration Services SSIS 3. Data Modeling Techniques and Methodologies 4. Data &amp; AI Strategy 5. Extract Transform and Load (ETL) 6. Microsoft SQL Server Analysis Services (SSAS) 7. Demonstrated experience of turning business use cases and requirements to technical solutions. 8. Experience in business processing mapping of data and analytics solutions. 9. Ability to conduct data profiling, cataloging, and mapping for technical design and construction of technical data flows. 10. The ability to apply such methods to solve business problems using one or more Azure Data and Analytics services in combination with building data pipelines, data streams, and system integration. 11. Mastery of .NET C# and T-SQL with the familiarity of U-SQL is required 12. Knowledge of Azure Data Factory, Azure Data Lake, Azure SQL DW, and Azure SQL, Azure App Service is required. Azure IoT, Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics is a plus. Knowledge of Python is a plus. Experience preparing data for Data Science and Machine Learning. Experience preparing data for use in Azure Machine Learning and/or Azure Databricks is a plus. Demonstrated experience preparing data and building data pipelines for AI Use Cases (text, voice, image, etc.…). Designing and building Data Pipelines using streams of IOT data. Knowledge of Lambda and Kappa architecture patterns. 13. Knowledge of Master Data Management (MDM) and Data Quality tools and processes 14. Strong team collaboration and experience working with remote teams. 15. Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals. 16. Working experience with Visual Studio, PowerShell Scripting, and ARM templates. 17. Experience with Git/TFS/VSTS is a must. Certifications Preferred Certifications: MCAD .NET, MCSD .NET, MCDBA Preferred Education Background: You likely possess MS/ Ph.D. in a quantitative field such as computer science, applied mathematics, statistics, or machine learning. An equivalent combination of education and experience will also suffice. Preferred Years of Work Experience: You likely have about 5+ years of relevant professional experience. Preferred Years of Management Experience: 3+ years managing &amp; leadership of 3 or more associates in management consulting or industry. -",https://www.jobstreet.com.sg/en/job/data-architect-contract-%3D-12-months-1034871160?jobId=jobstreet-sg-job-1034871160&sectionRank=298&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
298,Data Engineering Interns,Quadrant,"Responsibilities Analyze and organize raw data Build data systems and pipelines Evaluate business needs and objectives Interpret trends and patterns Conduct complex data analysis and report on results Prepare data for prescriptive and predictive modeling Build algorithms and prototypes Combine raw information from different sources Explore ways to enhance data quality and reliability Identify opportunities for data acquisition Develop analytical tools and programs Collaborate with data scientists and architects on several projects Requirements Previous experience as a data engineer or in a similar role Technical expertise with data models, data mining, and segmentation techniques Knowledge of programming languages (e.g. Java and Python) Hands-on experience with SQL database design Great numerical and analytical skills Degree in Computer Science, IT, or similar field; a Master’s is a plus Data engineering certification (e.g Certified Data Engineer) is a plus -",https://www.jobstreet.com.sg/en/job/data-engineering-interns-1034839264?jobId=jobstreet-sg-job-1034839264&sectionRank=299&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
299,Senior Data Architect,AMPLIFY HEALTH ASIA PTE. LIMITED,"Instructions for interested applicants Please apply for this position via the following link *************** What you will do? The role entails designing the architecture for the data platform layer, data cleansing layer, reporting and analytical layers within a cloud environment. Work closely with Data Scientists to understand model features and link back to transactional environment to understand data quality, data relationships and data availability. Document and define frameworks with the Data Engineer to build the data platform. Together these teams will enable data driven actionable insights. The role is based in Singapore. Core responsibilities include: Provide Data Architecture (DA) support for the Data Engineering team Define DA for the Data Science teams and participate in review and walk-through sessions for model fit and model productionization Assist with the definition of custom meta data models for ELT/ETL Direct data automation capabilities with the Data Engineer and Data Scientist Profile new data sources in a variety of formats including Json, XML, etc Define data quality rules with Data Scientists to clean data Define data mapping and transformation rules between source and datawarehouse and data lake Work closely with Data Engineer to facilitate Data Governance including access and security control Documentation of DA for new data sources, metadata and productionized information flow Knowledge of Master Data design and implementation Define data sharing architecture and framework for data ingress and egress What skills do you need? Behavioural skills A passion for programming and working with data Self-starter Willingness to learn and grow exponentially A restless curiosity in learning new technology Ability to work cohesively in a team environment and balance multiple priorities A team player who can work alone when required and without supervision High level of attention to detail, resilience, enthusiasm, energy and drive Positive, can-do attitude Ethical and able to maintain confidentiality and manage boundaries Technical understanding Advanced to expert knowledge in SQL - on any database platform Advanced to expert data architecture and data model design eg DataWarehouse, Data Lakehouse, Data Mesh, Data Vault Experience working on large and complex datasets Working with design tools eg Enterprise Architect, Power Designer Working with Data teams to design and implement solutions Advanced knowledge working with technologies on MS Azure DevOps/DataOps and CI/CD experience Qualifications The following requirements are essential: Honours or Master’s degree in BSc Computer Science Honours or Master’s degree in Engineering or Software Engineering with solid experience in data mining and machine learning Other qualifications will also be considered if accompanied by the relevant experience 5 to 10 years of experience is preferred -",https://www.jobstreet.com.sg/en/job/senior-data-architect-1034744290?jobId=jobstreet-sg-job-1034744290&sectionRank=300&token=0~12ff6112-8198-4e16-9e0c-18f2c89f3eb1&fr=SRP%20Job%20Listing
300,Data Integration Specialist,Keppel Enterprise Services,"About Group Digital Office – Data and Digital team The folks at Keppel Corporation’s Group Digital Office are digital natives whose goal is to drive digitalization and transformation across the group. Sparking innovation and thought leadership, with core competency as critical thinker, disciplined thinker that is clear, rational, open-minded, and informed by evidence. A lean organization understands the value of its wealth data and strives to derive the sharpest insights to create competitive advantages. Our goal is to deliver those insights and work with the businesses to execute those actions. We are on the hunt for a data integration specialist who is comfortable working across multiple functions and teams that can help us stich together all the data and systems needed to deliver improved holistic business insights. Your tenaciousness and passion will help to ensure we can see through our missions through from conceptualization to final delivery. Job Description The Data Integration specialist is a subject matter expert of data integration solutions and data architecture You will be responsible for the technical development of any new data integration solution to be plugged in to the overall enterprise data architecture You will be supporting the Data Engineer to organise data at the macro and micro levels, creating data models that enable the implementation of the intended business architecture, key data entity diagrams, and a data inventory to implement the architecture vision Responsibilities Planning and executing data migrations, providing logical data models with business logic needed for creation of data quality rules Contributing to the Data Quality Improvement Program through application of data management best practices, designing data solutions, implementing future proof fixes, identifying opportunities for driving data process efficiency and data quality Supporting the Data Engineer to scope out and recommend technologies to enhance data Extracting, transforming and integrating large and small datasets. Working alongside developers to develop data integration solutions Maintaining and developing a reliable and efficient master data for the long term Supporting the development of a reporting data warehouse Developing and maintaining documentation for each data solution to ensure it reflects current business rules and definitions Facilitating stakeholders in identifying technology challenges, supporting them in defining requirements of their projects Collaborating with technology business partners to allow the organisation to absorb and scale into business-as-usual development work Executing some routine tasks on regular basis, which can include data imports and executing SSIS packages, also to support the Data Operations Team during peak times Job Requirements A curious data enthusiast with a passion for technology and problem solving 5 years’ experience working with any of the mainstream RDBMS Experience with end-to-end data pipeline implementation with cloud services such as Azure Data Factory/AWS Glue Data manipulation, data integration design and development including T-SQL, SSIS and APIs Datawarehouse tech: experience developing OLAP cubes and/or in memory data models Business Intelligence technology (e.g., Power BI) Good understanding of data lifecycle and architecture best practices. Systems integration experience with SAP systems is a bonus Understanding of Data Protection Legislation is a plus Good communication and excellent listening skills. Strong relationship building skills and a collaborative attitude towards everyday working Empathetic when dealing with colleagues Ability to work with modern workplace technology (such as MS Teams) from home and in the office -",https://www.jobstreet.com.sg/en/job/data-integration-specialist-1034927266?jobId=jobstreet-sg-job-1034927266&sectionRank=301&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
301,Research Team Manager,ASUS Global Pte Ltd,"ASUS is looking for several outstanding deep learning and computer vision research engineers to join our research team in Singapore. Our team’s purpose is to enable and facilitate the use of AI systems in the world. Our research is grounded in applications with a potential for broad impact. We seek opportunities to improve products with the help of AI. Our team builds expertise and gains insight on applications by working on high-impact projects. You have the opportunity to join and shape a new research team, where your contributions can have a real impact on our products. Responsibilities: Leading and managing a team with Data Engineer / Data Scientist / Machine Learning Engineer to align company's business goal and find solutions to the real life problems other teams are facing. Learn the business domain, participate in requirements gathering process. Should be familiar with DevOps and MLOps development and improve our product or solutions. Support and provide technical advice for exploration of new technologies, POC development of new IT and OT solutions, data analytics, and AI/ML development. Skills/Qualifications: Experience with managing teams and an entrepreneurial spirit that thrives in a fast-paced environment. Master degree or above in a STEM field such as CS, Engineering or Mathematics/Statistics with a strong interest in machine learning and computer vision. Ability to present and communicate complex machine learning concepts and explain business backgrounds clearly. Ability to build, train, coach and mentor a team. Clearly and effectively present research findings and developments, both verbally and in writing, both internally and externally. Experience / Preferred Background Experience with managing one or more general purpose programming languages project development. Experience with machine learning systems, algorithms or applications such as: deep learning, computer vision, unsupervised/semi-supervised learning, meta-learning, or time-series analysis. Experience with edge AI development. Open-source projects that demonstrate relevant skills and/or publications in relevant conferences and journals (e.g. NeurIPS, ICML, ICLR, CVPR, ICCV, ECCV, ICASSP) Experience with the following technologies or engaged in the projects of the following technologies: Self-supervised learning, Active learning, Transformer, Meta learning, Reinforcement learning etc. -",https://www.jobstreet.com.sg/en/job/research-team-manager-1034890627?jobId=jobstreet-sg-job-1034890627&sectionRank=302&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
302,Staff/Senior Risk Data Scientist,Airwallex,"The Role: This is a diverse role working within Airwallex’s risk product &amp; analytics domain with a focus on delivering data insights to drive product &amp; analytics optimisations and enhancements. Airwallex is building a centralised risk platform that will harness advanced analytics and machine learning techniques to enable real-time decisioning across a diverse range of product lines and platforms. The risk product &amp; analytics domain is responsible for building the platforms, engines &amp; case management whilst also delivering the risk models so you will be involved in crafting the full end-to-end risk capability. Responsibilities： Work with risk stakeholders throughout the company to identify opportunities for leveraging company data to drive risk solutions. Mine and analyze data from the company database to drive optimization and improvement of risk strategies. Assess the effectiveness and accuracy of new risk data sources and data gathering techniques. Develop customized data models and algorithms to risk data sets and communicate the insights of the models to related stakeholders. Develop A/B testing framework and test model quality for risk product. Coordinate with multiple functional teams to implement models and monitor performance. Develop processes and tools to monitor and analyze model performance and data accuracy. Qualifications： Bachelor's degree or higher in Computer Science, Math &amp; Statistics, Finance &amp; Economics, Engineering or related data disciplines. At least 7 years of experience as a data analyst, data scientist or data engineer. Strong problem-solving skills with an emphasis on risk-related product development. Hands-on and solid experiences in using statistical computer languages (Python, R, SQL, etc.) to manipulate data and draw insights from large data sets. Knowledge of a variety of machine learning techniques (clustering, decision tree learning, neural networks, etc.) and their real-world advantages/drawbacks. Knowledge of advanced statistical techniques and concepts (regression, simulation, properties of distributions, statistical tests, etc.) and experience with applications. A drive to learn and master new technologies and techniques. Excellent written and verbal communication skills in English for coordinating across teams. Experience working on data-driven financial risk models (e.g., money-laundering risk, credit risk, fraud risk) is preferred. Experience running data analytics under cloud environments and using web applications is preferred. -",https://www.jobstreet.com.sg/en/job/staff-senior-risk-data-scientist-1034871267?jobId=jobstreet-sg-job-1034871267&sectionRank=303&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
303,Data Modeler,AMPLIFY HEALTH ASIA PTE. LIMITED,"Instructions for interested applicants Please apply for this position via the following link *************** What you will do? The role entails designing data models for the data platform layer, data cleansing layer, reporting and analytical layers within a cloud environment. Work closely with Data Scientists to understand model features and link back to transactional environment to understand data quality, data relationships and data availability. Document and define frameworks with the Data Engineer to build the data platform. Together these teams will enable data driven actionable insights. The role is based in Singapore. Core responsibilities include: Analyse data sources Design data model to support analytics and reporting Support Data Engineers with ETL pipelines and Data Scientists with data understanding and model development Profile new data sources in a variety of formats including Json, XML, etc Define data quality rules with Data Scientists to clean data Define data mapping and transformation rules between source and target Documentation of data models for new data sources, metadata and productionized information flow What skills do you need? Behavioural skills A passion for programming and working with data Self-starter Willingness to learn and grow exponentially A restless curiosity in learning new technology Ability to work cohesively in a team environment and balance multiple priorities A team player who can work alone when required and without supervision High level of attention to detail, resilience, enthusiasm, energy and drive Positive, can-do attitude Ethical and able to maintain confidentiality and manage boundaries Technical understanding Advanced to Expert knowledge in SQL – on any database platform Modern datawarehouse design skills eg DataWarehouse, Data Lakehouse, Data Mesh, Data Vault Experience working on large and complex datasets Working with design tools eg Enterprise Architect, Power Designer Working with Data Architects to design and implement solutions Nice to have Health Care or Health Insurance data experience Strong communicator (verbal and written) Qualifications The following requirements are essential: Honours or Master’s degree in BSc Computer Science Other qualifications will also be considered if accompanied by the relevant experience 5 to 10 years of experience is preferred -",https://www.jobstreet.com.sg/en/job/data-modeler-1034744027?jobId=jobstreet-sg-job-1034744027&sectionRank=304&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
304,Data Architect,IBM GLOBAL SERVICES PTE. LTD.,"As a DTT Engineer/Architect, you will guide the technical evaluation phase as well as during the design and development phase in a hands-on environment in the area of Data Platform, Internet of Things (IoT) and Automation, Analytics including AI and Machine Learning, as well as Blockchain. You will be a technical advisor internally to the sales and delivery team, and work with the product (analytics or data) team as an advocate of your customers in the field. You’ll grow as a leader in your field, while finding solutions to our customers’ biggest challenges in big data, IoT, automation, data engineering and data science and analytics problems. As a Data engineer or Solution Architect you will provide services to clients in the analytics or data related solutioning and delivery of complex projects/programs for cloud and non-cloud environments, including complex application and/or system integration projects. You will help our customers to achieve tangible data-driven outcomes through the use of Data Engineering frameworks or Data Platform or in the area of Automation and Blockchain, helping data and analytics teams complete projects and integrate our platform into their enterprise Ecosystem. You will be responsible in terms of stitching together architectural landscape starting from data acquisition, ingestion and transformation before loading the same in the desire data warehouses in form of datamarts as per the requirement. You will also facilitate the process of how the curated data could be consumed by downstream application in order to meet the business requirement in form of Management Information System or Analytics solutions. The solution architect will build architectures &amp; coordinate with other architects to build an end to end prescriptive guidance across network, storage, operating systems, virtualization, RDBMS &amp; NoSQL databases, and mid-tier technologies that include application integration, in-memory caches, and security. Required Technical and Professional Expertise Overall 12+ years of (consulting) experience focused in data and analytics. Have a good understanding of data warehousing, ETL, complex event processing, data engineering, Big Data principles and data visualization, Data Sciences, Business Intelligence, Analytics products etc Experienced in working in a hybrid cloud environment and exposure to Big Data framework is a must. Proficient understanding of distributed computing principles Deep experience with distributed systems, large scale non-relational data stores, map-reduce systems, data modelling, database performance, and multi-terabyte data warehouses Knowledge in the area of internet of things including IoT related device knowledge is a must for the role Desired knowledge in the area of containerization framework like Kubernetes or Red Hat Open Shift is an added advantage for the role Desired knowledge in the area of API/ Microservices development is a good to have skills Exposure in managing and implement integrations between internal and external solutions Demonstrated experience in collaborating with domain architecture leadership Extensive development expertise in Spark and other Big Data processing frameworks (Hadoop, Storm, Kafka etc) Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala Knowledge of various ETL techniques and frameworks, such as Flume and stream processing systems like Storm or Spark-Streaming Programming knowledge and skill with SQL, NoSQL, Python and PySpark Working knowledge of other BI / Analytics / Big Data tools (IBM Cognos, QlikView, HortonWorks, Cloudera, Azure Data Factory, Automation Anywhere, BluePrism) is a plus Experience in creating end to end blueprint, estimating the effort, pricing and risk assessment of the solution Excellent communication skills with an ability to lead right level conversations -",https://www.jobstreet.com.sg/en/job/data-architect-1034856459?jobId=jobstreet-sg-job-1034856459&sectionRank=305&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
305,Software Engineer (PySpark),Epam Systems Pte. Ltd.,"About EPAM EPAM is a leading global provider of digital platform engineering and development services. EPAM has been expanding in Singapore since 2013 and delivering the best solutions to our customers. As a recognized leader, EPAM Singapore achieved Great Place to Work Certification in 2021 and is committed to providing our team with inspiring careers. You will have the opportunity to work with fellow talented technologists and accelerate your career by participating in our numerous upskilling, training, and certification programs. That is why EPAM Singapore was awarded Silver in the SkillsFuture Employers Awards 2022 for our efforts in championing employees' skills development and building a lifelong learning culture at the workplace. You can also look forward to developing holistically with the multiracial festivals and various wellness and cultural activities organized by our passionate colleagues here. Why EPAM? By choosing EPAM, you're getting a job at one of the most loved workplaces according to Newsweek 2021 &amp; 2022. Employee ideas are the main driver of our business. We have a very supportive environment where your voice matters. You will be challenged while working side-by-side with the best talent globally. We work with top-notch technologies, constantly seeking new industry trends and best practices. We offer a transparent career path and an individual roadmap to engineer your future &amp; accelerate your journey. At EPAM, you can find vast opportunities for self-development: online courses and libraries, mentoring programs, partial grants of certification, and experience exchange with colleagues around the world. You will learn, contribute, and grow with us. What You’ll Do EPAM Singapore is looking for a Data Engineer with a good understanding of model implementation, data structures, data manipulation, distributed processing, application development, and automation. You will collaborate with teams across varying levels all over the world and be part of a major transformation program. Creating complex, enterprise-transforming applications on diverse, high-energy teams Work with the latest data tools and techniques Hands-on coding, usually in a pair programming environment Working in highly collaborative teams and building quality code What Will Make You Shine Degree in Computer Science or equivalent/higher Hand-on Development experience with PySpark, Scala Spark and Distributed computing. 4 - 6 years' experience designing and developing applications in Python and Hadoop Platform. 3 - 5 years' experience with Unix shell scripting and SQL 2 - 3 years' experience with Spark programming How We Hire Here, we summarize the typical journey to finding a job within EPAM: Apply and tell us about yourself Go through some standard interviews: General interview with a recruiter Technical interview with our technology experts Manager interview or Offer interview with a hiring manager Get ready to join the team Not sure if you meet all the requirements? No problem. Let’s talk anyway and find out more. It takes 1 min of application to start the journey with us. Apply now! -",https://www.jobstreet.com.sg/en/job/software-engineer-pyspark-1034709957?jobId=jobstreet-sg-job-1034709957&sectionRank=306&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
306,"Specialist Solutions Architect, Greater China Region",Databricks,"As a Specialist Solutions Architect (SSA), you will guide customers in building big data solutions on Databricks that span a large variety of use cases. These are customer-facing roles, working with and supporting the Solution Architects, requiring hands-on production experience with Apache Spark™ and expertise in other data technologies. SSAs help customers through design and successful implementation of essential workloads while aligning their technical roadmap for expanding the usage of the Databricks Lakehouse Platform. As a deep go-to-expert reporting to the Technical GM for the Greater China Refion, you will continue to strengthen your technical skills through mentorship, learning, and internal training programs and establish yourself in an area of specialty - whether that be performance tuning, machine learning, industry expertise, or more. The impact you will have: Provide technical leadership to guide customers in the Greater China Region for successful implementations on big data projects, ranging from architectural design to data engineering to model deployment Architect production level workloads, including end-to-end pipeline load performance testing and optimisation Provide technical expertise in an area such as data management, cloud platforms, data science, machine learning, or architecture Assist Solution Architects with more advanced aspects of the technical sale including custom proof of concept content, estimating workload sizing, and custom architectures Improve community adoption (through tutorials, training, hackathons, conference presentations) Contribute to the Databricks Community What we look for: ou will have experience in a customer-facing technical role with expertise in at least one of the following: Software Engineer/Data Engineer: query tuning, performance tuning, troubleshooting, and debugging Spark or other big data solutions. Data Scientist/ML Engineer: model selection, model lifecycle, hyper parameter tuning, model serving, deep learning. Data Applications Engineer: Build use cases that use data - such as risk modelling, fraud detection, customer life-time value. Experience with design and implementation of big data technologies such as Spark/Delta, Hadoop, NoSQL, MPP, OLTP, and OLAP. Maintain and extend production data systems to evolve with complex needs. Production programming experience in Python, R, Scala or Java Deep Specialty Expertise in at least one of the following areas: Experience scaling big data workloads that are performant and cost-effective. Experience with Development Tools for CI/CD, Unit and Integration testing, Automation and Orchestration, REST API, BI tools and SQL Interfaces. Experience designing data solutions on cloud infrastructure and services, such as AWS, Azure, or GCP using best practises in cloud security and networking. Experience with ML concepts covering Model Tracking, Model Serving and other aspects of productionizing ML pipelines in distributed data processing environments like Apache Spark, using tools like MLflow. Degree in a quantitative discipline (Computer Science, Applied Mathematics, Operations Research) Comfortable with 20%-30% travelling Native proficiency in Mandarin and English is required Benefits Private medical, dental and optical Life, accident, disability and critical illness coverage Central Provident Fund for local nationals Equity awards Paid parental leave Gym reimbursement Annual personal development fund Work headphones reimbursement Business travel accident insurance About Databricks Databricks is the lakehouse company. More than 7,000 organizations worldwide — including Comcast, Condé Nast, H&amp;M and over 50% of the Fortune 500 — rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark™, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world’s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook. Our Commitment to Diversity and Inclusion At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics. -",https://www.jobstreet.com.sg/en/job/specialist-solutions-architect-greater-china-region-1034955688?jobId=jobstreet-sg-job-1034955688&sectionRank=307&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
307,BI Lead,Defi,"Founded in 2019, Cake DeFi is a leading decentralised finance services provider and Southeast Asia’s fastest growing fintech platform. ""We Do Crypto. You Do You."" - Our vision is to become a one-stop platform for all crypto users to get easy access to DeFi and Web3 services. To date, more than 1 million users from over 190 countries trust us to manage over $1 billion in assets. We are a profitable, cashflow positive private rocket ship that's just getting ready for take-off. Join us. ************ - Engineering Our engineering team is the backbone of everything you see at the company. We pride ourselves on writing good code. We care about good engineering practices, working with great people, and working on real and impactful products. We practice test-driven development, and are more than happy to allow team members the opportunity to solve problems with unconventional or cutting-edge methods. If you care about continually improving your craft, and want to work with like-minded peers, this is the place for you! What You’ll Do Own and drive the design of complex reporting and analytical solutions Proactively work with internal stakeholders to visualize and supply useful business data Understand and analyze business needs of Cake DeFi Improve the overall data usage proficiency of the business as a whole Develop roadmaps for optimizing BI analysis insights Designing and managing the solutions empowering end-users to be self-reliant Utilize established data warehousing practices and data visualization Work on large datasets to retrieve data and compile them into digestible and actionable dashboards for effective decision-making Automate manual reporting process by SQL/Python and continuously improve existing automated processes What You’ll Need Extensive experience working as a BI / Data Engineer for a growth-stage tech startup Cryptocurrency experience Experience working with databases, we use PostgreSQL Extensive proficiency in SQL and query optimizations Understand accounting requirements Able to read &amp; code Python We value knowledge &amp; skills over paper qualifications A good eye for detail and the ability to turn complex data into useful insights Comfortable working remotely via telecommuting. We will be working closely via Slack video calls and other collaboration tools Fluency in English is required We want to transform and decentralise finance with tomorrow’s technology. This is where you come in. Join a company that is at the forefront of bleeding-edge innovations in blockchain and DeFi. You will be empowered to push boundaries and think out of the box. You will get to work with a bunch of ridiculously motivated and talented people. And most importantly, you'll have fun. The best places to work at, are often also the most fun to work at. That's us. We hire based on merit, fit, and strong alignment to our culture. Our culture is defined by 7 team principles: Integrity, Resourcefulness, Ownership, Meritocratic Decision-making, Customer Obsession, Radical Candour, and Passion. These 7 principles guide our company, our people, and our work. At Cake DeFi, our culture is our pride. It has been instrumental to our success, so we are steadfast in our commitment to it. We welcome you to add to it. -",https://www.jobstreet.com.sg/en/job/bi-lead-1034775263?jobId=jobstreet-sg-job-1034775263&sectionRank=308&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
308,Business Intelligence Lead,CAKE PTE. LTD.,"Founded in 2019, Cake DeFi is a leading decentralised finance services provider and Southeast Asia’s fastest growing fintech platform. ""We Do Crypto. You Do You."" - Our vision is to become a one-stop platform for all crypto users to get easy access to DeFi and Web3 services. To date, more than 1 million users from over 190 countries trust us to manage over $1 billion in assets. We are a profitable, cashflow positive private rocket ship that's just getting ready for take-off. Join us. ************ - Engineering Our engineering team is the backbone of everything you see at the company. We pride ourselves on writing good code. We care about good engineering practices, working with great people, and working on real and impactful products. We practice test-driven development, and are more than happy to allow team members the opportunity to solve problems with unconventional or cutting-edge methods. If you care about continually improving your craft, and want to work with like-minded peers, this is the place for you! What You’ll Do Own and drive the design of complex reporting and analytical solutions Proactively work with internal stakeholders to visualize and supply useful business data Understand and analyze business needs of Cake DeFi Improve the overall data usage proficiency of the business as a whole Develop roadmaps for optimizing BI analysis insights Designing and managing the solutions empowering end-users to be self-reliant Utilize established data warehousing practices and data visualization Work on large datasets to retrieve data and compile them into digestible and actionable dashboards for effective decision-making Automate manual reporting process by SQL/Python and continuously improve existing automated processes What You’ll Need Extensive experience working as a BI / Data Engineer for a growth-stage tech startup Cryptocurrency experience Experience working with databases, we use PostgreSQL Extensive proficiency in SQL and query optimizations Understand accounting requirements Able to read &amp; code Python We value knowledge &amp; skills over paper qualifications A good eye for detail and the ability to turn complex data into useful insights Comfortable working remotely via telecommuting. We will be working closely via Slack video calls and other collaboration tools Fluency in English is required We want to transform and decentralise finance with tomorrow’s technology. This is where you come in. Join a company that is at the forefront of bleeding-edge innovations in blockchain and DeFi. You will be empowered to push boundaries and think out of the box. You will get to work with a bunch of ridiculously motivated and talented people. And most importantly, you'll have fun. The best places to work at, are often also the most fun to work at. That's us. We hire based on merit, fit, and strong alignment to our culture. Our culture is defined by 7 team principles: Integrity, Resourcefulness, Ownership, Meritocratic Decision-making, Customer Obsession, Radical Candour, and Passion. These 7 principles guide our company, our people, and our work. At Cake DeFi, our culture is our pride. It has been instrumental to our success, so we are steadfast in our commitment to it. We welcome you to add to it. -",https://www.jobstreet.com.sg/en/job/business-intelligence-lead-1035025813?jobId=jobstreet-sg-job-1035025813&sectionRank=309&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
309,Senior Big Data Technical Architect,VISEO ASIA PTE. LTD,"Responsibilities •Provide the architectural view of the solution and will be responsible for the technical documentations necessary for validations in the technical committees. (e.g , PPC, ARC, S-CAM, CAM) •Responsible for the TAD (Technical Architecture Document) •Responsible for ensuring the security requirements adheres to group and WM standards. •Ensure the solution is in-line with the TP2024 vision. •Provide analysis/evaluation of technical solutions recommended by the group to facilitate management decision. •Provide architectural roadmap (planning) for software/platform upgrades (due to obsolescence or for migration to the target platform). •To engage the other technical stakeholders within WM (********** ARCHITECT, Conformity Cell, Security Team, Application Integration and Production team) in the course of work. •Responsible for implementing and enforcing the WMIT Governance as the development framework to optimize IT activities &amp; processes. In so doing, to assist the organization in attaining the level of quality as determined by the IT Management. • Profile •Minimum Diploma or Bachelors in Engineering or Business •About 12+ years of Total IT experience . •Including recent 3+ yrsinto Senior Architect Role on Data Intensive Platform. •Including 5+ yrsof hands onexperience working as Technical Lead &amp;/ Senior Data Engineer • Strong Architecture &amp; Design Experience in • Data Platform - Data Lake, Data Warehouse, Data Management, BI Analytics &amp; Data Science Platform • Data Engineering Workloads - Sourcing, Ingesting, Distributed Layered Storage, History, Warehousing, Data Mart • Data Sourcing Approach - Batch, Real-time Streams, Change Data Capture, Bulk REST API • Data Modelling design covering Landing-Base-Quality-Transformed, Dimension (SCD), Facts, Star Schema • Data Storage approach covering Interim, Base, History, Archive, Formats, Schema registry, Schema Evolution • Designing Interactive, intuitive &amp; fast User Consumption &amp; Semantic layers using Data Hub &amp; BI concepts • In-Depth understanding of Low level OS/DB/Server Security plus Data Security - at rest, In Motion &amp; at use • System tool Integration experience with DataLake, DWH, DM, BI, DS Platform following enterprise guidelines • In-Depth Internal working know-how of Clustered Distributed Architecture covering Resource Management, Data Partitioning, Fault Tolerance etc. • Data Platform Management concepts - Scalability, HA, Failover, DR, monitoring, Tuning, Workload, performance, troubleshooting, release • Implementation experience overseeing setup of Platform Tools covering Security Hardening, Multi-tenant, HA, DR Cluster, HA • Deployment Architecture implementation experience in Hybrid system with mix of On-premise (VM/PM), Private - Public Cloud • Designing Data Operations workloads covering Orchestration, Containers (Kubernetes, Docker &amp; Open Shift) &amp; CI/CD Pipeline • Technical Roadmap detailing for Data Platform covering Obsolescence, Upgrades (Major / Minor), Re-Architecture, Re-Platforming • Data Project Implementation platform-tools Experience as a Technical Lead for Data Engineers •Big Data Hadoop - Hortonworks HDP 3.1.x &amp; core Components covering data engineering, management, operation stack •Big Data Hadoop - Detailed Knowledge on HDP/CDH Migration to new Cloudera CDP platformDataStorage – HDFS (File Format – Parquet, ORC, Avro, JSON), Hive (Schema, Partitioning) , Data Lake (Object Store), •Expertise in RDBM solutions (Postgres &amp; Oracle) •NoSQL(MongoDB, HBase) •Access &amp; Data Security – AD-LDAP-SAML- Kerberos-2FA IDP AuthNplus Data security through encryption, masking, filtering , anonymization •Access &amp; Data Security – Tableau (Row Level Security, Access Management), Apache Ranger (Access Policy, Masking, Audit), OS Level (RHEL &amp; Centrify) •Strong hands onexperience in Processing Framework - Spark 2.x/3.x (Core, structured API, Streaming, MLLib) •Language &amp; Package - Python (Scripting &amp; PySpark), Scala using Spark API, Unix Shell, SQL Query (basic &amp; advanced) •Data Integration tool - Informatica BDM/DEI 10.4.x, Apache Nifi(API, Kafka, JDBC based Ingestion) Data Governance - Informatica EDC, BDQ &amp; Collibra covering Data Scanner, Catalog, Lineage, relationship, Dictionary (tech-biz) •Streaming Platform – Apache Kafka, Apache Nifi, Spark Streaming, Flink, Storm •BI Analytics – Tableau Server &amp; Creator, QlikView, Power BI, BO •Advanced Analytics - RStudio, Zeppelin, Jupyter(Preferred R &amp; Python skills) •Cloud – Migration to Public-Private cloud provider like IBM, AWS •OS &amp; DB - RHEL, Centrify, Oracle, PostgreSQL, MongoDB, SQL Server •DevOps/ DataOps- Bitbucket, Jenkins, Docker, Kubernetes, AutoSys •Strong Experience in Leading &amp; guiding developers in standards process &amp; tools used in design, development, testing &amp; deployment •Has experience working in Agile delivery model with team across local-remote -",https://www.jobstreet.com.sg/en/job/senior-big-data-technical-architect-1034890261?jobId=jobstreet-sg-job-1034890261&sectionRank=310&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
310,IT Engineer x3,Recruit Haus Pte Ltd,"Data Engineer Roles and Responsibilities Senior developer and Assistant Project Manager for datawarehousing and BI projects Assist project manager in management work and guide junior developers. Responsible for technical design and systems impact analysis Provide on-going application support and be involved in various stages of the SDLC. Conduct user requirement analysis for the development / implementation of new systems and enhancements to existing systems. Evaluate potential solutions and make recommendations to resolve business problems. Involvement in the system integration testing phase prior to implementation. Plan and coordinate end-user training for any system implementations or enhancements. Liaise closely with business users and build good rapport. Liaise closely with vendors in project implementation, application testing, supporting application patches and upgrades in accordance with project methodologies and policies. Support the team in defining project requirements, tracking and documentation. Provide 24/7 primary application maintenance support. Requirements / Qualifications Has at least 3 - 4 years’ experience in Business Intelligence/Analytics projects. Has implementation involvement in at least 3 - 4 project cycles Has at least 1 - 2 years’ experience in project management Has at least 3 - 4 years’ experience in gathering and documenting business requirements from end-users Preferably with experience in healthcare industry, with broad understanding of healthcare business processes like patient administration, patient medical and non-medical services. Understanding and hands on experience in all phases of project lifecycle. Strong communication skills and end-user focused. Effective written and verbal communication skills. Team player to ensure team meets delivery targets. Has technical skills and knowledge on Business Intelligence data model design; Databases – Oracle or SQL Server; Business Intelligence software – Oracle Business Intelligence (OBIEE); Tableau; ETL software – Informatica; Oracle PL/SQL scripting or SQL scripting or UNIX scripting. Degree in Computer Science, Computer Engineering or equivalent Preferably with experience in Informatica Powercenter and\or OBIEE/Tableau. -",https://www.jobstreet.com.sg/en/job/it-engineer-x3-1034776961?jobId=jobstreet-sg-job-1034776961&sectionRank=311&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
311,Senior IT Engineer x2,Recruit Haus Pte Ltd,"Data Engineer Roles and Responsibilities Senior developer and Assistant Project Manager for datawarehousing and BI projects Assist project manager in management work and guide junior developers. Responsible for technical design and systems impact analysis Provide on-going application support and be involved in various stages of the SDLC. Conduct user requirement analysis for the development / implementation of new systems and enhancements to existing systems. Evaluate potential solutions and make recommendations to resolve business problems. Involvement in the system integration testing phase prior to implementation. Plan and coordinate end-user training for any system implementations or enhancements. Liaise closely with business users and build good rapport. Liaise closely with vendors in project implementation, application testing, supporting application patches and upgrades in accordance with project methodologies and policies. Support the team in defining project requirements, tracking and documentation. Provide 24/7 primary application maintenance support. Requirements / Qualifications Has at least 6-7 years’ experience in Business Intelligence/Analytics projects. Has implementation involvement in at least 3 - 4 project cycles Has at least 3 - 4 years’ experience in project management Has at least 5 - 7 years’ experience in gathering and documenting business requirements from end-users Preferably with experience in healthcare industry, with broad understanding of healthcare business processes like patient administration, patient medical and non-medical services. Understanding and hands on experience in all phases of project lifecycle. Strong communication skills and end-user focused. Effective written and verbal communication skills. Team player to ensure team meets delivery targets. Has technical skills and knowledge on Business Intelligence data model design; Databases – Oracle or SQL Server; Business Intelligence software – Oracle Business Intelligence (OBIEE); Tableau; ETL software – Informatica; Oracle PL/SQL scripting or SQL scripting or UNIX scripting. Degree in Computer Science, Computer Engineering or equivalent Preferably with experience in Informatica Powercenter and\or OBIEE/Tableau. -",https://www.jobstreet.com.sg/en/job/senior-it-engineer-x2-1034777084?jobId=jobstreet-sg-job-1034777084&sectionRank=312&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
312,Junior Data Engineering Consultant - Graduate Programme,Fdm Singapore Consulting Pte. Ltd.,"About The Role The demand for big data professionals has never been higher. If you’re a graduate with a strong interest in data, finding patterns in data, and are drawn to programming this could be your opportunity to embark on an exciting future as a Data Engineer. About The FDM Data Engineering Graduate Programme Over 11 weeks you will gain many advanced tools and frameworks which you will use to solve various complex data problems. You’ll receive industry relevant training in diverse languages including SQL, Hive QL, Python and Spark. And you will learn how to process massive amounts of data, create data flows, manage data lakes, design real time streaming and batch type data ingestion pipelines. Working individually and on group projects, you’ll build collaboration skills and get a feel for the real working environment. What will I be doing? Upon training completion through the awards-winning Singapore Academy, you will become an FDM Consultant and begin two years’ invaluable experience working with one or more of our global clients. This crucial role involves the design and creation of data-centric scalable solutions which are vital to helping an organisation understand their data and use it to facilitate growth. You will be involved in exciting projects, managing and processing huge datasets, and become an expert in distributed data storage and computing frameworks. What we offer you: A full-time contract with a salary from Day 1 of training Training is provided by industry experts, covering both technical and professional skills to ensure you are job-ready Ongoing career support throughout your entire FDM journey, including professional development, mentoring, and social networking events with a community of peers A chance to launch a career in one of the most in-demand tech fields Minimum Qualifications Educated to a university degree level (bachelor or higher), no STEM degree required Demonstrable interest and desire to work in technology Ability to commit to completing our full 2.5-year graduate programme Eligible to work in Singapore About FDM Our people are our passion and that's why we make your training and career growth our priority. We are a global professional services provider focusing on IT and one of the Singapore's leading graduate employers, recruiting the brightest talent to become the innovators of tomorrow. With centres across Europe, North America and Asia-Pacific, and nearly 5000 consultants currently placed on client site around the world, FDM has shown exponential growth throughout the years, firmly establishing itself as an award-winning FTSE 250 employer. Diversity and Inclusion FDM Group is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, national origin, age, disability, veteran status or any other status protected by federal, provincial or local laws -",https://www.jobstreet.com.sg/en/job/junior-data-engineering-consultant-graduate-programme-1034940394?jobId=jobstreet-sg-job-1034940394&sectionRank=313&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
313,Senior Data Architect,BNP Paribas,"In Asia Pacific, BNP Paribas is one of the best-positioned international financial institutions with an uninterrupted presence since 1860. Currently with over 18,000 employees* and a presence in 13 markets, BNP Paribas provides corporates, institutional and private investors with product and service solutions tailored to their specific needs. It offers a wide range of financial services covering corporate &amp; institutional banking, wealth management, asset management, insurance, as well as retail banking and consumer financing through strategic partnerships. Worldwide, BNP Paribas has a presence in 68 markets with more than 193,000 employees. It has key positions in its three main activities: Domestic Markets and International Financial Services (whose retail-banking networks and financial services are covered by Retail Banking &amp; Services) and Corporate &amp; Institutional Banking, which serves two client franchises: corporate clients and institutional investors. Asia Pacific is a key strategic region for BNP Paribas and it continues to develop its franchise in the region. * excluding partnerships At BNP Paribas, we passionately embrace diversity and are committed to fostering an inclusive workplace where all employees are valued, respected and can bring their authentic selves to work. We prohibit Discrimination and Harassment of any kind and our policies promote equal employment opportunity for all employees and applicants, irrespective of, but not limited to their gender, gender identity, sex, sexual orientation, ethnicity, race, colour, national origin, age, religion, social status, mental or physical disabilities, veteran status etc. As a global Bank, we truly believe that inclusion and diversity of our teams is key to our success in serving our clients and the communities we operate in. *************** Position Purpose Under the direct responsibility of Data Solutions Co-Division heads. Senior Data Architect will lead the design and build efforts of Wealth Data Transformation Program. Senior Data Architect with specific technical expertise on data platform technologies will guide/manage/lead the technical developers and ensure the development team’s adherence to technical processes and methodology. In addition will contribute to people development by mentoring, identifying the training and development plan for each developer team member. Senior Data Architect will primarily be responsible with all aspects concerning data architecture, evaluation and implementation of capabilities in the areas of data science, data management, data analytics and business intelligence in alignment with group standards and security. Responsibilities • Lead the development teams effectively to drive project objectives to completion. • Engage the development team on all technical matters (e.g. design, estimation, planning, development review of technical solution, assessment on technical impact, assessment of quality and effectiveness of the solution) • Provide the architectural view of the solution and will be responsible for the technical documentations necessary for validations in the technical committees. (e.g , PPC, ARC, S- CAM, CAM) • Responsible for the TAD (Technical Architecture Document) • Responsible for ensuring the security requirements adheres to group and WM standards. • Control and maintain the quality of the developments (norms &amp; standards, frameworks, source control, technical reviews, code reviews) • Provide analysis/evaluation of technical solutions recommended by the group to facilitate management decision. • Provide architectural roadmap (planning) for software/platform upgrades (due to obsolescence or for migration to the target platform). • To engage the other technical stakeholders within WM (e.g. DOMAIN ARCHITECT, Conformity Cell, Security Team, Application Integration and Production team) in the course of work. • Participate to recruitment, onboard and train new comers whenever necessary. Work in close collaboration with the Offshore Delivery Manager. As Senior Data Architect • About 12+ years of Total IT experience. • Including recent 3+ yrs into Senior Architect Role on Data Intensive Platform. • Including 5+ yrs of hands on experience working as Technical Lead &amp;/ Senior Data Engineer Strong Architecture &amp; Design Experience in • Data Platform - Data Lake, Data Warehouse, Data Management, BI Analytics &amp; Data Science Platform • Data Engineering Workloads - Sourcing, Ingesting, Distributed Layered Storage, History, Warehousing, Data Mart • Data Sourcing Approach - Batch, Real-time Streams, Change Data Capture, Bulk REST API • Data Modelling design covering Landing-Base-Quality-Transformed, Dimension (SCD), Facts, Star Schema • Data Storage approach covering Interim, Base, History, Archive, Formats, Schema registry, Schema Evolution • Designing Interactive, intuitive &amp; fast User Consumption &amp; Semantic layers using Data Hub &amp; BI concepts • In-Depth understanding of Low level OS/DB/Server Security plus Data Security - at rest, In Motion &amp; at use • System tool Integration experience with DataLake, DWH, DM, BI, DS Platform following enterprise guidelines • In-Depth Internal working know-how of Clustered Distributed Architecture covering Resource Management, Data Partitioning, Fault Tolerance etc. • Data Platform Management concepts - Scalability, HA, Failover, DR, monitoring, Tuning, Workload, performance, troubleshooting, release • Implementation experience overseeing setup of Platform Tools covering Security Hardening, Multi-tenant, HA, DR Cluster, HA • Deployment Architecture implementation experience in Hybrid system with mix of On-premise (VM/PM), Private - Public Cloud • Designing Data Operations workloads covering Orchestration, Containers (Kubernetes, Docker &amp; Open Shift) &amp; CI/CD Pipeline • Technical Roadmap detailing for Data Platform covering Obsolescence, Upgrades (Major / Minor), Re-Architecture, Re-Platforming Qualifications Technical &amp; Behavioral Competencies Must possess a strong background on the following technologies/skills : • Strong hands on experience in Processing Framework - Spark 2.x/3.x (Core, structured API, Streaming, MLLib) • Expertise in RDBM solutions (Postgres &amp; Oracle) and NoSQL(MongoDB, HBase) • Data Integration tool - Informatica BDM/DEI 10.4.x, Apache Nifi (API, Kafka, JDBC based Ingestion) Data Governance - Informatica EDC, BDQ &amp; Collibra covering Data Scanner, Catalog, Lineage, relationship, Dictionary (tech-biz) • Big Data Hadoop – Knowledge Hortonworks HDP 3.1.x &amp; core Components covering data engineering, management, operation stack • Big Data Hadoop - Knowledge on HDP/CDH Migration to new Cloudera CDP platformData Storage – HDFS (File Format – Parquet, ORC, Avro, JSON), Hive (Schema, Partitioning) , Data Lake (Object Store) • Access &amp; Data Security – AD-LDAP-SAML- Kerberos-2FA IDP AuthN plus Data security through encryption, masking, filtering , anonymization • Access &amp; Data Security – Tableau (Row Level Security, Access Management), Apache Ranger (Access Policy, Masking, Audit), OS Level (RHEL &amp; Centrify) • Language &amp; Package - Python (Scripting &amp; PySpark), Scala using Spark API, Unix Shell, SQL Query (basic &amp; advanced) • Streaming Platform – Apache Kafka, Apache Nifi, Spark Streaming, Flink, Storm • BI Analytics – Tableau Server &amp; Creator, Power BI, BO • Advanced Analytics - RStudio, Zeppelin, Jupyter (Preferred R &amp; Python skills) • Cloud – Migration to Public-Private cloud provider like IBM, AWS • OS &amp; DB - RHEL, Centrify, Oracle, PostgreSQL, MongoDB, SQL Server • DevOps/ DataOps - Bitbucket, Jenkins, Docker, Kubernetes, AutoSys • Strong Experience in Leading &amp; guiding developers in standards process &amp; tools used in design, development. Optional • Knowledge of Data science workloads related Statistical, machine learning, AI use cases &amp; open source library • Knowledge of Cloud Migration, Storage &amp; Services especially for IBM Private-Public cloud stack • Wealth Management Domain experience working with IT, Business, Support, Product vendor Functional &amp; Behavioral Competencies • Client focused/Critical thinker and has ability to synthesize and simplify. • Ability to anticipate business/strategic evolution • Ability to collaborate/teamwork • Must have good organization skills • On Communication, must have the following traits: 1. Good oral &amp; written skills. 2. Ability to manage/facilitate a meeting / committee • A good team player with problem-solving attitude. • Analytical and precise: Capacity to challenge the solution to propose a more efficient one. • Multi-tasking: ability to accommodate concurrent projects and is self motivated. -",https://www.jobstreet.com.sg/en/job/senior-data-architect-1034803913?jobId=jobstreet-sg-job-1034803913&sectionRank=314&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
314,Network Data Professional - Routing and Switching,KG INFORMATION SYSTEMS PTE. LTD.,"Below is the Job Description - a) Manage network infrastructure such as internet links, traffic shapers, routers, and switches b) Support in daily operations on incident management, problem(s) / issue(s) remediation, and service(s) restoration c) Fulfilling of service request(s) following the Change Management procedure. d) Track and assess all announcements and/or advisories (from device principal, IT Security Team, Government IT Security Incident Response (GITSIR) Team, etc. on patches on vulnerabilities, software bugs and firmware upgrades for network devices. e) Planning and applying of devices’ security patches and firmware upgrades in accordance with the severity. f) Preparation of monthly reports on operational issues, link performance, patch status for all DMZ network equipment. g) Create and maintain documentations of network configuration, network diagram, mapping, processes, and service records. h) Any other tasks assigned by the Institute Qualification and Skills for Network Data Engineer: i) Relevant Diploma or bachelor’s degree in Computer Engineering (or equivalent). j) Candidate must have minimum CCNP certification (routing &amp; switching). k) At least 3 years of strong experience supporting a campus network infrastructure, with in-depth hands-on experience on network devices such as Cisco Nexus switches, Catalyst switches, ASR Routers, Networking Monitoring Tools, etc. l) Knowledge on network compliance is an added advantage. m) Excellent problem-solving skills in a multi-tasking, fast-paced and complex work environment. n) Good communication skill and written skills in English, positive attitude, team player, resourceful and resolve problems independently. -",https://www.jobstreet.com.sg/en/job/network-data-professional-routing-and-switching-1034902908?jobId=jobstreet-sg-job-1034902908&sectionRank=315&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
315,Technical Architect/Tech Lead,ANTAES ASIA PTE. LTD.,"Job Description: - Contribute to IT projects in the banking industry for Antaes clients - Provide the architectural view of the solution and will be responsible for the technical documentations necessary for validations in the technical committees. (e.g , PPC, ARC, S-CAM, CAM) - Responsible for the TAD (Technical Architecture Document) - Responsible for ensuring the security requirements adheres to group and project standards. - Ensure the solution is in-line with the TP2024 vision. - Provide analysis/evaluation of technical solutions recommended by the group to facilitate management decision. - Provide architectural roadmap (planning) for software/platform upgrades (due to obsolescence or for migration to the target platform). - To engage the other technical stakeholders within project (e.g. DOMAIN ARCHITECT, Conformity Cell, Security Team, Application Integration and Production team) in the course of work. - Responsible for implementing and enforcing the project Governance as the development framework to optimize IT activities &amp; processes. In so doing, to assist the organization in attaining the level of quality as determined by the IT Management. - Contribute to the promotion of Antaes services on top of assistance provided to clients Job Requirements: - Bachelor’s Degree, with 12 years of total IT experience - 3 years as Senior Architect Role on Data Intensive Platform. - 5 years of hands on experience working as Technical Lead &amp;/ Senior Data Engineer Strong Architecture &amp; Design Experience in Data Platform - Data Lake, Data Warehouse, Data Management, BI Analytics &amp; Data Science Platform Data Engineering Workloads - Sourcing, Ingesting, Distributed Layered Storage, History, Warehousing, Data Mart Data Sourcing Approach - Batch, Real-time Streams, Change Data Capture, Bulk REST API Data Modelling design covering Landing-Base-Quality-Transformed, Dimension (SCD), Facts, Star Schema Data Storage approach covering Interim, Base, History, Archive, Formats, Schema registry, Schema Evolution Designing Interactive, intuitive &amp; fast User Consumption &amp; Semantic layers using Data Hub &amp; BI concepts In-Depth understanding of Low level OS/DB/Server Security plus Data Security - at rest, In Motion &amp; at use System tool Integration experience with DataLake, DWH, DM, BI, DS Platform following enterprise guidelines In-Depth Internal working know-how of Clustered Distributed Architecture covering Resource Management, Data Partitioning, Fault Tolerance etc. Data Platform Management concepts - Scalability, HA, Failover, DR, monitoring, Tuning, Workload, performance, troubleshooting, release Implementation experience overseeing setup of Platform Tools covering Security Hardening, Multi-tenant, HA, DR Cluster, HA Deployment Architecture implementation experience in Hybrid system with mix of On-premise (VM/PM), Private - Public Cloud Designing Data Operations workloads covering Orchestration, Containers (Kubernetes, Docker &amp; Open Shift) &amp; CI/CD Pipeline Technical Roadmap detailing for Data Platform covering Obsolescence, Upgrades (Major / Minor), Re-Architecture, Re-Platforming As Technical lead Data Project Implementation platform-tools Experience as a Technical Lead for Data Engineers Big Data Hadoop - Hortonworks HDP 3.1.x &amp; core Components covering data engineering, management, operation stack Big Data Hadoop - Detailed Knowledge on HDP/CDH Migration to new Cloudera CDP platformData Storage – HDFS (File Format – Parquet, ORC, Avro, JSON), Hive (Schema, Partitioning), Data Lake (Object Store), NoSQL (MongoDB, HBase) Access &amp; Data Security – AD-LDAP-SAML- Kerberos-2FA IDP AuthN plus Data security through encryption, masking, filtering, anonymization Access &amp; Data Security – Tableau (Row Level Security, Access Management), Apache Ranger (Access Policy, Masking, Audit), OS Level (RHEL &amp; Centrify) Strong hands on experience in Processing Framework - Spark 2.x/3.x (Core, structured API, Streaming, MLLib) Language &amp; Package - Python (Scripting &amp; PySpark), Scala using Spark API, Unix Shell, SQL Query (basic &amp; advanced) Data Integration tool - Informatica BDM/DEI 10.4.x, Apache Nifi (API, Kafka, JDBC based Ingestion) Data Governance - Informatica EDC, BDQ &amp; Collibra covering Data Scanner, Catalog, Lineage, relationship, Dictionary (tech-biz) Streaming Platform – Apache Kafka, Apache Nifi, Spark Streaming, Flink, Storm BI Analytics – Tableau Server &amp; Creator, QlikView, Power BI, BO Advanced Analytics - RStudio, Zeppelin, Jupyter (Preferred R &amp; Python skills) Cloud – Migration to Public-Private cloud provider like IBM, AWS OS &amp; DB - RHEL, Centrify, Oracle, PostgreSQL, MongoDB, SQL Server DevOps/DataOps - Bitbucket, Jenkins, Docker, Kubernetes, AutoSys Strong Experience in Leading &amp; guiding developers in standards process &amp; tools used in design, development, testing &amp; deployment -",https://www.jobstreet.com.sg/en/job/technical-architect-tech-lead-1034856296?jobId=jobstreet-sg-job-1034856296&sectionRank=316&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
316,Developer Specialist,ANTAES ASIA PTE. LTD.,"Job Summary: - The Developer Specialist is responsible for developing dashboards and reports using business intelligence (BI) visualization software, such as Microsoft Power BI and AVEVA Unified Operations Centre (UOC). - The Developer Specialist is also responsible for developing digital workflow using Company’s software, such as Novacura and AVEVA WorkTask. - Additionally, the position is responsible for developing and integrating databases with other applications related to the BI and digital workflow tasks, using Company’s software such as Microsoft SQL, Microsoft Azure and BI Gateway. Job Description: - Contribute to IT projects in the Energy/ Logistics industry for Antaes clients. - Work closely with the Digital Workflow Coordinator and other related stakeholders to develop digital workflow and BI visualizations to meet business requirements. - Planning and documenting technical specifications for the developed digital solutions and visualizations. - Developing manual and user training procedures as required for the relevant developments. - Considering user experience, improve ease of use (usability), and create the best user experience. - Implement security on data and understand application security layer models in the BI tool. - Develop DAX queries and perform calculations on the data set. - Develop tabular and multidimensional models that are compatible with data warehouse requirements. - Together with the Data Engineer, develop pipelines for data analytics, data visualization, and data modelling. - Continuously develop and maintain a good working relationship with all relevant stakeholders, internally and externally, such as the clients, internal ALM, Information Technology (IT), and other Business Units. - Monitor identified and emerging risks and suggest their prevention, mitigation, and management. - Recognize barriers within the organization and assist in developing initiatives to address these. - Being committed to, and actively involved in, pursuing the Company’s Asset Lifecycle Management program’s outcomes. - Contribute to the promotion of Antaes services on top of assistance provided to clients. Job Requirements: - Bachelor’s in computer science, computer engineering, information technology or similar disciplines. - Minimum 2-3 Years of experience working as a developer. - Proficiency in Power BI and DAX . - Good to have Proficiency in programming languages, such as JavaScript , HTML5 , Java , C++ , and Python , is desirable. - Good to have experience with object Relational Mapping (ORM) frameworks. - Good to have familiarity with Agile development techniques. - Good to have experience with AVEVA UOC , AVEVA BI Gateway and AVEVA WorkTask is an advantage. - Good to have knowledge of Microsoft Business Intelligence stacks and Microsoft Azure or other cloud applications is advantageous. - Able to build rich dashboards , write DAX expressions , and implement security. - Familiar with database management, SQL querying , data modelling , and online analytical processing . - Comfortability in designing and implementing database structures to solve real-world problems effectively. - The ability to analyse complex technical information. -",https://www.jobstreet.com.sg/en/job/developer-specialist-1034743880?jobId=jobstreet-sg-job-1034743880&sectionRank=317&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
317,"AVP, Data Analyst, Consumer Banking (CBG) Data Chapter",DBS Bank Limited,"Job description: As a specialist Big Data Analyst, you will use your expertise to ideate and enhance the customer 360 through data and analytics – a holistic customer view across behaviors, journey, and touchpoints. This role will support BAU reports &amp; data mart management related to Consumer Banking Group and support ongoing improvements and migration efforts, including developing data pipelines, script optimization, job monitoring, data migration, and documentation. Responsibilities: Design and implement the analytic data pipeline from storage layer to analytics layer. Ideate, enhance, and own reusable data marts and data assets to support product, segments, and journey analytics. Work with data engineer to enhance the analytic data infrastructure and develop enterprise analytic data mart. Perform data wrangling and feature engineering for machine learning. Automate and productionize analytic data marts via batch jobs. Ensure quality controls are in place to deliver timely and accurate outputs. Liaise with Business Analytics team, develop a good understanding of existing solutions and be able to support maintenance, bug fixing and performance analysis of data pipelines. Manage the BAU reports and data marts and continue to look for improvements in the existing data management processes. Support the ongoing data and platform migration project. Requirements: At least 7 years of experience preferably in financial institution or top tier consulting. Highly proficient with data wrangling, analytic, transformation and feature engineering using programming tools such as Spark, Python or R. Excellent knowledge of SQL. Understand business context of data Exposure to customer data, developing single customer views, designing personas and segments. Knowledge of BI tools such as QlikView, Tableau or Power BI. Understanding of Retail Banking environment. Experience in delivering complex initiatives and to engage with cross functional stakeholders. Self-starter, strong communication and presentation skills to create and deliver compelling presentations of experimentation plans and insights to teams, senior management, and stakeholders. Delivery focused personality with analytical mindset. Process management capabilities; manage, optimize, and control process. -",https://www.jobstreet.com.sg/en/job/avp-data-analyst-consumer-banking-cbg-data-chapter-1034927514?jobId=jobstreet-sg-job-1034927514&sectionRank=318&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
318,Data Analyst / Senior,Benchmark Staffing Solutions,"Our Client is a leading worldwide technology partner providing critical components for IoT intelligence, with a special focus on Telecommunication Equipment and Metal Precision, LED technologies and Interconnect solutions. Technological innovation is in the DNA of entire organization and is also the cornerstone of state-of-the-art products and quality services. Towards this, they have established the data analytics COE to fully incorporate Big Data and Artificial Intelligence into strategic roadmap and enable digital transformation and smart manufacturing initiatives. This tole as Data Analyst / Senior will enable an organization to make more informed decisions by blending various data to provide actionable insight. He/she will be part of innovation drivers to improve business process and coordinates with internal stakeholders to develop projections on implementing digital transformation strategies. Meanwhile, he/she works in a team setting and is exposed to various technologies (e.g., Big Data, advanced analytics, cybersecurity) for further career progression. They are a public listed company and operates in more than 15 countries globally with annual revenue of more than US$4 billion. Data Analyst / Senior Job Responsibilities: Identify information required for stakeholders’ decision-making and translate business requirements into analytics and reporting requirements. Recommend types of data and data sources needed to obtain the required information and insights. Identify potential business intelligence service offerings required by the business and long-term analytics strategies. Work with data engineer team to prepare the data warehouse for BI reporting and analytics consumption. Collaborate with technical and non-technical stakeholders to identify opportunities for process improvements, recommend system modifications, and develop policies for data governance. Gather data from internal and external sources as needed to build POC in timely fashion. Perform data validation, cleaning and transformation as needed to ensure data quality before data consumption. Design data reports and visualization tools to facilitate data understanding through storytelling. Plan and conduct analytics training for business adoption and data-driven culture cultivation. Perform progress check, solution review and documentation on the regular basis. Job Requirements: Degree in Computer Science, Software Engineering, Applied Math, Business, Engineering or a related discipline. At least 3 to 5 years of relevant data analyst/developer experience in analysing large dataset. Hands-on experience in using data visualization tool, e.g., Power BI, Tableau, Fanruan. Hands-on experience in various data analysis, e.g., gap analysis, root cause, regression. Strong domain knowledge and product sense to drive the analytics adoption. Good analytical and critical thinking skills – able to drive the analytics adoption. Familiar with Agile methodology to continuously review and correct the “playbook”. Experience in supply chain, operation planning and manufacturing is highly valued. Able to communicate clearly and effectively in both English and Mandarin. Software development experience (front-end or backend) is a plus. Are you ready for a challenging and exciting endeavour that will require the investment of a lot of hard work, dedication and all your experience? Are you ready to bring your skills and competencies to support the establishment and enhancement of our client’s business? If yes, you might be exactly the new team member they are looking for! Please submit your updated and comprehensive CV in MS WORD FORMAT ONLY (NOT PDF) with full career details, stating current or last drawn salary with full breakdown such as base, incentives, AWS, etc. and expected salary, contact details, educational qualifications, working experiences, reasons for leaving each past employment(s) and availability date to: ***************@gmail.com What our client offers Our client offers an attractive remuneration package, a fast-paced and exciting working environment and provide challenging opportunities for career advancement. They care about their employees. They are not just an employer. They are a Team. They do not just offer you a job, they offer you a career. By joining their team, you will find strong purpose and deep meaning in everything you do. You will have the chance to make a real difference for customers, working alongside a passionate team of like-minded colleagues, while building your knowledge/skills and developing your career in a fun, dynamic and fast-growing organization. Personal Data Protection Statement for Job Applicants Please be informed that the personal data you provided by way of your job application to Benchmark will be collected, used and disclosed by or on behalf of Benchmark to determine or investigate your suitability, eligibility or qualifications for employment with Benchmark and/or its clients and manage your application for employment with Benchmark and/or its clients including identifying you as potential candidate for future suitable positions and/or notifying you of any such positions, either existing or in the future. Thank You! We thank all applicants for their interest in a career with our client. Due to the high volume of incoming applications, we will not be able to respond to all applicants. Therefore, only shortlisted applicants will be notified for interviews. All applications will be treated with the strictest confidence. THOMAS CHAN | CEI No: R1766693 | Benchmark Staffing Solutions | EA Licence: 21C0679 | UEN: 53435609E -",https://www.jobstreet.com.sg/en/job/data-analyst-senior-1034803508?jobId=jobstreet-sg-job-1034803508&sectionRank=319&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
319,Consultant,Infosys Consulting Pte. Ltd.,"Infosys Consulting is a global management consulting firm helping some of the world’s most recognizable brands transform and innovate. Our consultants are industry experts that lead complex change agendas driven by disruptive technology. With offices in 20 countries and backed by the power of the global Infosys brand, our teams help the C-suite navigate today’s digital landscape to win market share and create shareholder value for lasting competitive advantage. To see our ideas in action, or to join a new type of consulting firm, visit us at *************** Title: Consultant (Data) Summary: Infosys Consulting is looking for a highly skilled data engineer with 2-5 years of experience in data processing using ETL tools like Informatica, Python or similar. The ideal candidate should be a great communicator and have a strong background in data analytics patterns. The successful candidate will be responsible for designing and developing ML-based algorithms in Python and have good knowledge of CI-CD with DevOps. Key Responsibilities: · Design and develop ETL workflows to move data from various sources into the organization's data warehouse. · Develop and implement data quality controls and monitor data accuracy. · Design and develop ML-based algorithms in Python to automate and optimize data processing. · Work closely with cross-functional teams to ensure data solutions meet business requirements. · Develop and maintain data processing and automation scripts using Python. · Create data visualizations and provide insights to the data analytics team. · Design and implement data security and access controls. · Develop and maintain data pipelines and ETL workflows for various data sources. Qualifications: · Bachelor's degree in Computer Science, Information Systems, or related field. · 2-5 years of experience in data processing and ETL using SQL, Informatica, AWS Glue , Airflow, Python, or similar tools. · Experience with CI-CD with DevOps. · Experience in designing and developing ML-based algorithms in Python. · Strong knowledge of data analytics patterns and data processing techniques. · Good communication and interpersonal skills to effectively communicate with cross-functional teams. · Excellent problem-solving skills and the ability to work independently or as part of a team. · Knowledge of data security and access control. If you have a passion for data engineering and are looking for a challenging opportunity, we would love to hear from you. This is a great opportunity for someone who is looking to grow their skills and work with a dynamic team in a fast-paced environment. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion, or belief. We make recruiting decisions based on your experience, skills and personality. We believe that employing a diverse workforce is the right thing to do and is central to our success. We offer you great opportunities within a dynamically growing consultancy. You will elaborate and deliver best practice solutions and will be able to further develop your solution design, implementation, and project management skills. At Infosys Consulting you will discover a truly global culture, highly dedicated and motivated colleagues, a co-operative work environment and interesting training opportunities. -",https://www.jobstreet.com.sg/en/job/consultant-1034941294?jobId=jobstreet-sg-job-1034941294&sectionRank=320&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
320,Data Architect/Technical Architect,Infrasoft Technologies Pte Ltd,"Purpose Under the direct responsibility of the Division managers for Data Solutions. The Technical Architect cum Tech Lead will add to the needed capacity of the team to fulfil the demands expressed by Wealth Management Business to implement the road map of TP2024. Will primarily be responsible with all aspects concerning the platform architecture. Including alignment with group standards and security. Providing analysis (pros/cons) of different solutions and recommendation. In addition, guide/manage/lead the technical developers. Direct Responsibilities Provide the architectural view of the solution and will be responsible for the technical documentation necessary for validations in the technical committees. (e.g., PPC, ARC, S-CAM, CAM) Responsible for the TAD (Technical Architecture Document) Responsible for ensuring the security requirements adheres to group and WM standards. Ensure the solution is in-line with the TP2024 vision. Provide analysis/evaluation of technical solutions recommended by the group to facilitate management decision. Provide architectural roadmap (planning) for software/platform upgrades (due to obsolescence or for migration to the target platform). To engage the other technical stakeholders within WM (e.g., DOMAIN ARCHITECT, Conformity Cell, Security Team, Application Integration and Production team) in the course of work. Responsible for implementing and enforcing the WMIT Governance as the development framework to optimize IT activities &amp; processes. In so doing, to assist the organization in attaining the level of quality as determined by the IT Management. Technical and Behavioral Competencies required. As Technical Architect About 12+ years of Total IT experience. Including recent 3+ years into Senior Architect Role on Data Intensive Platform. Including 5+ years of hands-on experience working as Technical Lead &amp;/ Senior Data Engineer Strong Architecture &amp; Design Experience in Data Platform - Data Lake, Data Warehouse, Data Management, BI Analytics &amp; Data Science Platform Data Engineering Workloads - Sourcing, Ingesting, Distributed Layered Storage, History, Warehousing, Data Mart Data Sourcing Approach - Batch, Real-time Streams, Change Data Capture, Bulk REST API Data Modelling design covering Landing-Base-Quality-Transformed, Dimension (SCD), Facts, Star Schema Data Storage approach covering Interim, Base, History, Archive, Formats, Schema registry, Schema Evolution Designing Interactive, intuitive &amp; fast User Consumption &amp; Semantic layers using Data Hub &amp; BI concepts In-Depth understanding of Low level OS/DB/Server Security plus Data Security - at rest, In Motion &amp; at use System tool Integration experience with Data Lake, DWH, DM, BI, DS Platform following enterprise guidelines. In-Depth Internal working know-how of Clustered Distributed Architecture covering Resource Management, Data Partitioning, Fault Tolerance etc. Data Platform Management concepts - Scalability, HA, Failover, DR, monitoring, Tuning, Workload, performance, troubleshooting, release Implementation experience overseeing setup of Platform Tools covering Security Hardening, Multi-tenant, HA, DR Cluster, HA Deployment Architecture implementation experience in Hybrid system with mix of On-premises (VM/PM), Private - Public Cloud Designing Data Operations workloads covering Orchestration, Containers (Kubernetes, Docker &amp; Open Shift) &amp; CI/CD Pipeline Technical Roadmap detailing for Data Platform covering Obsolescence, Upgrades (Major / Minor), Re-Architecture, Re-Platforming As Technical lead Data Project Implementation platform-tools Experience as a Technical Lead for Data Engineers Big Data Hadoop - Hortonworks HDP 3.1.x &amp; core Components covering data engineering, management, operation stack. Big Data Hadoop - Detailed Knowledge on HDP/CDH Migration to new Cloudera CDP platform Data Storage – HDFS (File Format – Parquet, ORC, Avro, JSON), Hive (Schema, Partitioning) , Data Lake (Object Store), NoSQL(MongoDB, HBase) Access &amp; Data Security – AD-LDAP-SAML- Kerberos-2FA IDP AuthN plus Data security through encryption, masking, filtering , anonymization Access &amp; Data Security – Tableau (Row Level Security, Access Management), Apache Ranger (Access Policy, Masking, Audit), OS Level (RHEL &amp; Centrify) Strong hands on experience in Processing Framework - Spark 2.x/3.x (Core, structured API, Streaming, MLLib) Language &amp; Package - Python (Scripting &amp; PySpark), Scala using Spark API, Unix Shell, SQL Query (basic &amp; advanced) Data Integration tool - Informatica BDM/DEI 10.4.x, Apache Nifi (API, Kafka, JDBC based Ingestion) Data Governance - Informatica EDC, BDQ &amp; Collibra covering Data Scanner, Catalog, Lineage, relationship, Dictionary (tech-biz) Streaming Platform – Apache Kafka, Apache Nifi, Spark Streaming, Flink, Storm BI Analytics – Tableau Server &amp; Creator, QlikView, Power BI, BO Advanced Analytics - RStudio, Zeppelin, Jupyter (Preferred R &amp; Python skills) Cloud – Migration to Public-Private cloud provider like IBM, AWS OS &amp; DB - RHEL, Centrify, Oracle, PostgreSQL, MongoDB, SQL Server DevOps/ DataOps - Bitbucket, Jenkins, Docker, Kubernetes, AutoSys Strong Experience in Leading &amp; guiding developers in standards process &amp; tools used in design, development, testing &amp; deployment Has experience working in Agile delivery model with team across local-remote. -",https://www.jobstreet.com.sg/en/job/data-architect-technical-architect-1034941045?jobId=jobstreet-sg-job-1034941045&sectionRank=321&token=0~21fe4105-4a4c-46c4-b283-7190702afa3b&fr=SRP%20Job%20Listing
